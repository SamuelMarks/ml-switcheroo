"""
LaTeX DSL Framework Adapter.

This module registers `latex_dsl` as a valid framework in the `ml-switcheroo` ecosystem.
It enables the conversion of Neural Network architectures to and from the Machine
Intelligence Definition Language (MIDL) LaTeX format.

It acts as a facade:
-   **Output**: Delegates to `LatexEmitter` to generate .tex from Python AST.
-   **Input**: Delegates to `LatexParser` to generate mapped Python AST from .tex files,
    using the virtual `midl` namespace for semantic resolution.
"""

from typing import Dict, Any, List, Set, Tuple, Optional

from ml_switcheroo.frameworks.base import (
  register_framework,
  FrameworkAdapter,
  StandardMap,
  StandardCategory,
  GhostRef,
  ImportConfig,
  InitMode,
)
from ml_switcheroo.semantics.schema import StructuralTraits, PluginTraits, OpDefinition
from ml_switcheroo.enums import SemanticTier
from ml_switcheroo.core.latex.emitter import LatexEmitter
from ml_switcheroo.core.latex.parser import LatexParser


@register_framework("latex_dsl")
class LatexDSLAdapter(FrameworkAdapter):
  """
  Adapter for the LaTeX Machine Intelligence Definition Language (MIDL).

  When used as a **Target**:
      The `ASTEngine` detects the `latex_dsl` key and routes the Python AST
      to the `LatexEmitter` instead of the standard Python rewriter.

  When used as a **Source**:
      The `ASTEngine` uses the `LatexParser` to ingest the .tex file into
      a standard Python AST (LibCST) wrapped in the `midl` namespace.
      This adapter defines the semantic mappings to translation `midl.*` calls
      into Abstract Operations.
  """

  display_name: str = "LaTeX DSL (MIDL)"
  ui_priority: int = 950  # Place near end vertically
  inherits_from: Optional[str] = None

  def __init__(self) -> None:
    """Initialize the adapter in GHOST mode (no live python module)."""
    self._mode = InitMode.GHOST
    self._snapshot_data: Dict[str, Any] = {}

  @property
  def search_modules(self) -> List[str]:
    """No Python modules to scan for LaTeX."""
    return []

  @property
  def unsafe_submodules(self) -> Set[str]:
    """No submodules."""
    return set()

  @property
  def import_alias(self) -> Tuple[str, str]:
    """
    Virtual import alias matching the parser output.
    The LatexParser emits `import midl`.
    """
    return ("midl", "midl")

  @property
  def import_namespaces(self) -> Dict[str, ImportConfig]:
    """
    Declare the virtual 'midl' namespace as containing Neural definitions.
    """
    return {"midl": ImportConfig(tier=SemanticTier.NEURAL, recommended_alias="midl")}

  @property
  def discovery_heuristics(self) -> Dict[str, List[str]]:
    """No heuristics."""
    return {}

  @property
  def supported_tiers(self) -> List[SemanticTier]:
    """Supports Neural layer definitions primarily."""
    return [SemanticTier.NEURAL]

  @property
  def structural_traits(self) -> StructuralTraits:
    """
    Defines behavior when converting TO Python FROM LaTeX.
    We map the specific `midl.Module` base class generated by the Parser.
    """
    return StructuralTraits(
      module_base="midl.Module",
      forward_method="forward",
      init_method_name="__init__",
      requires_super_init=True,
    )

  @property
  def plugin_traits(self) -> PluginTraits:
    """Default capabilities."""
    return PluginTraits()

  @property
  def test_config(self) -> Dict[str, str]:
    """No unit tests can be generated for LaTeX output."""
    return {}

  @property
  def harness_imports(self) -> List[str]:
    """No harness imports."""
    return []

  def get_harness_init_code(self) -> str:
    """No init code."""
    return ""

  @property
  def declared_magic_args(self) -> List[str]:
    """No magic args."""
    return []

  @property
  def rng_seed_methods(self) -> List[str]:
    """No RNG."""
    return []

  @property
  def definitions(self) -> Dict[str, StandardMap]:
    """
    Semantic mappings for the virtual `midl` namespace.

    These definitions map the positional arguments generated by
    the LaTeX parser (e.g. `arg_0`, `arg_1`) back to semantic
    argument names (e.g. `in_channels`, `out_channels`).
    """
    return {
      "Module": StandardMap(api="midl.Module"),
      "Conv2d": StandardMap(
        api="midl.Conv2d",
        args={
          # Map Semantic Name -> Framework Name (Parser output, or LaTeX keyword)
          "in_channels": "arg_0",
          "out_channels": "arg_1",
          "kernel_size": "arg_2",
          "stride": "arg_3",
          "padding": "arg_4",
        },
      ),
      "Linear": StandardMap(
        api="midl.Linear",
        args={
          "in_features": "arg_0",
          "out_features": "arg_1",
          "bias": "arg_2",
        },
      ),
      "Flatten": StandardMap(
        api="midl.Flatten",
        args={
          "start_dim": "arg_0",
          "end_dim": "arg_1",
        },
      ),
      # Map "midl.ReLU" (Class, from \Attribute) to abstract "ReLU"
      "ReLU": StandardMap(api="midl.ReLU"),
      # Map "midl.relu" (Functional, from \Op{...}{relu}) to abstract "relu"
      # Note key must align with standards_internal 'relu' (lowercase)
      "relu": StandardMap(api="midl.relu"),
      # Additional entries to satisfy tests
      "Dropout": StandardMap(
        api="midl.Dropout",
        args={"p": "p"},  # Map 'p' to 'p' if used as kwarg in latex
      ),
    }

  @property
  def specifications(self) -> Dict[str, OpDefinition]:
    """No spec definitions."""
    return {}

  def collect_api(self, category: StandardCategory) -> List[GhostRef]:
    """No API to collect."""
    return []

  def convert(self, data: Any) -> Any:
    """Identity conversion."""
    return str(data)

  def get_device_syntax(self, device_type: str, device_index: Optional[str] = None) -> str:
    """No device logic."""
    return ""

  def get_device_check_syntax(self) -> str:
    """No device checks."""
    return "False"

  def get_rng_split_syntax(self, rng_var: str, key_var: str) -> str:
    """No RNG."""
    return ""

  def get_serialization_imports(self) -> List[str]:
    """No serialization."""
    return []

  def get_serialization_syntax(self, op: str, file_arg: str, object_arg: Optional[str] = None) -> str:
    """No serialization."""
    return ""

  def apply_wiring(self, snapshot: Dict[str, Any]) -> None:
    """No manual wiring."""
    pass

  @classmethod
  def get_example_code(cls) -> str:
    """Returns valid MIDL sample."""
    return r"""
\begin{DefModel}{ConvNet}
    \Attribute{conv}{Conv2d}{k=3}
    \Input{x}{_}
    \StateOp{y}{conv}{x}{_}
    \Return{y}
\end{DefModel}
"""

  def get_tiered_examples(self) -> Dict[str, str]:
    """Returns tiered examples."""
    code = self.get_example_code()
    return {
      "tier2_neural": code,
    }

  # --- Custom Engine Hooks (Duck Typing) ---
  # These methods are detected by the ASTEngine during initialization
  # to swap out the standard Parser/Rewriter pipeline.

  def create_parser(self, code: str):
    """Factory for the ingest parser."""
    return LatexParser(code)

  def create_emitter(self):
    """Factory for the output generator."""
    return LatexEmitter()  # src/ml_switcheroo/frameworks/latex_dsl.py


"""
LaTeX DSL Framework Adapter.

This module registers `latex_dsl` as a valid framework in the `ml-switcheroo` ecosystem.
It enables the conversion of Neural Network architectures to and from the Machine
Intelligence Definition Language (MIDL) LaTeX format.

It acts as a facade:
-   **Output**: Delegates to `LatexEmitter` to generate .tex from Python AST.
-   **Input**: Delegates to `LatexParser` to generate mapped Python AST from .tex files,
    using the virtual `midl` namespace for semantic resolution.
"""

from typing import Dict, Any, List, Set, Tuple, Optional

from ml_switcheroo.frameworks.base import (
  register_framework,
  FrameworkAdapter,
  StandardMap,
  StandardCategory,
  GhostRef,
  ImportConfig,
  InitMode,
)
from ml_switcheroo.semantics.schema import StructuralTraits, PluginTraits, OpDefinition
from ml_switcheroo.enums import SemanticTier
from ml_switcheroo.core.latex.emitter import LatexEmitter
from ml_switcheroo.core.latex.parser import LatexParser


@register_framework("latex_dsl")
class LatexDSLAdapter(FrameworkAdapter):
  """
  Adapter for the LaTeX Machine Intelligence Definition Language (MIDL).

  When used as a **Target**:
      The `ASTEngine` detects the `latex_dsl` key and routes the Python AST
      to the `LatexEmitter` instead of the standard Python rewriter.

  When used as a **Source**:
      The `ASTEngine` uses the `LatexParser` to ingest the .tex file into
      a standard Python AST (LibCST) wrapped in the `midl` namespace.
      This adapter defines the semantic mappings to translation `midl.*` calls
      into Abstract Operations.
  """

  display_name: str = "LaTeX DSL (MIDL)"
  ui_priority: int = 950  # Place near end vertically
  inherits_from: Optional[str] = None

  def __init__(self) -> None:
    """Initialize the adapter in GHOST mode (no live python module)."""
    self._mode = InitMode.GHOST
    self._snapshot_data: Dict[str, Any] = {}

  @property
  def search_modules(self) -> List[str]:
    """No Python modules to scan for LaTeX."""
    return []

  @property
  def unsafe_submodules(self) -> Set[str]:
    """No submodules."""
    return set()

  @property
  def import_alias(self) -> Tuple[str, str]:
    """
    Virtual import alias matching the parser output.
    The LatexParser emits `import midl`.
    """
    return ("midl", "midl")

  @property
  def import_namespaces(self) -> Dict[str, ImportConfig]:
    """
    Declare the virtual 'midl' namespace as containing Neural definitions.
    """
    return {"midl": ImportConfig(tier=SemanticTier.NEURAL, recommended_alias="midl")}

  @property
  def discovery_heuristics(self) -> Dict[str, List[str]]:
    """No heuristics."""
    return {}

  @property
  def supported_tiers(self) -> List[SemanticTier]:
    """Supports Neural layer definitions primarily."""
    return [SemanticTier.NEURAL]

  @property
  def structural_traits(self) -> StructuralTraits:
    """
    Defines behavior when converting TO Python FROM LaTeX.
    We map the specific `midl.Module` base class generated by the Parser.
    """
    return StructuralTraits(
      module_base="midl.Module",
      forward_method="forward",
      init_method_name="__init__",
      requires_super_init=True,
    )

  @property
  def plugin_traits(self) -> PluginTraits:
    """Default capabilities."""
    return PluginTraits()

  @property
  def test_config(self) -> Dict[str, str]:
    """No unit tests can be generated for LaTeX output."""
    return {}

  @property
  def harness_imports(self) -> List[str]:
    """No harness imports."""
    return []

  def get_harness_init_code(self) -> str:
    """No init code."""
    return ""

  @property
  def declared_magic_args(self) -> List[str]:
    """No magic args."""
    return []

  @property
  def rng_seed_methods(self) -> List[str]:
    """No RNG."""
    return []

  @property
  def definitions(self) -> Dict[str, StandardMap]:
    """
    Semantic mappings for the virtual `midl` namespace.

    These definitions map the positional arguments generated by
    the LaTeX parser (e.g. `arg_0`, `arg_1`) back to semantic
    argument names (e.g. `in_channels`, `out_channels`).
    """
    return {
      "Module": StandardMap(api="midl.Module"),
      "Conv2d": StandardMap(
        api="midl.Conv2d",
        args={
          # Map Semantic Name -> Framework Name (Parser output, or LaTeX keyword)
          "in_channels": "arg_0",
          "out_channels": "arg_1",
          "kernel_size": "arg_2",
          "stride": "arg_3",
          "padding": "arg_4",
        },
      ),
      "Linear": StandardMap(
        api="midl.Linear",
        args={
          "in_features": "arg_0",
          "out_features": "arg_1",
          "bias": "arg_2",
        },
      ),
      "Flatten": StandardMap(
        api="midl.Flatten",
        args={
          "start_dim": "arg_0",
          "end_dim": "arg_1",
        },
      ),
      # Map "midl.ReLU" (Class, from \Attribute) to abstract "ReLU"
      "ReLU": StandardMap(api="midl.ReLU"),
      # Map "midl.relu" (Functional, from \Op{...}{relu}) to abstract "relu"
      # Note key must align with standards_internal 'relu' (lowercase)
      "relu": StandardMap(api="midl.relu"),
      # Additional entries to satisfy tests
      "Dropout": StandardMap(
        api="midl.Dropout",
        args={"p": "p"},  # Map 'p' to 'p' if used as kwarg in latex
      ),
    }

  @property
  def specifications(self) -> Dict[str, OpDefinition]:
    """No spec definitions."""
    return {}

  def collect_api(self, category: StandardCategory) -> List[GhostRef]:
    """No API to collect."""
    return []

  def convert(self, data: Any) -> Any:
    """Identity conversion."""
    return str(data)

  def get_device_syntax(self, device_type: str, device_index: Optional[str] = None) -> str:
    """No device logic."""
    return ""

  def get_device_check_syntax(self) -> str:
    """No device checks."""
    return "False"

  def get_rng_split_syntax(self, rng_var: str, key_var: str) -> str:
    """No RNG."""
    return ""

  def get_serialization_imports(self) -> List[str]:
    """No serialization."""
    return []

  def get_serialization_syntax(self, op: str, file_arg: str, object_arg: Optional[str] = None) -> str:
    """No serialization."""
    return ""

  def apply_wiring(self, snapshot: Dict[str, Any]) -> None:
    """No manual wiring."""
    pass

  @classmethod
  def get_example_code(cls) -> str:
    """Returns valid MIDL sample."""
    return r"""
\begin{DefModel}{ConvNet}
    \Attribute{conv}{Conv2d}{k=3}
    \Input{x}{_}
    \StateOp{y}{conv}{x}{_}
    \Return{y}
\end{DefModel}
"""

  def get_tiered_examples(self) -> Dict[str, str]:
    """Returns tiered examples."""
    code = self.get_example_code()
    return {
      "tier2_neural": code,
    }

  # --- Custom Engine Hooks (Duck Typing) ---
  # These methods are detected by the ASTEngine during initialization
  # to swap out the standard Parser/Rewriter pipeline.

  def create_parser(self, code: str):
    """Factory for the ingest parser."""
    return LatexParser(code)

  def create_emitter(self):
    """Factory for the output generator."""
    return LatexEmitter()
