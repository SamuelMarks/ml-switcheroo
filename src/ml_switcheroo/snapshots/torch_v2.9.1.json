{
  "version": "2.9.1",
  "categories": {
    "loss": [
      {
        "name": "AdaptiveLogSoftmaxWithLoss",
        "api_path": "torch.nn.AdaptiveLogSoftmaxWithLoss",
        "kind": "class",
        "params": [
          {
            "name": "in_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "n_classes",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "cutoffs",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Sequence"
          },
          {
            "name": "div_value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "4.0",
            "annotation": "float"
          },
          {
            "name": "head_bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Efficient softmax approximation.\n\nAs described in\n`Efficient softmax approximation for GPUs by Edouard Grave, Armand Joulin,\nMoustapha Ciss\u00e9, David Grangier, and Herv\u00e9 J\u00e9gou\n<https://arxiv.org/abs/1609.04309>`__.\n\nAdaptive softmax is an approximate strategy for training models with large\noutput spaces. It is most effective when the label distribution is highly\nimbalanced, for example in natural language modelling, where the word\nfrequency distribution approximately follows the `Zipf's law`_.\n\nAdaptive softmax partitions the labels into several clusters, according to\ntheir frequency. These clusters may contain different number of targets\neach.\nAdditionally, clusters containing less frequent labels assign lower\ndimensional embeddings to those labels, which speeds up the computation.\nFor each minibatch, only clusters for which at least one target is\npresent are evaluated.\n\nThe idea is that the clusters which are accessed frequently\n(like the first one, containing most frequent labels), should also be cheap\nto compute -- that is, contain a small number of assigned labels.\n\nWe highly recommend taking a look at the original paper for more details.\n\n* :attr:`cutoffs` should be an ordered Sequence of integers sorted\n  in the increasing order.\n  It controls number of clusters and the partitioning of targets into\n  clusters. For example setting ``cutoffs = [10, 100, 1000]``\n  means that first `10` targets will be assigned\n  to the 'head' of the adaptive softmax, targets `11, 12, ..., 100` will be\n  assigned to the first cluster, and targets `101, 102, ..., 1000` will be\n  assigned to the second cluster, while targets\n  `1001, 1002, ..., n_classes - 1` will be assigned\n  to the last, third cluster.\n\n* :attr:`div_value` is used to compute the size of each additional cluster,\n  which is given as\n  :math:`\\left\\lfloor\\frac{\\texttt{in\\_features}}{\\texttt{div\\_value}^{idx}}\\right\\rfloor`,\n  where :math:`idx` is the cluster index (with clusters\n  for less frequent words having larger indices,\n  and indices starting from :math:`1`).\n\n* :attr:`head_bias` if set to True, adds a bias term to the 'head' of the\n  adaptive softmax. See paper for details. Set to False in the official\n  implementation.\n\n.. warning::\n    Labels passed as inputs to this module should be sorted according to\n    their frequency. This means that the most frequent label should be\n    represented by the index `0`, and the least frequent\n    label should be represented by the index `n_classes - 1`.\n\n.. note::\n    This module returns a ``NamedTuple`` with ``output``\n    and ``loss`` fields. See further documentation for details.\n\n.. note::\n    To compute log-probabilities for all classes, the ``log_prob``\n    method can be used.\n\nArgs:\n    in_features (int): Number of features in the input tensor\n    n_classes (int): Number of classes in the dataset\n    cutoffs (Sequence): Cutoffs used to assign targets to their buckets\n    div_value (float, optional): value used as an exponent to compute sizes\n        of the clusters. Default: 4.0\n    head_bias (bool, optional): If ``True``, adds a bias term to the 'head' of the\n        adaptive softmax. Default: ``False``\n\nReturns:\n    ``NamedTuple`` with ``output`` and ``loss`` fields:\n        * **output** is a Tensor of size ``N`` containing computed target\n          log probabilities for each example\n        * **loss** is a Scalar representing the computed negative\n          log likelihood loss\n\nShape:\n    - input: :math:`(N, \\texttt{in\\_features})` or :math:`(\\texttt{in\\_features})`\n    - target: :math:`(N)` or :math:`()` where each value satisfies :math:`0 <= \\texttt{target[i]} <= \\texttt{n\\_classes}`\n    - output1: :math:`(N)` or :math:`()`\n    - output2: ``Scalar``\n\n.. _Zipf's law: https://en.wikipedia.org/wiki/Zipf%27s_law",
        "has_varargs": false
      },
      {
        "name": "BCELoss",
        "api_path": "torch.nn.BCELoss",
        "kind": "class",
        "params": [
          {
            "name": "weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that measures the Binary Cross Entropy between the target and\nthe input probabilities:\n\nThe unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n\n.. math::\n    \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n    l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n\nwhere :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n(default ``'mean'``), then\n\n.. math::\n    \\ell(x, y) = \\begin{cases}\n        \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n        \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\nThis is used for measuring the error of a reconstruction in for example\nan auto-encoder. Note that the targets :math:`y` should be numbers\nbetween 0 and 1.\n\nNotice that if :math:`x_n` is either 0 or 1, one of the log terms would be\nmathematically undefined in the above loss equation. PyTorch chooses to set\n:math:`\\log (0) = -\\infty`, since :math:`\\lim_{x\\to 0} \\log (x) = -\\infty`.\nHowever, an infinite term in the loss equation is not desirable for several reasons.\n\nFor one, if either :math:`y_n = 0` or :math:`(1 - y_n) = 0`, then we would be\nmultiplying 0 with infinity. Secondly, if we have an infinite loss value, then\nwe would also have an infinite term in our gradient, since\n:math:`\\lim_{x\\to 0} \\frac{d}{dx} \\log (x) = \\infty`.\nThis would make BCELoss's backward method nonlinear with respect to :math:`x_n`,\nand using it for things like linear regression would not be straight-forward.\n\nOur solution is that BCELoss clamps its log function outputs to be greater than\nor equal to -100. This way, we can always have a finite loss value and a linear\nbackward method.\n\n\nArgs:\n    weight (Tensor, optional): a manual rescaling weight given to the loss\n        of each batch element. If given, has to be a Tensor of size `nbatch`.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n      shape as input.\n\nExamples:\n\n    >>> m = nn.Sigmoid()\n    >>> loss = nn.BCELoss()\n    >>> input = torch.randn(3, 2, requires_grad=True)\n    >>> target = torch.rand(3, 2, requires_grad=False)\n    >>> output = loss(m(input), target)\n    >>> output.backward()",
        "has_varargs": false
      },
      {
        "name": "BCEWithLogitsLoss",
        "api_path": "torch.nn.BCEWithLogitsLoss",
        "kind": "class",
        "params": [
          {
            "name": "weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          },
          {
            "name": "pos_weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "This loss combines a `Sigmoid` layer and the `BCELoss` in one single\nclass. This version is more numerically stable than using a plain `Sigmoid`\nfollowed by a `BCELoss` as, by combining the operations into one layer,\nwe take advantage of the log-sum-exp trick for numerical stability.\n\nThe unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n\n.. math::\n    \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n    l_n = - w_n \\left[ y_n \\cdot \\log \\sigma(x_n)\n    + (1 - y_n) \\cdot \\log (1 - \\sigma(x_n)) \\right],\n\nwhere :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n(default ``'mean'``), then\n\n.. math::\n    \\ell(x, y) = \\begin{cases}\n        \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n        \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\nThis is used for measuring the error of a reconstruction in for example\nan auto-encoder. Note that the targets `t[i]` should be numbers\nbetween 0 and 1.\n\nIt's possible to trade off recall and precision by adding weights to positive examples.\nIn the case of multi-label classification the loss can be described as:\n\n.. math::\n    \\ell_c(x, y) = L_c = \\{l_{1,c},\\dots,l_{N,c}\\}^\\top, \\quad\n    l_{n,c} = - w_{n,c} \\left[ p_c y_{n,c} \\cdot \\log \\sigma(x_{n,c})\n    + (1 - y_{n,c}) \\cdot \\log (1 - \\sigma(x_{n,c})) \\right],\n\nwhere :math:`c` is the class number (:math:`c > 1` for multi-label binary classification,\n:math:`c = 1` for single-label binary classification),\n:math:`n` is the number of the sample in the batch and\n:math:`p_c` is the weight of the positive answer for the class :math:`c`.\n\n:math:`p_c > 1` increases the recall, :math:`p_c < 1` increases the precision.\n\nFor example, if a dataset contains 100 positive and 300 negative examples of a single class,\nthen ``pos_weight`` for the class should be equal to :math:`\\frac{300}{100}=3`.\nThe loss would act as if the dataset contains :math:`3\\times 100=300` positive examples.\n\nExamples:\n\n    >>> target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\n    >>> output = torch.full([10, 64], 1.5)  # A prediction (logit)\n    >>> pos_weight = torch.ones([64])  # All weights are equal to 1\n    >>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n    >>> criterion(output, target)  # -log(sigmoid(1.5))\n    tensor(0.20...)\n\nIn the above example, the ``pos_weight`` tensor's elements correspond to the 64 distinct classes\nin a multi-label binary classification scenario. Each element in ``pos_weight`` is designed to adjust the\nloss function based on the imbalance between negative and positive samples for the respective class.\nThis approach is useful in datasets with varying levels of class imbalance, ensuring that the loss\ncalculation accurately accounts for the distribution in each class.\n\nArgs:\n    weight (Tensor, optional): a manual rescaling weight given to the loss\n        of each batch element. If given, has to be a Tensor of size `nbatch`.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n    pos_weight (Tensor, optional): a weight of positive examples to be broadcasted with target.\n        Must be a tensor with equal size along the class dimension to the number of classes.\n        Pay close attention to PyTorch's broadcasting semantics in order to achieve the desired\n        operations. For a target of size [B, C, H, W] (where B is batch size) pos_weight of\n        size [B, C, H, W] will apply different pos_weights to each element of the batch or\n        [C, H, W] the same pos_weights across the batch. To apply the same positive weight\n        along all spatial dimensions for a 2D multi-class target [C, H, W] use: [C, 1, 1].\n        Default: ``None``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n      shape as input.\n\nExamples:\n\n    >>> loss = nn.BCEWithLogitsLoss()\n    >>> input = torch.randn(3, requires_grad=True)\n    >>> target = torch.empty(3).random_(2)\n    >>> output = loss(input, target)\n    >>> output.backward()",
        "has_varargs": false
      },
      {
        "name": "CTCLoss",
        "api_path": "torch.nn.CTCLoss",
        "kind": "class",
        "params": [
          {
            "name": "blank",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "int"
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          },
          {
            "name": "zero_infinity",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "The Connectionist Temporal Classification loss.\n\nCalculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the\nprobability of possible alignments of input to target, producing a loss value which is differentiable\nwith respect to each input node. The alignment of input to target is assumed to be \"many-to-one\", which\nlimits the length of the target sequence such that it must be :math:`\\leq` the input length.\n\nArgs:\n    blank (int, optional): blank label. Default :math:`0`.\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the output losses will be divided by the target lengths and\n        then the mean over the batch is taken, ``'sum'``: the output losses will be summed.\n        Default: ``'mean'``\n    zero_infinity (bool, optional):\n        Whether to zero infinite losses and the associated gradients.\n        Default: ``False``\n        Infinite losses mainly occur when the inputs are too short\n        to be aligned to the targets.\n\nShape:\n    - Log_probs: Tensor of size :math:`(T, N, C)` or :math:`(T, C)`,\n      where :math:`T = \\text{input length}`,\n      :math:`N = \\text{batch size}`, and\n      :math:`C = \\text{number of classes (including blank)}`.\n      The logarithmized probabilities of the outputs (e.g. obtained with\n      :func:`torch.nn.functional.log_softmax`).\n    - Targets: Tensor of size :math:`(N, S)` or\n      :math:`(\\operatorname{sum}(\\text{target\\_lengths}))`,\n      where :math:`N = \\text{batch size}` and\n      :math:`S = \\text{max target length, if shape is } (N, S)`.\n      It represents the target sequences. Each element in the target\n      sequence is a class index. And the target index cannot be blank (default=0).\n      In the :math:`(N, S)` form, targets are padded to the\n      length of the longest sequence, and stacked.\n      In the :math:`(\\operatorname{sum}(\\text{target\\_lengths}))` form,\n      the targets are assumed to be un-padded and\n      concatenated within 1 dimension.\n    - Input_lengths: Tuple or tensor of size :math:`(N)` or :math:`()`,\n      where :math:`N = \\text{batch size}`. It represents the lengths of the\n      inputs (must each be :math:`\\leq T`). And the lengths are specified\n      for each sequence to achieve masking under the assumption that sequences\n      are padded to equal lengths.\n    - Target_lengths: Tuple or tensor of size :math:`(N)` or :math:`()`,\n      where :math:`N = \\text{batch size}`. It represents lengths of the targets.\n      Lengths are specified for each sequence to achieve masking under the\n      assumption that sequences are padded to equal lengths. If target shape is\n      :math:`(N,S)`, target_lengths are effectively the stop index\n      :math:`s_n` for each target sequence, such that ``target_n = targets[n,0:s_n]`` for\n      each target in a batch. Lengths must each be :math:`\\leq S`\n      If the targets are given as a 1d tensor that is the concatenation of individual\n      targets, the target_lengths must add up to the total length of the tensor.\n    - Output: scalar if :attr:`reduction` is ``'mean'`` (default) or\n      ``'sum'``. If :attr:`reduction` is ``'none'``, then :math:`(N)` if input is batched or\n      :math:`()` if input is unbatched, where :math:`N = \\text{batch size}`.\n\nExamples:\n\n    >>> # Target are to be padded\n    >>> T = 50  # Input sequence length\n    >>> C = 20  # Number of classes (including blank)\n    >>> N = 16  # Batch size\n    >>> S = 30  # Target sequence length of longest target in batch (padding length)\n    >>> S_min = 10  # Minimum target length, for demonstration purposes\n    >>>\n    >>> # Initialize random batch of input vectors, for *size = (T,N,C)\n    >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n    >>>\n    >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n    >>> target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n    >>>\n    >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n    >>> target_lengths = torch.randint(\n    ...     low=S_min,\n    ...     high=S,\n    ...     size=(N,),\n    ...     dtype=torch.long,\n    ... )\n    >>> ctc_loss = nn.CTCLoss()\n    >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n    >>> loss.backward()\n    >>>\n    >>>\n    >>> # Target are to be un-padded\n    >>> T = 50  # Input sequence length\n    >>> C = 20  # Number of classes (including blank)\n    >>> N = 16  # Batch size\n    >>>\n    >>> # Initialize random batch of input vectors, for *size = (T,N,C)\n    >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n    >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n    >>>\n    >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n    >>> target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)\n    >>> target = torch.randint(\n    ...     low=1,\n    ...     high=C,\n    ...     size=(sum(target_lengths),),\n    ...     dtype=torch.long,\n    ... )\n    >>> ctc_loss = nn.CTCLoss()\n    >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n    >>> loss.backward()\n    >>>\n    >>>\n    >>> # Target are to be un-padded and unbatched (effectively N=1)\n    >>> T = 50  # Input sequence length\n    >>> C = 20  # Number of classes (including blank)\n    >>>\n    >>> # Initialize random batch of input vectors, for *size = (T,C)\n    >>> # xdoctest: +SKIP(\"FIXME: error in doctest\")\n    >>> input = torch.randn(T, C).log_softmax(1).detach().requires_grad_()\n    >>> input_lengths = torch.tensor(T, dtype=torch.long)\n    >>>\n    >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n    >>> target_lengths = torch.randint(low=1, high=T, size=(), dtype=torch.long)\n    >>> target = torch.randint(\n    ...     low=1,\n    ...     high=C,\n    ...     size=(target_lengths,),\n    ...     dtype=torch.long,\n    ... )\n    >>> ctc_loss = nn.CTCLoss()\n    >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n    >>> loss.backward()\n\nReference:\n    A. Graves et al.: Connectionist Temporal Classification:\n    Labelling Unsegmented Sequence Data with Recurrent Neural Networks:\n    https://www.cs.toronto.edu/~graves/icml_2006.pdf\n\nNote:\n    In order to use CuDNN, the following must be satisfied: :attr:`targets` must be\n    in concatenated format, all :attr:`input_lengths` must be `T`.  :math:`blank=0`,\n    :attr:`target_lengths` :math:`\\leq 256`, the integer arguments must be of\n    dtype :attr:`torch.int32`.\n\n    The regular implementation uses the (more common in PyTorch) `torch.long` dtype.\n\n\nNote:\n    In some circumstances when using the CUDA backend with CuDNN, this operator\n    may select a nondeterministic algorithm to increase performance. If this is\n    undesirable, you can try to make the operation deterministic (potentially at\n    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n    True``.\n    Please see the notes on :doc:`/notes/randomness` for background.",
        "has_varargs": false
      },
      {
        "name": "CosineEmbeddingLoss",
        "api_path": "torch.nn.CosineEmbeddingLoss",
        "kind": "class",
        "params": [
          {
            "name": "margin",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0",
            "annotation": "float"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that measures the loss given input tensors\n:math:`x_1`, :math:`x_2` and a `Tensor` label :math:`y` with values 1 or -1.\nUse (:math:`y=1`) to maximize the cosine similarity of two inputs, and (:math:`y=-1`) otherwise.\nThis is typically used for learning nonlinear\nembeddings or semi-supervised learning.\n\nThe loss function for each sample is:\n\n.. math::\n    \\text{loss}(x, y) =\n    \\begin{cases}\n    1 - \\cos(x_1, x_2), & \\text{if } y = 1 \\\\\n    \\max(0, \\cos(x_1, x_2) - \\text{margin}), & \\text{if } y = -1\n    \\end{cases}\n\nArgs:\n    margin (float, optional): Should be a number from :math:`-1` to :math:`1`,\n        :math:`0` to :math:`0.5` is suggested. If :attr:`margin` is missing, the\n        default value is :math:`0`.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input1: :math:`(N, D)` or :math:`(D)`, where `N` is the batch size and `D` is the embedding dimension.\n    - Input2: :math:`(N, D)` or :math:`(D)`, same shape as Input1.\n    - Target: :math:`(N)` or :math:`()`.\n    - Output: If :attr:`reduction` is ``'none'``, then :math:`(N)`, otherwise scalar.\n\nExamples:\n\n    >>> loss = nn.CosineEmbeddingLoss()\n    >>> input1 = torch.randn(3, 5, requires_grad=True)\n    >>> input2 = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.ones(3)\n    >>> output = loss(input1, input2, target)\n    >>> output.backward()",
        "has_varargs": false
      },
      {
        "name": "CrossEntropyLoss",
        "api_path": "torch.nn.CrossEntropyLoss",
        "kind": "class",
        "params": [
          {
            "name": "weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "ignore_index",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-100",
            "annotation": "int"
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          },
          {
            "name": "label_smoothing",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0",
            "annotation": "float"
          }
        ],
        "docstring": "This criterion computes the cross entropy loss between input logits\nand target.\n\nIt is useful when training a classification problem with `C` classes.\nIf provided, the optional argument :attr:`weight` should be a 1D `Tensor`\nassigning weight to each of the classes.\nThis is particularly useful when you have an unbalanced training set.\n\nThe `input` is expected to contain the unnormalized logits for each class (which do `not` need\nto be positive or sum to 1, in general).\n`input` has to be a Tensor of size :math:`(C)` for unbatched input,\n:math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` for the\n`K`-dimensional case. The last being useful for higher dimension inputs, such\nas computing cross entropy loss per-pixel for 2D images.\n\nThe `target` that this criterion expects should contain either:\n\n- Class indices in the range :math:`[0, C)` where :math:`C` is the number of classes; if\n  `ignore_index` is specified, this loss also accepts this class index (this index\n  may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`\n  set to ``'none'``) loss for this case can be described as:\n\n  .. math::\n      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n      l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n      \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n\n  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n\n  .. math::\n      \\ell(x, y) = \\begin{cases}\n          \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, &\n           \\text{if reduction} = \\text{`mean';}\\\\\n            \\sum_{n=1}^N l_n,  &\n            \\text{if reduction} = \\text{`sum'.}\n        \\end{cases}\n\n  Note that this case is equivalent to applying :class:`~torch.nn.LogSoftmax`\n  on an input, followed by :class:`~torch.nn.NLLLoss`.\n\n- Probabilities for each class; useful when labels beyond a single class per minibatch item\n  are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\n  :attr:`reduction` set to ``'none'``) loss for this case can be described as:\n\n  .. math::\n      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n      l_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\sum_{i=1}^C \\exp(x_{n,i})} y_{n,c}\n\n  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n\n  .. math::\n      \\ell(x, y) = \\begin{cases}\n          \\frac{\\sum_{n=1}^N l_n}{N}, &\n           \\text{if reduction} = \\text{`mean';}\\\\\n            \\sum_{n=1}^N l_n,  &\n            \\text{if reduction} = \\text{`sum'.}\n        \\end{cases}\n\n.. note::\n    The performance of this criterion is generally better when `target` contains class\n    indices, as this allows for optimized computation. Consider providing `target` as\n    class probabilities only when a single class label per minibatch item is too restrictive.\n\nArgs:\n    weight (Tensor, optional): a manual rescaling weight given to each class.\n        If given, has to be a Tensor of size `C`.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    ignore_index (int, optional): Specifies a target value that is ignored\n        and does not contribute to the input gradient. When :attr:`size_average` is\n        ``True``, the loss is averaged over non-ignored targets. Note that\n        :attr:`ignore_index` is only applicable when the target contains class indices.\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n        be applied, ``'mean'``: the weighted mean of the output is taken,\n        ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in\n        the meantime, specifying either of those two args will override\n        :attr:`reduction`. Default: ``'mean'``\n    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n        become a mixture of the original ground truth and a uniform distribution as described in\n        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n\nShape:\n    - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n      in the case of `K`-dimensional loss.\n    - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with\n      :math:`K \\geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`. The\n      target data type is required to be long when using class indices. If containing class probabilities, the\n      target must be the same shape input, and each value should be between :math:`[0, 1]`. This means the target\n      data type is required to be float when using class probabilities. Note that PyTorch does not strictly enforce\n      probability constraints on the class probabilities and that it is the user's responsibility to ensure\n      ``target`` contains valid probability distributions (see below examples section for more details).\n    - Output: If reduction is 'none', shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n      in the case of K-dimensional loss, depending on the shape of the input. Otherwise, scalar.\n\n\n    where:\n\n    .. math::\n        \\begin{aligned}\n            C ={} & \\text{number of classes} \\\\\n            N ={} & \\text{batch size} \\\\\n        \\end{aligned}\n\nExamples:\n\n    >>> # Example of target with class indices\n    >>> loss = nn.CrossEntropyLoss()\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.empty(3, dtype=torch.long).random_(5)\n    >>> output = loss(input, target)\n    >>> output.backward()\n    >>>\n    >>> # Example of target with class probabilities\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.randn(3, 5).softmax(dim=1)\n    >>> output = loss(input, target)\n    >>> output.backward()\n\n.. note::\n    When ``target`` contains class probabilities, it should consist of soft labels\u2014that is,\n    each ``target`` entry should represent a probability distribution over the possible classes for a given data sample,\n    with individual probabilities between ``[0,1]`` and the total distribution summing to 1.\n    This is why the :func:`softmax()` function is applied to the ``target`` in the class probabilities example above.\n\n    PyTorch does not validate whether the values provided in ``target`` lie in the range ``[0,1]``\n    or whether the distribution of each data sample sums to ``1``.\n    No warning will be raised and it is the user's responsibility\n    to ensure that ``target`` contains valid probability distributions.\n    Providing arbitrary values may yield misleading loss values and unstable gradients during training.\n\nExamples:\n    >>> # xdoctest: +SKIP\n    >>> # Example of target with incorrectly specified class probabilities\n    >>> loss = nn.CrossEntropyLoss()\n    >>> torch.manual_seed(283)\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.randn(3, 5)\n    >>> # Provided target class probabilities are not in range [0,1]\n    >>> target\n    tensor([[ 0.7105,  0.4446,  2.0297,  0.2671, -0.6075],\n            [-1.0496, -0.2753, -0.3586,  0.9270,  1.0027],\n            [ 0.7551,  0.1003,  1.3468, -0.3581, -0.9569]])\n    >>> # Provided target class probabilities do not sum to 1\n    >>> target.sum(axis=1)\n    tensor([2.8444, 0.2462, 0.8873])\n    >>> # No error message and possible misleading loss value\n    >>> loss(input, target).item()\n    4.6379876136779785\n    >>>\n    >>> # Example of target with correctly specified class probabilities\n    >>> # Use .softmax() to ensure true probability distribution\n    >>> target_new = target.softmax(dim=1)\n    >>> # New target class probabilities all in range [0,1]\n    >>> target_new\n    tensor([[0.1559, 0.1195, 0.5830, 0.1000, 0.0417],\n            [0.0496, 0.1075, 0.0990, 0.3579, 0.3860],\n            [0.2607, 0.1355, 0.4711, 0.0856, 0.0471]])\n    >>> # New target class probabilities sum to 1\n    >>> target_new.sum(axis=1)\n    tensor([1.0000, 1.0000, 1.0000])\n    >>> loss(input, target_new).item()\n    2.55349063873291",
        "has_varargs": false
      },
      {
        "name": "GaussianNLLLoss",
        "api_path": "torch.nn.GaussianNLLLoss",
        "kind": "class",
        "params": [
          {
            "name": "full",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "eps",
            "kind": "KEYWORD_ONLY",
            "default": "1e-06",
            "annotation": "float"
          },
          {
            "name": "reduction",
            "kind": "KEYWORD_ONLY",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Gaussian negative log likelihood loss.\n\nThe targets are treated as samples from Gaussian distributions with\nexpectations and variances predicted by the neural network. For a\n``target`` tensor modelled as having Gaussian distribution with a tensor\nof expectations ``input`` and a tensor of positive variances ``var`` the loss is:\n\n.. math::\n    \\text{loss} = \\frac{1}{2}\\left(\\log\\left(\\text{max}\\left(\\text{var},\n    \\ \\text{eps}\\right)\\right) + \\frac{\\left(\\text{input} - \\text{target}\\right)^2}\n    {\\text{max}\\left(\\text{var}, \\ \\text{eps}\\right)}\\right) + \\text{const.}\n\nwhere :attr:`eps` is used for stability. By default, the constant term of\nthe loss function is omitted unless :attr:`full` is ``True``. If ``var`` is not the same\nsize as ``input`` (due to a homoscedastic assumption), it must either have a final dimension\nof 1 or have one fewer dimension (with all other sizes being the same) for correct broadcasting.\n\nArgs:\n    full (bool, optional): include the constant term in the loss\n        calculation. Default: ``False``.\n    eps (float, optional): value used to clamp ``var`` (see note below), for\n        stability. Default: 1e-6.\n    reduction (str, optional): specifies the reduction to apply to the\n        output:``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction\n        will be applied, ``'mean'``: the output is the average of all batch\n        member losses, ``'sum'``: the output is the sum of all batch member\n        losses. Default: ``'mean'``.\n\nShape:\n    - Input: :math:`(N, *)` or :math:`(*)` where :math:`*` means any number of additional\n      dimensions\n    - Target: :math:`(N, *)` or :math:`(*)`, same shape as the input, or same shape as the input\n      but with one dimension equal to 1 (to allow for broadcasting)\n    - Var: :math:`(N, *)` or :math:`(*)`, same shape as the input, or same shape as the input but\n      with one dimension equal to 1, or same shape as the input but with one fewer\n      dimension (to allow for broadcasting), or a scalar value\n    - Output: scalar if :attr:`reduction` is ``'mean'`` (default) or\n      ``'sum'``. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same\n      shape as the input\n\nExamples:\n    >>> loss = nn.GaussianNLLLoss()\n    >>> input = torch.randn(5, 2, requires_grad=True)\n    >>> target = torch.randn(5, 2)\n    >>> var = torch.ones(5, 2, requires_grad=True)  # heteroscedastic\n    >>> output = loss(input, target, var)\n    >>> output.backward()\n\n    >>> loss = nn.GaussianNLLLoss()\n    >>> input = torch.randn(5, 2, requires_grad=True)\n    >>> target = torch.randn(5, 2)\n    >>> var = torch.ones(5, 1, requires_grad=True)  # homoscedastic\n    >>> output = loss(input, target, var)\n    >>> output.backward()\n\nNote:\n    The clamping of ``var`` is ignored with respect to autograd, and so the\n    gradients are unaffected by it.\n\nReference:\n    Nix, D. A. and Weigend, A. S., \"Estimating the mean and variance of the\n    target probability distribution\", Proceedings of 1994 IEEE International\n    Conference on Neural Networks (ICNN'94), Orlando, FL, USA, 1994, pp. 55-60\n    vol.1, doi: 10.1109/ICNN.1994.374138.",
        "has_varargs": false
      },
      {
        "name": "HingeEmbeddingLoss",
        "api_path": "torch.nn.HingeEmbeddingLoss",
        "kind": "class",
        "params": [
          {
            "name": "margin",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Measures the loss given an input tensor :math:`x` and a labels tensor :math:`y`\n(containing 1 or -1).\nThis is usually used for measuring whether two inputs are similar or\ndissimilar, e.g. using the L1 pairwise distance as :math:`x`, and is typically\nused for learning nonlinear embeddings or semi-supervised learning.\n\nThe loss function for :math:`n`-th sample in the mini-batch is\n\n.. math::\n    l_n = \\begin{cases}\n        x_n, & \\text{if}\\; y_n = 1,\\\\\n        \\max \\{0, margin - x_n\\}, & \\text{if}\\; y_n = -1,\n    \\end{cases}\n\nand the total loss functions is\n\n.. math::\n    \\ell(x, y) = \\begin{cases}\n        \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n        \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\nwhere :math:`L = \\{l_1,\\dots,l_N\\}^\\top`.\n\nArgs:\n    margin (float, optional): Has a default value of `1`.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(*)` where :math:`*` means, any number of dimensions. The sum operation\n      operates over all the elements.\n    - Target: :math:`(*)`, same shape as the input\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then same shape as the input",
        "has_varargs": false
      },
      {
        "name": "HuberLoss",
        "api_path": "torch.nn.HuberLoss",
        "kind": "class",
        "params": [
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          },
          {
            "name": "delta",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          }
        ],
        "docstring": "Creates a criterion that uses a squared term if the absolute\nelement-wise error falls below delta and a delta-scaled L1 term otherwise.\nThis loss combines advantages of both :class:`L1Loss` and :class:`MSELoss`; the\ndelta-scaled L1 region makes the loss less sensitive to outliers than :class:`MSELoss`,\nwhile the L2 region provides smoothness over :class:`L1Loss` near 0. See\n`Huber loss <https://en.wikipedia.org/wiki/Huber_loss>`_ for more information.\n\nFor a batch of size :math:`N`, the unreduced loss can be described as:\n\n.. math::\n    \\ell(x, y) = L = \\{l_1, ..., l_N\\}^T\n\nwith\n\n.. math::\n    l_n = \\begin{cases}\n    0.5 (x_n - y_n)^2, & \\text{if } |x_n - y_n| < delta \\\\\n    delta * (|x_n - y_n| - 0.5 * delta), & \\text{otherwise }\n    \\end{cases}\n\nIf `reduction` is not `none`, then:\n\n.. math::\n    \\ell(x, y) =\n    \\begin{cases}\n        \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n        \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\n.. note::\n    When delta is set to 1, this loss is equivalent to :class:`SmoothL1Loss`.\n    In general, this loss differs from :class:`SmoothL1Loss` by a factor of delta (AKA beta\n    in Smooth L1).\n    See :class:`SmoothL1Loss` for additional discussion on the differences in behavior\n    between the two losses.\n\nArgs:\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Default: ``'mean'``\n    delta (float, optional): Specifies the threshold at which to change between delta-scaled L1 and L2 loss.\n        The value must be positive.  Default: 1.0\n\nShape:\n    - Input: :math:`(*)` where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same shape as the input.",
        "has_varargs": false
      },
      {
        "name": "KLDivLoss",
        "api_path": "torch.nn.KLDivLoss",
        "kind": "class",
        "params": [
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          },
          {
            "name": "log_target",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "The Kullback-Leibler divergence loss.\n\nFor tensors of the same shape :math:`y_{\\text{pred}},\\ y_{\\text{true}}`,\nwhere :math:`y_{\\text{pred}}` is the :attr:`input` and :math:`y_{\\text{true}}` is the\n:attr:`target`, we define the **pointwise KL-divergence** as\n\n.. math::\n\n    L(y_{\\text{pred}},\\ y_{\\text{true}})\n        = y_{\\text{true}} \\cdot \\log \\frac{y_{\\text{true}}}{y_{\\text{pred}}}\n        = y_{\\text{true}} \\cdot (\\log y_{\\text{true}} - \\log y_{\\text{pred}})\n\nTo avoid underflow issues when computing this quantity, this loss expects the argument\n:attr:`input` in the log-space. The argument :attr:`target` may also be provided in the\nlog-space if :attr:`log_target`\\ `= True`.\n\nTo summarise, this function is roughly equivalent to computing\n\n.. code-block:: python\n\n    if not log_target:  # default\n        loss_pointwise = target * (target.log() - input)\n    else:\n        loss_pointwise = target.exp() * (target - input)\n\nand then reducing this result depending on the argument :attr:`reduction` as\n\n.. code-block:: python\n\n    if reduction == \"mean\":  # default\n        loss = loss_pointwise.mean()\n    elif reduction == \"batchmean\":  # mathematically correct\n        loss = loss_pointwise.sum() / input.size(0)\n    elif reduction == \"sum\":\n        loss = loss_pointwise.sum()\n    else:  # reduction == \"none\"\n        loss = loss_pointwise\n\n.. note::\n    As all the other losses in PyTorch, this function expects the first argument,\n    :attr:`input`, to be the output of the model (e.g. the neural network)\n    and the second, :attr:`target`, to be the observations in the dataset.\n    This differs from the standard mathematical notation :math:`KL(P\\ ||\\ Q)` where\n    :math:`P` denotes the distribution of the observations and :math:`Q` denotes the model.\n\n.. warning::\n    :attr:`reduction`\\ `= \"mean\"` doesn't return the true KL divergence value, please use\n    :attr:`reduction`\\ `= \"batchmean\"` which aligns with the mathematical definition.\n\nArgs:\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to `False`, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is `False`. Default: `True`\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is `False`, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: `True`\n    reduction (str, optional): Specifies the reduction to apply to the output. Default: `\"mean\"`\n    log_target (bool, optional): Specifies whether `target` is the log space. Default: `False`\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n    - Output: scalar by default. If :attr:`reduction` is `'none'`, then :math:`(*)`,\n      same shape as the input.\n\nExamples:\n    >>> kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n    >>> # input should be a distribution in the log space\n    >>> input = F.log_softmax(torch.randn(3, 5, requires_grad=True), dim=1)\n    >>> # Sample a batch of distributions. Usually this would come from the dataset\n    >>> target = F.softmax(torch.rand(3, 5), dim=1)\n    >>> output = kl_loss(input, target)\n    >>>\n    >>> kl_loss = nn.KLDivLoss(reduction=\"batchmean\", log_target=True)\n    >>> log_target = F.log_softmax(torch.rand(3, 5), dim=1)\n    >>> output = kl_loss(input, log_target)",
        "has_varargs": false
      },
      {
        "name": "L1Loss",
        "api_path": "torch.nn.L1Loss",
        "kind": "class",
        "params": [
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that measures the mean absolute error (MAE) between each element in\nthe input :math:`x` and target :math:`y`.\n\nThe unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n\n.. math::\n    \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n    l_n = \\left| x_n - y_n \\right|,\n\nwhere :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n(default ``'mean'``), then:\n\n.. math::\n    \\ell(x, y) =\n    \\begin{cases}\n        \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n        \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\n:math:`x` and :math:`y` are tensors of arbitrary shapes with a total\nof :math:`N` elements each.\n\nThe sum operation still operates over all the elements, and divides by :math:`N`.\n\nThe division by :math:`N` can be avoided if one sets ``reduction = 'sum'``.\n\nSupports real-valued and complex-valued inputs.\n\nArgs:\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then\n      :math:`(*)`, same shape as the input.\n\nExamples:\n\n    >>> loss = nn.L1Loss()\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.randn(3, 5)\n    >>> output = loss(input, target)\n    >>> output.backward()",
        "has_varargs": false
      },
      {
        "name": "MSELoss",
        "api_path": "torch.nn.MSELoss",
        "kind": "class",
        "params": [
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that measures the mean squared error (squared L2 norm) between\neach element in the input :math:`x` and target :math:`y`.\n\nThe unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n\n.. math::\n    \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n    l_n = \\left( x_n - y_n \\right)^2,\n\nwhere :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n(default ``'mean'``), then:\n\n.. math::\n    \\ell(x, y) =\n    \\begin{cases}\n        \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n        \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\n:math:`x` and :math:`y` are tensors of arbitrary shapes with a total\nof :math:`N` elements each.\n\nThe mean operation still operates over all the elements, and divides by :math:`N`.\n\nThe division by :math:`N` can be avoided if one sets ``reduction = 'sum'``.\n\nArgs:\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n\nExamples:\n\n    >>> loss = nn.MSELoss()\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.randn(3, 5)\n    >>> output = loss(input, target)\n    >>> output.backward()",
        "has_varargs": false
      },
      {
        "name": "MarginRankingLoss",
        "api_path": "torch.nn.MarginRankingLoss",
        "kind": "class",
        "params": [
          {
            "name": "margin",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0",
            "annotation": "float"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that measures the loss given\ninputs :math:`x1`, :math:`x2`, two 1D mini-batch or 0D `Tensors`,\nand a label 1D mini-batch or 0D `Tensor` :math:`y` (containing 1 or -1).\n\nIf :math:`y = 1` then it assumed the first input should be ranked higher\n(have a larger value) than the second input, and vice-versa for :math:`y = -1`.\n\nThe loss function for each pair of samples in the mini-batch is:\n\n.. math::\n    \\text{loss}(x1, x2, y) = \\max(0, -y * (x1 - x2) + \\text{margin})\n\nArgs:\n    margin (float, optional): Has a default value of :math:`0`.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input1: :math:`(N)` or :math:`()` where `N` is the batch size.\n    - Input2: :math:`(N)` or :math:`()`, same shape as the Input1.\n    - Target: :math:`(N)` or :math:`()`, same shape as the inputs.\n    - Output: scalar. If :attr:`reduction` is ``'none'`` and Input size is not :math:`()`, then :math:`(N)`.\n\nExamples:\n\n    >>> loss = nn.MarginRankingLoss()\n    >>> input1 = torch.randn(3, requires_grad=True)\n    >>> input2 = torch.randn(3, requires_grad=True)\n    >>> target = torch.randn(3).sign()\n    >>> output = loss(input1, input2, target)\n    >>> output.backward()",
        "has_varargs": false
      },
      {
        "name": "MultiLabelMarginLoss",
        "api_path": "torch.nn.MultiLabelMarginLoss",
        "kind": "class",
        "params": [
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that optimizes a multi-class multi-classification\nhinge loss (margin-based loss) between input :math:`x` (a 2D mini-batch `Tensor`)\nand output :math:`y` (which is a 2D `Tensor` of target class indices).\nFor each sample in the mini-batch:\n\n.. math::\n    \\text{loss}(x, y) = \\sum_{ij}\\frac{\\max(0, 1 - (x[y[j]] - x[i]))}{\\text{x.size}(0)}\n\nwhere :math:`x \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}`, \\\n:math:`y \\in \\left\\{0, \\; \\cdots , \\; \\text{y.size}(0) - 1\\right\\}`, \\\n:math:`0 \\leq y[j] \\leq \\text{x.size}(0)-1`, \\\nand :math:`i \\neq y[j]` for all :math:`i` and :math:`j`.\n\n:math:`y` and :math:`x` must have the same size.\n\nThe criterion only considers a contiguous block of non-negative targets that\nstarts at the front.\n\nThis allows for different samples to have variable amounts of target classes.\n\nArgs:\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(C)` or :math:`(N, C)` where `N` is the batch size and `C`\n      is the number of classes.\n    - Target: :math:`(C)` or :math:`(N, C)`, label targets padded by -1 ensuring same shape as the input.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.\n\nExamples:\n\n    >>> loss = nn.MultiLabelMarginLoss()\n    >>> x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])\n    >>> # for target y, only consider labels 3 and 0, not after label -1\n    >>> y = torch.LongTensor([[3, 0, -1, 1]])\n    >>> # 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n    >>> loss(x, y)\n    tensor(0.85...)",
        "has_varargs": false
      },
      {
        "name": "MultiLabelSoftMarginLoss",
        "api_path": "torch.nn.MultiLabelSoftMarginLoss",
        "kind": "class",
        "params": [
          {
            "name": "weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that optimizes a multi-label one-versus-all\nloss based on max-entropy, between input :math:`x` and target :math:`y` of size\n:math:`(N, C)`.\nFor each sample in the minibatch:\n\n.. math::\n    loss(x, y) = - \\frac{1}{C} * \\sum_i y[i] * \\log((1 + \\exp(-x[i]))^{-1})\n                     + (1-y[i]) * \\log\\left(\\frac{\\exp(-x[i])}{(1 + \\exp(-x[i]))}\\right)\n\nwhere :math:`i \\in \\left\\{0, \\; \\cdots , \\; \\text{x.nElement}() - 1\\right\\}`,\n:math:`y[i] \\in \\left\\{0, \\; 1\\right\\}`.\n\nArgs:\n    weight (Tensor, optional): a manual rescaling weight given to each\n        class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n        treated as if having all ones.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(N, C)` where `N` is the batch size and `C` is the number of classes.\n    - Target: :math:`(N, C)`, label targets must have the same shape as the input.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.",
        "has_varargs": false
      },
      {
        "name": "MultiMarginLoss",
        "api_path": "torch.nn.MultiMarginLoss",
        "kind": "class",
        "params": [
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "margin",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that optimizes a multi-class classification hinge\nloss (margin-based loss) between input :math:`x` (a 2D mini-batch `Tensor`) and\noutput :math:`y` (which is a 1D tensor of target class indices,\n:math:`0 \\leq y \\leq \\text{x.size}(1)-1`):\n\nFor each mini-batch sample, the loss in terms of the 1D input :math:`x` and scalar\noutput :math:`y` is:\n\n.. math::\n    \\text{loss}(x, y) = \\frac{\\sum_i \\max(0, \\text{margin} - x[y] + x[i])^p}{\\text{x.size}(0)}\n\nwhere :math:`i \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}`\nand :math:`i \\neq y`.\n\nOptionally, you can give non-equal weighting on the classes by passing\na 1D :attr:`weight` tensor into the constructor.\n\nThe loss function then becomes:\n\n.. math::\n    \\text{loss}(x, y) = \\frac{\\sum_i w[y] * \\max(0, \\text{margin} - x[y] + x[i])^p}{\\text{x.size}(0)}\n\nArgs:\n    p (int, optional): Has a default value of :math:`1`. :math:`1` and :math:`2`\n        are the only supported values.\n    margin (float, optional): Has a default value of :math:`1`.\n    weight (Tensor, optional): a manual rescaling weight given to each\n        class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n        treated as if having all ones.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(N, C)` or :math:`(C)`, where :math:`N` is the batch size and :math:`C` is the number of classes.\n    - Target: :math:`(N)` or :math:`()`, where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then same shape as the target.\n\nExamples:\n\n    >>> loss = nn.MultiMarginLoss()\n    >>> x = torch.tensor([[0.1, 0.2, 0.4, 0.8]])\n    >>> y = torch.tensor([3])\n    >>> # 0.25 * ((1-(0.8-0.1)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n    >>> loss(x, y)\n    tensor(0.32...)",
        "has_varargs": false
      },
      {
        "name": "NLLLoss",
        "api_path": "torch.nn.NLLLoss",
        "kind": "class",
        "params": [
          {
            "name": "weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "ignore_index",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-100",
            "annotation": "int"
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "The negative log likelihood loss. It is useful to train a classification\nproblem with `C` classes.\n\nIf provided, the optional argument :attr:`weight` should be a 1D Tensor assigning\nweight to each of the classes. This is particularly useful when you have an\nunbalanced training set.\n\nThe `input` given through a forward call is expected to contain\nlog-probabilities of each class. `input` has to be a Tensor of size either\n:math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)`\nwith :math:`K \\geq 1` for the `K`-dimensional case. The latter is useful for\nhigher dimension inputs, such as computing NLL loss per-pixel for 2D images.\n\nObtaining log-probabilities in a neural network is easily achieved by\nadding a  `LogSoftmax`  layer in the last layer of your network.\nYou may use `CrossEntropyLoss` instead, if you prefer not to add an extra\nlayer.\n\nThe `target` that this loss expects should be a class index in the range :math:`[0, C-1]`\nwhere `C = number of classes`; if `ignore_index` is specified, this loss also accepts\nthis class index (this index may not necessarily be in the class range).\n\nThe unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n\n.. math::\n    \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\\\\n    l_n = - w_{y_n} x_{n,y_n}, \\\\\n    w_{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\},\n\nwhere :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight, and\n:math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n(default ``'mean'``), then\n\n.. math::\n    \\ell(x, y) = \\begin{cases}\n        \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n}} l_n, &\n        \\text{if reduction} = \\text{`mean';}\\\\\n        \\sum_{n=1}^N l_n,  &\n        \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\nArgs:\n    weight (Tensor, optional): a manual rescaling weight given to each\n        class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n        treated as if having all ones.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``None``\n    ignore_index (int, optional): Specifies a target value that is ignored\n        and does not contribute to the input gradient. When\n        :attr:`size_average` is ``True``, the loss is averaged over\n        non-ignored targets.\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``None``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n        be applied, ``'mean'``: the weighted mean of the output is taken,\n        ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in\n        the meantime, specifying either of those two args will override\n        :attr:`reduction`. Default: ``'mean'``\n\nShape::\n    - Input: :math:`(N, C)` or :math:`(C)`, where `C = number of classes`, `N = batch size`, or\n      :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n      in the case of `K`-dimensional loss.\n    - Target: :math:`(N)` or :math:`()`, where each value is\n      :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or\n      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of\n      K-dimensional loss.\n    - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or\n      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of K-dimensional loss.\n      Otherwise, scalar.\n\nExamples:\n\n    >>> log_softmax = nn.LogSoftmax(dim=1)\n    >>> loss_fn = nn.NLLLoss()\n    >>> # input to NLLLoss is of size N x C = 3 x 5\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> # each element in target must have 0 <= value < C\n    >>> target = torch.tensor([1, 0, 4])\n    >>> loss = loss_fn(log_softmax(input), target)\n    >>> loss.backward()\n    >>>\n    >>>\n    >>> # 2D loss example (used, for example, with image inputs)\n    >>> N, C = 5, 4\n    >>> loss_fn = nn.NLLLoss()\n    >>> data = torch.randn(N, 16, 10, 10)\n    >>> conv = nn.Conv2d(16, C, (3, 3))\n    >>> log_softmax = nn.LogSoftmax(dim=1)\n    >>> # output of conv forward is of shape [N, C, 8, 8]\n    >>> output = log_softmax(conv(data))\n    >>> # each element in target must have 0 <= value < C\n    >>> target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n    >>> # input to NLLLoss is of size N x C x height (8) x width (8)\n    >>> loss = loss_fn(output, target)\n    >>> loss.backward()",
        "has_varargs": false
      },
      {
        "name": "PoissonNLLLoss",
        "api_path": "torch.nn.PoissonNLLLoss",
        "kind": "class",
        "params": [
          {
            "name": "log_input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "full",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Negative log likelihood loss with Poisson distribution of target.\n\nThe loss can be described as:\n\n.. math::\n    \\text{target} \\sim \\mathrm{Poisson}(\\text{input})\n\n    \\text{loss}(\\text{input}, \\text{target}) = \\text{input} - \\text{target} * \\log(\\text{input})\n                                + \\log(\\text{target!})\n\nThe last term can be omitted or approximated with Stirling formula. The\napproximation is used for target values more than 1. For targets less or\nequal to 1 zeros are added to the loss.\n\nArgs:\n    log_input (bool, optional): if ``True`` the loss is computed as\n        :math:`\\exp(\\text{input}) - \\text{target}*\\text{input}`, if ``False`` the loss is\n        :math:`\\text{input} - \\text{target}*\\log(\\text{input}+\\text{eps})`.\n    full (bool, optional): whether to compute full loss, i. e. to add the\n        Stirling approximation term\n\n        .. math::\n            \\text{target}*\\log(\\text{target}) - \\text{target} + 0.5 * \\log(2\\pi\\text{target}).\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    eps (float, optional): Small value to avoid evaluation of :math:`\\log(0)` when\n        :attr:`log_input = False`. Default: 1e-8\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nExamples:\n\n    >>> loss = nn.PoissonNLLLoss()\n    >>> log_input = torch.randn(5, 2, requires_grad=True)\n    >>> target = torch.randn(5, 2)\n    >>> output = loss(log_input, target)\n    >>> output.backward()\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n    - Output: scalar by default. If :attr:`reduction` is ``'none'``, then :math:`(*)`,\n      the same shape as the input.",
        "has_varargs": false
      },
      {
        "name": "SmoothL1Loss",
        "api_path": "torch.nn.SmoothL1Loss",
        "kind": "class",
        "params": [
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          },
          {
            "name": "beta",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          }
        ],
        "docstring": "Creates a criterion that uses a squared term if the absolute\nelement-wise error falls below beta and an L1 term otherwise.\nIt is less sensitive to outliers than :class:`torch.nn.MSELoss` and in some cases\nprevents exploding gradients (e.g. see the paper `Fast R-CNN`_ by Ross Girshick).\n\nFor a batch of size :math:`N`, the unreduced loss can be described as:\n\n.. math::\n    \\ell(x, y) = L = \\{l_1, ..., l_N\\}^T\n\nwith\n\n.. math::\n    l_n = \\begin{cases}\n    0.5 (x_n - y_n)^2 / beta, & \\text{if } |x_n - y_n| < beta \\\\\n    |x_n - y_n| - 0.5 * beta, & \\text{otherwise }\n    \\end{cases}\n\nIf `reduction` is not `none`, then:\n\n.. math::\n    \\ell(x, y) =\n    \\begin{cases}\n        \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n        \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\n.. note::\n    Smooth L1 loss can be seen as exactly :class:`L1Loss`, but with the :math:`|x - y| < beta`\n    portion replaced with a quadratic function such that its slope is 1 at :math:`|x - y| = beta`.\n    The quadratic segment smooths the L1 loss near :math:`|x - y| = 0`.\n\n.. note::\n    Smooth L1 loss is closely related to :class:`HuberLoss`, being\n    equivalent to :math:`huber(x, y) / beta` (note that Smooth L1's beta hyper-parameter is\n    also known as delta for Huber). This leads to the following differences:\n\n    * As beta -> 0, Smooth L1 loss converges to :class:`L1Loss`, while :class:`HuberLoss`\n      converges to a constant 0 loss. When beta is 0, Smooth L1 loss is equivalent to L1 loss.\n    * As beta -> :math:`+\\infty`, Smooth L1 loss converges to a constant 0 loss, while\n      :class:`HuberLoss` converges to :class:`MSELoss`.\n    * For Smooth L1 loss, as beta varies, the L1 segment of the loss has a constant slope of 1.\n      For :class:`HuberLoss`, the slope of the L1 segment is beta.\n\n.. _`Fast R-CNN`: https://arxiv.org/abs/1504.08083\n\nArgs:\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n    beta (float, optional): Specifies the threshold at which to change between L1 and L2 loss.\n        The value must be non-negative. Default: 1.0\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same shape as the input.",
        "has_varargs": false
      },
      {
        "name": "SoftMarginLoss",
        "api_path": "torch.nn.SoftMarginLoss",
        "kind": "class",
        "params": [
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that optimizes a two-class classification\nlogistic loss between input tensor :math:`x` and target tensor :math:`y`\n(containing 1 or -1).\n\n.. math::\n    \\text{loss}(x, y) = \\sum_i \\frac{\\log(1 + \\exp(-y[i]*x[i]))}{\\text{x.nelement}()}\n\nArgs:\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Target: :math:`(*)`, same shape as the input.\n    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n      shape as input.",
        "has_varargs": false
      },
      {
        "name": "TripletMarginLoss",
        "api_path": "torch.nn.TripletMarginLoss",
        "kind": "class",
        "params": [
          {
            "name": "margin",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "2.0",
            "annotation": "float"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-06",
            "annotation": "float"
          },
          {
            "name": "swap",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that measures the triplet loss given an input\ntensors :math:`x1`, :math:`x2`, :math:`x3` and a margin with a value greater than :math:`0`.\nThis is used for measuring a relative similarity between samples. A triplet\nis composed by `a`, `p` and `n` (i.e., `anchor`, `positive examples` and `negative\nexamples` respectively). The shapes of all input tensors should be\n:math:`(N, D)`.\n\nThe distance swap is described in detail in the paper `Learning shallow\nconvolutional feature descriptors with triplet losses`_ by\nV. Balntas, E. Riba et al.\n\nThe loss function for each sample in the mini-batch is:\n\n.. math::\n    L(a, p, n) = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\}\n\n\nwhere\n\n.. math::\n    d(x_i, y_i) = \\left\\lVert {\\bf x}_i - {\\bf y}_i \\right\\rVert_p\n\nThe norm is calculated using the specified p value and a small constant :math:`\\varepsilon` is\nadded for numerical stability.\n\nSee also :class:`~torch.nn.TripletMarginWithDistanceLoss`, which computes the\ntriplet margin loss for input tensors using a custom distance function.\n\nArgs:\n    margin (float, optional): Default: :math:`1`.\n    p (int, optional): The norm degree for pairwise distance. Default: :math:`2`.\n    eps (float, optional): Small constant for numerical stability. Default: :math:`1e-6`.\n    swap (bool, optional): The distance swap is described in detail in the paper\n        `Learning shallow convolutional feature descriptors with triplet losses` by\n        V. Balntas, E. Riba et al. Default: ``False``.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n\nShape:\n    - Input: :math:`(N, D)` or :math:`(D)` where :math:`D` is the vector dimension.\n    - Output: A Tensor of shape :math:`(N)` if :attr:`reduction` is ``'none'`` and\n      input shape is :math:`(N, D)`; a scalar otherwise.\n\nExamples:\n\n>>> triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n>>> anchor = torch.randn(100, 128, requires_grad=True)\n>>> positive = torch.randn(100, 128, requires_grad=True)\n>>> negative = torch.randn(100, 128, requires_grad=True)\n>>> output = triplet_loss(anchor, positive, negative)\n>>> output.backward()\n\n.. _Learning shallow convolutional feature descriptors with triplet losses:\n    https://bmva-archive.org.uk/bmvc/2016/papers/paper119/index.html",
        "has_varargs": false
      },
      {
        "name": "TripletMarginWithDistanceLoss",
        "api_path": "torch.nn.TripletMarginWithDistanceLoss",
        "kind": "class",
        "params": [
          {
            "name": "distance_function",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "margin",
            "kind": "KEYWORD_ONLY",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "swap",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "reduction",
            "kind": "KEYWORD_ONLY",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "Creates a criterion that measures the triplet loss given input\ntensors :math:`a`, :math:`p`, and :math:`n` (representing anchor,\npositive, and negative examples, respectively), and a nonnegative,\nreal-valued function (\"distance function\") used to compute the relationship\nbetween the anchor and positive example (\"positive distance\") and the\nanchor and negative example (\"negative distance\").\n\nThe unreduced loss (i.e., with :attr:`reduction` set to ``'none'``)\ncan be described as:\n\n.. math::\n    \\ell(a, p, n) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n    l_i = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\}\n\nwhere :math:`N` is the batch size; :math:`d` is a nonnegative, real-valued function\nquantifying the closeness of two tensors, referred to as the :attr:`distance_function`;\nand :math:`margin` is a nonnegative margin representing the minimum difference\nbetween the positive and negative distances that is required for the loss to\nbe 0.  The input tensors have :math:`N` elements each and can be of any shape\nthat the distance function can handle.\n\nIf :attr:`reduction` is not ``'none'``\n(default ``'mean'``), then:\n\n.. math::\n    \\ell(x, y) =\n    \\begin{cases}\n        \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n        \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\nSee also :class:`~torch.nn.TripletMarginLoss`, which computes the triplet\nloss for input tensors using the :math:`l_p` distance as the distance function.\n\nArgs:\n    distance_function (Callable, optional): A nonnegative, real-valued function that\n        quantifies the closeness of two tensors. If not specified,\n        `nn.PairwiseDistance` will be used.  Default: ``None``\n    margin (float, optional): A nonnegative margin representing the minimum difference\n        between the positive and negative distances required for the loss to be 0. Larger\n        margins penalize cases where the negative examples are not distant enough from the\n        anchors, relative to the positives. Default: :math:`1`.\n    swap (bool, optional): Whether to use the distance swap described in the paper\n        `Learning shallow convolutional feature descriptors with triplet losses` by\n        V. Balntas, E. Riba et al. If True, and if the positive example is closer to the\n        negative example than the anchor is, swaps the positive example and the anchor in\n        the loss computation. Default: ``False``.\n    reduction (str, optional): Specifies the (optional) reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n        ``'mean'``: the sum of the output will be divided by the number of\n        elements in the output, ``'sum'``: the output will be summed. Default: ``'mean'``\n\n\nShape:\n    - Input: :math:`(N, *)` where :math:`*` represents any number of additional dimensions\n      as supported by the distance function.\n    - Output: A Tensor of shape :math:`(N)` if :attr:`reduction` is ``'none'``, or a scalar\n      otherwise.\n\nExamples:\n\n>>> # Initialize embeddings\n>>> embedding = nn.Embedding(1000, 128)\n>>> anchor_ids = torch.randint(0, 1000, (1,))\n>>> positive_ids = torch.randint(0, 1000, (1,))\n>>> negative_ids = torch.randint(0, 1000, (1,))\n>>> anchor = embedding(anchor_ids)\n>>> positive = embedding(positive_ids)\n>>> negative = embedding(negative_ids)\n>>>\n>>> # Built-in Distance Function\n>>> triplet_loss = \\\n>>>     nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance())\n>>> output = triplet_loss(anchor, positive, negative)\n>>> output.backward()\n>>>\n>>> # Custom Distance Function\n>>> def l_infinity(x1, x2):\n>>>     return torch.max(torch.abs(x1 - x2), dim=1).values\n>>>\n>>> # xdoctest: +SKIP(\"FIXME: Would call backwards a second time\")\n>>> triplet_loss = (\n>>>     nn.TripletMarginWithDistanceLoss(distance_function=l_infinity, margin=1.5))\n>>> output = triplet_loss(anchor, positive, negative)\n>>> output.backward()\n>>>\n>>> # Custom Distance Function (Lambda)\n>>> triplet_loss = (\n>>>     nn.TripletMarginWithDistanceLoss(\n>>>         distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))\n>>> output = triplet_loss(anchor, positive, negative)\n>>> output.backward()\n\nReference:\n    V. Balntas, et al.: Learning shallow convolutional feature descriptors with triplet losses:\n    https://bmva-archive.org.uk/bmvc/2016/papers/paper119/index.html",
        "has_varargs": false
      }
    ],
    "optimizer": [
      {
        "name": "ASGD",
        "api_path": "torch.optim.ASGD",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "Union"
          },
          {
            "name": "lambd",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0001",
            "annotation": "float"
          },
          {
            "name": "alpha",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.75",
            "annotation": "float"
          },
          {
            "name": "t0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1000000.0",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "foreach",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "capturable",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements Averaged Stochastic Gradient Descent.\n\nIt has been proposed in `Acceleration of stochastic approximation by\naveraging`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 1e-2)\n    lambd (float, optional): decay term (default: 1e-4)\n    alpha (float, optional): power for eta update (default: 0.75)\n    t0 (float, optional): point at which to start averaging (default: 1e6)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n\n.. _Acceleration of stochastic approximation by averaging:\n    https://meyn.ece.ufl.edu/wp-content/uploads/sites/77/archive/spm_files/Courses/ECE555-2011/555media/poljud92.pdf",
        "has_varargs": false
      },
      {
        "name": "Adadelta",
        "api_path": "torch.optim.Adadelta",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "Union"
          },
          {
            "name": "rho",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.9",
            "annotation": "float"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-06",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "foreach",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "capturable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements Adadelta algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)},\n            \\: f(\\theta) \\text{ (objective)}, \\: \\rho \\text{ (decay)},\n            \\: \\lambda \\text{ (weight decay)}                                                \\\\\n        &\\textbf{initialize} :  v_0  \\leftarrow 0 \\: \\text{ (square avg)},\n            \\: u_0 \\leftarrow 0 \\: \\text{ (accumulate variables)}                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n        &\\hspace{5mm}if \\: \\lambda \\neq 0                                                    \\\\\n        &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n        &\\hspace{5mm} v_t      \\leftarrow v_{t-1} \\rho + g^2_t (1 - \\rho)                    \\\\\n        &\\hspace{5mm}\\Delta x_t    \\leftarrow   \\frac{\\sqrt{u_{t-1} +\n            \\epsilon }}{ \\sqrt{v_t + \\epsilon}  }g_t \\hspace{21mm}                           \\\\\n        &\\hspace{5mm} u_t  \\leftarrow   u_{t-1}  \\rho +\n             \\Delta x^2_t  (1 - \\rho)                                                        \\\\\n        &\\hspace{5mm}\\theta_t      \\leftarrow   \\theta_{t-1} - \\gamma  \\Delta x_t            \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to `ADADELTA: An Adaptive Learning Rate Method`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): coefficient that scale delta before it is applied\n        to the parameters (default: 1.0)\n    rho (float, optional): coefficient used for computing a running average\n        of squared gradients (default: 0.9). A higher value of `rho` will\n        result in a slower average, which can be helpful for preventing\n        oscillations in the learning process.\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-6).\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n\n.. _ADADELTA\\: An Adaptive Learning Rate Method:\n    https://arxiv.org/abs/1212.5701",
        "has_varargs": false
      },
      {
        "name": "Adafactor",
        "api_path": "torch.optim.Adafactor",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "Union"
          },
          {
            "name": "beta2_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-0.8",
            "annotation": "float"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(None, 0.001)",
            "annotation": "tuple"
          },
          {
            "name": "d",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0",
            "annotation": "float"
          },
          {
            "name": "foreach",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements Adafactor algorithm.\n\n.. math::\n    \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{(lr)}, \\: \\tau\n            \\text{(}\\beta_2\\text{ decay)}, \\: \\theta_0 \\text{(params)}, \\: f(\\theta) \\text{(objective)},    \\\\\n        &\\hspace{15mm}      \\: \\epsilon_1, \\epsilon_2 \\text{ (epsilons)}, \\: d \\text{(clipping threshold)}, \\\\\n        &\\hspace{15mm}      \\: \\lambda \\text{(weight decay)},\n            \\: \\textit{maximize}                                                             \\\\\n        &\\textbf{initialize} : \\: R_0 \\leftarrow 0 \\text{ (second moment row factor)},       \\\\\n        &\\hspace{23mm} \\: C_0 \\leftarrow 0 \\text{ (second moment col factor)},               \\\\\n        &\\hspace{23mm} \\: \\widehat{V}_0 \\leftarrow 0 \\text{ (second moment for vectors)}     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n\n        &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n        &\\hspace{10mm}G_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n        &\\hspace{5mm}\\textbf{else}                                                           \\\\\n        &\\hspace{10mm}G_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n        &\\hspace{5mm}\\widehat{\\beta}_{2_t} \\leftarrow 1 - t^{\\tau}                           \\\\\n        &\\hspace{5mm}\\rho_t         \\leftarrow min(lr, \\frac{1}{\\sqrt{t}})                   \\\\\n        &\\hspace{5mm}\\alpha_t       \\leftarrow max(\\epsilon_2,\n            \\text{RMS}(\\theta_{t-1}))\\rho_t                                                  \\\\\n        &\\hspace{5mm}\\theta_t       \\leftarrow \\theta_{t-1} - \\gamma \\lambda \\theta_{t-1}    \\\\\n        &\\hspace{5mm}\\textbf{if} \\: \\text{dim}(G_t) > 1:                                     \\\\\n        &\\hspace{10mm}R_t           \\leftarrow \\widehat{\\beta}_{2_t}R_{t-1}+\n            (1-\\widehat{\\beta}_{2_t})(G_t \\odot G_t) \\cdot 1_m                               \\\\\n        &\\hspace{10mm}C_t           \\leftarrow \\widehat{\\beta}_{2_t}C_{t-1}+\n            (1-\\widehat{\\beta}_{2_t}) 1^\\top_n \\cdot (G_t \\odot G_t)                         \\\\\n        &\\hspace{10mm}\\widehat{V}_t \\leftarrow\n            \\frac{R_t \\cdot C_t}{max(1^\\top_n \\cdot R_t, \\epsilon_1)}                        \\\\\n        &\\hspace{5mm}\\textbf{else}                                                           \\\\\n        &\\hspace{10mm}\\widehat{V}_t \\leftarrow \\widehat{\\beta}_{2_t}\\widehat{V}_{t-1}+\n            (1-\\widehat{\\beta}_{2_t}) \\cdot (G_t \\odot G_t)                                  \\\\\n        &\\hspace{5mm}U_t            \\leftarrow\n            \\frac{G_t}{max(\\sqrt{\\widehat{V}_t}, \\epsilon_1)}                                \\\\\n        &\\hspace{5mm}\\widehat{U}_t  \\leftarrow \\frac{U_t}{max(1, \\frac{\\text{RMS}(U_t)}{d})} \\\\\n        &\\hspace{5mm}\\theta_t       \\leftarrow \\theta_{t-1} - \\alpha_t \\widehat{U}_t         \\\\\n\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n    \\end{aligned}\n\nFor further details regarding the algorithm we refer to `Adafactor: Adaptive Learning Rates with Sublinear Memory Cost`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): unlike other optimizers, Adafactor does not require a\n        learning rate, and Noam Shazeer and Mitchell Stern do not use lr at all.\n        Deviating from the paper, this implementation uses lr for applying weight\n        decay and as the maximum value for relative step size rho_t. Note that in\n        the paper, a constant of 0.01 is used as the maximum value for relative\n        step size, and so we set 0.01 as the default value. (default: 1e-2)\n    beta2_decay (float, optional): the decay rate of beta2. beta2 standardly refers\n        to the coefficient used for computing the running average of the gradient\n        squared. (default: -0.8)\n    eps (Tuple[float, float], optional): epsilon1 is the term added to the denominator\n        of the update calculation to improve numerical stability. This use of epsilon1\n        deviates from the algorithm written in the paper! See note below for more details.\n        epsilon2 is the term used to avoid having too small a weight update when applying\n        parameter scaling. (default: (None, 1e-3))\n    d (float, optional): the clipping threshold, used to avoid larger-than-desired\n        updates.\n    weight_decay (float, optional): weight decay coefficient (default: 1e-2)\n    foreach (bool, optional): whether foreach implementation of optimizer is used. Note\n        that the foreach implementation uses ~ sizeof(params) more peak memory than the\n        for-loop version due to the intermediates being a tensorlist vs just one tensor.\n        As Adafactor is commonly used when memory is prohibitive, Adafactor will default\n        to the slower single tensor for-loop implementation unless this flag is explicitly\n        True. This behavior is contrary to other optimizers, which will attempt defaulting\n        to foreach on CUDA for faster runtime. (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n.. Note::\n    The implementation of Adafactor subtly differs from Noam Shazeer and Mitchell Stern\n    and implementations in some other frameworks with its use of learning rate and\n    :math:`\\epsilon_1`.\n\n    Regarding the learning rate hyperparameter: Noam Shazeer and Mitchell Stern do not\n    use lr at all, as the stated algorithm uses :math:`\\rho_t` and update clipping to\n    affect the step size.\n\n    This implementation allows `lr` to influence the maximum value for :math:`\\rho_t`:\n\n    .. math::\n        \\begin{aligned}\n            &\\hspace{5mm}\\rho_t \\leftarrow min(lr, \\frac{1}{\\sqrt{t}})\n        \\end{aligned}\n\n    This differs from Noam Shazeer and Mitchell Stern, who use a constant of 0.01 as\n    the maximum value of :math:`\\rho_t`\n\n    .. math::\n        \\begin{aligned}\n            &\\hspace{5mm}\\rho_t \\leftarrow min(0.01, \\frac{1}{\\sqrt{t}})\n        \\end{aligned}\n\n    Noam Shazeer and Mitchell Stern do not enforce an opinion on how weight decay should\n    be computed, and so we use the learning rate as a coefficient for decoupled weight\n    decay, similar to what is suggested in `Decoupled Weight Decay Regularization`_.\n\n    Regarding the use of :math:`\\epsilon_1`: The implementation attempts to replicate the\n    presumed intention of Noam Shazeer and Mitchell Stern to use :math:`\\epsilon_1` as\n    a stabilizing term when the squared gradient becomes small.\n\n    This stabilization can be written as\n\n    .. math::\n        \\begin{aligned}\n            &\\hspace{5mm}R_t \\leftarrow \\widehat{\\beta}_{2_t}R_{t-1}+\n                (1-\\widehat{\\beta}_{2_t})(G_t \\odot G_t + 1_n \\cdot 1^\\top_m) \\cdot 1_m          \\\\\n            &\\hspace{5mm}C_t \\leftarrow \\widehat{\\beta}_{2_t}C_{t-1}+\n                (1-\\widehat{\\beta}_{2_t}) 1^\\top_n \\cdot (G_t \\odot G_t + 1_n \\cdot 1^\\top_m)    \\\\\n            &\\hspace{5mm}\\widehat{V}_t \\leftarrow\n                \\frac{R_t \\cdot C_t}{max(1^\\top_n \\cdot R_t, \\epsilon_1)}                        \\\\\n            &\\hspace{5mm}U_t \\leftarrow \\frac{G_t}{max(\\sqrt{\\widehat{V}_t}, \\epsilon_1)}        \\\\\n        \\end{aligned}\n\n    where the row and column factors of gradient squared :math:`R_t` and :math:`C_t`\n    are left alone, and we apply :math:`\\epsilon_1` at the final calculation of\n    the variance estimate :math:`\\widehat{V}_t` and for the update :math:`U_t`.\n\n    This is in contrast to Noam Shazeer and Mitchell Stern and other frameworks which\n    apply :math:`\\epsilon_1` to both row and column factors of the squared gradient, but\n    not in the calculations after:\n\n    .. math::\n        \\begin{aligned}\n            &\\hspace{5mm}R_t \\leftarrow \\widehat{\\beta}_{2_t}R_{t-1}+\n                        (1-\\widehat{\\beta}_{2_t})(G_t \\odot G_t + \\epsilon_1 1_n \\cdot 1^\\top_m) \\cdot 1_m          \\\\\n            &\\hspace{5mm}C_t \\leftarrow \\widehat{\\beta}_{2_t}C_{t-1}+\n                        (1-\\widehat{\\beta}_{2_t}) 1^\\top_n \\cdot (G_t \\odot G_t + \\epsilon_1 1_n \\cdot 1^\\top_m)    \\\\\n            &\\hspace{5mm}\\widehat{V}_t \\leftarrow \\frac{R_t \\cdot C_t}{1^\\top_n \\cdot R_t}                          \\\\\n            &\\hspace{5mm}U_t \\leftarrow \\frac{G_t}{\\sqrt{\\widehat{V}_t}}                                            \\\\\n        \\end{aligned}\n\n    You may note that Noam Shazeer and Mitchell Stern describe using the sum of squared gradients,\n    while this implementation uses the mean instead. This choice is mathematically equivalent and\n    allows for greater numerical stability for large sums.\n\n.. _Adafactor\\: Adaptive Learning Rates with Sublinear Memory Cost:\n    https://arxiv.org/pdf/1804.04235\n.. _Decoupled Weight Decay Regularization:\n    https://arxiv.org/abs/1711.05101",
        "has_varargs": false
      },
      {
        "name": "Adagrad",
        "api_path": "torch.optim.Adagrad",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "Union"
          },
          {
            "name": "lr_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "initial_accumulator_value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-10",
            "annotation": "float"
          },
          {
            "name": "foreach",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "fused",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Implements Adagrad algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)}, \\: f(\\theta)\n            \\text{ (objective)}, \\: \\lambda \\text{ (weight decay)},                          \\\\\n        &\\hspace{12mm}    \\tau \\text{ (initial accumulator value)}, \\: \\eta\\text{ (lr decay)}\\\\\n        &\\textbf{initialize} :  state\\_sum_0 \\leftarrow \\tau                          \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n        &\\hspace{5mm} \\tilde{\\gamma}    \\leftarrow \\gamma / (1 +(t-1) \\eta)                  \\\\\n        &\\hspace{5mm} \\textbf{if} \\: \\lambda \\neq 0                                          \\\\\n        &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda \\theta_{t-1}                             \\\\\n        &\\hspace{5mm}state\\_sum_t  \\leftarrow  state\\_sum_{t-1} + g^2_t                      \\\\\n        &\\hspace{5mm}\\theta_t \\leftarrow\n            \\theta_{t-1}- \\tilde{\\gamma} \\frac{g_t}{\\sqrt{state\\_sum_t}+\\epsilon}            \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to `Adaptive Subgradient Methods for Online Learning\nand Stochastic Optimization`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 1e-2)\n    lr_decay (float, optional): learning rate decay (default: 0)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    initial_accumulator_value (float, optional): initial value of the\n        sum of squares of gradients (default: 0)\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-10)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n    fused (bool, optional): whether the fused implementation (CPU only) is used.\n        Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n        are supported. (default: None). Please note that the fused implementations does not\n        support sparse or complex gradients.\n.. _Adaptive Subgradient Methods for Online Learning and Stochastic\n    Optimization: http://jmlr.org/papers/v12/duchi11a.html",
        "has_varargs": false
      },
      {
        "name": "Adam",
        "api_path": "torch.optim.Adam",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.001",
            "annotation": "Union"
          },
          {
            "name": "betas",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(0.9, 0.999)",
            "annotation": "tuple"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "amsgrad",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "foreach",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "capturable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "fused",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "decoupled_weight_decay",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements Adam algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{ (lr)}, \\beta_1, \\beta_2\n            \\text{ (betas)},\\theta_0 \\text{ (params)},f(\\theta) \\text{ (objective)}          \\\\\n        &\\hspace{13mm}      \\lambda \\text{ (weight decay)},  \\: \\textit{amsgrad},\n            \\:\\textit{maximize},  \\: \\epsilon \\text{ (epsilon)}                              \\\\\n        &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n            v_0\\leftarrow 0 \\text{ (second moment)},\\: v_0^{max}\\leftarrow 0          \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n\n        &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n        &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n        &\\hspace{5mm}\\textbf{else}                                                           \\\\\n        &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n        &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\n        &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n        &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n        &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n        &\\hspace{5mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n        &\\hspace{5mm}\\textbf{if} \\: amsgrad                                                  \\\\\n        &\\hspace{10mm} v_t^{max} \\leftarrow \\mathrm{max}(v_{t-1}^{max},v_t)                  \\\\\n        &\\hspace{10mm}\\widehat{v_t} \\leftarrow v_t^{max}/\\big(1-\\beta_2^t \\big)              \\\\\n        &\\hspace{5mm}\\textbf{else}                                                           \\\\\n        &\\hspace{10mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                  \\\\\n        &\\hspace{5mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\widehat{m_t}/\n            \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to `Adam: A Method for Stochastic Optimization`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 1e-3). A tensor LR\n        is not yet supported for all our implementations. Please use a float\n        LR if you are not also specifying fused=True or capturable=True.\n    betas (Tuple[float, float], optional): coefficients used for computing\n        running averages of gradient and its square (default: (0.9, 0.999))\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-8)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    decoupled_weight_decay (bool, optional): if True, this optimizer is\n        equivalent to AdamW and the algorithm will not accumulate weight\n        decay in the momentum nor variance. (default: False)\n    amsgrad (bool, optional): whether to use the AMSGrad variant of this\n        algorithm from the paper `On the Convergence of Adam and Beyond`_\n        (default: False)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n    fused (bool, optional): whether the fused implementation is used.\n        Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n        are supported. (default: None)\n\n.. note:: The foreach and fused implementations are typically faster than the for-loop,\n          single-tensor implementation, with fused being theoretically fastest with both\n          vertical and horizontal fusion. As such, if the user has not specified either\n          flag (i.e., when foreach = fused = None), we will attempt defaulting to the foreach\n          implementation when the tensors are all on CUDA. Why not fused? Since the fused\n          implementation is relatively new, we want to give it sufficient bake-in time.\n          To specify fused, pass True for fused. To force running the for-loop\n          implementation, pass False for either foreach or fused. \n.. Note::\n    A prototype implementation of Adam and AdamW for MPS supports `torch.float32` and `torch.float16`.\n.. _Adam\\: A Method for Stochastic Optimization:\n    https://arxiv.org/abs/1412.6980\n.. _On the Convergence of Adam and Beyond:\n    https://openreview.net/forum?id=ryQu7f-RZ",
        "has_varargs": false
      },
      {
        "name": "AdamW",
        "api_path": "torch.optim.AdamW",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.001",
            "annotation": "Union"
          },
          {
            "name": "betas",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(0.9, 0.999)",
            "annotation": "tuple"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "float"
          },
          {
            "name": "amsgrad",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "foreach",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "capturable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "fused",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Implements AdamW algorithm, where weight decay does not accumulate in the momentum nor variance.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{(lr)}, \\: \\beta_1, \\beta_2\n            \\text{(betas)}, \\: \\theta_0 \\text{(params)}, \\: f(\\theta) \\text{(objective)},\n            \\: \\epsilon \\text{ (epsilon)}                                                    \\\\\n        &\\hspace{13mm}      \\lambda \\text{(weight decay)},  \\: \\textit{amsgrad},\n            \\: \\textit{maximize}                                                             \\\\\n        &\\textbf{initialize} : m_0 \\leftarrow 0 \\text{ (first moment)}, v_0 \\leftarrow 0\n            \\text{ ( second moment)}, \\: v_0^{max}\\leftarrow 0                        \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n\n        &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n        &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n        &\\hspace{5mm}\\textbf{else}                                                           \\\\\n        &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n        &\\hspace{5mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\lambda \\theta_{t-1}         \\\\\n        &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n        &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n        &\\hspace{5mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n        &\\hspace{5mm}\\textbf{if} \\: amsgrad                                                  \\\\\n        &\\hspace{10mm} v_t^{max} \\leftarrow \\mathrm{max}(v_{t-1}^{max},v_t)                  \\\\\n        &\\hspace{10mm}\\widehat{v_t} \\leftarrow v_t^{max}/\\big(1-\\beta_2^t \\big)              \\\\\n        &\\hspace{5mm}\\textbf{else}                                                           \\\\\n        &\\hspace{10mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                  \\\\\n        &\\hspace{5mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}/\n            \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to `Decoupled Weight Decay Regularization`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 1e-3). A tensor LR\n        is not yet supported for all our implementations. Please use a float\n        LR if you are not also specifying fused=True or capturable=True.\n    betas (Tuple[float, float], optional): coefficients used for computing\n        running averages of gradient and its square (default: (0.9, 0.999))\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-8)\n    weight_decay (float, optional): weight decay coefficient (default: 1e-2)\n    amsgrad (bool, optional): whether to use the AMSGrad variant of this\n        algorithm from the paper `On the Convergence of Adam and Beyond`_\n        (default: False)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n    fused (bool, optional): whether the fused implementation is used.\n        Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n        are supported. (default: None)\n\n.. note:: The foreach and fused implementations are typically faster than the for-loop,\n          single-tensor implementation, with fused being theoretically fastest with both\n          vertical and horizontal fusion. As such, if the user has not specified either\n          flag (i.e., when foreach = fused = None), we will attempt defaulting to the foreach\n          implementation when the tensors are all on CUDA. Why not fused? Since the fused\n          implementation is relatively new, we want to give it sufficient bake-in time.\n          To specify fused, pass True for fused. To force running the for-loop\n          implementation, pass False for either foreach or fused. \n.. Note::\n    A prototype implementation of Adam and AdamW for MPS supports `torch.float32` and `torch.float16`.\n.. _Decoupled Weight Decay Regularization:\n    https://arxiv.org/abs/1711.05101\n.. _On the Convergence of Adam and Beyond:\n    https://openreview.net/forum?id=ryQu7f-RZ",
        "has_varargs": false
      },
      {
        "name": "Adamax",
        "api_path": "torch.optim.Adamax",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.002",
            "annotation": "Union"
          },
          {
            "name": "betas",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(0.9, 0.999)",
            "annotation": "tuple"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "foreach",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "capturable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements Adamax algorithm (a variant of Adam based on infinity norm).\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{ (lr)}, \\beta_1, \\beta_2\n            \\text{ (betas)},\\theta_0 \\text{ (params)},f(\\theta) \\text{ (objective)},\n            \\: \\lambda \\text{ (weight decay)},                                                \\\\\n        &\\hspace{13mm}    \\epsilon \\text{ (epsilon)}                                          \\\\\n        &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n            u_0 \\leftarrow 0 \\text{ ( infinity norm)}                                 \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n        &\\hspace{5mm}if \\: \\lambda \\neq 0                                                    \\\\\n        &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n        &\\hspace{5mm}m_t      \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t               \\\\\n        &\\hspace{5mm}u_t      \\leftarrow   \\mathrm{max}(\\beta_2 u_{t-1}, |g_{t}|+\\epsilon)   \\\\\n        &\\hspace{5mm}\\theta_t \\leftarrow \\theta_{t-1} - \\frac{\\gamma m_t}{(1-\\beta^t_1) u_t} \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to `Adam: A Method for Stochastic Optimization`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 2e-3)\n    betas (Tuple[float, float], optional): coefficients used for computing\n        running averages of gradient and its square\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-8)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n\n.. _Adam\\: A Method for Stochastic Optimization:\n    https://arxiv.org/abs/1412.6980",
        "has_varargs": false
      },
      {
        "name": "LBFGS",
        "api_path": "torch.optim.LBFGS",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "max_iter",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "20",
            "annotation": "int"
          },
          {
            "name": "max_eval",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "tolerance_grad",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-07",
            "annotation": "float"
          },
          {
            "name": "tolerance_change",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-09",
            "annotation": "float"
          },
          {
            "name": "history_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "100",
            "annotation": "int"
          },
          {
            "name": "line_search_fn",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Implements L-BFGS algorithm.\n\nHeavily inspired by `minFunc\n<https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html>`_.\n\n.. warning::\n    This optimizer doesn't support per-parameter options and parameter\n    groups (there can be only one).\n\n.. warning::\n    Right now all parameters have to be on a single device. This will be\n    improved in the future.\n\n.. note::\n    This is a very memory intensive optimizer (it requires additional\n    ``param_bytes * (history_size + 1)`` bytes). If it doesn't fit in memory\n    try reducing the history size, or use a different algorithm.\n\nArgs:\n    params (iterable): iterable of parameters to optimize. Parameters must be real.\n    lr (float, optional): learning rate (default: 1)\n    max_iter (int, optional): maximal number of iterations per optimization step\n        (default: 20)\n    max_eval (int, optional): maximal number of function evaluations per optimization\n        step (default: max_iter * 1.25).\n    tolerance_grad (float, optional): termination tolerance on first order optimality\n        (default: 1e-7).\n    tolerance_change (float, optional): termination tolerance on function\n        value/parameter changes (default: 1e-9).\n    history_size (int, optional): update history size (default: 100).\n    line_search_fn (str, optional): either 'strong_wolfe' or None (default: None).",
        "has_varargs": false
      },
      {
        "name": "Muon",
        "api_path": "torch.optim.Muon",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.001",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.95",
            "annotation": "float"
          },
          {
            "name": "nesterov",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "ns_coefficients",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(3.4445, -4.775, 2.0315)",
            "annotation": "tuple"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-07",
            "annotation": "float"
          },
          {
            "name": "ns_steps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "5",
            "annotation": "int"
          },
          {
            "name": "adjust_lr_fn",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Implements Muon algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt} \\\\\n        &\\textbf{input}      : \\gamma \\text{ (lr)},\\ \\lambda \\text{ (weight decay)},\\\n           \\mu \\text{ (momentum)},\\ \\textit{nesterov}\\in\\{True,False\\},\\\\\n        &\\hspace{13mm}(a,b,c)\\ \\text{ (NS coefficients)},\\\n           \\varepsilon \\text{ (epsilon)},\\ k \\text{ (NS steps)},\\\n           \\theta_0 \\text{ (params)},\\ f(\\theta) \\text{ (objective)} \\\\\n        &\\textbf{initialize} : B_0 \\leftarrow 0 \\text{ (momentum buffer)} \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt} \\\\\n        &\\textbf{for}\\ t=1\\ \\textbf{to}\\ \\ldots\\ \\textbf{do} \\\\[0.25ex]\n        &\\hspace{5mm} g_t \\leftarrow \\nabla_{\\theta} f_t(\\theta_{t-1}) \\\\[0.25ex]\n        &\\hspace{5mm} B_t \\leftarrow \\mu B_{t-1} + g_t \\\\[0.25ex]\n        &\\hspace{5mm} \\widetilde{B}_t \\leftarrow\n            \\begin{cases}\n               g_t + \\mu B_t, & \\text{if nesterov}=True \\\\\n               B_t,           & \\text{if nesterov}=False\n            \\end{cases} \\\\[1.0ex]\n        &\\hspace{5mm} O_t \\leftarrow \\mathrm{NS}^{(a,b,c)}_{k}\\!\\big(\\widetilde{B}_t;\\ \\varepsilon\\big) \\\\[0.5ex]\n        &\\hspace{5mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma\\,\\lambda\\,\\theta_{t-1}\n           \\quad\\text{(decoupled weight decay)} \\\\[0.25ex]\n\n        &\\hspace{5mm} \\gamma \\leftarrow \\mathrm{AdjustLR}\\!\\big(\\gamma;\\ \\mathrm{shape}\\!\\big(\\theta_t \\big) \\big) \\\\[0.25ex]\n        &\\hspace{5mm} \\theta_t \\leftarrow \\theta_t - \\gamma\\, O_t \\\\\n        &\\rule{110mm}{0.4pt} \\\\[-1.ex]\n        &\\mathbf{return}\\ \\theta_t \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}s\n   \\end{aligned}\n\nHere, :math:`\\mathrm{NS}^{(a,b,c)}_{k}(\\cdot;\\varepsilon)` denotes :math:`k` iterations of the\nNewton\u2013Schulz orthogonalization operator parameterized by coefficients :math:`(a,b,c)`\nwith numerical stabilization :math:`\\varepsilon`.\n\nThe purpose for :math:`\\mathrm{AdjustLR}\\!\\big(\\gamma;\\ \\mathrm{shape}\\!\\big(\\theta_t \\big) \\big)`\nis to make the orthogonalized update have a consistent :math:`RMS` across rectangular matrices.\n\nKeller's original implementation scales the update by :math:`\\sqrt{\\max\\!\\left(1, \\frac{A}{B}\\right)}`,\nwhere :math:`A` and :math:`B` are dimension of the matrix being optimized.\n\nMoonshot's implementation also focuses on matching :math:`RMS` of AdamW. The adjustment is computed as:\n:math:`\\gamma \\leftarrow {0.2}\\gamma\\,\\sqrt{\\max\\!\\left({A}, {B}\\right)}`\nThe method is adopted from `Muon is Scalable for LLM Training`_. Research\nresults show that with this adjustment Muon can directly reuse the learning rate\nand weight decay tuned for AdamW.\n\nWe provide two options for the learning rate adjustment: \"original\", which follows Keller's\nimplementation, and \"match_rms_adamw\", which refers to Moonshot's implementation. This gives users the\nflexibility to choose between the two. If `adjust_lr_fn` is not specified, the default is \"original\".\n\nFor further details regarding the algorithm we refer to `Muon: An optimizer for hidden layers in neural networks`_\nand `Muon is Scalable for LLM Training`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named. Note that Muon is an optimizer for 2D parameters of neural network hidden layers. Other\n        parameters, such as bias, and embedding, should be optimized by a standard method such as AdamW.\n    lr (float, Tensor, optional): learning rate (default: 1e-3).\n    weight_decay (float, optional): weight decay (L2 penalty). (default: 0.1)\n    momentum (float, optional): momentum factor (default: 0.95)\n    nesterov (bool, optional): enables Nesterov momentum. Only applicable\n        when momentum is non-zero\n    ns_coefficients (tuple of three floats, optional): coefficients \\(a,b,c\\) for the\n        Newton\u2013Schulz orthogonalization polynomial (default: (3.4445, -4.775, 2.0315))\n    eps (float, optional): term added to the denominator for numerical stability. (default: 1e-07)\n    ns_steps (int, optional): number of Newton\u2013Schulz iteration steps. (default: 5)\n    adjust_lr_fn (str, optional): function to adjust learning rate. One of \"original\" and \"match_rms_adamw\".\n        If not specified, we will default to use \"original\". (default: None)\n\n.. _Muon\\: An optimizer for hidden layers in neural networks:\n    https://kellerjordan.github.io/posts/muon/\n.. _Muon is Scalable for LLM Training:\n    https://arxiv.org/pdf/2502.16982",
        "has_varargs": false
      },
      {
        "name": "NAdam",
        "api_path": "torch.optim.NAdam",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.002",
            "annotation": "Union"
          },
          {
            "name": "betas",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(0.9, 0.999)",
            "annotation": "tuple"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "momentum_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.004",
            "annotation": "float"
          },
          {
            "name": "decoupled_weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "foreach",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "capturable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements NAdam algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma_t \\text{ (lr)}, \\: \\beta_1,\\beta_2 \\text{ (betas)},\n            \\: \\theta_0 \\text{ (params)}, \\: f(\\theta) \\text{ (objective)}                   \\\\\n        &\\hspace{13mm} \\: \\lambda \\text{ (weight decay)}, \\:\\psi \\text{ (momentum decay)}    \\\\\n        &\\hspace{13mm} \\: \\textit{decoupled\\_weight\\_decay}, \\:\\textit{maximize}             \\\\\n        &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n            v_0 \\leftarrow 0 \\text{ ( second moment)}                                 \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n        &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n        &\\hspace{5mm}\\textbf{else}                                                           \\\\\n        &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n        &\\hspace{5mm} \\theta_t \\leftarrow \\theta_{t-1}                                       \\\\\n        &\\hspace{5mm} \\textbf{if} \\: \\lambda \\neq 0                                          \\\\\n        &\\hspace{10mm}\\textbf{if} \\: \\textit{decoupled\\_weight\\_decay}                       \\\\\n        &\\hspace{15mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\lambda \\theta_{t-1}                    \\\\\n        &\\hspace{10mm}\\textbf{else}                                                          \\\\\n        &\\hspace{15mm} g_t \\leftarrow g_t + \\lambda \\theta_{t-1}                             \\\\\n        &\\hspace{5mm} \\mu_t \\leftarrow \\beta_1 \\big(1 - \\frac{1}{2}  0.96^{t \\psi} \\big)     \\\\\n        &\\hspace{5mm} \\mu_{t+1} \\leftarrow \\beta_1 \\big(1 - \\frac{1}{2} 0.96^{(t+1)\\psi}\\big)\\\\\n        &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n        &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n        &\\hspace{5mm}\\widehat{m_t} \\leftarrow \\mu_{t+1} m_t/(1-\\prod_{i=1}^{t+1}\\mu_i)\\\\[-1.ex]\n        & \\hspace{11mm} + (1-\\mu_t) g_t /(1-\\prod_{i=1}^{t} \\mu_{i})                         \\\\\n        &\\hspace{5mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                   \\\\\n        &\\hspace{5mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}/\n            \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to `Incorporating Nesterov Momentum into Adam`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 2e-3)\n    betas (Tuple[float, float], optional): coefficients used for computing\n        running averages of gradient and its square (default: (0.9, 0.999))\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-8)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    momentum_decay (float, optional): momentum momentum_decay (default: 4e-3)\n    decoupled_weight_decay (bool, optional): whether to decouple the weight\n        decay as in AdamW to obtain NAdamW. If True, the algorithm does not\n        accumulate weight decay in the momentum nor variance. (default: False)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n\n.. _Incorporating Nesterov Momentum into Adam:\n    https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ\n.. _Decoupled Weight Decay Regularization:\n    https://arxiv.org/abs/1711.05101",
        "has_varargs": false
      },
      {
        "name": "RAdam",
        "api_path": "torch.optim.RAdam",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.001",
            "annotation": "Union"
          },
          {
            "name": "betas",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(0.9, 0.999)",
            "annotation": "tuple"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "decoupled_weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "foreach",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "capturable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements RAdam algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\beta_1, \\beta_2\n            \\text{ (betas)}, \\: \\theta_0 \\text{ (params)}, \\:f(\\theta) \\text{ (objective)}, \\:\n            \\lambda \\text{ (weightdecay)}, \\:\\textit{maximize}                               \\\\\n        &\\hspace{13mm} \\epsilon \\text{ (epsilon)}, \\textit{decoupled\\_weight\\_decay}         \\\\\n        &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n            v_0 \\leftarrow 0 \\text{ ( second moment)},                                       \\\\\n        &\\hspace{18mm} \\rho_{\\infty} \\leftarrow 2/(1-\\beta_2) -1                      \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}  \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{6mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n        &\\hspace{12mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n        &\\hspace{6mm}\\textbf{else}                                                           \\\\\n        &\\hspace{12mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n        &\\hspace{6mm} \\theta_t \\leftarrow \\theta_{t-1}                                       \\\\\n        &\\hspace{6mm} \\textbf{if} \\: \\lambda \\neq 0                                          \\\\\n        &\\hspace{12mm}\\textbf{if} \\: \\textit{decoupled\\_weight\\_decay}                       \\\\\n        &\\hspace{18mm} \\theta_t \\leftarrow \\theta_{t} - \\gamma \\lambda \\theta_{t}            \\\\\n        &\\hspace{12mm}\\textbf{else}                                                          \\\\\n        &\\hspace{18mm} g_t \\leftarrow g_t + \\lambda \\theta_{t}                               \\\\\n        &\\hspace{6mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n        &\\hspace{6mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n        &\\hspace{6mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n        &\\hspace{6mm}\\rho_t \\leftarrow \\rho_{\\infty} -\n            2 t \\beta^t_2 /\\big(1-\\beta_2^t \\big)                                    \\\\[0.1.ex]\n        &\\hspace{6mm}\\textbf{if} \\: \\rho_t > 5                                               \\\\\n        &\\hspace{12mm} l_t \\leftarrow \\frac{\\sqrt{ (1-\\beta^t_2) }}{ \\sqrt{v_t} +\\epsilon  } \\\\\n        &\\hspace{12mm} r_t \\leftarrow\n  \\sqrt{\\frac{(\\rho_t-4)(\\rho_t-2)\\rho_{\\infty}}{(\\rho_{\\infty}-4)(\\rho_{\\infty}-2) \\rho_t}} \\\\\n        &\\hspace{12mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t} r_t l_t        \\\\\n        &\\hspace{6mm}\\textbf{else}                                                           \\\\\n        &\\hspace{12mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}                \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to `On the variance of the adaptive learning rate and beyond`_.\n\nThis implementation provides an option to use either the original weight_decay implementation as in Adam\n(where the weight_decay is applied to the gradient) or the one from AdamW (where weight_decay is applied\nto the weight) through the decoupled_weight_decay option. When decoupled_weight_decay is set to False\n(default), it uses the original Adam style weight decay, otherwise, it uses the AdamW style which\ncorresponds more closely to the `author's implementation`_ in the RAdam paper. Further information\nabout decoupled weight decay can be found in `Decoupled Weight Decay Regularization`_.\n\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 1e-3)\n    betas (Tuple[float, float], optional): coefficients used for computing\n        running averages of gradient and its square (default: (0.9, 0.999))\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-8)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    decoupled_weight_decay (bool, optional): whether to decouple the weight\n        decay as in AdamW to obtain RAdamW. If True, the algorithm does not\n        accumulate weight decay in the momentum nor variance. (default: False)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n\n.. _On the variance of the adaptive learning rate and beyond:\n    https://arxiv.org/abs/1908.03265\n.. _author's implementation:\n    https://github.com/LiyuanLucasLiu/RAdam\n.. _Decoupled Weight Decay Regularization:\n    https://arxiv.org/abs/1711.05101",
        "has_varargs": false
      },
      {
        "name": "RMSprop",
        "api_path": "torch.optim.RMSprop",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "Union"
          },
          {
            "name": "alpha",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.99",
            "annotation": "float"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "centered",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "capturable",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "foreach",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements RMSprop algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\alpha \\text{ (alpha)}, \\: \\gamma \\text{ (lr)},\n            \\: \\theta_0 \\text{ (params)}, \\: f(\\theta) \\text{ (objective)}                   \\\\\n        &\\hspace{13mm}   \\lambda \\text{ (weight decay)},\\: \\mu \\text{ (momentum)},\n            \\: centered, \\: \\epsilon \\text{ (epsilon)}                                       \\\\\n        &\\textbf{initialize} : v_0 \\leftarrow 0 \\text{ (square average)}, \\:\n            \\textbf{b}_0 \\leftarrow 0 \\text{ (buffer)}, \\: g^{ave}_0 \\leftarrow 0     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n        &\\hspace{5mm}if \\: \\lambda \\neq 0                                                    \\\\\n        &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n        &\\hspace{5mm}v_t           \\leftarrow   \\alpha v_{t-1} + (1 - \\alpha) g^2_t\n            \\hspace{8mm}                                                                     \\\\\n        &\\hspace{5mm} \\tilde{v_t} \\leftarrow v_t                                             \\\\\n        &\\hspace{5mm}if \\: centered                                                          \\\\\n        &\\hspace{10mm} g^{ave}_t \\leftarrow g^{ave}_{t-1} \\alpha + (1-\\alpha) g_t            \\\\\n        &\\hspace{10mm} \\tilde{v_t} \\leftarrow \\tilde{v_t} -  \\big(g^{ave}_{t} \\big)^2        \\\\\n        &\\hspace{5mm}if \\: \\mu > 0                                                           \\\\\n        &\\hspace{10mm} \\textbf{b}_t\\leftarrow \\mu \\textbf{b}_{t-1} +\n            g_t/ \\big(\\sqrt{\\tilde{v_t}} +  \\epsilon \\big)                                   \\\\\n        &\\hspace{10mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\textbf{b}_t                \\\\\n        &\\hspace{5mm} else                                                                   \\\\\n        &\\hspace{10mm}\\theta_t      \\leftarrow   \\theta_{t-1} -\n            \\gamma  g_t/ \\big(\\sqrt{\\tilde{v_t}} + \\epsilon \\big)  \\hspace{3mm}              \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to\n`lecture notes <https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>`_ by G. Hinton.\nand centered version `Generating Sequences\nWith Recurrent Neural Networks <https://arxiv.org/pdf/1308.0850v5.pdf>`_.\nThe implementation here takes the square root of the gradient average before\nadding epsilon (note that TensorFlow interchanges these two operations). The effective\nlearning rate is thus :math:`\\gamma/(\\sqrt{v} + \\epsilon)` where :math:`\\gamma`\nis the scheduled learning rate and :math:`v` is the weighted moving average\nof the squared gradient.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 1e-2)\n    alpha (float, optional): smoothing constant (default: 0.99)\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-8)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    momentum (float, optional): momentum factor (default: 0)\n    centered (bool, optional) : if ``True``, compute the centered RMSProp,\n        the gradient is normalized by an estimation of its variance\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)",
        "has_varargs": false
      },
      {
        "name": "Rprop",
        "api_path": "torch.optim.Rprop",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "Union"
          },
          {
            "name": "etas",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(0.5, 1.2)",
            "annotation": "tuple"
          },
          {
            "name": "step_sizes",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(1e-06, 50)",
            "annotation": "tuple"
          },
          {
            "name": "capturable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "foreach",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Implements the resilient backpropagation algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\theta_0 \\in \\mathbf{R}^d \\text{ (params)},f(\\theta)\n            \\text{ (objective)},                                                             \\\\\n        &\\hspace{13mm}      \\eta_{+/-} \\text{ (etaplus, etaminus)}, \\Gamma_{max/min}\n            \\text{ (step sizes)}                                                             \\\\\n        &\\textbf{initialize} :   g^0_{prev} \\leftarrow 0,\n            \\: \\eta_0 \\leftarrow \\text{lr (learning rate)}                                   \\\\\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n        &\\hspace{5mm} \\textbf{for} \\text{  } i = 0, 1, \\ldots, d-1 \\: \\mathbf{do}            \\\\\n        &\\hspace{10mm}  \\textbf{if} \\:   g^i_{prev} g^i_t  > 0                               \\\\\n        &\\hspace{15mm}  \\eta^i_t \\leftarrow \\mathrm{min}(\\eta^i_{t-1} \\eta_{+},\n            \\Gamma_{max})                                                                    \\\\\n        &\\hspace{10mm}  \\textbf{else if}  \\:  g^i_{prev} g^i_t < 0                           \\\\\n        &\\hspace{15mm}  \\eta^i_t \\leftarrow \\mathrm{max}(\\eta^i_{t-1} \\eta_{-},\n            \\Gamma_{min})                                                                    \\\\\n        &\\hspace{15mm}  g^i_t \\leftarrow 0                                                   \\\\\n        &\\hspace{10mm}  \\textbf{else}  \\:                                                    \\\\\n        &\\hspace{15mm}  \\eta^i_t \\leftarrow \\eta^i_{t-1}                                     \\\\\n        &\\hspace{5mm}\\theta_t \\leftarrow \\theta_{t-1}- \\eta_t \\mathrm{sign}(g_t)             \\\\\n        &\\hspace{5mm}g_{prev} \\leftarrow  g_t                                                \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to the paper\n`A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm\n<http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.1417>`_.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, optional): learning rate (default: 1e-2)\n    etas (Tuple[float, float], optional): pair of (etaminus, etaplus), that\n        are multiplicative increase and decrease factors\n        (default: (0.5, 1.2))\n    step_sizes (Tuple[float, float], optional): a pair of minimal and\n        maximal allowed step sizes (default: (1e-6, 50))\n    capturable (bool, optional): whether this instance is safe to\n        capture in a graph, whether for CUDA graphs or for torch.compile support.\n        Tensors are only capturable when on supported :ref:`accelerators<accelerators>`.\n        Passing True can impair ungraphed performance, so if you don't intend to graph\n        capture this instance, leave it False (default: False)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)",
        "has_varargs": false
      },
      {
        "name": "SGD",
        "api_path": "torch.optim.SGD",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.001",
            "annotation": "Union"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "dampening",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "float"
          },
          {
            "name": "weight_decay",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "nesterov",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "maximize",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "foreach",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "differentiable",
            "kind": "KEYWORD_ONLY",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "fused",
            "kind": "KEYWORD_ONLY",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Implements stochastic gradient descent (optionally with momentum).\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)}, \\: f(\\theta)\n            \\text{ (objective)}, \\: \\lambda \\text{ (weight decay)},                          \\\\\n        &\\hspace{13mm} \\:\\mu \\text{ (momentum)}, \\:\\tau \\text{ (dampening)},\n        \\:\\textit{ nesterov,}\\:\\textit{ maximize}                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n        &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n        &\\hspace{5mm}\\textbf{else}                                                           \\\\\n        &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n        &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\n        &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n        &\\hspace{5mm}\\textbf{if} \\: \\mu \\neq 0                                               \\\\\n        &\\hspace{10mm}\\textbf{if} \\: t > 1                                                   \\\\\n        &\\hspace{15mm} \\textbf{b}_t \\leftarrow \\mu \\textbf{b}_{t-1} + (1-\\tau) g_t           \\\\\n        &\\hspace{10mm}\\textbf{else}                                                          \\\\\n        &\\hspace{15mm} \\textbf{b}_t \\leftarrow g_t                                           \\\\\n        &\\hspace{10mm}\\textbf{if} \\: \\textit{nesterov}                                       \\\\\n        &\\hspace{15mm} g_t \\leftarrow g_{t} + \\mu \\textbf{b}_t                               \\\\\n        &\\hspace{10mm}\\textbf{else}                                                   \\\\[-1.ex]\n        &\\hspace{15mm} g_t  \\leftarrow  \\textbf{b}_t                                         \\\\\n        &\\hspace{5mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma g_t                    \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nNesterov momentum is based on the formula from\n`On the importance of initialization and momentum in deep learning`__.\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 1e-3)\n    momentum (float, optional): momentum factor (default: 0)\n    dampening (float, optional): dampening for momentum (default: 0)\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    nesterov (bool, optional): enables Nesterov momentum. Only applicable\n        when momentum is non-zero. (default: False)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n    foreach (bool, optional): whether foreach implementation of optimizer\n        is used. If unspecified by the user (so foreach is None), we will try to use\n        foreach over the for-loop implementation on CUDA, since it is usually\n        significantly more performant. Note that the foreach implementation uses\n        ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n        being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n        parameters through the optimizer at a time or switch this flag to False (default: None)\n    differentiable (bool, optional): whether autograd should\n        occur through the optimizer step in training. Otherwise, the step()\n        function runs in a torch.no_grad() context. Setting to True can impair\n        performance, so leave it False if you don't intend to run autograd\n        through this instance (default: False)\n    fused (bool, optional): whether the fused implementation is used.\n        Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n        are supported. (default: None)\n\n.. note:: The foreach and fused implementations are typically faster than the for-loop,\n          single-tensor implementation, with fused being theoretically fastest with both\n          vertical and horizontal fusion. As such, if the user has not specified either\n          flag (i.e., when foreach = fused = None), we will attempt defaulting to the foreach\n          implementation when the tensors are all on CUDA. Why not fused? Since the fused\n          implementation is relatively new, we want to give it sufficient bake-in time.\n          To specify fused, pass True for fused. To force running the for-loop\n          implementation, pass False for either foreach or fused. \n\n\nExample:\n    >>> # xdoctest: +SKIP\n    >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n    >>> optimizer.zero_grad()\n    >>> loss_fn(model(input), target).backward()\n    >>> optimizer.step()\n\n__ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf\n\n.. note::\n    The implementation of SGD with Momentum/Nesterov subtly differs from\n    Sutskever et al. and implementations in some other frameworks.\n\n    Considering the specific case of Momentum, the update can be written as\n\n    .. math::\n        \\begin{aligned}\n            v_{t+1} & = \\mu * v_{t} + g_{t+1}, \\\\\n            p_{t+1} & = p_{t} - \\text{lr} * v_{t+1},\n        \\end{aligned}\n\n    where :math:`p`, :math:`g`, :math:`v` and :math:`\\mu` denote the\n    parameters, gradient, velocity, and momentum respectively.\n\n    This is in contrast to Sutskever et al. and\n    other frameworks which employ an update of the form\n\n    .. math::\n        \\begin{aligned}\n            v_{t+1} & = \\mu * v_{t} + \\text{lr} * g_{t+1}, \\\\\n            p_{t+1} & = p_{t} - v_{t+1}.\n        \\end{aligned}\n\n    The Nesterov version is analogously modified.\n\n    Moreover, the initial value of the momentum buffer is set to the\n    gradient value at the first step. This is in contrast to some other\n    frameworks that initialize it to all zeros. One notable side effect\n    of this decision is that the first momentum value will not be scaled\n    by dampening. Dampening will be applied starting at the second step.",
        "has_varargs": false
      },
      {
        "name": "SparseAdam",
        "api_path": "torch.optim.SparseAdam",
        "kind": "class",
        "params": [
          {
            "name": "params",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "lr",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.001",
            "annotation": "Union"
          },
          {
            "name": "betas",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "(0.9, 0.999)",
            "annotation": "tuple"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          },
          {
            "name": "maximize",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "SparseAdam implements a masked version of the Adam algorithm\nsuitable for sparse gradients. Currently, due to implementation constraints (explained\nbelow), SparseAdam is only intended for a narrow subset of use cases, specifically\nparameters of a dense layout with gradients of a sparse layout. This occurs in a\nspecial case where the module backwards produces grads already in a sparse layout.\nOne example NN module that behaves as such is ``nn.Embedding(sparse=True)``.\n\nSparseAdam approximates the Adam algorithm by masking out the parameter and moment\nupdates corresponding to the zero values in the gradients. Whereas the Adam algorithm\nwill update the first moment, the second moment, and the parameters based on all values\nof the gradients, SparseAdam only updates the moments and parameters corresponding\nto the non-zero values of the gradients.\n\nA simplified way of thinking about the `intended` implementation is as such:\n\n1. Create a mask of the non-zero values in the sparse gradients. For example,\n   if your gradient looks like [0, 5, 0, 0, 9], the mask would be [0, 1, 0, 0, 1].\n2. Apply this mask over the running moments and do computation on only the\n   non-zero values.\n3. Apply this mask over the parameters and only apply an update on non-zero values.\n\nIn actuality, we use sparse layout Tensors to optimize this approximation, which means the\nmore gradients that are masked by not being materialized, the more performant the optimization.\nSince we rely on using sparse layout tensors, we infer that any materialized value in the\nsparse layout is non-zero and we do NOT actually verify that all values are not zero!\nIt is important to not conflate a semantically sparse tensor (a tensor where many\nof its values are zeros) with a sparse layout tensor (a tensor where ``.is_sparse``\nreturns ``True``). The SparseAdam approximation is intended for `semantically` sparse\ntensors and the sparse layout is only a implementation detail. A clearer implementation\nwould be to use MaskedTensors, but those are experimental.\n\n\n.. note::\n\n    If you suspect your gradients are semantically sparse (but do not have sparse\n    layout), this variant may not be the best for you. Ideally, you want to avoid\n    materializing anything that is suspected to be sparse in the first place, since\n    needing to convert all your grads from dense layout to sparse layout may outweigh\n    the performance gain. Here, using Adam may be the best alternative, unless you\n    can easily rig up your module to output sparse grads similar to\n    ``nn.Embedding(sparse=True)``. If you insist on converting your grads, you can do\n    so by manually overriding your parameters' ``.grad`` fields with their sparse\n    equivalents before calling ``.step()``.\n\n\nArgs:\n    params (iterable): iterable of parameters or named_parameters to optimize\n        or iterable of dicts defining parameter groups. When using named_parameters,\n        all parameters in all groups should be named\n    lr (float, Tensor, optional): learning rate (default: 1e-3)\n    betas (Tuple[float, float], optional): coefficients used for computing\n        running averages of gradient and its square (default: (0.9, 0.999))\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-8)\n    maximize (bool, optional): maximize the objective with respect to the\n        params, instead of minimizing (default: False)\n\n.. _Adam\\: A Method for Stochastic Optimization:\n    https://arxiv.org/abs/1412.6980",
        "has_varargs": false
      }
    ],
    "layer": [
      {
        "name": "AdaptiveAvgPool1d",
        "api_path": "torch.nn.AdaptiveAvgPool1d",
        "kind": "class",
        "params": [
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Applies a 1D adaptive average pooling over an input signal composed of several input planes.\n\nThe output size is :math:`L_{out}`, for any input size.\nThe number of output features is equal to the number of input planes.\n\nArgs:\n    output_size: the target output size :math:`L_{out}`.\n\nShape:\n    - Input: :math:`(N, C, L_{in})` or :math:`(C, L_{in})`.\n    - Output: :math:`(N, C, L_{out})` or :math:`(C, L_{out})`, where\n      :math:`L_{out}=\\text{output\\_size}`.\n\nExamples:\n    >>> # target output size of 5\n    >>> m = nn.AdaptiveAvgPool1d(5)\n    >>> input = torch.randn(1, 64, 8)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "AdaptiveAvgPool2d",
        "api_path": "torch.nn.AdaptiveAvgPool2d",
        "kind": "class",
        "params": [
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Applies a 2D adaptive average pooling over an input signal composed of several input planes.\n\nThe output is of size H x W, for any input size.\nThe number of output features is equal to the number of input planes.\n\nArgs:\n    output_size: the target output size of the image of the form H x W.\n                 Can be a tuple (H, W) or a single H for a square image H x H.\n                 H and W can be either a ``int``, or ``None`` which means the size will\n                 be the same as that of the input.\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, S_{0}, S_{1})` or :math:`(C, S_{0}, S_{1})`, where\n      :math:`S=\\text{output\\_size}`.\n\nExamples:\n    >>> # target output size of 5x7\n    >>> m = nn.AdaptiveAvgPool2d((5, 7))\n    >>> input = torch.randn(1, 64, 8, 9)\n    >>> output = m(input)\n    >>> # target output size of 7x7 (square)\n    >>> m = nn.AdaptiveAvgPool2d(7)\n    >>> input = torch.randn(1, 64, 10, 9)\n    >>> output = m(input)\n    >>> # target output size of 10x7\n    >>> m = nn.AdaptiveAvgPool2d((None, 7))\n    >>> input = torch.randn(1, 64, 10, 9)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "AdaptiveAvgPool3d",
        "api_path": "torch.nn.AdaptiveAvgPool3d",
        "kind": "class",
        "params": [
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Applies a 3D adaptive average pooling over an input signal composed of several input planes.\n\nThe output is of size D x H x W, for any input size.\nThe number of output features is equal to the number of input planes.\n\nArgs:\n    output_size: the target output size of the form D x H x W.\n                 Can be a tuple (D, H, W) or a single number D for a cube D x D x D.\n                 D, H and W can be either a ``int``, or ``None`` which means the size will\n                 be the same as that of the input.\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, S_{0}, S_{1}, S_{2})` or :math:`(C, S_{0}, S_{1}, S_{2})`,\n      where :math:`S=\\text{output\\_size}`.\n\nExamples:\n    >>> # target output size of 5x7x9\n    >>> m = nn.AdaptiveAvgPool3d((5, 7, 9))\n    >>> input = torch.randn(1, 64, 8, 9, 10)\n    >>> output = m(input)\n    >>> # target output size of 7x7x7 (cube)\n    >>> m = nn.AdaptiveAvgPool3d(7)\n    >>> input = torch.randn(1, 64, 10, 9, 8)\n    >>> output = m(input)\n    >>> # target output size of 7x9x8\n    >>> m = nn.AdaptiveAvgPool3d((7, None, None))\n    >>> input = torch.randn(1, 64, 10, 9, 8)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "AdaptiveMaxPool1d",
        "api_path": "torch.nn.AdaptiveMaxPool1d",
        "kind": "class",
        "params": [
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "return_indices",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 1D adaptive max pooling over an input signal composed of several input planes.\n\nThe output size is :math:`L_{out}`, for any input size.\nThe number of output features is equal to the number of input planes.\n\nArgs:\n    output_size: the target output size :math:`L_{out}`.\n    return_indices: if ``True``, will return the indices along with the outputs.\n                    Useful to pass to nn.MaxUnpool1d. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, L_{in})` or :math:`(C, L_{in})`.\n    - Output: :math:`(N, C, L_{out})` or :math:`(C, L_{out})`, where\n      :math:`L_{out}=\\text{output\\_size}`.\n\nExamples:\n    >>> # target output size of 5\n    >>> m = nn.AdaptiveMaxPool1d(5)\n    >>> input = torch.randn(1, 64, 8)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "AdaptiveMaxPool2d",
        "api_path": "torch.nn.AdaptiveMaxPool2d",
        "kind": "class",
        "params": [
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "return_indices",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 2D adaptive max pooling over an input signal composed of several input planes.\n\nThe output is of size :math:`H_{out} \\times W_{out}`, for any input size.\nThe number of output features is equal to the number of input planes.\n\nArgs:\n    output_size: the target output size of the image of the form :math:`H_{out} \\times W_{out}`.\n                 Can be a tuple :math:`(H_{out}, W_{out})` or a single :math:`H_{out}` for a\n                 square image :math:`H_{out} \\times H_{out}`. :math:`H_{out}` and :math:`W_{out}`\n                 can be either a ``int``, or ``None`` which means the size will be the same as that\n                 of the input.\n    return_indices: if ``True``, will return the indices along with the outputs.\n                    Useful to pass to nn.MaxUnpool2d. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n      :math:`(H_{out}, W_{out})=\\text{output\\_size}`.\n\nExamples:\n    >>> # target output size of 5x7\n    >>> m = nn.AdaptiveMaxPool2d((5, 7))\n    >>> input = torch.randn(1, 64, 8, 9)\n    >>> output = m(input)\n    >>> # target output size of 7x7 (square)\n    >>> m = nn.AdaptiveMaxPool2d(7)\n    >>> input = torch.randn(1, 64, 10, 9)\n    >>> output = m(input)\n    >>> # target output size of 10x7\n    >>> m = nn.AdaptiveMaxPool2d((None, 7))\n    >>> input = torch.randn(1, 64, 10, 9)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "AdaptiveMaxPool3d",
        "api_path": "torch.nn.AdaptiveMaxPool3d",
        "kind": "class",
        "params": [
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "return_indices",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 3D adaptive max pooling over an input signal composed of several input planes.\n\nThe output is of size :math:`D_{out} \\times H_{out} \\times W_{out}`, for any input size.\nThe number of output features is equal to the number of input planes.\n\nArgs:\n    output_size: the target output size of the image of the form :math:`D_{out} \\times H_{out} \\times W_{out}`.\n                 Can be a tuple :math:`(D_{out}, H_{out}, W_{out})` or a single\n                 :math:`D_{out}` for a cube :math:`D_{out} \\times D_{out} \\times D_{out}`.\n                 :math:`D_{out}`, :math:`H_{out}` and :math:`W_{out}` can be either a\n                 ``int``, or ``None`` which means the size will be the same as that of the input.\n\n    return_indices: if ``True``, will return the indices along with the outputs.\n                    Useful to pass to nn.MaxUnpool3d. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or :math:`(C, D_{out}, H_{out}, W_{out})`,\n      where :math:`(D_{out}, H_{out}, W_{out})=\\text{output\\_size}`.\n\nExamples:\n    >>> # target output size of 5x7x9\n    >>> m = nn.AdaptiveMaxPool3d((5, 7, 9))\n    >>> input = torch.randn(1, 64, 8, 9, 10)\n    >>> output = m(input)\n    >>> # target output size of 7x7x7 (cube)\n    >>> m = nn.AdaptiveMaxPool3d(7)\n    >>> input = torch.randn(1, 64, 10, 9, 8)\n    >>> output = m(input)\n    >>> # target output size of 7x9x8\n    >>> m = nn.AdaptiveMaxPool3d((7, None, None))\n    >>> input = torch.randn(1, 64, 10, 9, 8)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "AlphaDropout",
        "api_path": "torch.nn.AlphaDropout",
        "kind": "class",
        "params": [
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies Alpha Dropout over the input.\n\nAlpha Dropout is a type of Dropout that maintains the self-normalizing\nproperty.\nFor an input with zero mean and unit standard deviation, the output of\nAlpha Dropout maintains the original mean and standard deviation of the\ninput.\nAlpha Dropout goes hand-in-hand with SELU activation function, which ensures\nthat the outputs have zero mean and unit standard deviation.\n\nDuring training, it randomly masks some of the elements of the input\ntensor with probability *p* using samples from a bernoulli distribution.\nThe elements to masked are randomized on every forward call, and scaled\nand shifted to maintain zero mean and unit standard deviation.\n\nDuring evaluation the module simply computes an identity function.\n\nMore details can be found in the paper `Self-Normalizing Neural Networks`_ .\n\nArgs:\n    p (float): probability of an element to be dropped. Default: 0.5\n    inplace (bool, optional): If set to ``True``, will do this operation\n        in-place\n\nShape:\n    - Input: :math:`(*)`. Input can be of any shape\n    - Output: :math:`(*)`. Output is of the same shape as input\n\nExamples::\n\n    >>> m = nn.AlphaDropout(p=0.2)\n    >>> input = torch.randn(20, 16)\n    >>> output = m(input)\n\n.. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515",
        "has_varargs": false
      },
      {
        "name": "AvgPool1d",
        "api_path": "torch.nn.AvgPool1d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "count_include_pad",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 1D average pooling over an input signal composed of several input planes.\n\nIn the simplest case, the output value of the layer with input size :math:`(N, C, L)`,\noutput :math:`(N, C, L_{out})` and :attr:`kernel_size` :math:`k`\ncan be precisely described as:\n\n.. math::\n\n    \\text{out}(N_i, C_j, l) = \\frac{1}{k} \\sum_{m=0}^{k-1}\n                           \\text{input}(N_i, C_j, \\text{stride} \\times l + m)\n\nIf :attr:`padding` is non-zero, then the input is implicitly zero-padded on both sides\nfor :attr:`padding` number of points.\n\nNote:\n    When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\n    or the input. Sliding windows that would start in the right padded region are ignored.\n\n.. note::\n    pad should be at most half of effective kernel size.\n\nThe parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding` can each be\nan ``int`` or a one-element tuple.\n\nArgs:\n    kernel_size: the size of the window\n    stride: the stride of the window. Default value is :attr:`kernel_size`\n    padding: implicit zero padding to be added on both sides\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n    count_include_pad: when True, will include the zero-padding in the averaging calculation\n\nShape:\n    - Input: :math:`(N, C, L_{in})` or :math:`(C, L_{in})`.\n    - Output: :math:`(N, C, L_{out})` or :math:`(C, L_{out})`, where\n\n      .. math::\n          L_{out} = \\left\\lfloor \\frac{L_{in} +\n          2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} + 1\\right\\rfloor\n\n      Per the note above, if ``ceil_mode`` is True and :math:`(L_{out} - 1) \\times \\text{stride} \\geq L_{in}\n      + \\text{padding}`, we skip the last window as it would start in the right padded region, resulting in\n      :math:`L_{out}` being reduced by one.\n\nExamples::\n\n    >>> # pool with window of size=3, stride=2\n    >>> m = nn.AvgPool1d(3, stride=2)\n    >>> m(torch.tensor([[[1., 2, 3, 4, 5, 6, 7]]]))\n    tensor([[[2., 4., 6.]]])",
        "has_varargs": false
      },
      {
        "name": "AvgPool2d",
        "api_path": "torch.nn.AvgPool2d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "count_include_pad",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "divisor_override",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies a 2D average pooling over an input signal composed of several input planes.\n\nIn the simplest case, the output value of the layer with input size :math:`(N, C, H, W)`,\noutput :math:`(N, C, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kH, kW)`\ncan be precisely described as:\n\n.. math::\n\n    out(N_i, C_j, h, w)  = \\frac{1}{kH * kW} \\sum_{m=0}^{kH-1} \\sum_{n=0}^{kW-1}\n                           input(N_i, C_j, stride[0] \\times h + m, stride[1] \\times w + n)\n\nIf :attr:`padding` is non-zero, then the input is implicitly zero-padded on both sides\nfor :attr:`padding` number of points.\n\nNote:\n    When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\n    or the input. Sliding windows that would start in the right padded region are ignored.\n\n.. note::\n    pad should be at most half of effective kernel size.\n\nThe parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding` can either be:\n\n    - a single ``int`` or a single-element tuple -- in which case the same value is used for the height and width dimension\n    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n      and the second `int` for the width dimension\n\nArgs:\n    kernel_size: the size of the window\n    stride: the stride of the window. Default value is :attr:`kernel_size`\n    padding: implicit zero padding to be added on both sides\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n    count_include_pad: when True, will include the zero-padding in the averaging calculation\n    divisor_override: if specified, it will be used as divisor, otherwise size of the pooling region will be used.\n\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n\n      .. math::\n          H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] -\n            \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\n\n      .. math::\n          W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] -\n            \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\n\n      Per the note above, if ``ceil_mode`` is True and :math:`(H_{out} - 1)\\times \\text{stride}[0]\\geq H_{in}\n      + \\text{padding}[0]`, we skip the last window as it would start in the bottom padded region,\n      resulting in :math:`H_{out}` being reduced by one.\n\n      The same applies for :math:`W_{out}`.\n\nExamples::\n\n    >>> # pool of square window of size=3, stride=2\n    >>> m = nn.AvgPool2d(3, stride=2)\n    >>> # pool of non-square window\n    >>> m = nn.AvgPool2d((3, 2), stride=(2, 1))\n    >>> input = torch.randn(20, 16, 50, 32)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "AvgPool3d",
        "api_path": "torch.nn.AvgPool3d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "count_include_pad",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "divisor_override",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies a 3D average pooling over an input signal composed of several input planes.\n\nIn the simplest case, the output value of the layer with input size :math:`(N, C, D, H, W)`,\noutput :math:`(N, C, D_{out}, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kD, kH, kW)`\ncan be precisely described as:\n\n.. math::\n    \\begin{aligned}\n        \\text{out}(N_i, C_j, d, h, w) ={} & \\sum_{k=0}^{kD-1} \\sum_{m=0}^{kH-1} \\sum_{n=0}^{kW-1} \\\\\n                                          & \\frac{\\text{input}(N_i, C_j, \\text{stride}[0] \\times d + k,\n                                                  \\text{stride}[1] \\times h + m, \\text{stride}[2] \\times w + n)}\n                                                 {kD \\times kH \\times kW}\n    \\end{aligned}\n\nIf :attr:`padding` is non-zero, then the input is implicitly zero-padded on all three sides\nfor :attr:`padding` number of points.\n\nNote:\n    When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\n    or the input. Sliding windows that would start in the right padded region are ignored.\n\n.. note::\n    pad should be at most half of effective kernel size.\n\nThe parameters :attr:`kernel_size`, :attr:`stride` can either be:\n\n    - a single ``int`` -- in which case the same value is used for the depth, height and width dimension\n    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,\n      the second `int` for the height dimension and the third `int` for the width dimension\n\nArgs:\n    kernel_size: the size of the window\n    stride: the stride of the window. Default value is :attr:`kernel_size`\n    padding: implicit zero padding to be added on all three sides\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n    count_include_pad: when True, will include the zero-padding in the averaging calculation\n    divisor_override: if specified, it will be used as divisor, otherwise :attr:`kernel_size` will be used\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or\n      :math:`(C, D_{out}, H_{out}, W_{out})`, where\n\n      .. math::\n          D_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] -\n                \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\n\n      .. math::\n          H_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] -\n                \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\n\n      .. math::\n          W_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] -\n                \\text{kernel\\_size}[2]}{\\text{stride}[2]} + 1\\right\\rfloor\n\n      Per the note above, if ``ceil_mode`` is True and :math:`(D_{out} - 1)\\times \\text{stride}[0]\\geq D_{in}\n      + \\text{padding}[0]`, we skip the last window as it would start in the padded region,\n      resulting in :math:`D_{out}` being reduced by one.\n\n      The same applies for :math:`W_{out}` and :math:`H_{out}`.\n\nExamples::\n\n    >>> # pool of square window of size=3, stride=2\n    >>> m = nn.AvgPool3d(3, stride=2)\n    >>> # pool of non-square window\n    >>> m = nn.AvgPool3d((3, 2, 2), stride=(2, 1, 2))\n    >>> input = torch.randn(20, 16, 50, 44, 31)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "BatchNorm1d",
        "api_path": "torch.nn.BatchNorm1d",
        "kind": "class",
        "params": [
          {
            "name": "num_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "Optional"
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Batch Normalization over a 2D or 3D input.\n\nMethod described in the paper\n`Batch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift <https://arxiv.org/abs/1502.03167>`__ .\n\n.. math::\n\n    y = \\frac{x - \\mathrm{E}[x]}{\\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\nof size `C` (where `C` is the number of features or channels of the input). By default, the\nelements of :math:`\\gamma` are set to 1 and the elements of :math:`\\beta` are set to 0.\nAt train time in the forward pass, the variance is calculated via the biased estimator,\nequivalent to ``torch.var(input, unbiased=False)``. However, the value stored in the\nmoving average of the variance is calculated via the unbiased  estimator, equivalent to\n``torch.var(input, unbiased=True)``.\n\nAlso by default, during training this layer keeps running estimates of its\ncomputed mean and variance, which are then used for normalization during\nevaluation. The running estimates are kept with a default :attr:`momentum`\nof 0.1.\n\nIf :attr:`track_running_stats` is set to ``False``, this layer then does not\nkeep running estimates, and batch statistics are instead used during\nevaluation time as well.\n\n.. note::\n    This :attr:`momentum` argument is different from one used in optimizer\n    classes and the conventional notion of momentum. Mathematically, the\n    update rule for running statistics here is\n    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n    new observed value.\n\nBecause the Batch Normalization is done over the `C` dimension, computing statistics\non `(N, L)` slices, it's common terminology to call this Temporal Batch Normalization.\n\nArgs:\n    num_features: number of features or channels :math:`C` of the input\n    eps: a value added to the denominator for numerical stability.\n        Default: 1e-5\n    momentum: the value used for the running_mean and running_var\n        computation. Can be set to ``None`` for cumulative moving average\n        (i.e. simple average). Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters. Default: ``True``\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics, and initializes statistics\n        buffers :attr:`running_mean` and :attr:`running_var` as ``None``.\n        When these buffers are ``None``, this module always uses batch statistics.\n        in both training and eval modes. Default: ``True``\n\nShape:\n    - Input: :math:`(N, C)` or :math:`(N, C, L)`, where :math:`N` is the batch size,\n      :math:`C` is the number of features or channels, and :math:`L` is the sequence length\n    - Output: :math:`(N, C)` or :math:`(N, C, L)` (same shape as input)\n\nExamples::\n\n    >>> # With Learnable Parameters\n    >>> m = nn.BatchNorm1d(100)\n    >>> # Without Learnable Parameters\n    >>> m = nn.BatchNorm1d(100, affine=False)\n    >>> input = torch.randn(20, 100)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "BatchNorm2d",
        "api_path": "torch.nn.BatchNorm2d",
        "kind": "class",
        "params": [
          {
            "name": "num_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "Optional"
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Batch Normalization over a 4D input.\n\n4D is a mini-batch of 2D inputs\nwith additional channel dimension. Method described in the paper\n`Batch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift <https://arxiv.org/abs/1502.03167>`__ .\n\n.. math::\n\n    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\nof size `C` (where `C` is the input size). By default, the elements of :math:`\\gamma` are set\nto 1 and the elements of :math:`\\beta` are set to 0. At train time in the forward pass, the\nstandard-deviation is calculated via the biased estimator, equivalent to\n``torch.var(input, unbiased=False)``. However, the value stored in the moving average of the\nstandard-deviation is calculated via the unbiased  estimator, equivalent to\n``torch.var(input, unbiased=True)``.\n\nAlso by default, during training this layer keeps running estimates of its\ncomputed mean and variance, which are then used for normalization during\nevaluation. The running estimates are kept with a default :attr:`momentum`\nof 0.1.\n\nIf :attr:`track_running_stats` is set to ``False``, this layer then does not\nkeep running estimates, and batch statistics are instead used during\nevaluation time as well.\n\n.. note::\n    This :attr:`momentum` argument is different from one used in optimizer\n    classes and the conventional notion of momentum. Mathematically, the\n    update rule for running statistics here is\n    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n    new observed value.\n\nBecause the Batch Normalization is done over the `C` dimension, computing statistics\non `(N, H, W)` slices, it's common terminology to call this Spatial Batch Normalization.\n\nArgs:\n    num_features: :math:`C` from an expected input of size\n        :math:`(N, C, H, W)`\n    eps: a value added to the denominator for numerical stability.\n        Default: 1e-5\n    momentum: the value used for the running_mean and running_var\n        computation. Can be set to ``None`` for cumulative moving average\n        (i.e. simple average). Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters. Default: ``True``\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics, and initializes statistics\n        buffers :attr:`running_mean` and :attr:`running_var` as ``None``.\n        When these buffers are ``None``, this module always uses batch statistics.\n        in both training and eval modes. Default: ``True``\n\nShape:\n    - Input: :math:`(N, C, H, W)`\n    - Output: :math:`(N, C, H, W)` (same shape as input)\n\nExamples::\n\n    >>> # With Learnable Parameters\n    >>> m = nn.BatchNorm2d(100)\n    >>> # Without Learnable Parameters\n    >>> m = nn.BatchNorm2d(100, affine=False)\n    >>> input = torch.randn(20, 100, 35, 45)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "BatchNorm3d",
        "api_path": "torch.nn.BatchNorm3d",
        "kind": "class",
        "params": [
          {
            "name": "num_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "Optional"
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Batch Normalization over a 5D input.\n\n5D is a mini-batch of 3D inputs with additional channel dimension as described in the paper\n`Batch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift <https://arxiv.org/abs/1502.03167>`__ .\n\n.. math::\n\n    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\nof size `C` (where `C` is the input size). By default, the elements of :math:`\\gamma` are set\nto 1 and the elements of :math:`\\beta` are set to 0. At train time in the forward pass, the\nstandard-deviation is calculated via the biased estimator, equivalent to\n``torch.var(input, unbiased=False)``. However, the value stored in the moving average of the\nstandard-deviation is calculated via the unbiased  estimator, equivalent to\n``torch.var(input, unbiased=True)``.\n\nAlso by default, during training this layer keeps running estimates of its\ncomputed mean and variance, which are then used for normalization during\nevaluation. The running estimates are kept with a default :attr:`momentum`\nof 0.1.\n\nIf :attr:`track_running_stats` is set to ``False``, this layer then does not\nkeep running estimates, and batch statistics are instead used during\nevaluation time as well.\n\n.. note::\n    This :attr:`momentum` argument is different from one used in optimizer\n    classes and the conventional notion of momentum. Mathematically, the\n    update rule for running statistics here is\n    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n    new observed value.\n\nBecause the Batch Normalization is done over the `C` dimension, computing statistics\non `(N, D, H, W)` slices, it's common terminology to call this Volumetric Batch Normalization\nor Spatio-temporal Batch Normalization.\n\nArgs:\n    num_features: :math:`C` from an expected input of size\n        :math:`(N, C, D, H, W)`\n    eps: a value added to the denominator for numerical stability.\n        Default: 1e-5\n    momentum: the value used for the running_mean and running_var\n        computation. Can be set to ``None`` for cumulative moving average\n        (i.e. simple average). Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters. Default: ``True``\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics, and initializes statistics\n        buffers :attr:`running_mean` and :attr:`running_var` as ``None``.\n        When these buffers are ``None``, this module always uses batch statistics.\n        in both training and eval modes. Default: ``True``\n\nShape:\n    - Input: :math:`(N, C, D, H, W)`\n    - Output: :math:`(N, C, D, H, W)` (same shape as input)\n\nExamples::\n\n    >>> # With Learnable Parameters\n    >>> m = nn.BatchNorm3d(100)\n    >>> # Without Learnable Parameters\n    >>> m = nn.BatchNorm3d(100, affine=False)\n    >>> input = torch.randn(20, 100, 35, 45, 10)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Bilinear",
        "api_path": "torch.nn.Bilinear",
        "kind": "class",
        "params": [
          {
            "name": "in1_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "in2_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "out_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a bilinear transformation to the incoming data: :math:`y = x_1^T A x_2 + b`.\n\nArgs:\n    in1_features: size of each first input sample, must be > 0\n    in2_features: size of each second input sample, must be > 0\n    out_features: size of each output sample, must be > 0\n    bias: If set to ``False``, the layer will not learn an additive bias.\n        Default: ``True``\n\nShape:\n    - Input1: :math:`(*, H_\\text{in1})` where :math:`H_\\text{in1}=\\text{in1\\_features}` and\n      :math:`*` means any number of additional dimensions including none. All but the last dimension\n      of the inputs should be the same.\n    - Input2: :math:`(*, H_\\text{in2})` where :math:`H_\\text{in2}=\\text{in2\\_features}`.\n    - Output: :math:`(*, H_\\text{out})` where :math:`H_\\text{out}=\\text{out\\_features}`\n      and all but the last dimension are the same shape as the input.\n\nAttributes:\n    weight: the learnable weights of the module of shape\n        :math:`(\\text{out\\_features}, \\text{in1\\_features}, \\text{in2\\_features})`.\n        The values are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n        :math:`k = \\frac{1}{\\text{in1\\_features}}`\n    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n            If :attr:`bias` is ``True``, the values are initialized from\n            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n            :math:`k = \\frac{1}{\\text{in1\\_features}}`\n\nExamples::\n\n    >>> m = nn.Bilinear(20, 30, 40)\n    >>> input1 = torch.randn(128, 20)\n    >>> input2 = torch.randn(128, 30)\n    >>> output = m(input1, input2)\n    >>> print(output.size())\n    torch.Size([128, 40])",
        "has_varargs": false
      },
      {
        "name": "CELU",
        "api_path": "torch.nn.CELU",
        "kind": "class",
        "params": [
          {
            "name": "alpha",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the CELU function element-wise.\n\n.. math::\n    \\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))\n\nMore details can be found in the paper `Continuously Differentiable Exponential Linear Units`_ .\n\nArgs:\n    alpha: the :math:`\\alpha` value for the CELU formulation. Default: 1.0\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/CELU.png\n\nExamples::\n\n    >>> m = nn.CELU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)\n\n.. _`Continuously Differentiable Exponential Linear Units`:\n    https://arxiv.org/abs/1704.07483",
        "has_varargs": false
      },
      {
        "name": "ChannelShuffle",
        "api_path": "torch.nn.ChannelShuffle",
        "kind": "class",
        "params": [
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          }
        ],
        "docstring": "Divides and rearranges the channels in a tensor.\n\nThis operation divides the channels in a tensor of shape :math:`(N, C, *)`\ninto g groups as :math:`(N, \\frac{C}{g}, g, *)` and shuffles them,\nwhile retaining the original tensor shape in the final output.\n\nArgs:\n    groups (int): number of groups to divide channels in.\n\nExamples::\n\n    >>> channel_shuffle = nn.ChannelShuffle(2)\n    >>> input = torch.arange(1, 17, dtype=torch.float32).view(1, 4, 2, 2)\n    >>> input\n    tensor([[[[ 1.,  2.],\n              [ 3.,  4.]],\n             [[ 5.,  6.],\n              [ 7.,  8.]],\n             [[ 9., 10.],\n              [11., 12.]],\n             [[13., 14.],\n              [15., 16.]]]])\n    >>> output = channel_shuffle(input)\n    >>> output\n    tensor([[[[ 1.,  2.],\n              [ 3.,  4.]],\n             [[ 9., 10.],\n              [11., 12.]],\n             [[ 5.,  6.],\n              [ 7.,  8.]],\n             [[13., 14.],\n              [15., 16.]]]])",
        "has_varargs": false
      },
      {
        "name": "CircularPad1d",
        "api_path": "torch.nn.CircularPad1d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using circular padding of the input boundary.\n\nTensor values at the beginning of the dimension are used to pad the end,\nand values at the end are used to pad the beginning. If negative padding is\napplied then the ends of the tensor get removed.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 2-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`)\n        Note that padding size should be less than or equal to the corresponding input dimension.\n\nShape:\n    - Input: :math:`(C, W_{in})` or :math:`(N, C, W_{in})`.\n    - Output: :math:`(C, W_{out})` or :math:`(N, C, W_{out})`, where\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"not sure why xdoctest is choking on this\")\n    >>> m = nn.CircularPad1d(2)\n    >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4)\n    >>> input\n    tensor([[[0., 1., 2., 3.],\n             [4., 5., 6., 7.]]])\n    >>> m(input)\n    tensor([[[2., 3., 0., 1., 2., 3., 0., 1.],\n             [6., 7., 4., 5., 6., 7., 4., 5.]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.CircularPad1d((3, 1))\n    >>> m(input)\n    tensor([[[1., 2., 3., 0., 1., 2., 3., 0.],\n             [5., 6., 7., 4., 5., 6., 7., 4.]]])",
        "has_varargs": false
      },
      {
        "name": "CircularPad2d",
        "api_path": "torch.nn.CircularPad2d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using circular padding of the input boundary.\n\nTensor values at the beginning of the dimension are used to pad the end,\nand values at the end are used to pad the beginning. If negative padding is\napplied then the ends of the tensor get removed.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 4-`tuple`, uses (:math:`\\text{padding\\_left}`,\n        :math:`\\text{padding\\_right}`, :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`)\n        Note that padding size should be less than or equal to the corresponding input dimension.\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> m = nn.CircularPad2d(2)\n    >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3)\n    >>> input\n    tensor([[[[0., 1., 2.],\n              [3., 4., 5.],\n              [6., 7., 8.]]]])\n    >>> m(input)\n    tensor([[[[4., 5., 3., 4., 5., 3., 4.],\n              [7., 8., 6., 7., 8., 6., 7.],\n              [1., 2., 0., 1., 2., 0., 1.],\n              [4., 5., 3., 4., 5., 3., 4.],\n              [7., 8., 6., 7., 8., 6., 7.],\n              [1., 2., 0., 1., 2., 0., 1.],\n              [4., 5., 3., 4., 5., 3., 4.]]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.CircularPad2d((1, 1, 2, 0))\n    >>> m(input)\n    tensor([[[[5., 3., 4., 5., 3.],\n              [8., 6., 7., 8., 6.],\n              [2., 0., 1., 2., 0.],\n              [5., 3., 4., 5., 3.],\n              [8., 6., 7., 8., 6.]]]])",
        "has_varargs": false
      },
      {
        "name": "CircularPad3d",
        "api_path": "torch.nn.CircularPad3d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using circular padding of the input boundary.\n\nTensor values at the beginning of the dimension are used to pad the end,\nand values at the end are used to pad the beginning. If negative padding is\napplied then the ends of the tensor get removed.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 6-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`,\n        :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`,\n        :math:`\\text{padding\\_front}`, :math:`\\text{padding\\_back}`)\n        Note that padding size should be less than or equal to the corresponding input dimension.\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or :math:`(C, D_{out}, H_{out}, W_{out})`,\n      where\n\n      :math:`D_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}`\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = nn.CircularPad3d(3)\n    >>> input = torch.randn(16, 3, 8, 320, 480)\n    >>> output = m(input)\n    >>> # using different paddings for different sides\n    >>> m = nn.CircularPad3d((3, 3, 6, 6, 1, 1))\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "ConstantPad1d",
        "api_path": "torch.nn.ConstantPad1d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          }
        ],
        "docstring": "Pads the input tensor boundaries with a constant value.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in both boundaries. If a 2-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`)\n\nShape:\n    - Input: :math:`(C, W_{in})` or :math:`(N, C, W_{in})`.\n    - Output: :math:`(C, W_{out})` or :math:`(N, C, W_{out})`, where\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = nn.ConstantPad1d(2, 3.5)\n    >>> input = torch.randn(1, 2, 4)\n    >>> input\n    tensor([[[-1.0491, -0.7152, -0.0749,  0.8530],\n             [-1.3287,  1.8966,  0.1466, -0.2771]]])\n    >>> m(input)\n    tensor([[[ 3.5000,  3.5000, -1.0491, -0.7152, -0.0749,  0.8530,  3.5000,\n               3.5000],\n             [ 3.5000,  3.5000, -1.3287,  1.8966,  0.1466, -0.2771,  3.5000,\n               3.5000]]])\n    >>> m = nn.ConstantPad1d(2, 3.5)\n    >>> input = torch.randn(1, 2, 3)\n    >>> input\n    tensor([[[ 1.6616,  1.4523, -1.1255],\n             [-3.6372,  0.1182, -1.8652]]])\n    >>> m(input)\n    tensor([[[ 3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000,  3.5000],\n             [ 3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000,  3.5000]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.ConstantPad1d((3, 1), 3.5)\n    >>> m(input)\n    tensor([[[ 3.5000,  3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000],\n             [ 3.5000,  3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000]]])",
        "has_varargs": false
      },
      {
        "name": "ConstantPad2d",
        "api_path": "torch.nn.ConstantPad2d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          }
        ],
        "docstring": "Pads the input tensor boundaries with a constant value.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 4-`tuple`, uses (:math:`\\text{padding\\_left}`,\n        :math:`\\text{padding\\_right}`, :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`)\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = nn.ConstantPad2d(2, 3.5)\n    >>> input = torch.randn(1, 2, 2)\n    >>> input\n    tensor([[[ 1.6585,  0.4320],\n             [-0.8701, -0.4649]]])\n    >>> m(input)\n    tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n             [ 3.5000,  3.5000,  1.6585,  0.4320,  3.5000,  3.5000],\n             [ 3.5000,  3.5000, -0.8701, -0.4649,  3.5000,  3.5000],\n             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.ConstantPad2d((3, 0, 2, 1), 3.5)\n    >>> m(input)\n    tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n             [ 3.5000,  3.5000,  3.5000,  1.6585,  0.4320],\n             [ 3.5000,  3.5000,  3.5000, -0.8701, -0.4649],\n             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])",
        "has_varargs": false
      },
      {
        "name": "ConstantPad3d",
        "api_path": "torch.nn.ConstantPad3d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          }
        ],
        "docstring": "Pads the input tensor boundaries with a constant value.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 6-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`,\n        :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`,\n        :math:`\\text{padding\\_front}`, :math:`\\text{padding\\_back}`)\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or\n      :math:`(C, D_{out}, H_{out}, W_{out})`, where\n\n      :math:`D_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}`\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> m = nn.ConstantPad3d(3, 3.5)\n    >>> input = torch.randn(16, 3, 10, 20, 30)\n    >>> output = m(input)\n    >>> # using different paddings for different sides\n    >>> m = nn.ConstantPad3d((3, 3, 6, 6, 0, 1), 3.5)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Container",
        "api_path": "torch.nn.Container",
        "kind": "class",
        "params": [
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": "Any"
          }
        ],
        "docstring": "Base class for all neural network modules.\n\nYour models should also subclass this class.\n\nModules can also contain other Modules, allowing them to be nested in\na tree structure. You can assign the submodules as regular attributes::\n\n    import torch.nn as nn\n    import torch.nn.functional as F\n\n\n    class Model(nn.Module):\n        def __init__(self) -> None:\n            super().__init__()\n            self.conv1 = nn.Conv2d(1, 20, 5)\n            self.conv2 = nn.Conv2d(20, 20, 5)\n\n        def forward(self, x):\n            x = F.relu(self.conv1(x))\n            return F.relu(self.conv2(x))\n\nSubmodules assigned in this way will be registered, and will also have their\nparameters converted when you call :meth:`to`, etc.\n\n.. note::\n    As per the example above, an ``__init__()`` call to the parent class\n    must be made before assignment on the child.\n\n:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool",
        "has_varargs": false
      },
      {
        "name": "Conv1d",
        "api_path": "torch.nn.Conv1d",
        "kind": "class",
        "params": [
          {
            "name": "in_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a 1D convolution over an input signal composed of several input\nplanes.\n\nIn the simplest case, the output value of the layer with input size\n:math:`(N, C_{\\text{in}}, L)` and output :math:`(N, C_{\\text{out}}, L_{\\text{out}})` can be\nprecisely described as:\n\n.. math::\n    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n    \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n    \\star \\text{input}(N_i, k)\n\nwhere :math:`\\star` is the valid `cross-correlation`_ operator,\n:math:`N` is a batch size, :math:`C` denotes a number of channels,\n:math:`L` is a length of signal sequence.\n\n\nThis module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n* :attr:`stride` controls the stride for the cross-correlation, a single\n  number or a one-element tuple.\n\n* :attr:`padding` controls the amount of padding applied to the input. It\n  can be either a string {'valid', 'same'} or a tuple of ints giving the\n  amount of implicit padding applied on both sides.\n\n* :attr:`dilation` controls the spacing between the kernel points; also\n  known as the \u00e0 trous algorithm. It is harder to describe, but this `link`_\n  has a nice visualization of what :attr:`dilation` does.\n\n* :attr:`groups` controls the connections between inputs and outputs.\n  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n  :attr:`groups`. For example,\n\n    * At groups=1, all inputs are convolved to all outputs.\n    * At groups=2, the operation becomes equivalent to having two conv\n      layers side by side, each seeing half the input channels\n      and producing half the output channels, and both subsequently\n      concatenated.\n    * At groups= :attr:`in_channels`, each input channel is convolved with\n      its own set of filters (of size\n      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n\nNote:\n    When `groups == in_channels` and `out_channels == K * in_channels`,\n    where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n\n    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n    a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n    :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\nNote:\n    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n\nNote:\n    ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n    the input so the output has the shape as the input. However, this mode\n    doesn't support any stride values other than 1.\n\nNote:\n    This module supports complex data types i.e. ``complex32, complex64, complex128``.\n\nArgs:\n    in_channels (int): Number of channels in the input image\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int, tuple or str, optional): Padding added to both sides of\n        the input. Default: 0\n    dilation (int or tuple, optional): Spacing between kernel\n        elements. Default: 1\n    groups (int, optional): Number of blocked connections from input\n        channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the\n        output. Default: ``True``\n    padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n\n\n\nShape:\n    - Input: :math:`(N, C_{in}, L_{in})` or :math:`(C_{in}, L_{in})`\n    - Output: :math:`(N, C_{out}, L_{out})` or :math:`(C_{out}, L_{out})`, where\n\n      .. math::\n          L_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n                    \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n\nAttributes:\n    weight (Tensor): the learnable weights of the module of shape\n        :math:`(\\text{out\\_channels},\n        \\frac{\\text{in\\_channels}}{\\text{groups}}, \\text{kernel\\_size})`.\n        The values of these weights are sampled from\n        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n    bias (Tensor):   the learnable bias of the module of shape\n        (out_channels). If :attr:`bias` is ``True``, then the values of these weights are\n        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n\nExamples::\n\n    >>> m = nn.Conv1d(16, 33, 3, stride=2)\n    >>> input = torch.randn(20, 16, 50)\n    >>> output = m(input)\n\n.. _cross-correlation:\n    https://en.wikipedia.org/wiki/Cross-correlation\n\n.. _link:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
        "has_varargs": false
      },
      {
        "name": "Conv2d",
        "api_path": "torch.nn.Conv2d",
        "kind": "class",
        "params": [
          {
            "name": "in_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a 2D convolution over an input signal composed of several input\nplanes.\n\nIn the simplest case, the output value of the layer with input size\n:math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\ncan be precisely described as:\n\n.. math::\n    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n    \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n\n\nwhere :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n:math:`N` is a batch size, :math:`C` denotes a number of channels,\n:math:`H` is a height of input planes in pixels, and :math:`W` is\nwidth in pixels.\n\n\nThis module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n* :attr:`stride` controls the stride for the cross-correlation, a single\n  number or a tuple.\n\n* :attr:`padding` controls the amount of padding applied to the input. It\n  can be either a string {'valid', 'same'} or an int / a tuple of ints giving the\n  amount of implicit padding applied on both sides.\n\n* :attr:`dilation` controls the spacing between the kernel points; also\n  known as the \u00e0 trous algorithm. It is harder to describe, but this `link`_\n  has a nice visualization of what :attr:`dilation` does.\n\n\n* :attr:`groups` controls the connections between inputs and outputs.\n  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n  :attr:`groups`. For example,\n\n    * At groups=1, all inputs are convolved to all outputs.\n    * At groups=2, the operation becomes equivalent to having two conv\n      layers side by side, each seeing half the input channels\n      and producing half the output channels, and both subsequently\n      concatenated.\n    * At groups= :attr:`in_channels`, each input channel is convolved with\n      its own set of filters (of size\n      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n\nThe parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n\n    - a single ``int`` -- in which case the same value is used for the height and width dimension\n    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n      and the second `int` for the width dimension\n\nNote:\n    When `groups == in_channels` and `out_channels == K * in_channels`,\n    where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n\n    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n    a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n    :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n\nNote:\n    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n\nNote:\n    ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n    the input so the output has the shape as the input. However, this mode\n    doesn't support any stride values other than 1.\n\nNote:\n    This module supports complex data types i.e. ``complex32, complex64, complex128``.\n\nArgs:\n    in_channels (int): Number of channels in the input image\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int, tuple or str, optional): Padding added to all four sides of\n        the input. Default: 0\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n    groups (int, optional): Number of blocked connections from input\n        channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the\n        output. Default: ``True``\n    padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n\n\nShape:\n    - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n\n      .. math::\n          H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n                    \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\n      .. math::\n          W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n                    \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\nAttributes:\n    weight (Tensor): the learnable weights of the module of shape\n        :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n        :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n        The values of these weights are sampled from\n        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n    bias (Tensor):   the learnable bias of the module of shape\n        (out_channels). If :attr:`bias` is ``True``,\n        then the values of these weights are\n        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n\nExamples:\n\n    >>> # With square kernels and equal stride\n    >>> m = nn.Conv2d(16, 33, 3, stride=2)\n    >>> # non-square kernels and unequal stride and with padding\n    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n    >>> # non-square kernels and unequal stride and with padding and dilation\n    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n    >>> input = torch.randn(20, 16, 50, 100)\n    >>> output = m(input)\n\n.. _cross-correlation:\n    https://en.wikipedia.org/wiki/Cross-correlation\n\n.. _link:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
        "has_varargs": false
      },
      {
        "name": "Conv3d",
        "api_path": "torch.nn.Conv3d",
        "kind": "class",
        "params": [
          {
            "name": "in_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a 3D convolution over an input signal composed of several input\nplanes.\n\nIn the simplest case, the output value of the layer with input size :math:`(N, C_{in}, D, H, W)`\nand output :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` can be precisely described as:\n\n.. math::\n    out(N_i, C_{out_j}) = bias(C_{out_j}) +\n                            \\sum_{k = 0}^{C_{in} - 1} weight(C_{out_j}, k) \\star input(N_i, k)\n\nwhere :math:`\\star` is the valid 3D `cross-correlation`_ operator\n\n\nThis module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n* :attr:`stride` controls the stride for the cross-correlation.\n\n* :attr:`padding` controls the amount of padding applied to the input. It\n  can be either a string {'valid', 'same'} or a tuple of ints giving the\n  amount of implicit padding applied on both sides.\n\n* :attr:`dilation` controls the spacing between the kernel points; also known as the \u00e0 trous algorithm.\n  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n\n\n* :attr:`groups` controls the connections between inputs and outputs.\n  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n  :attr:`groups`. For example,\n\n    * At groups=1, all inputs are convolved to all outputs.\n    * At groups=2, the operation becomes equivalent to having two conv\n      layers side by side, each seeing half the input channels\n      and producing half the output channels, and both subsequently\n      concatenated.\n    * At groups= :attr:`in_channels`, each input channel is convolved with\n      its own set of filters (of size\n      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n\nThe parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n\n    - a single ``int`` -- in which case the same value is used for the depth, height and width dimension\n    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,\n      the second `int` for the height dimension and the third `int` for the width dimension\n\nNote:\n    When `groups == in_channels` and `out_channels == K * in_channels`,\n    where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n\n    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n    a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n    :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n\nNote:\n    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n\nNote:\n    ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n    the input so the output has the shape as the input. However, this mode\n    doesn't support any stride values other than 1.\n\nNote:\n    This module supports complex data types i.e. ``complex32, complex64, complex128``.\n\nArgs:\n    in_channels (int): Number of channels in the input image\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int, tuple or str, optional): Padding added to all six sides of\n        the input. Default: 0\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n    padding_mode (str, optional): ``'zeros'``, ``'reflect'``, ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n\n\nShape:\n    - Input: :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})` or :math:`(C_{in}, D_{in}, H_{in}, W_{in})`\n    - Output: :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` or :math:`(C_{out}, D_{out}, H_{out}, W_{out})`,\n      where\n\n      .. math::\n          D_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n                \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\n      .. math::\n          H_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n                \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\n      .. math::\n          W_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2]\n                \\times (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\n\nAttributes:\n    weight (Tensor): the learnable weights of the module of shape\n                     :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n                     :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]}, \\text{kernel\\_size[2]})`.\n                     The values of these weights are sampled from\n                     :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                     :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}`\n    bias (Tensor):   the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``,\n                     then the values of these weights are\n                     sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                     :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}`\n\nExamples::\n\n    >>> # With square kernels and equal stride\n    >>> m = nn.Conv3d(16, 33, 3, stride=2)\n    >>> # non-square kernels and unequal stride and with padding\n    >>> m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n    >>> input = torch.randn(20, 16, 10, 50, 100)\n    >>> output = m(input)\n\n.. _cross-correlation:\n    https://en.wikipedia.org/wiki/Cross-correlation\n\n.. _link:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
        "has_varargs": false
      },
      {
        "name": "ConvTranspose1d",
        "api_path": "torch.nn.ConvTranspose1d",
        "kind": "class",
        "params": [
          {
            "name": "in_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "output_padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a 1D transposed convolution operator over an input image\ncomposed of several input planes.\n\nThis module can be seen as the gradient of Conv1d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation as it does\nnot compute a true inverse of convolution). For more information, see the visualizations\n`here`_ and the `Deconvolutional Networks`_ paper.\n\nThis module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n* :attr:`stride` controls the stride for the cross-correlation.\n\n* :attr:`padding` controls the amount of implicit zero padding on both\n  sides for ``dilation * (kernel_size - 1) - padding`` number of points. See note\n  below for details.\n\n* :attr:`output_padding` controls the additional size added to one side\n  of the output shape. See note below for details.\n\n* :attr:`dilation` controls the spacing between the kernel points; also known as the \u00e0 trous algorithm.\n  It is harder to describe, but the link `here`_ has a nice visualization of what :attr:`dilation` does.\n\n* :attr:`groups` controls the connections between inputs and outputs.\n  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n  :attr:`groups`. For example,\n\n    * At groups=1, all inputs are convolved to all outputs.\n    * At groups=2, the operation becomes equivalent to having two conv\n      layers side by side, each seeing half the input channels\n      and producing half the output channels, and both subsequently\n      concatenated.\n    * At groups= :attr:`in_channels`, each input channel is convolved with\n      its own set of filters (of size\n      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n\nNote:\n    The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``\n    amount of zero padding to both sizes of the input. This is set so that\n    when a :class:`~torch.nn.Conv1d` and a :class:`~torch.nn.ConvTranspose1d`\n    are initialized with same parameters, they are inverses of each other in\n    regard to the input and output shapes. However, when ``stride > 1``,\n    :class:`~torch.nn.Conv1d` maps multiple input shapes to the same output\n    shape. :attr:`output_padding` is provided to resolve this ambiguity by\n    effectively increasing the calculated output shape on one side. Note\n    that :attr:`output_padding` is only used to find output shape, but does\n    not actually add zero-padding to output.\n\nNote:\n    In some circumstances when using the CUDA backend with CuDNN, this operator\n    may select a nondeterministic algorithm to increase performance. If this is\n    undesirable, you can try to make the operation deterministic (potentially at\n    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n    True``.\n    Please see the notes on :doc:`/notes/randomness` for background.\n\n\nArgs:\n    in_channels (int): Number of channels in the input image\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n        will be added to both sides of the input. Default: 0\n    output_padding (int or tuple, optional): Additional size added to one side\n        of the output shape. Default: 0\n    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n\n\nShape:\n    - Input: :math:`(N, C_{in}, L_{in})` or :math:`(C_{in}, L_{in})`\n    - Output: :math:`(N, C_{out}, L_{out})` or :math:`(C_{out}, L_{out})`, where\n\n      .. math::\n          L_{out} = (L_{in} - 1) \\times \\text{stride} - 2 \\times \\text{padding} + \\text{dilation}\n                    \\times (\\text{kernel\\_size} - 1) + \\text{output\\_padding} + 1\n\nAttributes:\n    weight (Tensor): the learnable weights of the module of shape\n                     :math:`(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},`\n                     :math:`\\text{kernel\\_size})`.\n                     The values of these weights are sampled from\n                     :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                     :math:`k = \\frac{groups}{C_\\text{out} * \\text{kernel\\_size}}`\n    bias (Tensor):   the learnable bias of the module of shape (out_channels).\n                     If :attr:`bias` is ``True``, then the values of these weights are\n                     sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                     :math:`k = \\frac{groups}{C_\\text{out} * \\text{kernel\\_size}}`\n\n.. _`here`:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n\n.. _`Deconvolutional Networks`:\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf",
        "has_varargs": false
      },
      {
        "name": "ConvTranspose2d",
        "api_path": "torch.nn.ConvTranspose2d",
        "kind": "class",
        "params": [
          {
            "name": "in_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "output_padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a 2D transposed convolution operator over an input image\ncomposed of several input planes.\n\nThis module can be seen as the gradient of Conv2d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation as it does\nnot compute a true inverse of convolution). For more information, see the visualizations\n`here`_ and the `Deconvolutional Networks`_ paper.\n\nThis module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n* :attr:`stride` controls the stride for the cross-correlation. When stride > 1, ConvTranspose2d inserts zeros between input\n  elements along the spatial dimensions before applying the convolution kernel. This zero-insertion operation is the standard\n  behavior of transposed convolutions, which can increase the spatial resolution and is equivalent to a learnable\n  upsampling operation.\n\n* :attr:`padding` controls the amount of implicit zero padding on both\n  sides for ``dilation * (kernel_size - 1) - padding`` number of points. See note\n  below for details.\n\n* :attr:`output_padding` controls the additional size added to one side\n  of the output shape. See note below for details.\n\n* :attr:`dilation` controls the spacing between the kernel points; also known as the \u00e0 trous algorithm.\n  It is harder to describe, but the link `here`_ has a nice visualization of what :attr:`dilation` does.\n\n* :attr:`groups` controls the connections between inputs and outputs.\n  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n  :attr:`groups`. For example,\n\n    * At groups=1, all inputs are convolved to all outputs.\n    * At groups=2, the operation becomes equivalent to having two conv\n      layers side by side, each seeing half the input channels\n      and producing half the output channels, and both subsequently\n      concatenated.\n    * At groups= :attr:`in_channels`, each input channel is convolved with\n      its own set of filters (of size\n      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n\nThe parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`output_padding`\ncan either be:\n\n    - a single ``int`` -- in which case the same value is used for the height and width dimensions\n    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n      and the second `int` for the width dimension\n\nNote:\n    The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``\n    amount of zero padding to both sizes of the input. This is set so that\n    when a :class:`~torch.nn.Conv2d` and a :class:`~torch.nn.ConvTranspose2d`\n    are initialized with same parameters, they are inverses of each other in\n    regard to the input and output shapes. However, when ``stride > 1``,\n    :class:`~torch.nn.Conv2d` maps multiple input shapes to the same output\n    shape. :attr:`output_padding` is provided to resolve this ambiguity by\n    effectively increasing the calculated output shape on one side. Note\n    that :attr:`output_padding` is only used to find output shape, but does\n    not actually add zero-padding to output.\n\nNote:\n    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n\nArgs:\n    in_channels (int): Number of channels in the input image\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n        will be added to both sides of each dimension in the input. Default: 0\n    output_padding (int or tuple, optional): Additional size added to one side\n        of each dimension in the output shape. Default: 0\n    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n\n\nShape:\n    - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n\n    .. math::\n          H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n                    \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\n    .. math::\n          W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n                    \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\n\nAttributes:\n    weight (Tensor): the learnable weights of the module of shape\n                     :math:`(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},`\n                     :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n                     The values of these weights are sampled from\n                     :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                     :math:`k = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n    bias (Tensor):   the learnable bias of the module of shape (out_channels)\n                     If :attr:`bias` is ``True``, then the values of these weights are\n                     sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                     :math:`k = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n\nExamples::\n\n    >>> # With square kernels and equal stride\n    >>> m = nn.ConvTranspose2d(16, 33, 3, stride=2)\n    >>> # non-square kernels and unequal stride and with padding\n    >>> m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n    >>> input = torch.randn(20, 16, 50, 100)\n    >>> output = m(input)\n    >>> # exact output size can be also specified as an argument\n    >>> input = torch.randn(1, 16, 12, 12)\n    >>> downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1)\n    >>> upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)\n    >>> h = downsample(input)\n    >>> h.size()\n    torch.Size([1, 16, 6, 6])\n    >>> output = upsample(h, output_size=input.size())\n    >>> output.size()\n    torch.Size([1, 16, 12, 12])\n\n.. _`here`:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n\n.. _`Deconvolutional Networks`:\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf",
        "has_varargs": false
      },
      {
        "name": "ConvTranspose3d",
        "api_path": "torch.nn.ConvTranspose3d",
        "kind": "class",
        "params": [
          {
            "name": "in_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "output_padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a 3D transposed convolution operator over an input image composed of several input\nplanes.\nThe transposed convolution operator multiplies each input value element-wise by a learnable kernel,\nand sums over the outputs from all input feature planes.\n\nThis module can be seen as the gradient of Conv3d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation as it does\nnot compute a true inverse of convolution). For more information, see the visualizations\n`here`_ and the `Deconvolutional Networks`_ paper.\n\nThis module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n* :attr:`stride` controls the stride for the cross-correlation.\n\n* :attr:`padding` controls the amount of implicit zero padding on both\n  sides for ``dilation * (kernel_size - 1) - padding`` number of points. See note\n  below for details.\n\n* :attr:`output_padding` controls the additional size added to one side\n  of the output shape. See note below for details.\n\n* :attr:`dilation` controls the spacing between the kernel points; also known as the \u00e0 trous algorithm.\n  It is harder to describe, but the link `here`_ has a nice visualization of what :attr:`dilation` does.\n\n* :attr:`groups` controls the connections between inputs and outputs.\n  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n  :attr:`groups`. For example,\n\n    * At groups=1, all inputs are convolved to all outputs.\n    * At groups=2, the operation becomes equivalent to having two conv\n      layers side by side, each seeing half the input channels\n      and producing half the output channels, and both subsequently\n      concatenated.\n    * At groups= :attr:`in_channels`, each input channel is convolved with\n      its own set of filters (of size\n      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n\nThe parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`output_padding`\ncan either be:\n\n    - a single ``int`` -- in which case the same value is used for the depth, height and width dimensions\n    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,\n      the second `int` for the height dimension and the third `int` for the width dimension\n\nNote:\n    The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``\n    amount of zero padding to both sizes of the input. This is set so that\n    when a :class:`~torch.nn.Conv3d` and a :class:`~torch.nn.ConvTranspose3d`\n    are initialized with same parameters, they are inverses of each other in\n    regard to the input and output shapes. However, when ``stride > 1``,\n    :class:`~torch.nn.Conv3d` maps multiple input shapes to the same output\n    shape. :attr:`output_padding` is provided to resolve this ambiguity by\n    effectively increasing the calculated output shape on one side. Note\n    that :attr:`output_padding` is only used to find output shape, but does\n    not actually add zero-padding to output.\n\nNote:\n    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n\nArgs:\n    in_channels (int): Number of channels in the input image\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n        will be added to both sides of each dimension in the input. Default: 0\n    output_padding (int or tuple, optional): Additional size added to one side\n        of each dimension in the output shape. Default: 0\n    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n\n\nShape:\n    - Input: :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})` or :math:`(C_{in}, D_{in}, H_{in}, W_{in})`\n    - Output: :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` or\n      :math:`(C_{out}, D_{out}, H_{out}, W_{out})`, where\n\n    .. math::\n          D_{out} = (D_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n                    \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\n    .. math::\n          H_{out} = (H_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n                    \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\n    .. math::\n          W_{out} = (W_{in} - 1) \\times \\text{stride}[2] - 2 \\times \\text{padding}[2] + \\text{dilation}[2]\n                    \\times (\\text{kernel\\_size}[2] - 1) + \\text{output\\_padding}[2] + 1\n\n\nAttributes:\n    weight (Tensor): the learnable weights of the module of shape\n                     :math:`(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},`\n                     :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]}, \\text{kernel\\_size[2]})`.\n                     The values of these weights are sampled from\n                     :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                     :math:`k = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}`\n    bias (Tensor):   the learnable bias of the module of shape (out_channels)\n                     If :attr:`bias` is ``True``, then the values of these weights are\n                     sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                     :math:`k = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}`\n\nExamples::\n\n    >>> # With square kernels and equal stride\n    >>> m = nn.ConvTranspose3d(16, 33, 3, stride=2)\n    >>> # non-square kernels and unequal stride and with padding\n    >>> m = nn.ConvTranspose3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(0, 4, 2))\n    >>> input = torch.randn(20, 16, 10, 50, 100)\n    >>> output = m(input)\n\n.. _`here`:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n\n.. _`Deconvolutional Networks`:\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf",
        "has_varargs": false
      },
      {
        "name": "CosineSimilarity",
        "api_path": "torch.nn.CosineSimilarity",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-08",
            "annotation": "float"
          }
        ],
        "docstring": "Returns cosine similarity between :math:`x_1` and :math:`x_2`, computed along `dim`.\n\n.. math ::\n    \\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}.\n\nArgs:\n    dim (int, optional): Dimension where cosine similarity is computed. Default: 1\n    eps (float, optional): Small value to avoid division by zero.\n        Default: 1e-8\nShape:\n    - Input1: :math:`(\\ast_1, D, \\ast_2)` where D is at position `dim`\n    - Input2: :math:`(\\ast_1, D, \\ast_2)`, same number of dimensions as x1, matching x1 size at dimension `dim`,\n      and broadcastable with x1 at other dimensions.\n    - Output: :math:`(\\ast_1, \\ast_2)`\n\nExamples:\n    >>> input1 = torch.randn(100, 128)\n    >>> input2 = torch.randn(100, 128)\n    >>> cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n    >>> output = cos(input1, input2)",
        "has_varargs": false
      },
      {
        "name": "CrossMapLRN2d",
        "api_path": "torch.nn.CrossMapLRN2d",
        "kind": "class",
        "params": [
          {
            "name": "size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "alpha",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0001",
            "annotation": "float"
          },
          {
            "name": "beta",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.75",
            "annotation": "float"
          },
          {
            "name": "k",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "float"
          }
        ],
        "docstring": "Base class for all neural network modules.\n\nYour models should also subclass this class.\n\nModules can also contain other Modules, allowing them to be nested in\na tree structure. You can assign the submodules as regular attributes::\n\n    import torch.nn as nn\n    import torch.nn.functional as F\n\n\n    class Model(nn.Module):\n        def __init__(self) -> None:\n            super().__init__()\n            self.conv1 = nn.Conv2d(1, 20, 5)\n            self.conv2 = nn.Conv2d(20, 20, 5)\n\n        def forward(self, x):\n            x = F.relu(self.conv1(x))\n            return F.relu(self.conv2(x))\n\nSubmodules assigned in this way will be registered, and will also have their\nparameters converted when you call :meth:`to`, etc.\n\n.. note::\n    As per the example above, an ``__init__()`` call to the parent class\n    must be made before assignment on the child.\n\n:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool",
        "has_varargs": false
      },
      {
        "name": "DataParallel",
        "api_path": "torch.nn.DataParallel",
        "kind": "class",
        "params": [
          {
            "name": "module",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "T"
          },
          {
            "name": "device_ids",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "output_device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "int"
          }
        ],
        "docstring": "Implements data parallelism at the module level.\n\nThis container parallelizes the application of the given :attr:`module` by\nsplitting the input across the specified devices by chunking in the batch\ndimension (other objects will be copied once per device). In the forward\npass, the module is replicated on each device, and each replica handles a\nportion of the input. During the backwards pass, gradients from each replica\nare summed into the original module.\n\nThe batch size should be larger than the number of GPUs used.\n\n.. warning::\n    It is recommended to use :class:`~torch.nn.parallel.DistributedDataParallel`,\n    instead of this class, to do multi-GPU training, even if there is only a single\n    node. See: :ref:`cuda-nn-ddp-instead` and :ref:`ddp`.\n\nArbitrary positional and keyword inputs are allowed to be passed into\nDataParallel but some types are specially handled. tensors will be\n**scattered** on dim specified (default 0). tuple, list and dict types will\nbe shallow copied. The other types will be shared among different threads\nand can be corrupted if written to in the model's forward pass.\n\nThe parallelized :attr:`module` must have its parameters and buffers on\n``device_ids[0]`` before running this :class:`~torch.nn.DataParallel`\nmodule.\n\n.. warning::\n    In each forward, :attr:`module` is **replicated** on each device, so any\n    updates to the running module in ``forward`` will be lost. For example,\n    if :attr:`module` has a counter attribute that is incremented in each\n    ``forward``, it will always stay at the initial value because the update\n    is done on the replicas which are destroyed after ``forward``. However,\n    :class:`~torch.nn.DataParallel` guarantees that the replica on\n    ``device[0]`` will have its parameters and buffers sharing storage with\n    the base parallelized :attr:`module`. So **in-place** updates to the\n    parameters or buffers on ``device[0]`` will be recorded. E.g.,\n    :class:`~torch.nn.BatchNorm2d` and :func:`~torch.nn.utils.spectral_norm`\n    rely on this behavior to update the buffers.\n\n.. warning::\n    Forward and backward hooks defined on :attr:`module` and its submodules\n    will be invoked ``len(device_ids)`` times, each with inputs located on\n    a particular device. Particularly, the hooks are only guaranteed to be\n    executed in correct order with respect to operations on corresponding\n    devices. For example, it is not guaranteed that hooks set via\n    :meth:`~torch.nn.Module.register_forward_pre_hook` be executed before\n    `all` ``len(device_ids)`` :meth:`~torch.nn.Module.forward` calls, but\n    that each such hook be executed before the corresponding\n    :meth:`~torch.nn.Module.forward` call of that device.\n\n.. warning::\n    When :attr:`module` returns a scalar (i.e., 0-dimensional tensor) in\n    :func:`forward`, this wrapper will return a vector of length equal to\n    number of devices used in data parallelism, containing the result from\n    each device.\n\n.. note::\n    There is a subtlety in using the\n    ``pack sequence -> recurrent network -> unpack sequence`` pattern in a\n    :class:`~torch.nn.Module` wrapped in :class:`~torch.nn.DataParallel`.\n    See :ref:`pack-rnn-unpack-with-data-parallelism` section in FAQ for\n    details.\n\n\nArgs:\n    module (Module): module to be parallelized\n    device_ids (list of int or torch.device): CUDA devices (default: all devices)\n    output_device (int or torch.device): device location of output (default: device_ids[0])\n\nAttributes:\n    module (Module): the module to be parallelized\n\nExample::\n\n    >>> # xdoctest: +SKIP\n    >>> net = torch.nn.DataParallel(model, device_ids=[0, 1, 2])\n    >>> output = net(input_var)  # input_var can be on any device, including CPU",
        "has_varargs": false
      },
      {
        "name": "Dropout",
        "api_path": "torch.nn.Dropout",
        "kind": "class",
        "params": [
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "During training, randomly zeroes some of the elements of the input tensor with probability :attr:`p`.\n\nThe zeroed elements are chosen independently for each forward call and are sampled from a Bernoulli distribution.\n\nEach channel will be zeroed out independently on every forward call.\n\nThis has proven to be an effective technique for regularization and\npreventing the co-adaptation of neurons as described in the paper\n`Improving neural networks by preventing co-adaptation of feature\ndetectors`_ .\n\nFurthermore, the outputs are scaled by a factor of :math:`\\frac{1}{1-p}` during\ntraining. This means that during evaluation the module simply computes an\nidentity function.\n\nArgs:\n    p: probability of an element to be zeroed. Default: 0.5\n    inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`. Input can be of any shape\n    - Output: :math:`(*)`. Output is of the same shape as input\n\nExamples::\n\n    >>> m = nn.Dropout(p=0.2)\n    >>> input = torch.randn(20, 16)\n    >>> output = m(input)\n\n.. _Improving neural networks by preventing co-adaptation of feature\n    detectors: https://arxiv.org/abs/1207.0580",
        "has_varargs": false
      },
      {
        "name": "Dropout1d",
        "api_path": "torch.nn.Dropout1d",
        "kind": "class",
        "params": [
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Randomly zero out entire channels.\n\nA channel is a 1D feature map,\ne.g., the :math:`j`-th channel of the :math:`i`-th sample in the\nbatched input is a 1D tensor :math:`\\text{input}[i, j]`.\n\nEach channel will be zeroed out independently on every forward call with\nprobability :attr:`p` using samples from a Bernoulli distribution.\n\nUsually the input comes from :class:`nn.Conv1d` modules.\n\nAs described in the paper\n`Efficient Object Localization Using Convolutional Networks`_ ,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d. dropout\nwill not regularize the activations and will otherwise just result\nin an effective learning rate decrease.\n\nIn this case, :func:`nn.Dropout1d` will help promote independence between\nfeature maps and should be used instead.\n\nArgs:\n    p (float, optional): probability of an element to be zero-ed.\n    inplace (bool, optional): If set to ``True``, will do this operation\n        in-place\n\nShape:\n    - Input: :math:`(N, C, L)` or :math:`(C, L)`.\n    - Output: :math:`(N, C, L)` or :math:`(C, L)` (same shape as input).\n\nExamples::\n\n    >>> m = nn.Dropout1d(p=0.2)\n    >>> input = torch.randn(20, 16, 32)\n    >>> output = m(input)\n\n.. _Efficient Object Localization Using Convolutional Networks:\n   https://arxiv.org/abs/1411.4280",
        "has_varargs": false
      },
      {
        "name": "Dropout2d",
        "api_path": "torch.nn.Dropout2d",
        "kind": "class",
        "params": [
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Randomly zero out entire channels.\n\nA channel is a 2D feature map,\ne.g., the :math:`j`-th channel of the :math:`i`-th sample in the\nbatched input is a 2D tensor :math:`\\text{input}[i, j]`.\n\nEach channel will be zeroed out independently on every forward call with\nprobability :attr:`p` using samples from a Bernoulli distribution.\n\nUsually the input comes from :class:`nn.Conv2d` modules.\n\nAs described in the paper\n`Efficient Object Localization Using Convolutional Networks`_ ,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d. dropout\nwill not regularize the activations and will otherwise just result\nin an effective learning rate decrease.\n\nIn this case, :func:`nn.Dropout2d` will help promote independence between\nfeature maps and should be used instead.\n\nArgs:\n    p (float, optional): probability of an element to be zero-ed.\n    inplace (bool, optional): If set to ``True``, will do this operation\n        in-place\n\n.. warning ::\n    Due to historical reasons, this class will perform 1D channel-wise dropout\n    for 3D inputs (as done by :class:`nn.Dropout1d`). Thus, it currently does NOT\n    support inputs without a batch dimension of shape :math:`(C, H, W)`. This\n    behavior will change in a future release to interpret 3D inputs as no-batch-dim\n    inputs. To maintain the old behavior, switch to :class:`nn.Dropout1d`.\n\nShape:\n    - Input: :math:`(N, C, H, W)` or :math:`(N, C, L)`.\n    - Output: :math:`(N, C, H, W)` or :math:`(N, C, L)` (same shape as input).\n\nExamples::\n\n    >>> m = nn.Dropout2d(p=0.2)\n    >>> input = torch.randn(20, 16, 32, 32)\n    >>> output = m(input)\n\n.. _Efficient Object Localization Using Convolutional Networks:\n   https://arxiv.org/abs/1411.4280",
        "has_varargs": false
      },
      {
        "name": "Dropout3d",
        "api_path": "torch.nn.Dropout3d",
        "kind": "class",
        "params": [
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Randomly zero out entire channels.\n\nA channel is a 3D feature map,\ne.g., the :math:`j`-th channel of the :math:`i`-th sample in the\nbatched input is a 3D tensor :math:`\\text{input}[i, j]`.\n\nEach channel will be zeroed out independently on every forward call with\nprobability :attr:`p` using samples from a Bernoulli distribution.\n\nUsually the input comes from :class:`nn.Conv3d` modules.\n\nAs described in the paper\n`Efficient Object Localization Using Convolutional Networks`_ ,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d. dropout\nwill not regularize the activations and will otherwise just result\nin an effective learning rate decrease.\n\nIn this case, :func:`nn.Dropout3d` will help promote independence between\nfeature maps and should be used instead.\n\nArgs:\n    p (float, optional): probability of an element to be zeroed.\n    inplace (bool, optional): If set to ``True``, will do this operation\n        in-place\n\nShape:\n    - Input: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)`.\n    - Output: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)` (same shape as input).\n\nExamples::\n\n    >>> m = nn.Dropout3d(p=0.2)\n    >>> input = torch.randn(20, 16, 4, 32, 32)\n    >>> output = m(input)\n\n.. _Efficient Object Localization Using Convolutional Networks:\n   https://arxiv.org/abs/1411.4280",
        "has_varargs": false
      },
      {
        "name": "ELU",
        "api_path": "torch.nn.ELU",
        "kind": "class",
        "params": [
          {
            "name": "alpha",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Exponential Linear Unit (ELU) function, element-wise.\n\nMethod described in the paper: `Fast and Accurate Deep Network Learning by Exponential Linear\nUnits (ELUs) <https://arxiv.org/abs/1511.07289>`__.\n\nELU is defined as:\n\n.. math::\n    \\text{ELU}(x) = \\begin{cases}\n    x, & \\text{ if } x > 0\\\\\n    \\alpha * (\\exp(x) - 1), & \\text{ if } x \\leq 0\n    \\end{cases}\n\nArgs:\n    alpha: the :math:`\\alpha` value for the ELU formulation. Default: 1.0\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/ELU.png\n\nExamples::\n\n    >>> m = nn.ELU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Embedding",
        "api_path": "torch.nn.Embedding",
        "kind": "class",
        "params": [
          {
            "name": "num_embeddings",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "embedding_dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "padding_idx",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "max_norm",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "norm_type",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "2.0",
            "annotation": "float"
          },
          {
            "name": "scale_grad_by_freq",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "sparse",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "_weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "_freeze",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A simple lookup table that stores embeddings of a fixed dictionary and size.\n\nThis module is often used to store word embeddings and retrieve them using indices.\nThe input to the module is a list of indices, and the output is the corresponding\nword embeddings.\n\nArgs:\n    num_embeddings (int): size of the dictionary of embeddings\n    embedding_dim (int): the size of each embedding vector\n    padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n                                 therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n                                 i.e. it remains as a fixed \"pad\". For a newly constructed Embedding,\n                                 the embedding vector at :attr:`padding_idx` will default to all zeros,\n                                 but can be updated to another value to be used as the padding vector.\n    max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n                                is renormalized to have norm :attr:`max_norm`.\n    norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n    scale_grad_by_freq (bool, optional): If given, this will scale gradients by the inverse of frequency of\n                                            the words in the mini-batch. Default ``False``.\n    sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\n                             See Notes for more details regarding sparse gradients.\n\nAttributes:\n    weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n                     initialized from :math:`\\mathcal{N}(0, 1)`\n\nShape:\n    - Input: :math:`(*)`, IntTensor or LongTensor of arbitrary shape containing the indices to extract\n    - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\\text{embedding\\_dim}`\n\n.. note::\n    Keep in mind that only a limited number of optimizers support\n    sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),\n    :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\n\n.. note::\n    When :attr:`max_norm` is not ``None``, :class:`Embedding`'s forward method will modify the\n    :attr:`weight` tensor in-place. Since tensors needed for gradient computations cannot be\n    modified in-place, performing a differentiable operation on ``Embedding.weight`` before\n    calling :class:`Embedding`'s forward method requires cloning ``Embedding.weight`` when\n    :attr:`max_norm` is not ``None``. For example::\n\n        n, d, m = 3, 5, 7\n        embedding = nn.Embedding(n, d, max_norm=1.0)\n        W = torch.randn((m, d), requires_grad=True)\n        idx = torch.tensor([1, 2])\n        a = (\n            embedding.weight.clone() @ W.t()\n        )  # weight must be cloned for this to be differentiable\n        b = embedding(idx) @ W.t()  # modifies weight in-place\n        out = a.unsqueeze(0) + b.unsqueeze(1)\n        loss = out.sigmoid().prod()\n        loss.backward()\n\nExamples::\n\n    >>> # an Embedding module containing 10 tensors of size 3\n    >>> embedding = nn.Embedding(10, 3)\n    >>> # a batch of 2 samples of 4 indices each\n    >>> input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> embedding(input)\n    tensor([[[-0.0251, -1.6902,  0.7172],\n             [-0.6431,  0.0748,  0.6969],\n             [ 1.4970,  1.3448, -0.9685],\n             [-0.3677, -2.7265, -0.1685]],\n\n            [[ 1.4970,  1.3448, -0.9685],\n             [ 0.4362, -0.4004,  0.9400],\n             [-0.6431,  0.0748,  0.6969],\n             [ 0.9124, -2.3616,  1.1151]]])\n\n\n    >>> # example with padding_idx\n    >>> embedding = nn.Embedding(10, 3, padding_idx=0)\n    >>> input = torch.LongTensor([[0, 2, 0, 5]])\n    >>> embedding(input)\n    tensor([[[ 0.0000,  0.0000,  0.0000],\n             [ 0.1535, -2.0309,  0.9315],\n             [ 0.0000,  0.0000,  0.0000],\n             [-0.1655,  0.9897,  0.0635]]])\n\n    >>> # example of changing `pad` vector\n    >>> padding_idx = 0\n    >>> embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n    >>> embedding.weight\n    Parameter containing:\n    tensor([[ 0.0000,  0.0000,  0.0000],\n            [-0.7895, -0.7089, -0.0364],\n            [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n    >>> with torch.no_grad():\n    ...     embedding.weight[padding_idx] = torch.ones(3)\n    >>> embedding.weight\n    Parameter containing:\n    tensor([[ 1.0000,  1.0000,  1.0000],\n            [-0.7895, -0.7089, -0.0364],\n            [ 0.6778,  0.5803,  0.2678]], requires_grad=True)",
        "has_varargs": false
      },
      {
        "name": "EmbeddingBag",
        "api_path": "torch.nn.EmbeddingBag",
        "kind": "class",
        "params": [
          {
            "name": "num_embeddings",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "embedding_dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "max_norm",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "norm_type",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "2.0",
            "annotation": "float"
          },
          {
            "name": "scale_grad_by_freq",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          },
          {
            "name": "sparse",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "_weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "include_last_offset",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "padding_idx",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Compute sums or means of 'bags' of embeddings, without instantiating the intermediate embeddings.\n\nFor bags of constant length, no :attr:`per_sample_weights`, no indices equal to :attr:`padding_idx`,\nand with 2D inputs, this class\n\n    * with ``mode=\"sum\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.sum(dim=1)``,\n    * with ``mode=\"mean\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.mean(dim=1)``,\n    * with ``mode=\"max\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.max(dim=1)``.\n\nHowever, :class:`~torch.nn.EmbeddingBag` is much more time and memory efficient than using a chain of these\noperations.\n\nEmbeddingBag also supports per-sample weights as an argument to the forward\npass. This scales the output of the Embedding before performing a weighted\nreduction as specified by ``mode``. If :attr:`per_sample_weights` is passed, the\nonly supported ``mode`` is ``\"sum\"``, which computes a weighted sum according to\n:attr:`per_sample_weights`.\n\nArgs:\n    num_embeddings (int): size of the dictionary of embeddings\n    embedding_dim (int): the size of each embedding vector\n    max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n                                is renormalized to have norm :attr:`max_norm`.\n    norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n    scale_grad_by_freq (bool, optional): if given, this will scale gradients by the inverse of frequency of\n                                            the words in the mini-batch. Default ``False``.\n                                            Note: this option is not supported when ``mode=\"max\"``.\n    mode (str, optional): ``\"sum\"``, ``\"mean\"`` or ``\"max\"``. Specifies the way to reduce the bag.\n                             ``\"sum\"`` computes the weighted sum, taking :attr:`per_sample_weights`\n                             into consideration. ``\"mean\"`` computes the average of the values\n                             in the bag, ``\"max\"`` computes the max value over each bag.\n                             Default: ``\"mean\"``\n    sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor. See\n                             Notes for more details regarding sparse gradients. Note: this option is not\n                             supported when ``mode=\"max\"``.\n    include_last_offset (bool, optional): if ``True``, :attr:`offsets` has one additional element, where the last element\n                                  is equivalent to the size of `indices`. This matches the CSR format.\n    padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the\n                                 gradient; therefore, the embedding vector at :attr:`padding_idx` is not updated\n                                 during training, i.e. it remains as a fixed \"pad\". For a newly constructed\n                                 EmbeddingBag, the embedding vector at :attr:`padding_idx` will default to all\n                                 zeros, but can be updated to another value to be used as the padding vector.\n                                 Note that the embedding vector at :attr:`padding_idx` is excluded from the\n                                 reduction.\n\nAttributes:\n    weight (Tensor): the learnable weights of the module of shape `(num_embeddings, embedding_dim)`\n                     initialized from :math:`\\mathcal{N}(0, 1)`.\n\nExamples::\n\n    >>> # an EmbeddingBag module containing 10 tensors of size 3\n    >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum')\n    >>> # a batch of 2 samples of 4 indices each\n    >>> input = torch.tensor([1, 2, 4, 5, 4, 3, 2, 9], dtype=torch.long)\n    >>> offsets = torch.tensor([0, 4], dtype=torch.long)\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> embedding_sum(input, offsets)\n    tensor([[-0.8861, -5.4350, -0.0523],\n            [ 1.1306, -2.5798, -1.0044]])\n\n    >>> # Example with padding_idx\n    >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum', padding_idx=2)\n    >>> input = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9], dtype=torch.long)\n    >>> offsets = torch.tensor([0, 4], dtype=torch.long)\n    >>> embedding_sum(input, offsets)\n    tensor([[ 0.0000,  0.0000,  0.0000],\n            [-0.7082,  3.2145, -2.6251]])\n\n    >>> # An EmbeddingBag can be loaded from an Embedding like so\n    >>> embedding = nn.Embedding(10, 3, padding_idx=2)\n    >>> embedding_sum = nn.EmbeddingBag.from_pretrained(\n            embedding.weight,\n            padding_idx=embedding.padding_idx,\n            mode='sum')",
        "has_varargs": false
      },
      {
        "name": "FeatureAlphaDropout",
        "api_path": "torch.nn.FeatureAlphaDropout",
        "kind": "class",
        "params": [
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Randomly masks out entire channels.\n\nA channel is a feature map,\ne.g. the :math:`j`-th channel of the :math:`i`-th sample in the batch input\nis a tensor :math:`\\text{input}[i, j]` of the input tensor). Instead of\nsetting activations to zero, as in regular Dropout, the activations are set\nto the negative saturation value of the SELU activation function. More details\ncan be found in the paper `Self-Normalizing Neural Networks`_ .\n\nEach element will be masked independently for each sample on every forward\ncall with probability :attr:`p` using samples from a Bernoulli distribution.\nThe elements to be masked are randomized on every forward call, and scaled\nand shifted to maintain zero mean and unit variance.\n\nUsually the input comes from :class:`nn.AlphaDropout` modules.\n\nAs described in the paper\n`Efficient Object Localization Using Convolutional Networks`_ ,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d. dropout\nwill not regularize the activations and will otherwise just result\nin an effective learning rate decrease.\n\nIn this case, :func:`nn.AlphaDropout` will help promote independence between\nfeature maps and should be used instead.\n\nArgs:\n    p (float, optional): probability of an element to be zeroed. Default: 0.5\n    inplace (bool, optional): If set to ``True``, will do this operation\n        in-place\n\nShape:\n    - Input: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)`.\n    - Output: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)` (same shape as input).\n\nExamples::\n\n    >>> m = nn.FeatureAlphaDropout(p=0.2)\n    >>> input = torch.randn(20, 16, 4, 32, 32)\n    >>> output = m(input)\n\n.. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515\n.. _Efficient Object Localization Using Convolutional Networks:\n   https://arxiv.org/abs/1411.4280",
        "has_varargs": false
      },
      {
        "name": "Flatten",
        "api_path": "torch.nn.Flatten",
        "kind": "class",
        "params": [
          {
            "name": "start_dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "end_dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-1",
            "annotation": "int"
          }
        ],
        "docstring": "Flattens a contiguous range of dims into a tensor.\n\nFor use with :class:`~nn.Sequential`, see :meth:`torch.flatten` for details.\n\nShape:\n    - Input: :math:`(*, S_{\\text{start}},..., S_{i}, ..., S_{\\text{end}}, *)`,'\n      where :math:`S_{i}` is the size at dimension :math:`i` and :math:`*` means any\n      number of dimensions including none.\n    - Output: :math:`(*, \\prod_{i=\\text{start}}^{\\text{end}} S_{i}, *)`.\n\nArgs:\n    start_dim: first dim to flatten (default = 1).\n    end_dim: last dim to flatten (default = -1).\n\nExamples::\n    >>> input = torch.randn(32, 1, 5, 5)\n    >>> # With default parameters\n    >>> m = nn.Flatten()\n    >>> output = m(input)\n    >>> output.size()\n    torch.Size([32, 25])\n    >>> # With non-default parameters\n    >>> m = nn.Flatten(0, 2)\n    >>> output = m(input)\n    >>> output.size()\n    torch.Size([160, 5])",
        "has_varargs": false
      },
      {
        "name": "Fold",
        "api_path": "torch.nn.Fold",
        "kind": "class",
        "params": [
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          }
        ],
        "docstring": "Combines an array of sliding local blocks into a large containing tensor.\n\nConsider a batched :attr:`input` tensor containing sliding local blocks,\ne.g., patches of images, of shape :math:`(N, C \\times  \\prod(\\text{kernel\\_size}), L)`,\nwhere :math:`N` is batch dimension, :math:`C \\times \\prod(\\text{kernel\\_size})`\nis the number of values within a block (a block has :math:`\\prod(\\text{kernel\\_size})`\nspatial locations each containing a :math:`C`-channeled vector), and\n:math:`L` is the total number of blocks. (This is exactly the\nsame specification as the output shape of :class:`~torch.nn.Unfold`.) This\noperation combines these local blocks into the large :attr:`output` tensor\nof shape :math:`(N, C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)`\nby summing the overlapping values. Similar to :class:`~torch.nn.Unfold`, the\narguments must satisfy\n\n.. math::\n    L = \\prod_d \\left\\lfloor\\frac{\\text{output\\_size}[d] + 2 \\times \\text{padding}[d] %\n        - \\text{dilation}[d] \\times (\\text{kernel\\_size}[d] - 1) - 1}{\\text{stride}[d]} + 1\\right\\rfloor,\n\nwhere :math:`d` is over all spatial dimensions.\n\n* :attr:`output_size` describes the spatial shape of the large containing\n  tensor of the sliding local blocks. It is useful to resolve the ambiguity\n  when multiple input shapes map to same number of sliding blocks, e.g.,\n  with ``stride > 0``.\n\nThe :attr:`padding`, :attr:`stride` and :attr:`dilation` arguments specify\nhow the sliding blocks are retrieved.\n\n* :attr:`stride` controls the stride for the sliding blocks.\n\n* :attr:`padding` controls the amount of implicit zero-paddings on both\n  sides for :attr:`padding` number of points for each dimension before\n  reshaping.\n\n* :attr:`dilation` controls the spacing between the kernel points; also known as the \u00e0 trous algorithm.\n  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n\nArgs:\n    output_size (int or tuple): the shape of the spatial dimensions of the\n                                output (i.e., ``output.sizes()[2:]``)\n    kernel_size (int or tuple): the size of the sliding blocks\n    dilation (int or tuple, optional): a parameter that controls the\n                                       stride of elements within the\n                                       neighborhood. Default: 1\n    padding (int or tuple, optional): implicit zero padding to be added on\n                                      both sides of input. Default: 0\n    stride (int or tuple): the stride of the sliding blocks in the input\n                           spatial dimensions. Default: 1\n\n* If :attr:`output_size`, :attr:`kernel_size`, :attr:`dilation`,\n  :attr:`padding` or :attr:`stride` is an int or a tuple of length 1 then\n  their values will be replicated across all spatial dimensions.\n\n* For the case of two output spatial dimensions this operation is sometimes\n  called ``col2im``.\n\n.. note::\n    :class:`~torch.nn.Fold` calculates each combined value in the resulting\n    large tensor by summing all values from all containing blocks.\n    :class:`~torch.nn.Unfold` extracts the values in the local blocks by\n    copying from the large tensor. So, if the blocks overlap, they are not\n    inverses of each other.\n\n    In general, folding and unfolding operations are related as\n    follows. Consider :class:`~torch.nn.Fold` and\n    :class:`~torch.nn.Unfold` instances created with the same\n    parameters:\n\n    >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n    >>> fold = nn.Fold(output_size=..., **fold_params)\n    >>> unfold = nn.Unfold(**fold_params)\n\n    Then for any (supported) ``input`` tensor the following\n    equality holds:\n\n    ::\n\n        fold(unfold(input)) == divisor * input\n\n    where ``divisor`` is a tensor that depends only on the shape\n    and dtype of the ``input``:\n\n    >>> # xdoctest: +SKIP\n    >>> input_ones = torch.ones(input.shape, dtype=input.dtype)\n    >>> divisor = fold(unfold(input_ones))\n\n    When the ``divisor`` tensor contains no zero elements, then\n    ``fold`` and ``unfold`` operations are inverses of each\n    other (up to constant divisor).\n\n.. warning::\n    Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported.\n\nShape:\n    - Input: :math:`(N, C \\times \\prod(\\text{kernel\\_size}), L)` or :math:`(C \\times \\prod(\\text{kernel\\_size}), L)`\n    - Output: :math:`(N, C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)`\n      or :math:`(C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)` as described above\n\nExamples::\n\n    >>> fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2))\n    >>> input = torch.randn(1, 3 * 2 * 2, 12)\n    >>> output = fold(input)\n    >>> output.size()\n    torch.Size([1, 3, 4, 5])\n\n.. _link:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
        "has_varargs": false
      },
      {
        "name": "FractionalMaxPool2d",
        "api_path": "torch.nn.FractionalMaxPool2d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "output_ratio",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "return_indices",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "_random_samples",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a 2D fractional max pooling over an input signal composed of several input planes.\n\nFractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham\n\nThe max-pooling operation is applied in :math:`kH \\times kW` regions by a stochastic\nstep size determined by the target output size.\nThe number of output features is equal to the number of input planes.\n\n.. note:: Exactly one of ``output_size`` or ``output_ratio`` must be defined.\n\nArgs:\n    kernel_size: the size of the window to take a max over.\n                 Can be a single number k (for a square kernel of k x k) or a tuple `(kh, kw)`\n    output_size: the target output size of the image of the form `oH x oW`.\n                 Can be a tuple `(oH, oW)` or a single number oH for a square image `oH x oH`.\n                 Note that we must have :math:`kH + oH - 1 <= H_{in}` and :math:`kW + oW - 1 <= W_{in}`\n    output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.\n                  This has to be a number or tuple in the range (0, 1).\n                  Note that we must have :math:`kH + (output\\_ratio\\_H * H_{in}) - 1 <= H_{in}`\n                  and :math:`kW + (output\\_ratio\\_W * W_{in}) - 1 <= W_{in}`\n    return_indices: if ``True``, will return the indices along with the outputs.\n                    Useful to pass to :meth:`nn.MaxUnpool2d`. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n      :math:`(H_{out}, W_{out})=\\text{output\\_size}` or\n      :math:`(H_{out}, W_{out})=\\text{output\\_ratio} \\times (H_{in}, W_{in})`.\n\nExamples:\n    >>> # pool of square window of size=3, and target output size 13x12\n    >>> m = nn.FractionalMaxPool2d(3, output_size=(13, 12))\n    >>> # pool of square window and target output size being half of input image size\n    >>> m = nn.FractionalMaxPool2d(3, output_ratio=(0.5, 0.5))\n    >>> input = torch.randn(20, 16, 50, 32)\n    >>> output = m(input)\n\n.. _Fractional MaxPooling:\n    https://arxiv.org/abs/1412.6071",
        "has_varargs": false
      },
      {
        "name": "FractionalMaxPool3d",
        "api_path": "torch.nn.FractionalMaxPool3d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "output_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "output_ratio",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "return_indices",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "_random_samples",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies a 3D fractional max pooling over an input signal composed of several input planes.\n\nFractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham\n\nThe max-pooling operation is applied in :math:`kT \\times kH \\times kW` regions by a stochastic\nstep size determined by the target output size.\nThe number of output features is equal to the number of input planes.\n\n.. note:: Exactly one of ``output_size`` or ``output_ratio`` must be defined.\n\nArgs:\n    kernel_size: the size of the window to take a max over.\n                 Can be a single number `k` (for a square kernel of `k x k x k`) or a tuple `(kt x kh x kw)`,\n                 `k` must greater than 0.\n    output_size: the target output size of the image of the form `oT x oH x oW`.\n                 Can be a tuple `(oT, oH, oW)` or a single number oH for a square image `oH x oH x oH`\n    output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.\n                  This has to be a number or tuple in the range (0, 1)\n    return_indices: if ``True``, will return the indices along with the outputs.\n                    Useful to pass to :meth:`nn.MaxUnpool3d`. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, T_{in}, H_{in}, W_{in})` or :math:`(C, T_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, T_{out}, H_{out}, W_{out})` or :math:`(C, T_{out}, H_{out}, W_{out})`, where\n      :math:`(T_{out}, H_{out}, W_{out})=\\text{output\\_size}` or\n      :math:`(T_{out}, H_{out}, W_{out})=\\text{output\\_ratio} \\times (T_{in}, H_{in}, W_{in})`\n\nExamples:\n    >>> # pool of cubic window of size=3, and target output size 13x12x11\n    >>> m = nn.FractionalMaxPool3d(3, output_size=(13, 12, 11))\n    >>> # pool of cubic window and target output size being half of input size\n    >>> m = nn.FractionalMaxPool3d(3, output_ratio=(0.5, 0.5, 0.5))\n    >>> input = torch.randn(20, 16, 50, 32, 16)\n    >>> output = m(input)\n\n.. _Fractional MaxPooling:\n    https://arxiv.org/abs/1412.6071",
        "has_varargs": false
      },
      {
        "name": "GELU",
        "api_path": "torch.nn.GELU",
        "kind": "class",
        "params": [
          {
            "name": "approximate",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "none",
            "annotation": "str"
          }
        ],
        "docstring": "Applies the Gaussian Error Linear Units function.\n\n.. math:: \\text{GELU}(x) = x * \\Phi(x)\n\nwhere :math:`\\Phi(x)` is the Cumulative Distribution Function for Gaussian Distribution.\n\nWhen the approximate argument is 'tanh', Gelu is estimated with:\n\n.. math:: \\text{GELU}(x) = 0.5 * x * (1 + \\text{Tanh}(\\sqrt{2 / \\pi} * (x + 0.044715 * x^3)))\n\nArgs:\n    approximate (str, optional): the gelu approximation algorithm to use:\n        ``'none'`` | ``'tanh'``. Default: ``'none'``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/GELU.png\n\nExamples::\n\n    >>> m = nn.GELU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "GLU",
        "api_path": "torch.nn.GLU",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-1",
            "annotation": "int"
          }
        ],
        "docstring": "Applies the gated linear unit function.\n\n:math:`{GLU}(a, b)= a \\otimes \\sigma(b)` where :math:`a` is the first half\nof the input matrices and :math:`b` is the second half.\n\nArgs:\n    dim (int): the dimension on which to split the input. Default: -1\n\nShape:\n    - Input: :math:`(\\ast_1, N, \\ast_2)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(\\ast_1, M, \\ast_2)` where :math:`M=N/2`\n\n.. image:: ../scripts/activation_images/GLU.png\n\nExamples::\n\n    >>> m = nn.GLU()\n    >>> input = torch.randn(4, 2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "GRU",
        "api_path": "torch.nn.GRU",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "__init__(input_size,hidden_size,num_layers=1,bias=True,batch_first=False,dropout=0.0,bidirectional=False,device=None,dtype=None)\n\nApply a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\nFor each element in the input sequence, each layer computes the following\nfunction:\n\n.. math::\n    \\begin{array}{ll}\n        r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n        z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n        n_t = \\tanh(W_{in} x_t + b_{in} + r_t \\odot (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n        h_t = (1 - z_t) \\odot n_t + z_t \\odot h_{(t-1)}\n    \\end{array}\n\nwhere :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input\nat time `t`, :math:`h_{(t-1)}` is the hidden state of the layer\nat time `t-1` or the initial hidden state at time `0`, and :math:`r_t`,\n:math:`z_t`, :math:`n_t` are the reset, update, and new gates, respectively.\n:math:`\\sigma` is the sigmoid function, and :math:`\\odot` is the Hadamard product.\n\nIn a multilayer GRU, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n(:math:`l \\ge 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\ndropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\nvariable which is :math:`0` with probability :attr:`dropout`.\n\nArgs:\n    input_size: The number of expected features in the input `x`\n    hidden_size: The number of features in the hidden state `h`\n    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n        would mean stacking two GRUs together to form a `stacked GRU`,\n        with the second GRU taking in outputs of the first GRU and\n        computing the final results. Default: 1\n    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n        Default: ``True``\n    batch_first: If ``True``, then the input and output tensors are provided\n        as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n        Note that this does not apply to hidden or cell states. See the\n        Inputs/Outputs sections below for details.  Default: ``False``\n    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n        GRU layer except the last layer, with dropout probability equal to\n        :attr:`dropout`. Default: 0\n    bidirectional: If ``True``, becomes a bidirectional GRU. Default: ``False``\n\nInputs: input, h_0\n    * **input**: tensor of shape :math:`(L, H_{in})` for unbatched input,\n      :math:`(L, N, H_{in})` when ``batch_first=False`` or\n      :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n      the input sequence.  The input can also be a packed variable length sequence.\n      See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n      :func:`torch.nn.utils.rnn.pack_sequence` for details.\n    * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` or\n      :math:`(D * \\text{num\\_layers}, N, H_{out})`\n      containing the initial hidden state for the input sequence. Defaults to zeros if not provided.\n\n    where:\n\n    .. math::\n        \\begin{aligned}\n            N ={} & \\text{batch size} \\\\\n            L ={} & \\text{sequence length} \\\\\n            D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n            H_{in} ={} & \\text{input\\_size} \\\\\n            H_{out} ={} & \\text{hidden\\_size}\n        \\end{aligned}\n\nOutputs: output, h_n\n    * **output**: tensor of shape :math:`(L, D * H_{out})` for unbatched input,\n      :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n      :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n      `(h_t)` from the last layer of the GRU, for each `t`. If a\n      :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n      will also be a packed sequence.\n    * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` or\n      :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the final hidden state\n      for the input sequence.\n\nAttributes:\n    weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n        (W_ir|W_iz|W_in), of shape `(3*hidden_size, input_size)` for `k = 0`.\n        Otherwise, the shape is `(3*hidden_size, num_directions * hidden_size)`\n    weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n        (W_hr|W_hz|W_hn), of shape `(3*hidden_size, hidden_size)`\n    bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n        (b_ir|b_iz|b_in), of shape `(3*hidden_size)`\n    bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n        (b_hr|b_hz|b_hn), of shape `(3*hidden_size)`\n\n.. note::\n    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n\n.. note::\n    For bidirectional GRUs, forward and backward are directions 0 and 1 respectively.\n    Example of splitting the output layers when ``batch_first=False``:\n    ``output.view(seq_len, batch, num_directions, hidden_size)``.\n\n.. note::\n    ``batch_first`` argument is ignored for unbatched inputs.\n\n.. note::\n    The calculation of new gate :math:`n_t` subtly differs from the original paper and other frameworks.\n    In the original implementation, the Hadamard product :math:`(\\odot)` between :math:`r_t` and the\n    previous hidden state :math:`h_{(t-1)}` is done before the multiplication with the weight matrix\n    `W` and addition of bias:\n\n    .. math::\n        \\begin{aligned}\n            n_t = \\tanh(W_{in} x_t + b_{in} + W_{hn} ( r_t \\odot h_{(t-1)} ) + b_{hn})\n        \\end{aligned}\n\n    This is in contrast to PyTorch implementation, which is done after :math:`W_{hn} h_{(t-1)}`\n\n    .. math::\n        \\begin{aligned}\n            n_t = \\tanh(W_{in} x_t + b_{in} + r_t \\odot (W_{hn} h_{(t-1)}+ b_{hn}))\n        \\end{aligned}\n\n    This implementation differs on purpose for efficiency.\n\n.. include:: ../cudnn_persistent_rnn.rst\n\nExamples::\n\n    >>> rnn = nn.GRU(10, 20, 2)\n    >>> input = torch.randn(5, 3, 10)\n    >>> h0 = torch.randn(2, 3, 20)\n    >>> output, hn = rnn(input, h0)",
        "has_varargs": true
      },
      {
        "name": "GRUCell",
        "api_path": "torch.nn.GRUCell",
        "kind": "class",
        "params": [
          {
            "name": "input_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "hidden_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A gated recurrent unit (GRU) cell.\n\n.. math::\n\n    \\begin{array}{ll}\n    r = \\sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\\\\n    z = \\sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\\\\n    n = \\tanh(W_{in} x + b_{in} + r \\odot (W_{hn} h + b_{hn})) \\\\\n    h' = (1 - z) \\odot n + z \\odot h\n    \\end{array}\n\nwhere :math:`\\sigma` is the sigmoid function, and :math:`\\odot` is the Hadamard product.\n\nArgs:\n    input_size: The number of expected features in the input `x`\n    hidden_size: The number of features in the hidden state `h`\n    bias: If ``False``, then the layer does not use bias weights `b_ih` and\n        `b_hh`. Default: ``True``\n\nInputs: input, hidden\n    - **input** : tensor containing input features\n    - **hidden** : tensor containing the initial hidden\n      state for each element in the batch.\n      Defaults to zero if not provided.\n\nOutputs: h'\n    - **h'** : tensor containing the next hidden state\n      for each element in the batch\n\nShape:\n    - input: :math:`(N, H_{in})` or :math:`(H_{in})` tensor containing input features where\n      :math:`H_{in}` = `input_size`.\n    - hidden: :math:`(N, H_{out})` or :math:`(H_{out})` tensor containing the initial hidden\n      state where :math:`H_{out}` = `hidden_size`. Defaults to zero if not provided.\n    - output: :math:`(N, H_{out})` or :math:`(H_{out})` tensor containing the next hidden state.\n\nAttributes:\n    weight_ih: the learnable input-hidden weights, of shape\n        `(3*hidden_size, input_size)`\n    weight_hh: the learnable hidden-hidden weights, of shape\n        `(3*hidden_size, hidden_size)`\n    bias_ih: the learnable input-hidden bias, of shape `(3*hidden_size)`\n    bias_hh: the learnable hidden-hidden bias, of shape `(3*hidden_size)`\n\n.. note::\n    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\nExamples::\n\n    >>> rnn = nn.GRUCell(10, 20)\n    >>> input = torch.randn(6, 3, 10)\n    >>> hx = torch.randn(3, 20)\n    >>> output = []\n    >>> for i in range(6):\n    ...     hx = rnn(input[i], hx)\n    ...     output.append(hx)",
        "has_varargs": false
      },
      {
        "name": "GroupNorm",
        "api_path": "torch.nn.GroupNorm",
        "kind": "class",
        "params": [
          {
            "name": "num_groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "num_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Group Normalization over a mini-batch of inputs.\n\nThis layer implements the operation as described in\nthe paper `Group Normalization <https://arxiv.org/abs/1803.08494>`__\n\n.. math::\n    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe input channels are separated into :attr:`num_groups` groups, each containing\n``num_channels / num_groups`` channels. :attr:`num_channels` must be divisible by\n:attr:`num_groups`. The mean and standard-deviation are calculated\nseparately over each group. :math:`\\gamma` and :math:`\\beta` are learnable\nper-channel affine transform parameter vectors of size :attr:`num_channels` if\n:attr:`affine` is ``True``.\nThe variance is calculated via the biased estimator, equivalent to\n`torch.var(input, unbiased=False)`.\n\nThis layer uses statistics computed from input data in both training and\nevaluation modes.\n\nArgs:\n    num_groups (int): number of groups to separate the channels into\n    num_channels (int): number of channels expected in input\n    eps: a value added to the denominator for numerical stability. Default: 1e-5\n    affine: a boolean value that when set to ``True``, this module\n        has learnable per-channel affine parameters initialized to ones (for weights)\n        and zeros (for biases). Default: ``True``.\n\nShape:\n    - Input: :math:`(N, C, *)` where :math:`C=\\text{num\\_channels}`\n    - Output: :math:`(N, C, *)` (same shape as input)\n\nExamples::\n\n    >>> input = torch.randn(20, 6, 10, 10)\n    >>> # Separate 6 channels into 3 groups\n    >>> m = nn.GroupNorm(3, 6)\n    >>> # Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n    >>> m = nn.GroupNorm(6, 6)\n    >>> # Put all 6 channels into a single group (equivalent with LayerNorm)\n    >>> m = nn.GroupNorm(1, 6)\n    >>> # Activating the module\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Hardshrink",
        "api_path": "torch.nn.Hardshrink",
        "kind": "class",
        "params": [
          {
            "name": "lambd",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          }
        ],
        "docstring": "Applies the Hard Shrinkage (Hardshrink) function element-wise.\n\nHardshrink is defined as:\n\n.. math::\n    \\text{HardShrink}(x) =\n    \\begin{cases}\n    x, & \\text{ if } x > \\lambda \\\\\n    x, & \\text{ if } x < -\\lambda \\\\\n    0, & \\text{ otherwise }\n    \\end{cases}\n\nArgs:\n    lambd: the :math:`\\lambda` value for the Hardshrink formulation. Default: 0.5\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Hardshrink.png\n\nExamples::\n\n    >>> m = nn.Hardshrink()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Hardsigmoid",
        "api_path": "torch.nn.Hardsigmoid",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Hardsigmoid function element-wise.\n\nHardsigmoid is defined as:\n\n.. math::\n    \\text{Hardsigmoid}(x) = \\begin{cases}\n        0 & \\text{if~} x \\le -3, \\\\\n        1 & \\text{if~} x \\ge +3, \\\\\n        x / 6 + 1 / 2 & \\text{otherwise}\n    \\end{cases}\n\nArgs:\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Hardsigmoid.png\n\nExamples::\n\n    >>> m = nn.Hardsigmoid()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Hardswish",
        "api_path": "torch.nn.Hardswish",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Hardswish function, element-wise.\n\nMethod described in the paper: `Searching for MobileNetV3 <https://arxiv.org/abs/1905.02244>`_.\n\nHardswish is defined as:\n\n.. math::\n    \\text{Hardswish}(x) = \\begin{cases}\n        0 & \\text{if~} x \\le -3, \\\\\n        x & \\text{if~} x \\ge +3, \\\\\n        x \\cdot (x + 3) /6 & \\text{otherwise}\n    \\end{cases}\n\nArgs:\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Hardswish.png\n\nExamples::\n\n    >>> m = nn.Hardswish()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Hardtanh",
        "api_path": "torch.nn.Hardtanh",
        "kind": "class",
        "params": [
          {
            "name": "min_val",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-1.0",
            "annotation": "float"
          },
          {
            "name": "max_val",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "min_value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "max_value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies the HardTanh function element-wise.\n\nHardTanh is defined as:\n\n.. math::\n    \\text{HardTanh}(x) = \\begin{cases}\n        \\text{max\\_val} & \\text{ if } x > \\text{ max\\_val } \\\\\n        \\text{min\\_val} & \\text{ if } x < \\text{ min\\_val } \\\\\n        x & \\text{ otherwise } \\\\\n    \\end{cases}\n\nArgs:\n    min_val: minimum value of the linear region range. Default: -1\n    max_val: maximum value of the linear region range. Default: 1\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nKeyword arguments :attr:`min_value` and :attr:`max_value`\nhave been deprecated in favor of :attr:`min_val` and :attr:`max_val`.\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Hardtanh.png\n\nExamples::\n\n    >>> m = nn.Hardtanh(-2, 2)\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Identity",
        "api_path": "torch.nn.Identity",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": "Any"
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": "Any"
          }
        ],
        "docstring": "A placeholder identity operator that is argument-insensitive.\n\nArgs:\n    args: any argument (unused)\n    kwargs: any keyword argument (unused)\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\nExamples::\n\n    >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)\n    >>> input = torch.randn(128, 20)\n    >>> output = m(input)\n    >>> print(output.size())\n    torch.Size([128, 20])",
        "has_varargs": true
      },
      {
        "name": "InstanceNorm1d",
        "api_path": "torch.nn.InstanceNorm1d",
        "kind": "class",
        "params": [
          {
            "name": "num_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "float"
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Instance Normalization.\n\nThis operation applies Instance Normalization\nover a 2D (unbatched) or 3D (batched) input as described in the paper\n`Instance Normalization: The Missing Ingredient for Fast Stylization\n<https://arxiv.org/abs/1607.08022>`__.\n\n.. math::\n\n    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch. :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\nof size `C` (where `C` is the number of features or channels of the input) if :attr:`affine` is ``True``.\nThe variance is calculated via the biased estimator, equivalent to\n`torch.var(input, unbiased=False)`.\n\nBy default, this layer uses instance statistics computed from input data in\nboth training and evaluation modes.\n\nIf :attr:`track_running_stats` is set to ``True``, during training this\nlayer keeps running estimates of its computed mean and variance, which are\nthen used for normalization during evaluation. The running estimates are\nkept with a default :attr:`momentum` of 0.1.\n\n.. note::\n    This :attr:`momentum` argument is different from one used in optimizer\n    classes and the conventional notion of momentum. Mathematically, the\n    update rule for running statistics here is\n    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n    new observed value.\n\n.. note::\n    :class:`InstanceNorm1d` and :class:`LayerNorm` are very similar, but\n    have some subtle differences. :class:`InstanceNorm1d` is applied\n    on each channel of channeled data like multidimensional time series, but\n    :class:`LayerNorm` is usually applied on entire sample and often in NLP\n    tasks. Additionally, :class:`LayerNorm` applies elementwise affine\n    transform, while :class:`InstanceNorm1d` usually don't apply affine\n    transform.\n\nArgs:\n    num_features: number of features or channels :math:`C` of the input\n    eps: a value added to the denominator for numerical stability. Default: 1e-5\n    momentum: the value used for the running_mean and running_var computation. Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters, initialized the same way as done for batch normalization.\n        Default: ``False``.\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics and always uses batch\n        statistics in both training and eval modes. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, L)` or :math:`(C, L)`\n    - Output: :math:`(N, C, L)` or :math:`(C, L)` (same shape as input)\n\nExamples::\n\n    >>> # Without Learnable Parameters\n    >>> m = nn.InstanceNorm1d(100)\n    >>> # With Learnable Parameters\n    >>> m = nn.InstanceNorm1d(100, affine=True)\n    >>> input = torch.randn(20, 100, 40)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "InstanceNorm2d",
        "api_path": "torch.nn.InstanceNorm2d",
        "kind": "class",
        "params": [
          {
            "name": "num_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "float"
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Instance Normalization.\n\nThis operation applies Instance Normalization\nover a 4D input (a mini-batch of 2D inputs\nwith additional channel dimension) as described in the paper\n`Instance Normalization: The Missing Ingredient for Fast Stylization\n<https://arxiv.org/abs/1607.08022>`__.\n\n.. math::\n\n    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch. :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\nof size `C` (where `C` is the input size) if :attr:`affine` is ``True``.\nThe standard-deviation is calculated via the biased estimator, equivalent to\n`torch.var(input, unbiased=False)`.\n\nBy default, this layer uses instance statistics computed from input data in\nboth training and evaluation modes.\n\nIf :attr:`track_running_stats` is set to ``True``, during training this\nlayer keeps running estimates of its computed mean and variance, which are\nthen used for normalization during evaluation. The running estimates are\nkept with a default :attr:`momentum` of 0.1.\n\n.. note::\n    This :attr:`momentum` argument is different from one used in optimizer\n    classes and the conventional notion of momentum. Mathematically, the\n    update rule for running statistics here is\n    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n    new observed value.\n\n.. note::\n    :class:`InstanceNorm2d` and :class:`LayerNorm` are very similar, but\n    have some subtle differences. :class:`InstanceNorm2d` is applied\n    on each channel of channeled data like RGB images, but\n    :class:`LayerNorm` is usually applied on entire sample and often in NLP\n    tasks. Additionally, :class:`LayerNorm` applies elementwise affine\n    transform, while :class:`InstanceNorm2d` usually don't apply affine\n    transform.\n\nArgs:\n    num_features: :math:`C` from an expected input of size\n        :math:`(N, C, H, W)` or :math:`(C, H, W)`\n    eps: a value added to the denominator for numerical stability. Default: 1e-5\n    momentum: the value used for the running_mean and running_var computation. Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters, initialized the same way as done for batch normalization.\n        Default: ``False``.\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics and always uses batch\n        statistics in both training and eval modes. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, H, W)` or :math:`(C, H, W)`\n    - Output: :math:`(N, C, H, W)` or :math:`(C, H, W)` (same shape as input)\n\nExamples::\n\n    >>> # Without Learnable Parameters\n    >>> m = nn.InstanceNorm2d(100)\n    >>> # With Learnable Parameters\n    >>> m = nn.InstanceNorm2d(100, affine=True)\n    >>> input = torch.randn(20, 100, 35, 45)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "InstanceNorm3d",
        "api_path": "torch.nn.InstanceNorm3d",
        "kind": "class",
        "params": [
          {
            "name": "num_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "float"
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Instance Normalization.\n\nThis operation applies Instance Normalization\nover a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper\n`Instance Normalization: The Missing Ingredient for Fast Stylization\n<https://arxiv.org/abs/1607.08022>`__.\n\n.. math::\n\n    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch. :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\nof size C (where C is the input size) if :attr:`affine` is ``True``.\nThe standard-deviation is calculated via the biased estimator, equivalent to\n`torch.var(input, unbiased=False)`.\n\nBy default, this layer uses instance statistics computed from input data in\nboth training and evaluation modes.\n\nIf :attr:`track_running_stats` is set to ``True``, during training this\nlayer keeps running estimates of its computed mean and variance, which are\nthen used for normalization during evaluation. The running estimates are\nkept with a default :attr:`momentum` of 0.1.\n\n.. note::\n    This :attr:`momentum` argument is different from one used in optimizer\n    classes and the conventional notion of momentum. Mathematically, the\n    update rule for running statistics here is\n    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n    new observed value.\n\n.. note::\n    :class:`InstanceNorm3d` and :class:`LayerNorm` are very similar, but\n    have some subtle differences. :class:`InstanceNorm3d` is applied\n    on each channel of channeled data like 3D models with RGB color, but\n    :class:`LayerNorm` is usually applied on entire sample and often in NLP\n    tasks. Additionally, :class:`LayerNorm` applies elementwise affine\n    transform, while :class:`InstanceNorm3d` usually don't apply affine\n    transform.\n\nArgs:\n    num_features: :math:`C` from an expected input of size\n        :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)`\n    eps: a value added to the denominator for numerical stability. Default: 1e-5\n    momentum: the value used for the running_mean and running_var computation. Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters, initialized the same way as done for batch normalization.\n        Default: ``False``.\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics and always uses batch\n        statistics in both training and eval modes. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)`\n    - Output: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)` (same shape as input)\n\nExamples::\n\n    >>> # Without Learnable Parameters\n    >>> m = nn.InstanceNorm3d(100)\n    >>> # With Learnable Parameters\n    >>> m = nn.InstanceNorm3d(100, affine=True)\n    >>> input = torch.randn(20, 100, 35, 45, 10)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "LPPool1d",
        "api_path": "torch.nn.LPPool1d",
        "kind": "class",
        "params": [
          {
            "name": "norm_type",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 1D power-average pooling over an input signal composed of several input planes.\n\nOn each window, the function computed is:\n\n.. math::\n    f(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}}\n\n- At p = :math:`\\infty`, one gets Max Pooling\n- At p = 1, one gets Sum Pooling (which is proportional to Average Pooling)\n\n.. note:: If the sum to the power of `p` is zero, the gradient of this function is\n          not defined. This implementation will set the gradient to zero in this case.\n\nArgs:\n    kernel_size: a single int, the size of the window\n    stride: a single int, the stride of the window. Default value is :attr:`kernel_size`\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n\nShape:\n    - Input: :math:`(N, C, L_{in})` or :math:`(C, L_{in})`.\n    - Output: :math:`(N, C, L_{out})` or :math:`(C, L_{out})`, where\n\n      .. math::\n          L_{out} = \\left\\lfloor\\frac{L_{in} - \\text{kernel\\_size}}{\\text{stride}} + 1\\right\\rfloor\n\nExamples::\n    >>> # power-2 pool of window of length 3, with stride 2.\n    >>> m = nn.LPPool1d(2, 3, stride=2)\n    >>> input = torch.randn(20, 16, 50)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "LPPool2d",
        "api_path": "torch.nn.LPPool2d",
        "kind": "class",
        "params": [
          {
            "name": "norm_type",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 2D power-average pooling over an input signal composed of several input planes.\n\nOn each window, the function computed is:\n\n.. math::\n    f(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}}\n\n- At p = :math:`\\infty`, one gets Max Pooling\n- At p = 1, one gets Sum Pooling (which is proportional to average pooling)\n\nThe parameters :attr:`kernel_size`, :attr:`stride` can either be:\n\n    - a single ``int`` -- in which case the same value is used for the height and width dimension\n    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n      and the second `int` for the width dimension\n\n.. note:: If the sum to the power of `p` is zero, the gradient of this function is\n          not defined. This implementation will set the gradient to zero in this case.\n\nArgs:\n    kernel_size: the size of the window\n    stride: the stride of the window. Default value is :attr:`kernel_size`\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n\n      .. math::\n          H_{out} = \\left\\lfloor\\frac{H_{in} - \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\n\n      .. math::\n          W_{out} = \\left\\lfloor\\frac{W_{in} - \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\n\nExamples::\n\n    >>> # power-2 pool of square window of size=3, stride=2\n    >>> m = nn.LPPool2d(2, 3, stride=2)\n    >>> # pool of non-square window of power 1.2\n    >>> m = nn.LPPool2d(1.2, (3, 2), stride=(2, 1))\n    >>> input = torch.randn(20, 16, 50, 32)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "LPPool3d",
        "api_path": "torch.nn.LPPool3d",
        "kind": "class",
        "params": [
          {
            "name": "norm_type",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 3D power-average pooling over an input signal composed of several input planes.\n\nOn each window, the function computed is:\n\n.. math::\n    f(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}}\n\n- At p = :math:`\\infty`, one gets Max Pooling\n- At p = 1, one gets Sum Pooling (which is proportional to average pooling)\n\nThe parameters :attr:`kernel_size`, :attr:`stride` can either be:\n\n    - a single ``int`` -- in which case the same value is used for the height, width and depth dimension\n    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,\n      the second `int` for the height dimension and the third `int` for the width dimension\n\n.. note:: If the sum to the power of `p` is zero, the gradient of this function is\n          not defined. This implementation will set the gradient to zero in this case.\n\nArgs:\n    kernel_size: the size of the window\n    stride: the stride of the window. Default value is :attr:`kernel_size`\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or\n      :math:`(C, D_{out}, H_{out}, W_{out})`, where\n\n      .. math::\n          D_{out} = \\left\\lfloor\\frac{D_{in} - \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\n\n      .. math::\n          H_{out} = \\left\\lfloor\\frac{H_{in} - \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\n\n      .. math::\n          W_{out} = \\left\\lfloor\\frac{W_{in} - \\text{kernel\\_size}[2]}{\\text{stride}[2]} + 1\\right\\rfloor\n\nExamples::\n\n    >>> # power-2 pool of square window of size=3, stride=2\n    >>> m = nn.LPPool3d(2, 3, stride=2)\n    >>> # pool of non-square window of power 1.2\n    >>> m = nn.LPPool3d(1.2, (3, 2, 2), stride=(2, 1, 2))\n    >>> input = torch.randn(20, 16, 50, 44, 31)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "LSTM",
        "api_path": "torch.nn.LSTM",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "__init__(input_size,hidden_size,num_layers=1,bias=True,batch_first=False,dropout=0.0,bidirectional=False,proj_size=0,device=None,dtype=None)\n\nApply a multi-layer long short-term memory (LSTM) RNN to an input sequence.\nFor each element in the input sequence, each layer computes the following\nfunction:\n\n.. math::\n    \\begin{array}{ll} \\\\\n        i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n        f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n        g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n        o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n        c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n        h_t = o_t \\odot \\tanh(c_t) \\\\\n    \\end{array}\n\nwhere :math:`h_t` is the hidden state at time `t`, :math:`c_t` is the cell\nstate at time `t`, :math:`x_t` is the input at time `t`, :math:`h_{t-1}`\nis the hidden state of the layer at time `t-1` or the initial hidden\nstate at time `0`, and :math:`i_t`, :math:`f_t`, :math:`g_t`,\n:math:`o_t` are the input, forget, cell, and output gates, respectively.\n:math:`\\sigma` is the sigmoid function, and :math:`\\odot` is the Hadamard product.\n\nIn a multilayer LSTM, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n(:math:`l \\ge 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\ndropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\nvariable which is :math:`0` with probability :attr:`dropout`.\n\nIf ``proj_size > 0`` is specified, LSTM with projections will be used. This changes\nthe LSTM cell in the following way. First, the dimension of :math:`h_t` will be changed from\n``hidden_size`` to ``proj_size`` (dimensions of :math:`W_{hi}` will be changed accordingly).\nSecond, the output hidden state of each layer will be multiplied by a learnable projection\nmatrix: :math:`h_t = W_{hr}h_t`. Note that as a consequence of this, the output\nof LSTM network will be of different shape as well. See Inputs/Outputs sections below for exact\ndimensions of all variables. You can find more details in https://arxiv.org/abs/1402.1128.\n\nArgs:\n    input_size: The number of expected features in the input `x`\n    hidden_size: The number of features in the hidden state `h`\n    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n        would mean stacking two LSTMs together to form a `stacked LSTM`,\n        with the second LSTM taking in outputs of the first LSTM and\n        computing the final results. Default: 1\n    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n        Default: ``True``\n    batch_first: If ``True``, then the input and output tensors are provided\n        as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n        Note that this does not apply to hidden or cell states. See the\n        Inputs/Outputs sections below for details.  Default: ``False``\n    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n        LSTM layer except the last layer, with dropout probability equal to\n        :attr:`dropout`. Default: 0\n    bidirectional: If ``True``, becomes a bidirectional LSTM. Default: ``False``\n    proj_size: If ``> 0``, will use LSTM with projections of corresponding size. Default: 0\n\nInputs: input, (h_0, c_0)\n    * **input**: tensor of shape :math:`(L, H_{in})` for unbatched input,\n      :math:`(L, N, H_{in})` when ``batch_first=False`` or\n      :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n      the input sequence.  The input can also be a packed variable length sequence.\n      See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n      :func:`torch.nn.utils.rnn.pack_sequence` for details.\n    * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` for unbatched input or\n      :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the\n      initial hidden state for each element in the input sequence.\n      Defaults to zeros if (h_0, c_0) is not provided.\n    * **c_0**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{cell})` for unbatched input or\n      :math:`(D * \\text{num\\_layers}, N, H_{cell})` containing the\n      initial cell state for each element in the input sequence.\n      Defaults to zeros if (h_0, c_0) is not provided.\n\n    where:\n\n    .. math::\n        \\begin{aligned}\n            N ={} & \\text{batch size} \\\\\n            L ={} & \\text{sequence length} \\\\\n            D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n            H_{in} ={} & \\text{input\\_size} \\\\\n            H_{cell} ={} & \\text{hidden\\_size} \\\\\n            H_{out} ={} & \\text{proj\\_size if } \\text{proj\\_size}>0 \\text{ otherwise hidden\\_size} \\\\\n        \\end{aligned}\n\nOutputs: output, (h_n, c_n)\n    * **output**: tensor of shape :math:`(L, D * H_{out})` for unbatched input,\n      :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n      :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n      `(h_t)` from the last layer of the LSTM, for each `t`. If a\n      :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n      will also be a packed sequence. When ``bidirectional=True``, `output` will contain\n      a concatenation of the forward and reverse hidden states at each time step in the sequence.\n    * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` for unbatched input or\n      :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the\n      final hidden state for each element in the sequence. When ``bidirectional=True``,\n      `h_n` will contain a concatenation of the final forward and reverse hidden states, respectively.\n    * **c_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{cell})` for unbatched input or\n      :math:`(D * \\text{num\\_layers}, N, H_{cell})` containing the\n      final cell state for each element in the sequence. When ``bidirectional=True``,\n      `c_n` will contain a concatenation of the final forward and reverse cell states, respectively.\n\nAttributes:\n    weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n        `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`.\n        Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`. If\n        ``proj_size > 0`` was specified, the shape will be\n        `(4*hidden_size, num_directions * proj_size)` for `k > 0`\n    weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n        `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`. If ``proj_size > 0``\n        was specified, the shape will be `(4*hidden_size, proj_size)`.\n    bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n        `(b_ii|b_if|b_ig|b_io)`, of shape `(4*hidden_size)`\n    bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n        `(b_hi|b_hf|b_hg|b_ho)`, of shape `(4*hidden_size)`\n    weight_hr_l[k] : the learnable projection weights of the :math:`\\text{k}^{th}` layer\n        of shape `(proj_size, hidden_size)`. Only present when ``proj_size > 0`` was\n        specified.\n    weight_ih_l[k]_reverse: Analogous to `weight_ih_l[k]` for the reverse direction.\n        Only present when ``bidirectional=True``.\n    weight_hh_l[k]_reverse:  Analogous to `weight_hh_l[k]` for the reverse direction.\n        Only present when ``bidirectional=True``.\n    bias_ih_l[k]_reverse:  Analogous to `bias_ih_l[k]` for the reverse direction.\n        Only present when ``bidirectional=True``.\n    bias_hh_l[k]_reverse:  Analogous to `bias_hh_l[k]` for the reverse direction.\n        Only present when ``bidirectional=True``.\n    weight_hr_l[k]_reverse:  Analogous to `weight_hr_l[k]` for the reverse direction.\n        Only present when ``bidirectional=True`` and ``proj_size > 0`` was specified.\n\n.. note::\n    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n\n.. note::\n    For bidirectional LSTMs, forward and backward are directions 0 and 1 respectively.\n    Example of splitting the output layers when ``batch_first=False``:\n    ``output.view(seq_len, batch, num_directions, hidden_size)``.\n\n.. note::\n    For bidirectional LSTMs, `h_n` is not equivalent to the last element of `output`; the\n    former contains the final forward and reverse hidden states, while the latter contains the\n    final forward hidden state and the initial reverse hidden state.\n\n.. note::\n    ``batch_first`` argument is ignored for unbatched inputs.\n\n.. note::\n    ``proj_size`` should be smaller than ``hidden_size``.\n\n.. include:: ../cudnn_rnn_determinism.rst\n\n.. include:: ../cudnn_persistent_rnn.rst\n\nExamples::\n\n    >>> rnn = nn.LSTM(10, 20, 2)\n    >>> input = torch.randn(5, 3, 10)\n    >>> h0 = torch.randn(2, 3, 20)\n    >>> c0 = torch.randn(2, 3, 20)\n    >>> output, (hn, cn) = rnn(input, (h0, c0))",
        "has_varargs": true
      },
      {
        "name": "LSTMCell",
        "api_path": "torch.nn.LSTMCell",
        "kind": "class",
        "params": [
          {
            "name": "input_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "hidden_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A long short-term memory (LSTM) cell.\n\n.. math::\n\n    \\begin{array}{ll}\n    i = \\sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\\\\n    f = \\sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\\\\n    g = \\tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\\\\n    o = \\sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\\\\n    c' = f \\odot c + i \\odot g \\\\\n    h' = o \\odot \\tanh(c') \\\\\n    \\end{array}\n\nwhere :math:`\\sigma` is the sigmoid function, and :math:`\\odot` is the Hadamard product.\n\nArgs:\n    input_size: The number of expected features in the input `x`\n    hidden_size: The number of features in the hidden state `h`\n    bias: If ``False``, then the layer does not use bias weights `b_ih` and\n        `b_hh`. Default: ``True``\n\nInputs: input, (h_0, c_0)\n    - **input** of shape `(batch, input_size)` or `(input_size)`: tensor containing input features\n    - **h_0** of shape `(batch, hidden_size)` or `(hidden_size)`: tensor containing the initial hidden state\n    - **c_0** of shape `(batch, hidden_size)` or `(hidden_size)`: tensor containing the initial cell state\n\n      If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.\n\nOutputs: (h_1, c_1)\n    - **h_1** of shape `(batch, hidden_size)` or `(hidden_size)`: tensor containing the next hidden state\n    - **c_1** of shape `(batch, hidden_size)` or `(hidden_size)`: tensor containing the next cell state\n\nAttributes:\n    weight_ih: the learnable input-hidden weights, of shape\n        `(4*hidden_size, input_size)`\n    weight_hh: the learnable hidden-hidden weights, of shape\n        `(4*hidden_size, hidden_size)`\n    bias_ih: the learnable input-hidden bias, of shape `(4*hidden_size)`\n    bias_hh: the learnable hidden-hidden bias, of shape `(4*hidden_size)`\n\n.. note::\n    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\nExamples::\n\n    >>> rnn = nn.LSTMCell(10, 20)  # (input_size, hidden_size)\n    >>> input = torch.randn(2, 3, 10)  # (time_steps, batch, input_size)\n    >>> hx = torch.randn(3, 20)  # (batch, hidden_size)\n    >>> cx = torch.randn(3, 20)\n    >>> output = []\n    >>> for i in range(input.size()[0]):\n    ...     hx, cx = rnn(input[i], (hx, cx))\n    ...     output.append(hx)\n    >>> output = torch.stack(output, dim=0)",
        "has_varargs": false
      },
      {
        "name": "LayerNorm",
        "api_path": "torch.nn.LayerNorm",
        "kind": "class",
        "params": [
          {
            "name": "normalized_shape",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "elementwise_affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Layer Normalization over a mini-batch of inputs.\n\nThis layer implements the operation as described in\nthe paper `Layer Normalization <https://arxiv.org/abs/1607.06450>`__\n\n.. math::\n    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe mean and standard-deviation are calculated over the last `D` dimensions, where `D`\nis the dimension of :attr:`normalized_shape`. For example, if :attr:`normalized_shape`\nis ``(3, 5)`` (a 2-dimensional shape), the mean and standard-deviation are computed over\nthe last 2 dimensions of the input (i.e. ``input.mean((-2, -1))``).\n:math:`\\gamma` and :math:`\\beta` are learnable affine transform parameters of\n:attr:`normalized_shape` if :attr:`elementwise_affine` is ``True``.\nThe variance is calculated via the biased estimator, equivalent to\n`torch.var(input, unbiased=False)`.\n\n.. note::\n    Unlike Batch Normalization and Instance Normalization, which applies\n    scalar scale and bias for each entire channel/plane with the\n    :attr:`affine` option, Layer Normalization applies per-element scale and\n    bias with :attr:`elementwise_affine`.\n\nThis layer uses statistics computed from input data in both training and\nevaluation modes.\n\nArgs:\n    normalized_shape (int or list or torch.Size): input shape from an expected input\n        of size\n\n        .. math::\n            [* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n                \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n\n        If a single integer is used, it is treated as a singleton list, and this module will\n        normalize over the last dimension which is expected to be of that specific size.\n    eps: a value added to the denominator for numerical stability. Default: 1e-5\n    elementwise_affine: a boolean value that when set to ``True``, this module\n        has learnable per-element affine parameters initialized to ones (for weights)\n        and zeros (for biases). Default: ``True``.\n    bias: If set to ``False``, the layer will not learn an additive bias (only relevant if\n        :attr:`elementwise_affine` is ``True``). Default: ``True``.\n\nAttributes:\n    weight: the learnable weights of the module of shape\n        :math:`\\text{normalized\\_shape}` when :attr:`elementwise_affine` is set to ``True``.\n        The values are initialized to 1.\n    bias:   the learnable bias of the module of shape\n            :math:`\\text{normalized\\_shape}` when :attr:`elementwise_affine` is set to ``True``.\n            The values are initialized to 0.\n\nShape:\n    - Input: :math:`(N, *)`\n    - Output: :math:`(N, *)` (same shape as input)\n\nExamples::\n\n    >>> # NLP Example\n    >>> batch, sentence_length, embedding_dim = 20, 5, 10\n    >>> embedding = torch.randn(batch, sentence_length, embedding_dim)\n    >>> layer_norm = nn.LayerNorm(embedding_dim)\n    >>> # Activate module\n    >>> layer_norm(embedding)\n    >>>\n    >>> # Image Example\n    >>> N, C, H, W = 20, 5, 10, 10\n    >>> input = torch.randn(N, C, H, W)\n    >>> # Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n    >>> # as shown in the image below\n    >>> layer_norm = nn.LayerNorm([C, H, W])\n    >>> output = layer_norm(input)\n\n.. image:: ../_static/img/nn/layer_norm.jpg\n    :scale: 50 %",
        "has_varargs": false
      },
      {
        "name": "LazyBatchNorm1d",
        "api_path": "torch.nn.LazyBatchNorm1d",
        "kind": "class",
        "params": [
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": null
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": null
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.BatchNorm1d` module with lazy initialization.\n\nLazy initialization based on the ``num_features`` argument of the :class:`BatchNorm1d` that is inferred\nfrom the ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight`, `bias`,\n`running_mean` and `running_var`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    eps: a value added to the denominator for numerical stability.\n        Default: 1e-5\n    momentum: the value used for the running_mean and running_var\n        computation. Can be set to ``None`` for cumulative moving average\n        (i.e. simple average). Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters. Default: ``True``\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics, and initializes statistics\n        buffers :attr:`running_mean` and :attr:`running_var` as ``None``.\n        When these buffers are ``None``, this module always uses batch statistics.\n        in both training and eval modes. Default: ``True``",
        "has_varargs": false
      },
      {
        "name": "LazyBatchNorm2d",
        "api_path": "torch.nn.LazyBatchNorm2d",
        "kind": "class",
        "params": [
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": null
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": null
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.BatchNorm2d` module with lazy initialization.\n\nLazy initialization is done for the ``num_features`` argument of the :class:`BatchNorm2d` that is inferred\nfrom the ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight`, `bias`,\n`running_mean` and `running_var`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    eps: a value added to the denominator for numerical stability.\n        Default: 1e-5\n    momentum: the value used for the running_mean and running_var\n        computation. Can be set to ``None`` for cumulative moving average\n        (i.e. simple average). Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters. Default: ``True``\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics, and initializes statistics\n        buffers :attr:`running_mean` and :attr:`running_var` as ``None``.\n        When these buffers are ``None``, this module always uses batch statistics.\n        in both training and eval modes. Default: ``True``",
        "has_varargs": false
      },
      {
        "name": "LazyBatchNorm3d",
        "api_path": "torch.nn.LazyBatchNorm3d",
        "kind": "class",
        "params": [
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": null
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": null
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.BatchNorm3d` module with lazy initialization.\n\nLazy initialization is done for the ``num_features`` argument of the :class:`BatchNorm3d` that is inferred\nfrom the ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight`, `bias`,\n`running_mean` and `running_var`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    eps: a value added to the denominator for numerical stability.\n        Default: 1e-5\n    momentum: the value used for the running_mean and running_var\n        computation. Can be set to ``None`` for cumulative moving average\n        (i.e. simple average). Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters. Default: ``True``\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics, and initializes statistics\n        buffers :attr:`running_mean` and :attr:`running_var` as ``None``.\n        When these buffers are ``None``, this module always uses batch statistics.\n        in both training and eval modes. Default: ``True``",
        "has_varargs": false
      },
      {
        "name": "LazyConv1d",
        "api_path": "torch.nn.LazyConv1d",
        "kind": "class",
        "params": [
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.Conv1d` module with lazy initialization of the ``in_channels`` argument.\n\nThe ``in_channels`` argument of the :class:`Conv1d` is inferred from the ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight` and `bias`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): Zero-padding added to both sides of\n        the input. Default: 0\n    dilation (int or tuple, optional): Spacing between kernel\n        elements. Default: 1\n    groups (int, optional): Number of blocked connections from input\n        channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the\n        output. Default: ``True``\n    padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n\n.. seealso:: :class:`torch.nn.Conv1d` and :class:`torch.nn.modules.lazy.LazyModuleMixin`",
        "has_varargs": false
      },
      {
        "name": "LazyConv2d",
        "api_path": "torch.nn.LazyConv2d",
        "kind": "class",
        "params": [
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.Conv2d` module with lazy initialization of the ``in_channels`` argument.\n\nThe ``in_channels`` argument of the :class:`Conv2d` that is inferred from the ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight` and `bias`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): Zero-padding added to both sides of\n        the input. Default: 0\n    dilation (int or tuple, optional): Spacing between kernel\n        elements. Default: 1\n    groups (int, optional): Number of blocked connections from input\n        channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the\n        output. Default: ``True``\n    padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n\n.. seealso:: :class:`torch.nn.Conv2d` and :class:`torch.nn.modules.lazy.LazyModuleMixin`",
        "has_varargs": false
      },
      {
        "name": "LazyConv3d",
        "api_path": "torch.nn.LazyConv3d",
        "kind": "class",
        "params": [
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.Conv3d` module with lazy initialization of the ``in_channels`` argument.\n\nThe ``in_channels`` argument of the :class:`Conv3d` that is inferred from\nthe ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight` and `bias`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): Zero-padding added to both sides of\n        the input. Default: 0\n    dilation (int or tuple, optional): Spacing between kernel\n        elements. Default: 1\n    groups (int, optional): Number of blocked connections from input\n        channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the\n        output. Default: ``True``\n    padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n\n.. seealso:: :class:`torch.nn.Conv3d` and :class:`torch.nn.modules.lazy.LazyModuleMixin`",
        "has_varargs": false
      },
      {
        "name": "LazyConvTranspose1d",
        "api_path": "torch.nn.LazyConvTranspose1d",
        "kind": "class",
        "params": [
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "output_padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.ConvTranspose1d` module with lazy initialization of the ``in_channels`` argument.\n\nThe ``in_channels`` argument of the :class:`ConvTranspose1d` that is inferred from\nthe ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight` and `bias`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n        will be added to both sides of the input. Default: 0\n    output_padding (int or tuple, optional): Additional size added to one side\n        of the output shape. Default: 0\n    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n\n.. seealso:: :class:`torch.nn.ConvTranspose1d` and :class:`torch.nn.modules.lazy.LazyModuleMixin`",
        "has_varargs": false
      },
      {
        "name": "LazyConvTranspose2d",
        "api_path": "torch.nn.LazyConvTranspose2d",
        "kind": "class",
        "params": [
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "output_padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.ConvTranspose2d` module with lazy initialization of the ``in_channels`` argument.\n\nThe ``in_channels`` argument of the :class:`ConvTranspose2d` is inferred from\nthe ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight` and `bias`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n        will be added to both sides of each dimension in the input. Default: 0\n    output_padding (int or tuple, optional): Additional size added to one side\n        of each dimension in the output shape. Default: 0\n    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n\n.. seealso:: :class:`torch.nn.ConvTranspose2d` and :class:`torch.nn.modules.lazy.LazyModuleMixin`",
        "has_varargs": false
      },
      {
        "name": "LazyConvTranspose3d",
        "api_path": "torch.nn.LazyConvTranspose3d",
        "kind": "class",
        "params": [
          {
            "name": "out_channels",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "output_padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "groups",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "zeros",
            "annotation": "Literal"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.ConvTranspose3d` module with lazy initialization of the ``in_channels`` argument.\n\nThe ``in_channels`` argument of the :class:`ConvTranspose3d` is inferred from\nthe ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight` and `bias`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    out_channels (int): Number of channels produced by the convolution\n    kernel_size (int or tuple): Size of the convolving kernel\n    stride (int or tuple, optional): Stride of the convolution. Default: 1\n    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n        will be added to both sides of each dimension in the input. Default: 0\n    output_padding (int or tuple, optional): Additional size added to one side\n        of each dimension in the output shape. Default: 0\n    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n\n.. seealso:: :class:`torch.nn.ConvTranspose3d` and :class:`torch.nn.modules.lazy.LazyModuleMixin`",
        "has_varargs": false
      },
      {
        "name": "LazyInstanceNorm1d",
        "api_path": "torch.nn.LazyInstanceNorm1d",
        "kind": "class",
        "params": [
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": null
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": null
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.InstanceNorm1d` module with lazy initialization of the ``num_features`` argument.\n\nThe ``num_features`` argument of the :class:`InstanceNorm1d` is inferred from the ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight`, `bias`, `running_mean` and `running_var`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    num_features: :math:`C` from an expected input of size\n        :math:`(N, C, L)` or :math:`(C, L)`\n    eps: a value added to the denominator for numerical stability. Default: 1e-5\n    momentum: the value used for the running_mean and running_var computation. Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters, initialized the same way as done for batch normalization.\n        Default: ``False``.\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics and always uses batch\n        statistics in both training and eval modes. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, L)` or :math:`(C, L)`\n    - Output: :math:`(N, C, L)` or :math:`(C, L)` (same shape as input)",
        "has_varargs": false
      },
      {
        "name": "LazyInstanceNorm2d",
        "api_path": "torch.nn.LazyInstanceNorm2d",
        "kind": "class",
        "params": [
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": null
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": null
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.InstanceNorm2d` module with lazy initialization of the ``num_features`` argument.\n\nThe ``num_features`` argument of the :class:`InstanceNorm2d` is inferred from the ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight`, `bias`,\n`running_mean` and `running_var`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    num_features: :math:`C` from an expected input of size\n        :math:`(N, C, H, W)` or :math:`(C, H, W)`\n    eps: a value added to the denominator for numerical stability. Default: 1e-5\n    momentum: the value used for the running_mean and running_var computation. Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters, initialized the same way as done for batch normalization.\n        Default: ``False``.\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics and always uses batch\n        statistics in both training and eval modes. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, H, W)` or :math:`(C, H, W)`\n    - Output: :math:`(N, C, H, W)` or :math:`(C, H, W)` (same shape as input)",
        "has_varargs": false
      },
      {
        "name": "LazyInstanceNorm3d",
        "api_path": "torch.nn.LazyInstanceNorm3d",
        "kind": "class",
        "params": [
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": null
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": null
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.InstanceNorm3d` module with lazy initialization of the ``num_features`` argument.\n\nThe ``num_features`` argument of the :class:`InstanceNorm3d` is inferred from the ``input.size(1)``.\nThe attributes that will be lazily initialized are `weight`, `bias`,\n`running_mean` and `running_var`.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    num_features: :math:`C` from an expected input of size\n        :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)`\n    eps: a value added to the denominator for numerical stability. Default: 1e-5\n    momentum: the value used for the running_mean and running_var computation. Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters, initialized the same way as done for batch normalization.\n        Default: ``False``.\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics and always uses batch\n        statistics in both training and eval modes. Default: ``False``\n\nShape:\n    - Input: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)`\n    - Output: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)` (same shape as input)",
        "has_varargs": false
      },
      {
        "name": "LazyLinear",
        "api_path": "torch.nn.LazyLinear",
        "kind": "class",
        "params": [
          {
            "name": "out_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A :class:`torch.nn.Linear` module where `in_features` is inferred.\n\nIn this module, the `weight` and `bias` are of :class:`torch.nn.UninitializedParameter`\nclass. They will be initialized after the first call to ``forward`` is done and the\nmodule will become a regular :class:`torch.nn.Linear` module. The ``in_features`` argument\nof the :class:`Linear` is inferred from the ``input.shape[-1]``.\n\nCheck the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\non lazy modules and their limitations.\n\nArgs:\n    out_features: size of each output sample\n    bias: If set to ``False``, the layer will not learn an additive bias.\n        Default: ``True``\n\nAttributes:\n    weight: the learnable weights of the module of shape\n        :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n        initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n        :math:`k = \\frac{1}{\\text{in\\_features}}`\n    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n            If :attr:`bias` is ``True``, the values are initialized from\n            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n            :math:`k = \\frac{1}{\\text{in\\_features}}`",
        "has_varargs": false
      },
      {
        "name": "LeakyReLU",
        "api_path": "torch.nn.LeakyReLU",
        "kind": "class",
        "params": [
          {
            "name": "negative_slope",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the LeakyReLU function element-wise.\n\n.. math::\n    \\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)\n\n\nor\n\n.. math::\n    \\text{LeakyReLU}(x) =\n    \\begin{cases}\n    x, & \\text{ if } x \\geq 0 \\\\\n    \\text{negative\\_slope} \\times x, & \\text{ otherwise }\n    \\end{cases}\n\nArgs:\n    negative_slope: Controls the angle of the negative slope (which is used for\n      negative input values). Default: 1e-2\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(*)`, same shape as the input\n\n.. image:: ../scripts/activation_images/LeakyReLU.png\n\nExamples::\n\n    >>> m = nn.LeakyReLU(0.1)\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Linear",
        "api_path": "torch.nn.Linear",
        "kind": "class",
        "params": [
          {
            "name": "in_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "out_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies an affine linear transformation to the incoming data: :math:`y = xA^T + b`.\n\nThis module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\nArgs:\n    in_features: size of each input sample\n    out_features: size of each output sample\n    bias: If set to ``False``, the layer will not learn an additive bias.\n        Default: ``True``\n\nShape:\n    - Input: :math:`(*, H_\\text{in})` where :math:`*` means any number of\n      dimensions including none and :math:`H_\\text{in} = \\text{in\\_features}`.\n    - Output: :math:`(*, H_\\text{out})` where all but the last dimension\n      are the same shape as the input and :math:`H_\\text{out} = \\text{out\\_features}`.\n\nAttributes:\n    weight: the learnable weights of the module of shape\n        :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n        initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n        :math:`k = \\frac{1}{\\text{in\\_features}}`\n    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n            If :attr:`bias` is ``True``, the values are initialized from\n            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n            :math:`k = \\frac{1}{\\text{in\\_features}}`\n\nExamples::\n\n    >>> m = nn.Linear(20, 30)\n    >>> input = torch.randn(128, 20)\n    >>> output = m(input)\n    >>> print(output.size())\n    torch.Size([128, 30])",
        "has_varargs": false
      },
      {
        "name": "LocalResponseNorm",
        "api_path": "torch.nn.LocalResponseNorm",
        "kind": "class",
        "params": [
          {
            "name": "size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "alpha",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0001",
            "annotation": "float"
          },
          {
            "name": "beta",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.75",
            "annotation": "float"
          },
          {
            "name": "k",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          }
        ],
        "docstring": "Applies local response normalization over an input signal.\n\nThe input signal is composed of several input planes, where channels occupy the second dimension.\nApplies normalization across channels.\n\n.. math::\n    b_{c} = a_{c}\\left(k + \\frac{\\alpha}{n}\n    \\sum_{c'=\\max(0, c-n/2)}^{\\min(N-1,c+n/2)}a_{c'}^2\\right)^{-\\beta}\n\nArgs:\n    size: amount of neighbouring channels used for normalization\n    alpha: multiplicative factor. Default: 0.0001\n    beta: exponent. Default: 0.75\n    k: additive factor. Default: 1\n\nShape:\n    - Input: :math:`(N, C, *)`\n    - Output: :math:`(N, C, *)` (same shape as input)\n\nExamples::\n\n    >>> lrn = nn.LocalResponseNorm(2)\n    >>> signal_2d = torch.randn(32, 5, 24, 24)\n    >>> signal_4d = torch.randn(16, 5, 7, 7, 7, 7)\n    >>> output_2d = lrn(signal_2d)\n    >>> output_4d = lrn(signal_4d)",
        "has_varargs": false
      },
      {
        "name": "LogSigmoid",
        "api_path": "torch.nn.LogSigmoid",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the Logsigmoid function element-wise.\n\n.. math::\n    \\text{LogSigmoid}(x) = \\log\\left(\\frac{ 1 }{ 1 + \\exp(-x)}\\right)\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/LogSigmoid.png\n\nExamples::\n\n    >>> m = nn.LogSigmoid()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "LogSoftmax",
        "api_path": "torch.nn.LogSoftmax",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies the :math:`\\log(\\text{Softmax}(x))` function to an n-dimensional input Tensor.\n\nThe LogSoftmax formulation can be simplified as:\n\n.. math::\n    \\text{LogSoftmax}(x_{i}) = \\log\\left(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} \\right)\n\nShape:\n    - Input: :math:`(*)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(*)`, same shape as the input\n\nArgs:\n    dim (int): A dimension along which LogSoftmax will be computed.\n\nReturns:\n    a Tensor of the same dimension and shape as the input with\n    values in the range [-inf, 0)\n\nExamples::\n\n    >>> m = nn.LogSoftmax(dim=1)\n    >>> input = torch.randn(2, 3)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "MaxPool1d",
        "api_path": "torch.nn.MaxPool1d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "return_indices",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 1D max pooling over an input signal composed of several input planes.\n\nIn the simplest case, the output value of the layer with input size :math:`(N, C, L)`\nand output :math:`(N, C, L_{out})` can be precisely described as:\n\n.. math::\n    out(N_i, C_j, k) = \\max_{m=0, \\ldots, \\text{kernel\\_size} - 1}\n            input(N_i, C_j, stride \\times k + m)\n\nIf :attr:`padding` is non-zero, then the input is implicitly padded with negative infinity on both sides\nfor :attr:`padding` number of points. :attr:`dilation` is the stride between the elements within the\nsliding window. This `link`_ has a nice visualization of the pooling parameters.\n\nNote:\n    When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\n    or the input. Sliding windows that would start in the right padded region are ignored.\n\nArgs:\n    kernel_size: The size of the sliding window, must be > 0.\n    stride: The stride of the sliding window, must be > 0. Default value is :attr:`kernel_size`.\n    padding: Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.\n    dilation: The stride between elements within a sliding window, must be > 0.\n    return_indices: If ``True``, will return the argmax along with the max values.\n                    Useful for :class:`torch.nn.MaxUnpool1d` later\n    ceil_mode: If ``True``, will use `ceil` instead of `floor` to compute the output shape. This\n               ensures that every element in the input tensor is covered by a sliding window.\n\nShape:\n    - Input: :math:`(N, C, L_{in})` or :math:`(C, L_{in})`.\n    - Output: :math:`(N, C, L_{out})` or :math:`(C, L_{out})`,\n\n      where ``ceil_mode = False``\n\n      .. math::\n          L_{out} = \\left\\lfloor \\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n               \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}}\\right\\rfloor + 1\n\n      where ``ceil_mode = True``\n\n      .. math::\n          L_{out} = \\left\\lceil \\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n                \\times (\\text{kernel\\_size} - 1) - 1 + (stride - 1)}{\\text{stride}}\\right\\rceil + 1\n\n    - Ensure that the last pooling starts inside the image, make :math:`L_{out} = L_{out} - 1`\n      when :math:`(L_{out} - 1) * \\text{stride} >= L_{in} + \\text{padding}`.\n\nExamples::\n\n    >>> # pool of size=3, stride=2\n    >>> m = nn.MaxPool1d(3, stride=2)\n    >>> input = torch.randn(20, 16, 50)\n    >>> output = m(input)\n\n.. _link:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
        "has_varargs": false
      },
      {
        "name": "MaxPool2d",
        "api_path": "torch.nn.MaxPool2d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "return_indices",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 2D max pooling over an input signal composed of several input planes.\n\nIn the simplest case, the output value of the layer with input size :math:`(N, C, H, W)`,\noutput :math:`(N, C, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kH, kW)`\ncan be precisely described as:\n\n.. math::\n    \\begin{aligned}\n        out(N_i, C_j, h, w) ={} & \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\\n                                & \\text{input}(N_i, C_j, \\text{stride[0]} \\times h + m,\n                                               \\text{stride[1]} \\times w + n)\n    \\end{aligned}\n\nIf :attr:`padding` is non-zero, then the input is implicitly padded with negative infinity on both sides\nfor :attr:`padding` number of points. :attr:`dilation` controls the spacing between the kernel points.\nIt is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n\nNote:\n    When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\n    or the input. Sliding windows that would start in the right padded region are ignored.\n\nThe parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n\n    - a single ``int`` -- in which case the same value is used for the height and width dimension\n    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n      and the second `int` for the width dimension\n\nArgs:\n    kernel_size: the size of the window to take a max over\n    stride: the stride of the window. Default value is :attr:`kernel_size`\n    padding: Implicit negative infinity padding to be added on both sides\n    dilation: a parameter that controls the stride of elements in the window\n    return_indices: if ``True``, will return the max indices along with the outputs.\n                    Useful for :class:`torch.nn.MaxUnpool2d` later\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n\n      .. math::\n          H_{out} = \\left\\lfloor\\frac{H_{in} + 2 * \\text{padding[0]} - \\text{dilation[0]}\n                \\times (\\text{kernel\\_size[0]} - 1) - 1}{\\text{stride[0]}} + 1\\right\\rfloor\n\n      .. math::\n          W_{out} = \\left\\lfloor\\frac{W_{in} + 2 * \\text{padding[1]} - \\text{dilation[1]}\n                \\times (\\text{kernel\\_size[1]} - 1) - 1}{\\text{stride[1]}} + 1\\right\\rfloor\n\nExamples::\n\n    >>> # pool of square window of size=3, stride=2\n    >>> m = nn.MaxPool2d(3, stride=2)\n    >>> # pool of non-square window\n    >>> m = nn.MaxPool2d((3, 2), stride=(2, 1))\n    >>> input = torch.randn(20, 16, 50, 32)\n    >>> output = m(input)\n\n.. _link:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
        "has_varargs": false
      },
      {
        "name": "MaxPool3d",
        "api_path": "torch.nn.MaxPool3d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "return_indices",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "ceil_mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies a 3D max pooling over an input signal composed of several input planes.\n\nIn the simplest case, the output value of the layer with input size :math:`(N, C, D, H, W)`,\noutput :math:`(N, C, D_{out}, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kD, kH, kW)`\ncan be precisely described as:\n\n.. math::\n    \\begin{aligned}\n        \\text{out}(N_i, C_j, d, h, w) ={} & \\max_{k=0, \\ldots, kD-1} \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\\n                                          & \\text{input}(N_i, C_j, \\text{stride[0]} \\times d + k,\n                                                         \\text{stride[1]} \\times h + m, \\text{stride[2]} \\times w + n)\n    \\end{aligned}\n\nIf :attr:`padding` is non-zero, then the input is implicitly padded with negative infinity on both sides\nfor :attr:`padding` number of points. :attr:`dilation` controls the spacing between the kernel points.\nIt is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n\nNote:\n    When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\n    or the input. Sliding windows that would start in the right padded region are ignored.\n\nThe parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n\n    - a single ``int`` -- in which case the same value is used for the depth, height and width dimension\n    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,\n      the second `int` for the height dimension and the third `int` for the width dimension\n\nArgs:\n    kernel_size: the size of the window to take a max over\n    stride: the stride of the window. Default value is :attr:`kernel_size`\n    padding: Implicit negative infinity padding to be added on all three sides\n    dilation: a parameter that controls the stride of elements in the window\n    return_indices: if ``True``, will return the max indices along with the outputs.\n                    Useful for :class:`torch.nn.MaxUnpool3d` later\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or :math:`(C, D_{out}, H_{out}, W_{out})`, where\n\n      .. math::\n          D_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times\n            (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\n      .. math::\n          H_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times\n            (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\n      .. math::\n          W_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2] \\times\n            (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\n\nExamples::\n\n    >>> # pool of square window of size=3, stride=2\n    >>> m = nn.MaxPool3d(3, stride=2)\n    >>> # pool of non-square window\n    >>> m = nn.MaxPool3d((3, 2, 2), stride=(2, 1, 2))\n    >>> input = torch.randn(20, 16, 50, 44, 31)\n    >>> output = m(input)\n\n.. _link:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
        "has_varargs": false
      },
      {
        "name": "MaxUnpool1d",
        "api_path": "torch.nn.MaxUnpool1d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          }
        ],
        "docstring": "Computes a partial inverse of :class:`MaxPool1d`.\n\n:class:`MaxPool1d` is not fully invertible, since the non-maximal values are lost.\n\n:class:`MaxUnpool1d` takes in as input the output of :class:`MaxPool1d`\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\n\nNote:\n    This operation may behave nondeterministically when the input indices has repeat values.\n    See https://github.com/pytorch/pytorch/issues/80827 and :doc:`/notes/randomness` for more information.\n\n.. note:: :class:`MaxPool1d` can map several input sizes to the same output\n          sizes. Hence, the inversion process can get ambiguous.\n          To accommodate this, you can provide the needed output size\n          as an additional argument :attr:`output_size` in the forward call.\n          See the Inputs and Example below.\n\nArgs:\n    kernel_size (int or tuple): Size of the max pooling window.\n    stride (int or tuple): Stride of the max pooling window.\n        It is set to :attr:`kernel_size` by default.\n    padding (int or tuple): Padding that was added to the input\n\nInputs:\n    - `input`: the input Tensor to invert\n    - `indices`: the indices given out by :class:`~torch.nn.MaxPool1d`\n    - `output_size` (optional): the targeted output size\n\nShape:\n    - Input: :math:`(N, C, H_{in})` or :math:`(C, H_{in})`.\n    - Output: :math:`(N, C, H_{out})` or :math:`(C, H_{out})`, where\n\n      .. math::\n          H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{kernel\\_size}[0]\n\n      or as given by :attr:`output_size` in the call operator\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"do other tests modify the global state?\")\n    >>> pool = nn.MaxPool1d(2, stride=2, return_indices=True)\n    >>> unpool = nn.MaxUnpool1d(2, stride=2)\n    >>> input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8]]])\n    >>> output, indices = pool(input)\n    >>> unpool(output, indices)\n    tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])\n\n    >>> # Example showcasing the use of output_size\n    >>> input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8, 9]]])\n    >>> output, indices = pool(input)\n    >>> unpool(output, indices, output_size=input.size())\n    tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.,  0.]]])\n\n    >>> unpool(output, indices)\n    tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])",
        "has_varargs": false
      },
      {
        "name": "MaxUnpool2d",
        "api_path": "torch.nn.MaxUnpool2d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          }
        ],
        "docstring": "Computes a partial inverse of :class:`MaxPool2d`.\n\n:class:`MaxPool2d` is not fully invertible, since the non-maximal values are lost.\n\n:class:`MaxUnpool2d` takes in as input the output of :class:`MaxPool2d`\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\n\nNote:\n    This operation may behave nondeterministically when the input indices has repeat values.\n    See https://github.com/pytorch/pytorch/issues/80827 and :doc:`/notes/randomness` for more information.\n\n.. note:: :class:`MaxPool2d` can map several input sizes to the same output\n          sizes. Hence, the inversion process can get ambiguous.\n          To accommodate this, you can provide the needed output size\n          as an additional argument :attr:`output_size` in the forward call.\n          See the Inputs and Example below.\n\nArgs:\n    kernel_size (int or tuple): Size of the max pooling window.\n    stride (int or tuple): Stride of the max pooling window.\n        It is set to :attr:`kernel_size` by default.\n    padding (int or tuple): Padding that was added to the input\n\nInputs:\n    - `input`: the input Tensor to invert\n    - `indices`: the indices given out by :class:`~torch.nn.MaxPool2d`\n    - `output_size` (optional): the targeted output size\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n\n      .. math::\n        H_{out} = (H_{in} - 1) \\times \\text{stride[0]} - 2 \\times \\text{padding[0]} + \\text{kernel\\_size[0]}\n\n      .. math::\n        W_{out} = (W_{in} - 1) \\times \\text{stride[1]} - 2 \\times \\text{padding[1]} + \\text{kernel\\_size[1]}\n\n      or as given by :attr:`output_size` in the call operator\n\nExample::\n\n    >>> pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n    >>> unpool = nn.MaxUnpool2d(2, stride=2)\n    >>> input = torch.tensor([[[[ 1.,  2.,  3.,  4.],\n                                [ 5.,  6.,  7.,  8.],\n                                [ 9., 10., 11., 12.],\n                                [13., 14., 15., 16.]]]])\n    >>> output, indices = pool(input)\n    >>> unpool(output, indices)\n    tensor([[[[  0.,   0.,   0.,   0.],\n              [  0.,   6.,   0.,   8.],\n              [  0.,   0.,   0.,   0.],\n              [  0.,  14.,   0.,  16.]]]])\n    >>> # Now using output_size to resolve an ambiguous size for the inverse\n    >>> input = torch.tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n                                [ 6.,  7.,  8.,  9., 10.],\n                                [11., 12., 13., 14., 15.],\n                                [16., 17., 18., 19., 20.]]]])\n    >>> output, indices = pool(input)\n    >>> # This call will not work without specifying output_size\n    >>> unpool(output, indices, output_size=input.size())\n    tensor([[[[ 0.,  0.,  0.,  0.,  0.],\n              [ 0.,  7.,  0.,  9.,  0.],\n              [ 0.,  0.,  0.,  0.,  0.],\n              [ 0., 17.,  0., 19.,  0.]]]])",
        "has_varargs": false
      },
      {
        "name": "MaxUnpool3d",
        "api_path": "torch.nn.MaxUnpool3d",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          }
        ],
        "docstring": "Computes a partial inverse of :class:`MaxPool3d`.\n\n:class:`MaxPool3d` is not fully invertible, since the non-maximal values are lost.\n:class:`MaxUnpool3d` takes in as input the output of :class:`MaxPool3d`\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\n\nNote:\n    This operation may behave nondeterministically when the input indices has repeat values.\n    See https://github.com/pytorch/pytorch/issues/80827 and :doc:`/notes/randomness` for more information.\n\n.. note:: :class:`MaxPool3d` can map several input sizes to the same output\n          sizes. Hence, the inversion process can get ambiguous.\n          To accommodate this, you can provide the needed output size\n          as an additional argument :attr:`output_size` in the forward call.\n          See the Inputs section below.\n\nArgs:\n    kernel_size (int or tuple): Size of the max pooling window.\n    stride (int or tuple): Stride of the max pooling window.\n        It is set to :attr:`kernel_size` by default.\n    padding (int or tuple): Padding that was added to the input\n\nInputs:\n    - `input`: the input Tensor to invert\n    - `indices`: the indices given out by :class:`~torch.nn.MaxPool3d`\n    - `output_size` (optional): the targeted output size\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or :math:`(C, D_{out}, H_{out}, W_{out})`, where\n\n      .. math::\n          D_{out} = (D_{in} - 1) \\times \\text{stride[0]} - 2 \\times \\text{padding[0]} + \\text{kernel\\_size[0]}\n\n      .. math::\n          H_{out} = (H_{in} - 1) \\times \\text{stride[1]} - 2 \\times \\text{padding[1]} + \\text{kernel\\_size[1]}\n\n      .. math::\n          W_{out} = (W_{in} - 1) \\times \\text{stride[2]} - 2 \\times \\text{padding[2]} + \\text{kernel\\_size[2]}\n\n      or as given by :attr:`output_size` in the call operator\n\nExample::\n\n    >>> # pool of square window of size=3, stride=2\n    >>> pool = nn.MaxPool3d(3, stride=2, return_indices=True)\n    >>> unpool = nn.MaxUnpool3d(3, stride=2)\n    >>> output, indices = pool(torch.randn(20, 16, 51, 33, 15))\n    >>> unpooled_output = unpool(output, indices)\n    >>> unpooled_output.size()\n    torch.Size([20, 16, 51, 33, 15])",
        "has_varargs": false
      },
      {
        "name": "Mish",
        "api_path": "torch.nn.Mish",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Mish function, element-wise.\n\nMish: A Self Regularized Non-Monotonic Neural Activation Function.\n\n.. math::\n    \\text{Mish}(x) = x * \\text{Tanh}(\\text{Softplus}(x))\n\n.. note::\n    See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Mish.png\n\nExamples::\n\n    >>> m = nn.Mish()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Module",
        "api_path": "torch.nn.Module",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Base class for all neural network modules.\n\nYour models should also subclass this class.\n\nModules can also contain other Modules, allowing them to be nested in\na tree structure. You can assign the submodules as regular attributes::\n\n    import torch.nn as nn\n    import torch.nn.functional as F\n\n\n    class Model(nn.Module):\n        def __init__(self) -> None:\n            super().__init__()\n            self.conv1 = nn.Conv2d(1, 20, 5)\n            self.conv2 = nn.Conv2d(20, 20, 5)\n\n        def forward(self, x):\n            x = F.relu(self.conv1(x))\n            return F.relu(self.conv2(x))\n\nSubmodules assigned in this way will be registered, and will also have their\nparameters converted when you call :meth:`to`, etc.\n\n.. note::\n    As per the example above, an ``__init__()`` call to the parent class\n    must be made before assignment on the child.\n\n:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool",
        "has_varargs": true
      },
      {
        "name": "ModuleDict",
        "api_path": "torch.nn.ModuleDict",
        "kind": "class",
        "params": [
          {
            "name": "modules",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional[Mapping[str, Module]]"
          }
        ],
        "docstring": "Holds submodules in a dictionary.\n\n:class:`~torch.nn.ModuleDict` can be indexed like a regular Python dictionary,\nbut modules it contains are properly registered, and will be visible by all\n:class:`~torch.nn.Module` methods.\n\n:class:`~torch.nn.ModuleDict` is an **ordered** dictionary that respects\n\n* the order of insertion, and\n\n* in :meth:`~torch.nn.ModuleDict.update`, the order of the merged\n  ``OrderedDict``, ``dict`` (started from Python 3.6) or another\n  :class:`~torch.nn.ModuleDict` (the argument to\n  :meth:`~torch.nn.ModuleDict.update`).\n\nNote that :meth:`~torch.nn.ModuleDict.update` with other unordered mapping\ntypes (e.g., Python's plain ``dict`` before Python version 3.6) does not\npreserve the order of the merged mapping.\n\nArgs:\n    modules (iterable, optional): a mapping (dictionary) of (string: module)\n        or an iterable of key-value pairs of type (string, module)\n\nExample::\n\n    class MyModule(nn.Module):\n        def __init__(self) -> None:\n            super().__init__()\n            self.choices = nn.ModuleDict(\n                {\"conv\": nn.Conv2d(10, 10, 3), \"pool\": nn.MaxPool2d(3)}\n            )\n            self.activations = nn.ModuleDict(\n                [[\"lrelu\", nn.LeakyReLU()], [\"prelu\", nn.PReLU()]]\n            )\n\n        def forward(self, x, choice, act):\n            x = self.choices[choice](x)\n            x = self.activations[act](x)\n            return x",
        "has_varargs": false
      },
      {
        "name": "ModuleList",
        "api_path": "torch.nn.ModuleList",
        "kind": "class",
        "params": [
          {
            "name": "modules",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional[Iterable[Module]]"
          }
        ],
        "docstring": "Holds submodules in a list.\n\n:class:`~torch.nn.ModuleList` can be indexed like a regular Python list, but\nmodules it contains are properly registered, and will be visible by all\n:class:`~torch.nn.Module` methods.\n\nArgs:\n    modules (iterable, optional): an iterable of modules to add\n\nExample::\n\n    class MyModule(nn.Module):\n        def __init__(self) -> None:\n            super().__init__()\n            self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n\n        def forward(self, x):\n            # ModuleList can act as an iterable, or be indexed using ints\n            for i, l in enumerate(self.linears):\n                x = self.linears[i // 2](x) + l(x)\n            return x",
        "has_varargs": false
      },
      {
        "name": "MultiheadAttention",
        "api_path": "torch.nn.MultiheadAttention",
        "kind": "class",
        "params": [
          {
            "name": "embed_dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": null
          },
          {
            "name": "num_heads",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": null
          },
          {
            "name": "dropout",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0",
            "annotation": null
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": null
          },
          {
            "name": "add_bias_kv",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": null
          },
          {
            "name": "add_zero_attn",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": null
          },
          {
            "name": "kdim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "vdim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "batch_first",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": null
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Allows the model to jointly attend to information from different representation subspaces.\n\nThis MultiheadAttention layer implements the original architecture described\nin the `Attention Is All You Need <https://arxiv.org/abs/1706.03762>`_ paper. The\nintent of this layer is as a reference implementation for foundational understanding\nand thus it contains only limited features relative to newer architectures.\nGiven the fast pace of innovation in transformer-like architectures, we recommend\nexploring this `tutorial <https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html>`_\nto build efficient layers from building blocks in core or using higher\nlevel libraries from the `PyTorch Ecosystem <https://landscape.pytorch.org/>`_.\n\nMulti-Head Attention is defined as:\n\n.. math::\n    \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1,\\dots,\\text{head}_h)W^O\n\nwhere :math:`\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)`.\n\n``nn.MultiheadAttention`` will use the optimized implementations of\n``scaled_dot_product_attention()`` when possible.\n\nIn addition to support for the new ``scaled_dot_product_attention()``\nfunction, for speeding up Inference, MHA will use\nfastpath inference with support for Nested Tensors, iff:\n\n- self attention is being computed (i.e., ``query``, ``key``, and ``value`` are the same tensor).\n- inputs are batched (3D) with ``batch_first==True``\n- Either autograd is disabled (using ``torch.inference_mode`` or ``torch.no_grad``) or no tensor argument ``requires_grad``\n- training is disabled (using ``.eval()``)\n- ``add_bias_kv`` is ``False``\n- ``add_zero_attn`` is ``False``\n- ``kdim`` and ``vdim`` are equal to ``embed_dim``\n- if a `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_ is passed, neither ``key_padding_mask``\n  nor ``attn_mask`` is passed\n- autocast is disabled\n\nIf the optimized inference fastpath implementation is in use, a\n`NestedTensor <https://pytorch.org/docs/stable/nested.html>`_ can be passed for\n``query``/``key``/``value`` to represent padding more efficiently than using a\npadding mask. In this case, a `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_\nwill be returned, and an additional speedup proportional to the fraction of the input\nthat is padding can be expected.\n\nArgs:\n    embed_dim: Total dimension of the model.\n    num_heads: Number of parallel attention heads. Note that ``embed_dim`` will be split\n        across ``num_heads`` (i.e. each head will have dimension ``embed_dim // num_heads``).\n    dropout: Dropout probability on ``attn_output_weights``. Default: ``0.0`` (no dropout).\n    bias: If specified, adds bias to input / output projection layers. Default: ``True``.\n    add_bias_kv: If specified, adds bias to the key and value sequences at dim=0. Default: ``False``.\n    add_zero_attn: If specified, adds a new batch of zeros to the key and value sequences at dim=1.\n        Default: ``False``.\n    kdim: Total number of features for keys. Default: ``None`` (uses ``kdim=embed_dim``).\n    vdim: Total number of features for values. Default: ``None`` (uses ``vdim=embed_dim``).\n    batch_first: If ``True``, then the input and output tensors are provided\n        as (batch, seq, feature). Default: ``False`` (seq, batch, feature).\n\nExamples::\n\n    >>> # xdoctest: +SKIP\n    >>> multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n    >>> attn_output, attn_output_weights = multihead_attn(query, key, value)\n\n.. _`FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness`:\n     https://arxiv.org/abs/2205.14135",
        "has_varargs": false
      },
      {
        "name": "NLLLoss2d",
        "api_path": "torch.nn.NLLLoss2d",
        "kind": "class",
        "params": [
          {
            "name": "weight",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "size_average",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "ignore_index",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-100",
            "annotation": "int"
          },
          {
            "name": "reduce",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "reduction",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "mean",
            "annotation": "str"
          }
        ],
        "docstring": "The negative log likelihood loss. It is useful to train a classification\nproblem with `C` classes.\n\nIf provided, the optional argument :attr:`weight` should be a 1D Tensor assigning\nweight to each of the classes. This is particularly useful when you have an\nunbalanced training set.\n\nThe `input` given through a forward call is expected to contain\nlog-probabilities of each class. `input` has to be a Tensor of size either\n:math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)`\nwith :math:`K \\geq 1` for the `K`-dimensional case. The latter is useful for\nhigher dimension inputs, such as computing NLL loss per-pixel for 2D images.\n\nObtaining log-probabilities in a neural network is easily achieved by\nadding a  `LogSoftmax`  layer in the last layer of your network.\nYou may use `CrossEntropyLoss` instead, if you prefer not to add an extra\nlayer.\n\nThe `target` that this loss expects should be a class index in the range :math:`[0, C-1]`\nwhere `C = number of classes`; if `ignore_index` is specified, this loss also accepts\nthis class index (this index may not necessarily be in the class range).\n\nThe unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n\n.. math::\n    \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\\\\n    l_n = - w_{y_n} x_{n,y_n}, \\\\\n    w_{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\},\n\nwhere :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight, and\n:math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n(default ``'mean'``), then\n\n.. math::\n    \\ell(x, y) = \\begin{cases}\n        \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n}} l_n, &\n        \\text{if reduction} = \\text{`mean';}\\\\\n        \\sum_{n=1}^N l_n,  &\n        \\text{if reduction} = \\text{`sum'.}\n    \\end{cases}\n\nArgs:\n    weight (Tensor, optional): a manual rescaling weight given to each\n        class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n        treated as if having all ones.\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``None``\n    ignore_index (int, optional): Specifies a target value that is ignored\n        and does not contribute to the input gradient. When\n        :attr:`size_average` is ``True``, the loss is averaged over\n        non-ignored targets.\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``None``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n        be applied, ``'mean'``: the weighted mean of the output is taken,\n        ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in\n        the meantime, specifying either of those two args will override\n        :attr:`reduction`. Default: ``'mean'``\n\nShape::\n    - Input: :math:`(N, C)` or :math:`(C)`, where `C = number of classes`, `N = batch size`, or\n      :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n      in the case of `K`-dimensional loss.\n    - Target: :math:`(N)` or :math:`()`, where each value is\n      :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or\n      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of\n      K-dimensional loss.\n    - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or\n      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of K-dimensional loss.\n      Otherwise, scalar.\n\nExamples:\n\n    >>> log_softmax = nn.LogSoftmax(dim=1)\n    >>> loss_fn = nn.NLLLoss()\n    >>> # input to NLLLoss is of size N x C = 3 x 5\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> # each element in target must have 0 <= value < C\n    >>> target = torch.tensor([1, 0, 4])\n    >>> loss = loss_fn(log_softmax(input), target)\n    >>> loss.backward()\n    >>>\n    >>>\n    >>> # 2D loss example (used, for example, with image inputs)\n    >>> N, C = 5, 4\n    >>> loss_fn = nn.NLLLoss()\n    >>> data = torch.randn(N, 16, 10, 10)\n    >>> conv = nn.Conv2d(16, C, (3, 3))\n    >>> log_softmax = nn.LogSoftmax(dim=1)\n    >>> # output of conv forward is of shape [N, C, 8, 8]\n    >>> output = log_softmax(conv(data))\n    >>> # each element in target must have 0 <= value < C\n    >>> target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n    >>> # input to NLLLoss is of size N x C x height (8) x width (8)\n    >>> loss = loss_fn(output, target)\n    >>> loss.backward()",
        "has_varargs": false
      },
      {
        "name": "PReLU",
        "api_path": "torch.nn.PReLU",
        "kind": "class",
        "params": [
          {
            "name": "num_parameters",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "init",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.25",
            "annotation": "float"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies the element-wise PReLU function.\n\n.. math::\n    \\text{PReLU}(x) = \\max(0,x) + a * \\min(0,x)\n\nor\n\n.. math::\n    \\text{PReLU}(x) =\n    \\begin{cases}\n    x, & \\text{ if } x \\ge 0 \\\\\n    ax, & \\text{ otherwise }\n    \\end{cases}\n\nHere :math:`a` is a learnable parameter. When called without arguments, `nn.PReLU()` uses a single\nparameter :math:`a` across all input channels. If called with `nn.PReLU(nChannels)`,\na separate :math:`a` is used for each input channel.\n\n\n.. note::\n    weight decay should not be used when learning :math:`a` for good performance.\n\n.. note::\n    Channel dim is the 2nd dim of input. When input has dims < 2, then there is\n    no channel dim and the number of channels = 1.\n\nArgs:\n    num_parameters (int): number of :math:`a` to learn.\n        Although it takes an int as input, there is only two values are legitimate:\n        1, or the number of channels at input. Default: 1\n    init (float): the initial value of :math:`a`. Default: 0.25\n\nShape:\n    - Input: :math:`( *)` where `*` means, any number of additional\n      dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\nAttributes:\n    weight (Tensor): the learnable weights of shape (:attr:`num_parameters`).\n\n.. image:: ../scripts/activation_images/PReLU.png\n\nExamples::\n\n    >>> m = nn.PReLU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "PairwiseDistance",
        "api_path": "torch.nn.PairwiseDistance",
        "kind": "class",
        "params": [
          {
            "name": "p",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "2.0",
            "annotation": "float"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-06",
            "annotation": "float"
          },
          {
            "name": "keepdim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Computes the pairwise distance between input vectors, or between columns of input matrices.\n\nDistances are computed using ``p``-norm, with constant ``eps`` added to avoid division by zero\nif ``p`` is negative, i.e.:\n\n.. math ::\n    \\mathrm{dist}\\left(x, y\\right) = \\left\\Vert x-y + \\epsilon e \\right\\Vert_p,\n\nwhere :math:`e` is the vector of ones and the ``p``-norm is given by.\n\n.. math ::\n    \\Vert x \\Vert _p = \\left( \\sum_{i=1}^n  \\vert x_i \\vert ^ p \\right) ^ {1/p}.\n\nArgs:\n    p (real, optional): the norm degree. Can be negative. Default: 2\n    eps (float, optional): Small value to avoid division by zero.\n        Default: 1e-6\n    keepdim (bool, optional): Determines whether or not to keep the vector dimension.\n        Default: False\nShape:\n    - Input1: :math:`(N, D)` or :math:`(D)` where `N = batch dimension` and `D = vector dimension`\n    - Input2: :math:`(N, D)` or :math:`(D)`, same shape as the Input1\n    - Output: :math:`(N)` or :math:`()` based on input dimension.\n      If :attr:`keepdim` is ``True``, then :math:`(N, 1)` or :math:`(1)` based on input dimension.\n\nExamples:\n    >>> pdist = nn.PairwiseDistance(p=2)\n    >>> input1 = torch.randn(100, 128)\n    >>> input2 = torch.randn(100, 128)\n    >>> output = pdist(input1, input2)",
        "has_varargs": false
      },
      {
        "name": "ParameterDict",
        "api_path": "torch.nn.ParameterDict",
        "kind": "class",
        "params": [
          {
            "name": "parameters",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Any"
          }
        ],
        "docstring": "Holds parameters in a dictionary.\n\nParameterDict can be indexed like a regular Python dictionary, but Parameters it\ncontains are properly registered, and will be visible by all Module methods.\nOther objects are treated as would be done by a regular Python dictionary\n\n:class:`~torch.nn.ParameterDict` is an **ordered** dictionary.\n:meth:`~torch.nn.ParameterDict.update` with other unordered mapping\ntypes (e.g., Python's plain ``dict``) does not preserve the order of the\nmerged mapping. On the other hand, ``OrderedDict`` or another :class:`~torch.nn.ParameterDict`\nwill preserve their ordering.\n\nNote that the constructor, assigning an element of the dictionary and the\n:meth:`~torch.nn.ParameterDict.update` method will convert any :class:`~torch.Tensor` into\n:class:`~torch.nn.Parameter`.\n\nArgs:\n    values (iterable, optional): a mapping (dictionary) of\n        (string : Any) or an iterable of key-value pairs\n        of type (string, Any)\n\nExample::\n\n    class MyModule(nn.Module):\n        def __init__(self) -> None:\n            super().__init__()\n            self.params = nn.ParameterDict(\n                {\n                    \"left\": nn.Parameter(torch.randn(5, 10)),\n                    \"right\": nn.Parameter(torch.randn(5, 10)),\n                }\n            )\n\n        def forward(self, x, choice):\n            x = self.params[choice].mm(x)\n            return x",
        "has_varargs": false
      },
      {
        "name": "ParameterList",
        "api_path": "torch.nn.ParameterList",
        "kind": "class",
        "params": [
          {
            "name": "values",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional[Iterable[Any]]"
          }
        ],
        "docstring": "Holds parameters in a list.\n\n:class:`~torch.nn.ParameterList` can be used like a regular Python\nlist, but Tensors that are :class:`~torch.nn.Parameter` are properly registered,\nand will be visible by all :class:`~torch.nn.Module` methods.\n\nNote that the constructor, assigning an element of the list, the\n:meth:`~torch.nn.ParameterList.append` method and the :meth:`~torch.nn.ParameterList.extend`\nmethod will convert any :class:`~torch.Tensor` into :class:`~torch.nn.Parameter`.\n\nArgs:\n    parameters (iterable, optional): an iterable of elements to add to the list.\n\nExample::\n\n    class MyModule(nn.Module):\n        def __init__(self) -> None:\n            super().__init__()\n            self.params = nn.ParameterList(\n                [nn.Parameter(torch.randn(10, 10)) for i in range(10)]\n            )\n\n        def forward(self, x):\n            # ParameterList can act as an iterable, or be indexed using ints\n            for i, p in enumerate(self.params):\n                x = self.params[i // 2].mm(x) + p.mm(x)\n            return x",
        "has_varargs": false
      },
      {
        "name": "PixelShuffle",
        "api_path": "torch.nn.PixelShuffle",
        "kind": "class",
        "params": [
          {
            "name": "upscale_factor",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          }
        ],
        "docstring": "Rearrange elements in a tensor according to an upscaling factor.\n\nRearranges elements in a tensor of shape :math:`(*, C \\times r^2, H, W)`\nto a tensor of shape :math:`(*, C, H \\times r, W \\times r)`, where r is an upscale factor.\n\nThis is useful for implementing efficient sub-pixel convolution\nwith a stride of :math:`1/r`.\n\nSee the paper:\n`Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network`_\nby Shi et al. (2016) for more details.\n\nArgs:\n    upscale_factor (int): factor to increase spatial resolution by\n\nShape:\n    - Input: :math:`(*, C_{in}, H_{in}, W_{in})`, where * is zero or more batch dimensions\n    - Output: :math:`(*, C_{out}, H_{out}, W_{out})`, where\n\n.. math::\n    C_{out} = C_{in} \\div \\text{upscale\\_factor}^2\n\n.. math::\n    H_{out} = H_{in} \\times \\text{upscale\\_factor}\n\n.. math::\n    W_{out} = W_{in} \\times \\text{upscale\\_factor}\n\nExamples::\n\n    >>> pixel_shuffle = nn.PixelShuffle(3)\n    >>> input = torch.randn(1, 9, 4, 4)\n    >>> output = pixel_shuffle(input)\n    >>> print(output.size())\n    torch.Size([1, 1, 12, 12])\n\n.. _Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network:\n    https://arxiv.org/abs/1609.05158",
        "has_varargs": false
      },
      {
        "name": "PixelUnshuffle",
        "api_path": "torch.nn.PixelUnshuffle",
        "kind": "class",
        "params": [
          {
            "name": "downscale_factor",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          }
        ],
        "docstring": "Reverse the PixelShuffle operation.\n\nReverses the :class:`~torch.nn.PixelShuffle` operation by rearranging elements\nin a tensor of shape :math:`(*, C, H \\times r, W \\times r)` to a tensor of shape\n:math:`(*, C \\times r^2, H, W)`, where r is a downscale factor.\n\nSee the paper:\n`Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network`_\nby Shi et al. (2016) for more details.\n\nArgs:\n    downscale_factor (int): factor to decrease spatial resolution by\n\nShape:\n    - Input: :math:`(*, C_{in}, H_{in}, W_{in})`, where * is zero or more batch dimensions\n    - Output: :math:`(*, C_{out}, H_{out}, W_{out})`, where\n\n.. math::\n    C_{out} = C_{in} \\times \\text{downscale\\_factor}^2\n\n.. math::\n    H_{out} = H_{in} \\div \\text{downscale\\_factor}\n\n.. math::\n    W_{out} = W_{in} \\div \\text{downscale\\_factor}\n\nExamples::\n\n    >>> pixel_unshuffle = nn.PixelUnshuffle(3)\n    >>> input = torch.randn(1, 1, 12, 12)\n    >>> output = pixel_unshuffle(input)\n    >>> print(output.size())\n    torch.Size([1, 9, 4, 4])\n\n.. _Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network:\n    https://arxiv.org/abs/1609.05158",
        "has_varargs": false
      },
      {
        "name": "RMSNorm",
        "api_path": "torch.nn.RMSNorm",
        "kind": "class",
        "params": [
          {
            "name": "normalized_shape",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "elementwise_affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Root Mean Square Layer Normalization over a mini-batch of inputs.\n\nThis layer implements the operation as described in\nthe paper `Root Mean Square Layer Normalization <https://arxiv.org/pdf/1910.07467.pdf>`__\n\n.. math::\n    y_i = \\frac{x_i}{\\mathrm{RMS}(x)} * \\gamma_i, \\quad\n    \\text{where} \\quad \\text{RMS}(x) = \\sqrt{\\epsilon + \\frac{1}{n} \\sum_{i=1}^{n} x_i^2}\n\nThe RMS is taken over the last ``D`` dimensions, where ``D``\nis the dimension of :attr:`normalized_shape`. For example, if :attr:`normalized_shape`\nis ``(3, 5)`` (a 2-dimensional shape), the RMS is computed over\nthe last 2 dimensions of the input.\n\nArgs:\n    normalized_shape (int or list or torch.Size): input shape from an expected input\n        of size\n\n        .. math::\n            [* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n                \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n\n        If a single integer is used, it is treated as a singleton list, and this module will\n        normalize over the last dimension which is expected to be of that specific size.\n    eps: a value added to the denominator for numerical stability. Default: ``torch.finfo(x.dtype).eps``\n    elementwise_affine: a boolean value that when set to ``True``, this module\n        has learnable per-element affine parameters initialized to ones (for weights). Default: ``True``.\n\nShape:\n    - Input: :math:`(N, *)`\n    - Output: :math:`(N, *)` (same shape as input)\n\nExamples::\n\n    >>> rms_norm = nn.RMSNorm([2, 3])\n    >>> input = torch.randn(2, 2, 3)\n    >>> rms_norm(input)",
        "has_varargs": false
      },
      {
        "name": "RNN",
        "api_path": "torch.nn.RNN",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "__init__(input_size,hidden_size,num_layers=1,nonlinearity='tanh',bias=True,batch_first=False,dropout=0.0,bidirectional=False,device=None,dtype=None)\n\nApply a multi-layer Elman RNN with :math:`\\tanh` or :math:`\\text{ReLU}`\nnon-linearity to an input sequence. For each element in the input sequence,\neach layer computes the following function:\n\n.. math::\n    h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})\n\nwhere :math:`h_t` is the hidden state at time `t`, :math:`x_t` is\nthe input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the\nprevious layer at time `t-1` or the initial hidden state at time `0`.\nIf :attr:`nonlinearity` is ``'relu'``, then :math:`\\text{ReLU}` is used instead of :math:`\\tanh`.\n\n.. code-block:: python\n\n    # Efficient implementation equivalent to the following with bidirectional=False\n    rnn = nn.RNN(input_size, hidden_size, num_layers)\n    params = dict(rnn.named_parameters())\n    def forward(x, hx=None, batch_first=False):\n        if batch_first:\n            x = x.transpose(0, 1)\n        seq_len, batch_size, _ = x.size()\n        if hx is None:\n            hx = torch.zeros(rnn.num_layers, batch_size, rnn.hidden_size)\n        h_t_minus_1 = hx.clone()\n        h_t = hx.clone()\n        output = []\n        for t in range(seq_len):\n            for layer in range(rnn.num_layers):\n                input_t = x[t] if layer == 0 else h_t[layer - 1]\n                h_t[layer] = torch.tanh(\n                    input_t @ params[f\"weight_ih_l{layer}\"].T\n                    + h_t_minus_1[layer] @ params[f\"weight_hh_l{layer}\"].T\n                    + params[f\"bias_hh_l{layer}\"]\n                    + params[f\"bias_ih_l{layer}\"]\n                )\n            output.append(h_t[-1].clone())\n            h_t_minus_1 = h_t.clone()\n        output = torch.stack(output)\n        if batch_first:\n            output = output.transpose(0, 1)\n        return output, h_t\n\nArgs:\n    input_size: The number of expected features in the input `x`\n    hidden_size: The number of features in the hidden state `h`\n    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n        would mean stacking two RNNs together to form a `stacked RNN`,\n        with the second RNN taking in outputs of the first RNN and\n        computing the final results. Default: 1\n    nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n        Default: ``True``\n    batch_first: If ``True``, then the input and output tensors are provided\n        as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n        Note that this does not apply to hidden or cell states. See the\n        Inputs/Outputs sections below for details.  Default: ``False``\n    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n        RNN layer except the last layer, with dropout probability equal to\n        :attr:`dropout`. Default: 0\n    bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n\nInputs: input, hx\n    * **input**: tensor of shape :math:`(L, H_{in})` for unbatched input,\n      :math:`(L, N, H_{in})` when ``batch_first=False`` or\n      :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n      the input sequence.  The input can also be a packed variable length sequence.\n      See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n      :func:`torch.nn.utils.rnn.pack_sequence` for details.\n    * **hx**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` for unbatched input or\n      :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the initial hidden\n      state for the input sequence batch. Defaults to zeros if not provided.\n\n    where:\n\n    .. math::\n        \\begin{aligned}\n            N ={} & \\text{batch size} \\\\\n            L ={} & \\text{sequence length} \\\\\n            D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n            H_{in} ={} & \\text{input\\_size} \\\\\n            H_{out} ={} & \\text{hidden\\_size}\n        \\end{aligned}\n\nOutputs: output, h_n\n    * **output**: tensor of shape :math:`(L, D * H_{out})` for unbatched input,\n      :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n      :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n      `(h_t)` from the last layer of the RNN, for each `t`. If a\n      :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n      will also be a packed sequence.\n    * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` for unbatched input or\n      :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the final hidden state\n      for each element in the batch.\n\nAttributes:\n    weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,\n        of shape `(hidden_size, input_size)` for `k = 0`. Otherwise, the shape is\n        `(hidden_size, num_directions * hidden_size)`\n    weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,\n        of shape `(hidden_size, hidden_size)`\n    bias_ih_l[k]: the learnable input-hidden bias of the k-th layer,\n        of shape `(hidden_size)`\n    bias_hh_l[k]: the learnable hidden-hidden bias of the k-th layer,\n        of shape `(hidden_size)`\n\n.. note::\n    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n\n.. note::\n    For bidirectional RNNs, forward and backward are directions 0 and 1 respectively.\n    Example of splitting the output layers when ``batch_first=False``:\n    ``output.view(seq_len, batch, num_directions, hidden_size)``.\n\n.. note::\n    ``batch_first`` argument is ignored for unbatched inputs.\n\n.. include:: ../cudnn_rnn_determinism.rst\n\n.. include:: ../cudnn_persistent_rnn.rst\n\nExamples::\n\n    >>> rnn = nn.RNN(10, 20, 2)\n    >>> input = torch.randn(5, 3, 10)\n    >>> h0 = torch.randn(2, 3, 20)\n    >>> output, hn = rnn(input, h0)",
        "has_varargs": true
      },
      {
        "name": "RNNBase",
        "api_path": "torch.nn.RNNBase",
        "kind": "class",
        "params": [
          {
            "name": "mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "str"
          },
          {
            "name": "input_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "hidden_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "num_layers",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "batch_first",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "dropout",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.0",
            "annotation": "float"
          },
          {
            "name": "bidirectional",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "proj_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "int"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Base class for RNN modules (RNN, LSTM, GRU).\n\nImplements aspects of RNNs shared by the RNN, LSTM, and GRU classes, such as module initialization\nand utility methods for parameter storage management.\n\n.. note::\n    The forward method is not implemented by the RNNBase class.\n\n.. note::\n    LSTM and GRU classes override some methods implemented by RNNBase.",
        "has_varargs": false
      },
      {
        "name": "RNNCell",
        "api_path": "torch.nn.RNNCell",
        "kind": "class",
        "params": [
          {
            "name": "input_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "hidden_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "nonlinearity",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "tanh",
            "annotation": "str"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "An Elman RNN cell with tanh or ReLU non-linearity.\n\n.. math::\n\n    h' = \\tanh(W_{ih} x + b_{ih}  +  W_{hh} h + b_{hh})\n\nIf :attr:`nonlinearity` is `'relu'`, then ReLU is used in place of tanh.\n\nArgs:\n    input_size: The number of expected features in the input `x`\n    hidden_size: The number of features in the hidden state `h`\n    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n        Default: ``True``\n    nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n\nInputs: input, hidden\n    - **input**: tensor containing input features\n    - **hidden**: tensor containing the initial hidden state\n      Defaults to zero if not provided.\n\nOutputs: h'\n    - **h'** of shape `(batch, hidden_size)`: tensor containing the next hidden state\n      for each element in the batch\n\nShape:\n    - input: :math:`(N, H_{in})` or :math:`(H_{in})` tensor containing input features where\n      :math:`H_{in}` = `input_size`.\n    - hidden: :math:`(N, H_{out})` or :math:`(H_{out})` tensor containing the initial hidden\n      state where :math:`H_{out}` = `hidden_size`. Defaults to zero if not provided.\n    - output: :math:`(N, H_{out})` or :math:`(H_{out})` tensor containing the next hidden state.\n\nAttributes:\n    weight_ih: the learnable input-hidden weights, of shape\n        `(hidden_size, input_size)`\n    weight_hh: the learnable hidden-hidden weights, of shape\n        `(hidden_size, hidden_size)`\n    bias_ih: the learnable input-hidden bias, of shape `(hidden_size)`\n    bias_hh: the learnable hidden-hidden bias, of shape `(hidden_size)`\n\n.. note::\n    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n\nExamples::\n\n    >>> rnn = nn.RNNCell(10, 20)\n    >>> input = torch.randn(6, 3, 10)\n    >>> hx = torch.randn(3, 20)\n    >>> output = []\n    >>> for i in range(6):\n    ...     hx = rnn(input[i], hx)\n    ...     output.append(hx)",
        "has_varargs": false
      },
      {
        "name": "RNNCellBase",
        "api_path": "torch.nn.RNNCellBase",
        "kind": "class",
        "params": [
          {
            "name": "input_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "hidden_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "bool"
          },
          {
            "name": "num_chunks",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Base class for all neural network modules.\n\nYour models should also subclass this class.\n\nModules can also contain other Modules, allowing them to be nested in\na tree structure. You can assign the submodules as regular attributes::\n\n    import torch.nn as nn\n    import torch.nn.functional as F\n\n\n    class Model(nn.Module):\n        def __init__(self) -> None:\n            super().__init__()\n            self.conv1 = nn.Conv2d(1, 20, 5)\n            self.conv2 = nn.Conv2d(20, 20, 5)\n\n        def forward(self, x):\n            x = F.relu(self.conv1(x))\n            return F.relu(self.conv2(x))\n\nSubmodules assigned in this way will be registered, and will also have their\nparameters converted when you call :meth:`to`, etc.\n\n.. note::\n    As per the example above, an ``__init__()`` call to the parent class\n    must be made before assignment on the child.\n\n:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool",
        "has_varargs": false
      },
      {
        "name": "RReLU",
        "api_path": "torch.nn.RReLU",
        "kind": "class",
        "params": [
          {
            "name": "lower",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.125",
            "annotation": "float"
          },
          {
            "name": "upper",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.3333333333333333",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the randomized leaky rectified linear unit function, element-wise.\n\nMethod described in the paper:\n`Empirical Evaluation of Rectified Activations in Convolutional Network <https://arxiv.org/abs/1505.00853>`_.\n\nThe function is defined as:\n\n.. math::\n    \\text{RReLU}(x) =\n    \\begin{cases}\n        x & \\text{if } x \\geq 0 \\\\\n        ax & \\text{ otherwise }\n    \\end{cases}\n\nwhere :math:`a` is randomly sampled from uniform distribution\n:math:`\\mathcal{U}(\\text{lower}, \\text{upper})` during training while during\nevaluation :math:`a` is fixed with :math:`a = \\frac{\\text{lower} + \\text{upper}}{2}`.\n\nArgs:\n    lower: lower bound of the uniform distribution. Default: :math:`\\frac{1}{8}`\n    upper: upper bound of the uniform distribution. Default: :math:`\\frac{1}{3}`\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/RReLU.png\n\nExamples::\n\n    >>> m = nn.RReLU(0.1, 0.3)\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "ReLU",
        "api_path": "torch.nn.ReLU",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the rectified linear unit function element-wise.\n\n:math:`\\text{ReLU}(x) = (x)^+ = \\max(0, x)`\n\nArgs:\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/ReLU.png\n\nExamples::\n\n    >>> m = nn.ReLU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)\n\n\n  An implementation of CReLU - https://arxiv.org/abs/1603.05201\n\n    >>> m = nn.ReLU()\n    >>> input = torch.randn(2).unsqueeze(0)\n    >>> output = torch.cat((m(input), m(-input)))",
        "has_varargs": false
      },
      {
        "name": "ReLU6",
        "api_path": "torch.nn.ReLU6",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the ReLU6 function element-wise.\n\n.. math::\n    \\text{ReLU6}(x) = \\min(\\max(0,x), 6)\n\nArgs:\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/ReLU6.png\n\nExamples::\n\n    >>> m = nn.ReLU6()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "ReflectionPad1d",
        "api_path": "torch.nn.ReflectionPad1d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using the reflection of the input boundary.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 2-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`)\n        Note that padding size should be less than the corresponding input dimension.\n\nShape:\n    - Input: :math:`(C, W_{in})` or :math:`(N, C, W_{in})`.\n    - Output: :math:`(C, W_{out})` or :math:`(N, C, W_{out})`, where\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> m = nn.ReflectionPad1d(2)\n    >>> # xdoctest: +IGNORE_WANT(\"other tests seem to modify printing styles\")\n    >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4)\n    >>> input\n    tensor([[[0., 1., 2., 3.],\n             [4., 5., 6., 7.]]])\n    >>> m(input)\n    tensor([[[2., 1., 0., 1., 2., 3., 2., 1.],\n             [6., 5., 4., 5., 6., 7., 6., 5.]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.ReflectionPad1d((3, 1))\n    >>> m(input)\n    tensor([[[3., 2., 1., 0., 1., 2., 3., 2.],\n             [7., 6., 5., 4., 5., 6., 7., 6.]]])",
        "has_varargs": false
      },
      {
        "name": "ReflectionPad2d",
        "api_path": "torch.nn.ReflectionPad2d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using the reflection of the input boundary.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 4-`tuple`, uses (:math:`\\text{padding\\_left}`,\n        :math:`\\text{padding\\_right}`, :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`)\n        Note that padding size should be less than the corresponding input dimension.\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})` where\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"not sure why xdoctest is choking on this\")\n    >>> m = nn.ReflectionPad2d(2)\n    >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3)\n    >>> input\n    tensor([[[[0., 1., 2.],\n              [3., 4., 5.],\n              [6., 7., 8.]]]])\n    >>> m(input)\n    tensor([[[[8., 7., 6., 7., 8., 7., 6.],\n              [5., 4., 3., 4., 5., 4., 3.],\n              [2., 1., 0., 1., 2., 1., 0.],\n              [5., 4., 3., 4., 5., 4., 3.],\n              [8., 7., 6., 7., 8., 7., 6.],\n              [5., 4., 3., 4., 5., 4., 3.],\n              [2., 1., 0., 1., 2., 1., 0.]]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.ReflectionPad2d((1, 1, 2, 0))\n    >>> m(input)\n    tensor([[[[7., 6., 7., 8., 7.],\n              [4., 3., 4., 5., 4.],\n              [1., 0., 1., 2., 1.],\n              [4., 3., 4., 5., 4.],\n              [7., 6., 7., 8., 7.]]]])",
        "has_varargs": false
      },
      {
        "name": "ReflectionPad3d",
        "api_path": "torch.nn.ReflectionPad3d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using the reflection of the input boundary.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 6-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`,\n        :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`,\n        :math:`\\text{padding\\_front}`, :math:`\\text{padding\\_back}`)\n        Note that padding size should be less than the corresponding input dimension.\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or :math:`(C, D_{out}, H_{out}, W_{out})`,\n      where\n\n      :math:`D_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}`\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"not sure why xdoctest is choking on this\")\n    >>> m = nn.ReflectionPad3d(1)\n    >>> input = torch.arange(8, dtype=torch.float).reshape(1, 1, 2, 2, 2)\n    >>> m(input)\n    tensor([[[[[7., 6., 7., 6.],\n               [5., 4., 5., 4.],\n               [7., 6., 7., 6.],\n               [5., 4., 5., 4.]],\n              [[3., 2., 3., 2.],\n               [1., 0., 1., 0.],\n               [3., 2., 3., 2.],\n               [1., 0., 1., 0.]],\n              [[7., 6., 7., 6.],\n               [5., 4., 5., 4.],\n               [7., 6., 7., 6.],\n               [5., 4., 5., 4.]],\n              [[3., 2., 3., 2.],\n               [1., 0., 1., 0.],\n               [3., 2., 3., 2.],\n               [1., 0., 1., 0.]]]]])",
        "has_varargs": false
      },
      {
        "name": "ReplicationPad1d",
        "api_path": "torch.nn.ReplicationPad1d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using replication of the input boundary.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 2-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`)\n        Note that the output dimensions must remain positive.\n\nShape:\n    - Input: :math:`(C, W_{in})` or :math:`(N, C, W_{in})`.\n    - Output: :math:`(C, W_{out})` or :math:`(N, C, W_{out})`, where\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"not sure why xdoctest is choking on this\")\n    >>> m = nn.ReplicationPad1d(2)\n    >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4)\n    >>> input\n    tensor([[[0., 1., 2., 3.],\n             [4., 5., 6., 7.]]])\n    >>> m(input)\n    tensor([[[0., 0., 0., 1., 2., 3., 3., 3.],\n             [4., 4., 4., 5., 6., 7., 7., 7.]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.ReplicationPad1d((3, 1))\n    >>> m(input)\n    tensor([[[0., 0., 0., 0., 1., 2., 3., 3.],\n             [4., 4., 4., 4., 5., 6., 7., 7.]]])",
        "has_varargs": false
      },
      {
        "name": "ReplicationPad2d",
        "api_path": "torch.nn.ReplicationPad2d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using replication of the input boundary.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 4-`tuple`, uses (:math:`\\text{padding\\_left}`,\n        :math:`\\text{padding\\_right}`, :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`)\n        Note that the output dimensions must remain positive.\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> m = nn.ReplicationPad2d(2)\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3)\n    >>> input\n    tensor([[[[0., 1., 2.],\n              [3., 4., 5.],\n              [6., 7., 8.]]]])\n    >>> m(input)\n    tensor([[[[0., 0., 0., 1., 2., 2., 2.],\n              [0., 0., 0., 1., 2., 2., 2.],\n              [0., 0., 0., 1., 2., 2., 2.],\n              [3., 3., 3., 4., 5., 5., 5.],\n              [6., 6., 6., 7., 8., 8., 8.],\n              [6., 6., 6., 7., 8., 8., 8.],\n              [6., 6., 6., 7., 8., 8., 8.]]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.ReplicationPad2d((1, 1, 2, 0))\n    >>> m(input)\n    tensor([[[[0., 0., 1., 2., 2.],\n              [0., 0., 1., 2., 2.],\n              [0., 0., 1., 2., 2.],\n              [3., 3., 4., 5., 5.],\n              [6., 6., 7., 8., 8.]]]])",
        "has_varargs": false
      },
      {
        "name": "ReplicationPad3d",
        "api_path": "torch.nn.ReplicationPad3d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor using replication of the input boundary.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 6-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`,\n        :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`,\n        :math:`\\text{padding\\_front}`, :math:`\\text{padding\\_back}`)\n        Note that the output dimensions must remain positive.\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or :math:`(C, D_{out}, H_{out}, W_{out})`,\n      where\n\n      :math:`D_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}`\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = nn.ReplicationPad3d(3)\n    >>> input = torch.randn(16, 3, 8, 320, 480)\n    >>> output = m(input)\n    >>> # using different paddings for different sides\n    >>> m = nn.ReplicationPad3d((3, 3, 6, 6, 1, 1))\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "SELU",
        "api_path": "torch.nn.SELU",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the SELU function element-wise.\n\n.. math::\n    \\text{SELU}(x) = \\text{scale} * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))\n\nwith :math:`\\alpha = 1.6732632423543772848170429916717` and\n:math:`\\text{scale} = 1.0507009873554804934193349852946`.\n\n.. warning::\n    When using ``kaiming_normal`` or ``kaiming_normal_`` for initialisation,\n    ``nonlinearity='linear'`` should be used instead of ``nonlinearity='selu'``\n    in order to get `Self-Normalizing Neural Networks`_.\n    See :func:`torch.nn.init.calculate_gain` for more information.\n\nMore details can be found in the paper `Self-Normalizing Neural Networks`_ .\n\nArgs:\n    inplace (bool, optional): can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/SELU.png\n\nExamples::\n\n    >>> m = nn.SELU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)\n\n.. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515",
        "has_varargs": false
      },
      {
        "name": "Sequential",
        "api_path": "torch.nn.Sequential",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "A sequential container.\n\nModules will be added to it in the order they are passed in the\nconstructor. Alternatively, an ``OrderedDict`` of modules can be\npassed in. The ``forward()`` method of ``Sequential`` accepts any\ninput and forwards it to the first module it contains. It then\n\"chains\" outputs to inputs sequentially for each subsequent module,\nfinally returning the output of the last module.\n\nThe value a ``Sequential`` provides over manually calling a sequence\nof modules is that it allows treating the whole container as a\nsingle module, such that performing a transformation on the\n``Sequential`` applies to each of the modules it stores (which are\neach a registered submodule of the ``Sequential``).\n\nWhat's the difference between a ``Sequential`` and a\n:class:`torch.nn.ModuleList`? A ``ModuleList`` is exactly what it\nsounds like--a list for storing ``Module`` s! On the other hand,\nthe layers in a ``Sequential`` are connected in a cascading way.\n\nExample::\n\n    # Using Sequential to create a small model. When `model` is run,\n    # input will first be passed to `Conv2d(1,20,5)`. The output of\n    # `Conv2d(1,20,5)` will be used as the input to the first\n    # `ReLU`; the output of the first `ReLU` will become the input\n    # for `Conv2d(20,64,5)`. Finally, the output of\n    # `Conv2d(20,64,5)` will be used as input to the second `ReLU`\n    model = nn.Sequential(\n        nn.Conv2d(1, 20, 5), nn.ReLU(), nn.Conv2d(20, 64, 5), nn.ReLU()\n    )\n\n    # Using Sequential with OrderedDict. This is functionally the\n    # same as the above code\n    model = nn.Sequential(\n        OrderedDict(\n            [\n                (\"conv1\", nn.Conv2d(1, 20, 5)),\n                (\"relu1\", nn.ReLU()),\n                (\"conv2\", nn.Conv2d(20, 64, 5)),\n                (\"relu2\", nn.ReLU()),\n            ]\n        )\n    )",
        "has_varargs": true
      },
      {
        "name": "SiLU",
        "api_path": "torch.nn.SiLU",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Sigmoid Linear Unit (SiLU) function, element-wise.\n\nThe SiLU function is also known as the swish function.\n\n.. math::\n    \\text{silu}(x) = x * \\sigma(x), \\text{where } \\sigma(x) \\text{ is the logistic sigmoid.}\n\n.. note::\n    See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_\n    where the SiLU (Sigmoid Linear Unit) was originally coined, and see\n    `Sigmoid-Weighted Linear Units for Neural Network Function Approximation\n    in Reinforcement Learning <https://arxiv.org/abs/1702.03118>`_ and `Swish:\n    a Self-Gated Activation Function <https://arxiv.org/abs/1710.05941v1>`_\n    where the SiLU was experimented with later.\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/SiLU.png\n\nExamples::\n\n    >>> m = nn.SiLU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Sigmoid",
        "api_path": "torch.nn.Sigmoid",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the Sigmoid function element-wise.\n\n.. math::\n    \\text{Sigmoid}(x) = \\sigma(x) = \\frac{1}{1 + \\exp(-x)}\n\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Sigmoid.png\n\nExamples::\n\n    >>> m = nn.Sigmoid()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "Softmax",
        "api_path": "torch.nn.Softmax",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies the Softmax function to an n-dimensional input Tensor.\n\nRescales them so that the elements of the n-dimensional output Tensor\nlie in the range [0,1] and sum to 1.\n\nSoftmax is defined as:\n\n.. math::\n    \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n\nWhen the input Tensor is a sparse tensor then the unspecified\nvalues are treated as ``-inf``.\n\nShape:\n    - Input: :math:`(*)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(*)`, same shape as the input\n\nReturns:\n    a Tensor of the same dimension and shape as the input with\n    values in the range [0, 1]\n\nArgs:\n    dim (int): A dimension along which Softmax will be computed (so every slice\n        along dim will sum to 1).\n\n.. note::\n    This module doesn't work directly with NLLLoss,\n    which expects the Log to be computed between the Softmax and itself.\n    Use `LogSoftmax` instead (it's faster and has better numerical properties).\n\nExamples::\n\n    >>> m = nn.Softmax(dim=1)\n    >>> input = torch.randn(2, 3)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Softmax2d",
        "api_path": "torch.nn.Softmax2d",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies SoftMax over features to each spatial location.\n\nWhen given an image of ``Channels x Height x Width``, it will\napply `Softmax` to each location :math:`(Channels, h_i, w_j)`\n\nShape:\n    - Input: :math:`(N, C, H, W)` or :math:`(C, H, W)`.\n    - Output: :math:`(N, C, H, W)` or :math:`(C, H, W)` (same shape as input)\n\nReturns:\n    a Tensor of the same dimension and shape as the input with\n    values in the range [0, 1]\n\nExamples::\n\n    >>> m = nn.Softmax2d()\n    >>> # you softmax over the 2nd dimension\n    >>> input = torch.randn(2, 3, 12, 13)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "Softmin",
        "api_path": "torch.nn.Softmin",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies the Softmin function to an n-dimensional input Tensor.\n\nRescales them so that the elements of the n-dimensional output Tensor\nlie in the range `[0, 1]` and sum to 1.\n\nSoftmin is defined as:\n\n.. math::\n    \\text{Softmin}(x_{i}) = \\frac{\\exp(-x_i)}{\\sum_j \\exp(-x_j)}\n\nShape:\n    - Input: :math:`(*)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(*)`, same shape as the input\n\nArgs:\n    dim (int): A dimension along which Softmin will be computed (so every slice\n        along dim will sum to 1).\n\nReturns:\n    a Tensor of the same dimension and shape as the input, with\n    values in the range [0, 1]\n\nExamples::\n\n    >>> m = nn.Softmin(dim=1)\n    >>> input = torch.randn(2, 3)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Softplus",
        "api_path": "torch.nn.Softplus",
        "kind": "class",
        "params": [
          {
            "name": "beta",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "threshold",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "20.0",
            "annotation": "float"
          }
        ],
        "docstring": "Applies the Softplus function element-wise.\n\n.. math::\n    \\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))\n\nSoftPlus is a smooth approximation to the ReLU function and can be used\nto constrain the output of a machine to always be positive.\n\nFor numerical stability the implementation reverts to the linear function\nwhen :math:`input \\times \\beta > threshold`.\n\nArgs:\n    beta: the :math:`\\beta` value for the Softplus formulation. Default: 1\n    threshold: values above this revert to a linear function. Default: 20\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Softplus.png\n\nExamples::\n\n    >>> m = nn.Softplus()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Softshrink",
        "api_path": "torch.nn.Softshrink",
        "kind": "class",
        "params": [
          {
            "name": "lambd",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          }
        ],
        "docstring": "Applies the soft shrinkage function element-wise.\n\n.. math::\n    \\text{SoftShrinkage}(x) =\n    \\begin{cases}\n    x - \\lambda, & \\text{ if } x > \\lambda \\\\\n    x + \\lambda, & \\text{ if } x < -\\lambda \\\\\n    0, & \\text{ otherwise }\n    \\end{cases}\n\nArgs:\n    lambd: the :math:`\\lambda` (must be no less than zero) value for the Softshrink formulation. Default: 0.5\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Softshrink.png\n\nExamples::\n\n    >>> m = nn.Softshrink()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Softsign",
        "api_path": "torch.nn.Softsign",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the element-wise Softsign function.\n\n.. math::\n    \\text{SoftSign}(x) = \\frac{x}{ 1 + |x|}\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Softsign.png\n\nExamples::\n\n    >>> m = nn.Softsign()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "SyncBatchNorm",
        "api_path": "torch.nn.SyncBatchNorm",
        "kind": "class",
        "params": [
          {
            "name": "num_features",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "momentum",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "Optional"
          },
          {
            "name": "affine",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "track_running_stats",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "process_group",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies Batch Normalization over a N-Dimensional input.\n\nThe N-D input is a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper\n`Batch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift <https://arxiv.org/abs/1502.03167>`__ .\n\n.. math::\n\n    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\nThe mean and standard-deviation are calculated per-dimension over all\nmini-batches of the same process groups. :math:`\\gamma` and :math:`\\beta`\nare learnable parameter vectors of size `C` (where `C` is the input size).\nBy default, the elements of :math:`\\gamma` are sampled from\n:math:`\\mathcal{U}(0, 1)` and the elements of :math:`\\beta` are set to 0.\nThe standard-deviation is calculated via the biased estimator, equivalent to\n`torch.var(input, unbiased=False)`.\n\nAlso by default, during training this layer keeps running estimates of its\ncomputed mean and variance, which are then used for normalization during\nevaluation. The running estimates are kept with a default :attr:`momentum`\nof 0.1.\n\nIf :attr:`track_running_stats` is set to ``False``, this layer then does not\nkeep running estimates, and batch statistics are instead used during\nevaluation time as well.\n\n.. note::\n    This :attr:`momentum` argument is different from one used in optimizer\n    classes and the conventional notion of momentum. Mathematically, the\n    update rule for running statistics here is\n    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n    new observed value.\n\nBecause the Batch Normalization is done for each channel in the ``C`` dimension, computing\nstatistics on ``(N, +)`` slices, it's common terminology to call this Volumetric Batch\nNormalization or Spatio-temporal Batch Normalization.\n\nCurrently :class:`SyncBatchNorm` only supports\n:class:`~torch.nn.DistributedDataParallel` (DDP) with single GPU per process. Use\n:meth:`torch.nn.SyncBatchNorm.convert_sync_batchnorm()` to convert\n:attr:`BatchNorm*D` layer to :class:`SyncBatchNorm` before wrapping\nNetwork with DDP.\n\nArgs:\n    num_features: :math:`C` from an expected input of size\n        :math:`(N, C, +)`\n    eps: a value added to the denominator for numerical stability.\n        Default: ``1e-5``\n    momentum: the value used for the running_mean and running_var\n        computation. Can be set to ``None`` for cumulative moving average\n        (i.e. simple average). Default: 0.1\n    affine: a boolean value that when set to ``True``, this module has\n        learnable affine parameters. Default: ``True``\n    track_running_stats: a boolean value that when set to ``True``, this\n        module tracks the running mean and variance, and when set to ``False``,\n        this module does not track such statistics, and initializes statistics\n        buffers :attr:`running_mean` and :attr:`running_var` as ``None``.\n        When these buffers are ``None``, this module always uses batch statistics.\n        in both training and eval modes. Default: ``True``\n    process_group: synchronization of stats happen within each process group\n        individually. Default behavior is synchronization across the whole\n        world\n\nShape:\n    - Input: :math:`(N, C, +)`\n    - Output: :math:`(N, C, +)` (same shape as input)\n\n.. note::\n    Synchronization of batchnorm statistics occurs only while training, i.e.\n    synchronization is disabled when ``model.eval()`` is set or if\n    ``self.training`` is otherwise ``False``.\n\nExamples::\n\n    >>> # xdoctest: +SKIP\n    >>> # With Learnable Parameters\n    >>> m = nn.SyncBatchNorm(100)\n    >>> # creating process group (optional)\n    >>> # ranks is a list of int identifying rank ids.\n    >>> ranks = list(range(8))\n    >>> r1, r2 = ranks[:4], ranks[4:]\n    >>> # Note: every rank calls into new_group for every\n    >>> # process group created, even if that rank is not\n    >>> # part of the group.\n    >>> process_groups = [torch.distributed.new_group(pids) for pids in [r1, r2]]\n    >>> process_group = process_groups[0 if dist.get_rank() <= 3 else 1]\n    >>> # Without Learnable Parameters\n    >>> m = nn.BatchNorm3d(100, affine=False, process_group=process_group)\n    >>> input = torch.randn(20, 100, 35, 45, 10)\n    >>> output = m(input)\n\n    >>> # network is nn.BatchNorm layer\n    >>> sync_bn_network = nn.SyncBatchNorm.convert_sync_batchnorm(network, process_group)\n    >>> # only single gpu per process is currently supported\n    >>> ddp_sync_bn_network = torch.nn.parallel.DistributedDataParallel(\n    >>>                         sync_bn_network,\n    >>>                         device_ids=[args.local_rank],\n    >>>                         output_device=args.local_rank)",
        "has_varargs": false
      },
      {
        "name": "Tanh",
        "api_path": "torch.nn.Tanh",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the Hyperbolic Tangent (Tanh) function element-wise.\n\nTanh is defined as:\n\n.. math::\n    \\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)} {\\exp(x) + \\exp(-x)}\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Tanh.png\n\nExamples::\n\n    >>> m = nn.Tanh()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "Tanhshrink",
        "api_path": "torch.nn.Tanhshrink",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the element-wise Tanhshrink function.\n\n.. math::\n    \\text{Tanhshrink}(x) = x - \\tanh(x)\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Tanhshrink.png\n\nExamples::\n\n    >>> m = nn.Tanhshrink()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "Threshold",
        "api_path": "torch.nn.Threshold",
        "kind": "class",
        "params": [
          {
            "name": "threshold",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          },
          {
            "name": "value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Thresholds each element of the input Tensor.\n\nThreshold is defined as:\n\n.. math::\n    y =\n    \\begin{cases}\n    x, &\\text{ if } x > \\text{threshold} \\\\\n    \\text{value}, &\\text{ otherwise }\n    \\end{cases}\n\nArgs:\n    threshold: The value to threshold at\n    value: The value to replace with\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Threshold.png\n\nExamples::\n\n    >>> m = nn.Threshold(0, 0.5)\n    >>> input = torch.arange(-3, 3)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Transformer",
        "api_path": "torch.nn.Transformer",
        "kind": "class",
        "params": [
          {
            "name": "d_model",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "512",
            "annotation": "int"
          },
          {
            "name": "nhead",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "8",
            "annotation": "int"
          },
          {
            "name": "num_encoder_layers",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "6",
            "annotation": "int"
          },
          {
            "name": "num_decoder_layers",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "6",
            "annotation": "int"
          },
          {
            "name": "dim_feedforward",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "2048",
            "annotation": "int"
          },
          {
            "name": "dropout",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "float"
          },
          {
            "name": "activation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "<function relu at 0x7ab3f69f1080>",
            "annotation": "Union"
          },
          {
            "name": "custom_encoder",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "custom_decoder",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "layer_norm_eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "batch_first",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "norm_first",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "A basic transformer layer.\n\n\nThis Transformer layer implements the original Transformer architecture described\nin the `Attention Is All You Need <https://arxiv.org/abs/1706.03762>`_ paper. The\nintent of this layer is as a reference implementation for foundational understanding\nand thus it contains only limited features relative to newer Transformer architectures.\nGiven the fast pace of innovation in transformer-like architectures, we recommend\nexploring this `tutorial <https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html>`_\nto build an efficient transformer layer from building blocks in core or using higher\nlevel libraries from the `PyTorch Ecosystem <https://landscape.pytorch.org/>`_.\n\nArgs:\n    d_model: the number of expected features in the encoder/decoder inputs (default=512).\n    nhead: the number of heads in the multiheadattention models (default=8).\n    num_encoder_layers: the number of sub-encoder-layers in the encoder (default=6).\n    num_decoder_layers: the number of sub-decoder-layers in the decoder (default=6).\n    dim_feedforward: the dimension of the feedforward network model (default=2048).\n    dropout: the dropout value (default=0.1).\n    activation: the activation function of encoder/decoder intermediate layer, can be a string\n        (\"relu\" or \"gelu\") or a unary callable. Default: relu\n    custom_encoder: custom encoder (default=None).\n    custom_decoder: custom decoder (default=None).\n    layer_norm_eps: the eps value in layer normalization components (default=1e-5).\n    batch_first: If ``True``, then the input and output tensors are provided\n        as (batch, seq, feature). Default: ``False`` (seq, batch, feature).\n    norm_first: if ``True``, encoder and decoder layers will perform LayerNorms before\n        other attention and feedforward operations, otherwise after. Default: ``False`` (after).\n    bias: If set to ``False``, ``Linear`` and ``LayerNorm`` layers will not learn an additive\n        bias. Default: ``True``.\n\nExamples:\n    >>> transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n    >>> src = torch.rand((10, 32, 512))\n    >>> tgt = torch.rand((20, 32, 512))\n    >>> out = transformer_model(src, tgt)\n\nNote: A full example to apply nn.Transformer module for the word language model is available in\nhttps://github.com/pytorch/examples/tree/master/word_language_model",
        "has_varargs": false
      },
      {
        "name": "TransformerDecoder",
        "api_path": "torch.nn.TransformerDecoder",
        "kind": "class",
        "params": [
          {
            "name": "decoder_layer",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "TransformerDecoderLayer"
          },
          {
            "name": "num_layers",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "norm",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "TransformerDecoder is a stack of N decoder layers.\n\nThis TransformerDecoder layer implements the original architecture described\nin the `Attention Is All You Need <https://arxiv.org/abs/1706.03762>`_ paper. The\nintent of this layer is as a reference implementation for foundational understanding\nand thus it contains only limited features relative to newer Transformer architectures.\nGiven the fast pace of innovation in transformer-like architectures, we recommend\nexploring this `tutorial <https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html>`_\nto build efficient layers from building blocks in core or using higher\nlevel libraries from the `PyTorch Ecosystem <https://landscape.pytorch.org/>`_.\n\n.. warning::\n    All layers in the TransformerDecoder are initialized with the same parameters.\n    It is recommended to manually initialize the layers after creating the TransformerDecoder instance.\n\nArgs:\n    decoder_layer: an instance of the TransformerDecoderLayer() class (required).\n    num_layers: the number of sub-decoder-layers in the decoder (required).\n    norm: the layer normalization component (optional).\n\nExamples:\n    >>> decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n    >>> transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n    >>> memory = torch.rand(10, 32, 512)\n    >>> tgt = torch.rand(20, 32, 512)\n    >>> out = transformer_decoder(tgt, memory)",
        "has_varargs": false
      },
      {
        "name": "TransformerDecoderLayer",
        "api_path": "torch.nn.TransformerDecoderLayer",
        "kind": "class",
        "params": [
          {
            "name": "d_model",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "nhead",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "dim_feedforward",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "2048",
            "annotation": "int"
          },
          {
            "name": "dropout",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "float"
          },
          {
            "name": "activation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "<function relu at 0x7ab3f69f1080>",
            "annotation": "Union"
          },
          {
            "name": "layer_norm_eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "batch_first",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "norm_first",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\n\nThis TransformerDecoderLayer implements the original architecture described\nin the `Attention Is All You Need <https://arxiv.org/abs/1706.03762>`_ paper. The\nintent of this layer is as a reference implementation for foundational understanding\nand thus it contains only limited features relative to newer Transformer architectures.\nGiven the fast pace of innovation in transformer-like architectures, we recommend\nexploring this `tutorial <https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html>`_\nto build efficient layers from building blocks in core or using higher\nlevel libraries from the `PyTorch Ecosystem <https://landscape.pytorch.org/>`_.\n\nArgs:\n    d_model: the number of expected features in the input (required).\n    nhead: the number of heads in the multiheadattention models (required).\n    dim_feedforward: the dimension of the feedforward network model (default=2048).\n    dropout: the dropout value (default=0.1).\n    activation: the activation function of the intermediate layer, can be a string\n        (\"relu\" or \"gelu\") or a unary callable. Default: relu\n    layer_norm_eps: the eps value in layer normalization components (default=1e-5).\n    batch_first: If ``True``, then the input and output tensors are provided\n        as (batch, seq, feature). Default: ``False`` (seq, batch, feature).\n    norm_first: if ``True``, layer norm is done prior to self attention, multihead\n        attention and feedforward operations, respectively. Otherwise it's done after.\n        Default: ``False`` (after).\n    bias: If set to ``False``, ``Linear`` and ``LayerNorm`` layers will not learn an additive\n        bias. Default: ``True``.\n\nExamples:\n    >>> decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n    >>> memory = torch.rand(10, 32, 512)\n    >>> tgt = torch.rand(20, 32, 512)\n    >>> out = decoder_layer(tgt, memory)\n\nAlternatively, when ``batch_first`` is ``True``:\n    >>> decoder_layer = nn.TransformerDecoderLayer(\n    ...     d_model=512, nhead=8, batch_first=True\n    ... )\n    >>> memory = torch.rand(32, 10, 512)\n    >>> tgt = torch.rand(32, 20, 512)\n    >>> out = decoder_layer(tgt, memory)",
        "has_varargs": false
      },
      {
        "name": "TransformerEncoder",
        "api_path": "torch.nn.TransformerEncoder",
        "kind": "class",
        "params": [
          {
            "name": "encoder_layer",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "TransformerEncoderLayer"
          },
          {
            "name": "num_layers",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "norm",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "enable_nested_tensor",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "mask_check",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          }
        ],
        "docstring": "TransformerEncoder is a stack of N encoder layers.\n\nThis TransformerEncoder layer implements the original architecture described\nin the `Attention Is All You Need <https://arxiv.org/abs/1706.03762>`_ paper. The\nintent of this layer is as a reference implementation for foundational understanding\nand thus it contains only limited features relative to newer Transformer architectures.\nGiven the fast pace of innovation in transformer-like architectures, we recommend\nexploring this `tutorial <https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html>`_\nto build efficient layers from building blocks in core or using higher\nlevel libraries from the `PyTorch Ecosystem <https://landscape.pytorch.org/>`_.\n\n.. warning::\n    All layers in the TransformerEncoder are initialized with the same parameters.\n    It is recommended to manually initialize the layers after creating the TransformerEncoder instance.\n\nArgs:\n    encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n    num_layers: the number of sub-encoder-layers in the encoder (required).\n    norm: the layer normalization component (optional).\n    enable_nested_tensor: if True, input will automatically convert to nested tensor\n        (and convert back on output). This will improve the overall performance of\n        TransformerEncoder when padding rate is high. Default: ``True`` (enabled).\n\nExamples:\n    >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n    >>> transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n    >>> src = torch.rand(10, 32, 512)\n    >>> out = transformer_encoder(src)",
        "has_varargs": false
      },
      {
        "name": "TransformerEncoderLayer",
        "api_path": "torch.nn.TransformerEncoderLayer",
        "kind": "class",
        "params": [
          {
            "name": "d_model",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "nhead",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "int"
          },
          {
            "name": "dim_feedforward",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "2048",
            "annotation": "int"
          },
          {
            "name": "dropout",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.1",
            "annotation": "float"
          },
          {
            "name": "activation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "<function relu at 0x7ab3f69f1080>",
            "annotation": "Union"
          },
          {
            "name": "layer_norm_eps",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1e-05",
            "annotation": "float"
          },
          {
            "name": "batch_first",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "norm_first",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "bias",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "True",
            "annotation": "bool"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "TransformerEncoderLayer is made up of self-attn and feedforward network.\n\nThis TransformerEncoderLayer implements the original architecture described\nin the `Attention Is All You Need <https://arxiv.org/abs/1706.03762>`_ paper. The\nintent of this layer is as a reference implementation for foundational understanding\nand thus it contains only limited features relative to newer Transformer architectures.\nGiven the fast pace of innovation in transformer-like architectures, we recommend\nexploring this `tutorial <https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html>`_\nto build efficient layers from building blocks in core or using higher\nlevel libraries from the `PyTorch Ecosystem <https://landscape.pytorch.org/>`_.\n\nTransformerEncoderLayer can handle either traditional torch.tensor inputs,\nor Nested Tensor inputs.  Derived classes are expected to similarly accept\nboth input formats.  (Not all combinations of inputs are currently\nsupported by TransformerEncoderLayer while Nested Tensor is in prototype\nstate.)\n\nIf you are implementing a custom layer, you may derive it either from\nthe Module or TransformerEncoderLayer class.  If your custom layer\nsupports both torch.Tensors and Nested Tensors inputs, make its\nimplementation a derived class of TransformerEncoderLayer. If your custom\nLayer supports only torch.Tensor inputs, derive its implementation from\nModule.\n\nArgs:\n    d_model: the number of expected features in the input (required).\n    nhead: the number of heads in the multiheadattention models (required).\n    dim_feedforward: the dimension of the feedforward network model (default=2048).\n    dropout: the dropout value (default=0.1).\n    activation: the activation function of the intermediate layer, can be a string\n        (\"relu\" or \"gelu\") or a unary callable. Default: relu\n    layer_norm_eps: the eps value in layer normalization components (default=1e-5).\n    batch_first: If ``True``, then the input and output tensors are provided\n        as (batch, seq, feature). Default: ``False`` (seq, batch, feature).\n    norm_first: if ``True``, layer norm is done prior to attention and feedforward\n        operations, respectively. Otherwise it's done after. Default: ``False`` (after).\n    bias: If set to ``False``, ``Linear`` and ``LayerNorm`` layers will not learn an additive\n        bias. Default: ``True``.\n\nExamples:\n    >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n    >>> src = torch.rand(10, 32, 512)\n    >>> out = encoder_layer(src)\n\nAlternatively, when ``batch_first`` is ``True``:\n    >>> encoder_layer = nn.TransformerEncoderLayer(\n    ...     d_model=512, nhead=8, batch_first=True\n    ... )\n    >>> src = torch.rand(32, 10, 512)\n    >>> out = encoder_layer(src)\n\nFast path:\n    forward() will use a special optimized implementation described in\n    `FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness`_ if all of the following\n    conditions are met:\n\n    - Either autograd is disabled (using ``torch.inference_mode`` or ``torch.no_grad``) or no tensor\n      argument ``requires_grad``\n    - training is disabled (using ``.eval()``)\n    - batch_first is ``True`` and the input is batched (i.e., ``src.dim() == 3``)\n    - activation is one of: ``\"relu\"``, ``\"gelu\"``, ``torch.functional.relu``, or ``torch.functional.gelu``\n    - at most one of ``src_mask`` and ``src_key_padding_mask`` is passed\n    - if src is a `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_, neither ``src_mask``\n      nor ``src_key_padding_mask`` is passed\n    - the two ``LayerNorm`` instances have a consistent ``eps`` value (this will naturally be the case\n      unless the caller has manually modified one without modifying the other)\n\n    If the optimized implementation is in use, a\n    `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_ can be\n    passed for ``src`` to represent padding more efficiently than using a padding\n    mask. In this case, a `NestedTensor <https://pytorch.org/docs/stable/nested.html>`_ will be\n    returned, and an additional speedup proportional to the fraction of the input that\n    is padding can be expected.\n\n    .. _`FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness`:\n     https://arxiv.org/abs/2205.14135",
        "has_varargs": false
      },
      {
        "name": "Unflatten",
        "api_path": "torch.nn.Unflatten",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "unflattened_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Unflattens a tensor dim expanding it to a desired shape. For use with :class:`~nn.Sequential`.\n\n* :attr:`dim` specifies the dimension of the input tensor to be unflattened, and it can\n  be either `int` or `str` when `Tensor` or `NamedTensor` is used, respectively.\n\n* :attr:`unflattened_size` is the new shape of the unflattened dimension of the tensor and it can be\n  a `tuple` of ints or a `list` of ints or `torch.Size` for `Tensor` input;  a `NamedShape`\n  (tuple of `(name, size)` tuples) for `NamedTensor` input.\n\nShape:\n    - Input: :math:`(*, S_{\\text{dim}}, *)`, where :math:`S_{\\text{dim}}` is the size at\n      dimension :attr:`dim` and :math:`*` means any number of dimensions including none.\n    - Output: :math:`(*, U_1, ..., U_n, *)`, where :math:`U` = :attr:`unflattened_size` and\n      :math:`\\prod_{i=1}^n U_i = S_{\\text{dim}}`.\n\nArgs:\n    dim (Union[int, str]): Dimension to be unflattened\n    unflattened_size (Union[torch.Size, Tuple, List, NamedShape]): New shape of the unflattened dimension\n\nExamples:\n    >>> input = torch.randn(2, 50)\n    >>> # With tuple of ints\n    >>> m = nn.Sequential(\n    >>>     nn.Linear(50, 50),\n    >>>     nn.Unflatten(1, (2, 5, 5))\n    >>> )\n    >>> output = m(input)\n    >>> output.size()\n    torch.Size([2, 2, 5, 5])\n    >>> # With torch.Size\n    >>> m = nn.Sequential(\n    >>>     nn.Linear(50, 50),\n    >>>     nn.Unflatten(1, torch.Size([2, 5, 5]))\n    >>> )\n    >>> output = m(input)\n    >>> output.size()\n    torch.Size([2, 2, 5, 5])\n    >>> # With namedshape (tuple of tuples)\n    >>> input = torch.randn(2, 50, names=(\"N\", \"features\"))\n    >>> unflatten = nn.Unflatten(\"features\", ((\"C\", 2), (\"H\", 5), (\"W\", 5)))\n    >>> output = unflatten(input)\n    >>> output.size()\n    torch.Size([2, 2, 5, 5])",
        "has_varargs": false
      },
      {
        "name": "Unfold",
        "api_path": "torch.nn.Unfold",
        "kind": "class",
        "params": [
          {
            "name": "kernel_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          },
          {
            "name": "dilation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          },
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0",
            "annotation": "Union"
          },
          {
            "name": "stride",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "Union"
          }
        ],
        "docstring": "Extracts sliding local blocks from a batched input tensor.\n\nConsider a batched :attr:`input` tensor of shape :math:`(N, C, *)`,\nwhere :math:`N` is the batch dimension, :math:`C` is the channel dimension,\nand :math:`*` represent arbitrary spatial dimensions. This operation flattens\neach sliding :attr:`kernel_size`-sized block within the spatial dimensions\nof :attr:`input` into a column (i.e., last dimension) of a 3-D :attr:`output`\ntensor of shape :math:`(N, C \\times \\prod(\\text{kernel\\_size}), L)`, where\n:math:`C \\times \\prod(\\text{kernel\\_size})` is the total number of values\nwithin each block (a block has :math:`\\prod(\\text{kernel\\_size})` spatial\nlocations each containing a :math:`C`-channeled vector), and :math:`L` is\nthe total number of such blocks:\n\n.. math::\n    L = \\prod_d \\left\\lfloor\\frac{\\text{spatial\\_size}[d] + 2 \\times \\text{padding}[d] %\n        - \\text{dilation}[d] \\times (\\text{kernel\\_size}[d] - 1) - 1}{\\text{stride}[d]} + 1\\right\\rfloor,\n\nwhere :math:`\\text{spatial\\_size}` is formed by the spatial dimensions\nof :attr:`input` (:math:`*` above), and :math:`d` is over all spatial\ndimensions.\n\nTherefore, indexing :attr:`output` at the last dimension (column dimension)\ngives all values within a certain block.\n\nThe :attr:`padding`, :attr:`stride` and :attr:`dilation` arguments specify\nhow the sliding blocks are retrieved.\n\n* :attr:`stride` controls the stride for the sliding blocks.\n\n* :attr:`padding` controls the amount of implicit zero-paddings on both\n  sides for :attr:`padding` number of points for each dimension before\n  reshaping.\n\n* :attr:`dilation` controls the spacing between the kernel points; also known as the \u00e0 trous algorithm.\n  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n\nArgs:\n    kernel_size (int or tuple): the size of the sliding blocks\n    dilation (int or tuple, optional): a parameter that controls the\n                                       stride of elements within the\n                                       neighborhood. Default: 1\n    padding (int or tuple, optional): implicit zero padding to be added on\n                                      both sides of input. Default: 0\n    stride (int or tuple, optional): the stride of the sliding blocks in the input\n                                     spatial dimensions. Default: 1\n\n* If :attr:`kernel_size`, :attr:`dilation`, :attr:`padding` or\n  :attr:`stride` is an int or a tuple of length 1, their values will be\n  replicated across all spatial dimensions.\n\n* For the case of two input spatial dimensions this operation is sometimes\n  called ``im2col``.\n\n.. note::\n    :class:`~torch.nn.Fold` calculates each combined value in the resulting\n    large tensor by summing all values from all containing blocks.\n    :class:`~torch.nn.Unfold` extracts the values in the local blocks by\n    copying from the large tensor. So, if the blocks overlap, they are not\n    inverses of each other.\n\n    In general, folding and unfolding operations are related as\n    follows. Consider :class:`~torch.nn.Fold` and\n    :class:`~torch.nn.Unfold` instances created with the same\n    parameters:\n\n    >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n    >>> fold = nn.Fold(output_size=..., **fold_params)\n    >>> unfold = nn.Unfold(**fold_params)\n\n    Then for any (supported) ``input`` tensor the following\n    equality holds:\n\n    ::\n\n        fold(unfold(input)) == divisor * input\n\n    where ``divisor`` is a tensor that depends only on the shape\n    and dtype of the ``input``:\n\n    >>> # xdoctest: +SKIP\n    >>> input_ones = torch.ones(input.shape, dtype=input.dtype)\n    >>> divisor = fold(unfold(input_ones))\n\n    When the ``divisor`` tensor contains no zero elements, then\n    ``fold`` and ``unfold`` operations are inverses of each\n    other (up to constant divisor).\n\n.. warning::\n    Currently, only 4-D input tensors (batched image-like tensors) are\n    supported.\n\nShape:\n    - Input: :math:`(N, C, *)`\n    - Output: :math:`(N, C \\times \\prod(\\text{kernel\\_size}), L)` as described above\n\nExamples::\n\n    >>> unfold = nn.Unfold(kernel_size=(2, 3))\n    >>> input = torch.randn(2, 5, 3, 4)\n    >>> output = unfold(input)\n    >>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n    >>> # 4 blocks (2x3 kernels) in total in the 3x4 input\n    >>> output.size()\n    torch.Size([2, 30, 4])\n\n    >>> # xdoctest: +IGNORE_WANT\n    >>> # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n    >>> inp = torch.randn(1, 3, 10, 12)\n    >>> w = torch.randn(2, 3, 4, 5)\n    >>> inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n    >>> out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n    >>> out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))\n    >>> # or equivalently (and avoiding a copy),\n    >>> # out = out_unf.view(1, 2, 7, 8)\n    >>> (torch.nn.functional.conv2d(inp, w) - out).abs().max()\n    tensor(1.9073e-06)\n\n.. _link:\n    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
        "has_varargs": false
      },
      {
        "name": "Upsample",
        "api_path": "torch.nn.Upsample",
        "kind": "class",
        "params": [
          {
            "name": "size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "scale_factor",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "mode",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "nearest",
            "annotation": "str"
          },
          {
            "name": "align_corners",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "recompute_scale_factor",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.\n\nThe input data is assumed to be of the form\n`minibatch x channels x [optional depth] x [optional height] x width`.\nHence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.\n\nThe algorithms available for upsampling are nearest neighbor and linear,\nbilinear, bicubic and trilinear for 3D, 4D and 5D input Tensor,\nrespectively.\n\nOne can either give a :attr:`scale_factor` or the target output :attr:`size` to\ncalculate the output size. (You cannot give both, as it is ambiguous)\n\nArgs:\n    size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int], optional):\n        output spatial sizes\n    scale_factor (float or Tuple[float] or Tuple[float, float] or Tuple[float, float, float], optional):\n        multiplier for spatial size. Has to match input size if it is a tuple.\n    mode (str, optional): the upsampling algorithm: one of ``'nearest'``,\n        ``'linear'``, ``'bilinear'``, ``'bicubic'`` and ``'trilinear'``.\n        Default: ``'nearest'``\n    align_corners (bool, optional): if ``True``, the corner pixels of the input\n        and output tensors are aligned, and thus preserving the values at\n        those pixels. This only has effect when :attr:`mode` is\n        ``'linear'``, ``'bilinear'``, ``'bicubic'``, or ``'trilinear'``.\n        Default: ``False``\n    recompute_scale_factor (bool, optional): recompute the scale_factor for use in the\n        interpolation calculation. If `recompute_scale_factor` is ``True``, then\n        `scale_factor` must be passed in and `scale_factor` is used to compute the\n        output `size`. The computed output `size` will be used to infer new scales for\n        the interpolation. Note that when `scale_factor` is floating-point, it may differ\n        from the recomputed `scale_factor` due to rounding and precision issues.\n        If `recompute_scale_factor` is ``False``, then `size` or `scale_factor` will\n        be used directly for interpolation.\n\nShape:\n    - Input: :math:`(N, C, W_{in})`, :math:`(N, C, H_{in}, W_{in})` or :math:`(N, C, D_{in}, H_{in}, W_{in})`\n    - Output: :math:`(N, C, W_{out})`, :math:`(N, C, H_{out}, W_{out})`\n      or :math:`(N, C, D_{out}, H_{out}, W_{out})`, where\n\n.. math::\n    D_{out} = \\left\\lfloor D_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\n.. math::\n    H_{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\n.. math::\n    W_{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\n.. warning::\n    With ``align_corners = True``, the linearly interpolating modes\n    (`linear`, `bilinear`, `bicubic`, and `trilinear`) don't proportionally\n    align the output and input pixels, and thus the output values can depend\n    on the input size. This was the default behavior for these modes up to\n    version 0.3.1. Since then, the default behavior is\n    ``align_corners = False``. See below for concrete examples on how this\n    affects the outputs.\n\n.. note::\n    If you want downsampling/general resizing, you should use :func:`~nn.functional.interpolate`.\n\nExamples::\n\n    >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)\n    >>> input\n    tensor([[[[1., 2.],\n              [3., 4.]]]])\n\n    >>> m = nn.Upsample(scale_factor=2, mode='nearest')\n    >>> m(input)\n    tensor([[[[1., 1., 2., 2.],\n              [1., 1., 2., 2.],\n              [3., 3., 4., 4.],\n              [3., 3., 4., 4.]]]])\n\n    >>> # xdoctest: +IGNORE_WANT(\"other tests seem to modify printing styles\")\n    >>> m = nn.Upsample(scale_factor=2, mode='bilinear')  # align_corners=False\n    >>> m(input)\n    tensor([[[[1.0000, 1.2500, 1.7500, 2.0000],\n              [1.5000, 1.7500, 2.2500, 2.5000],\n              [2.5000, 2.7500, 3.2500, 3.5000],\n              [3.0000, 3.2500, 3.7500, 4.0000]]]])\n\n    >>> m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n    >>> m(input)\n    tensor([[[[1.0000, 1.3333, 1.6667, 2.0000],\n              [1.6667, 2.0000, 2.3333, 2.6667],\n              [2.3333, 2.6667, 3.0000, 3.3333],\n              [3.0000, 3.3333, 3.6667, 4.0000]]]])\n\n    >>> # Try scaling the same data in a larger tensor\n    >>> input_3x3 = torch.zeros(3, 3).view(1, 1, 3, 3)\n    >>> input_3x3[:, :, :2, :2].copy_(input)\n    tensor([[[[1., 2.],\n              [3., 4.]]]])\n    >>> input_3x3\n    tensor([[[[1., 2., 0.],\n              [3., 4., 0.],\n              [0., 0., 0.]]]])\n\n    >>> # xdoctest: +IGNORE_WANT(\"seems to fail when other tests are run in the same session\")\n    >>> m = nn.Upsample(scale_factor=2, mode='bilinear')  # align_corners=False\n    >>> # Notice that values in top left corner are the same with the small input (except at boundary)\n    >>> m(input_3x3)\n    tensor([[[[1.0000, 1.2500, 1.7500, 1.5000, 0.5000, 0.0000],\n              [1.5000, 1.7500, 2.2500, 1.8750, 0.6250, 0.0000],\n              [2.5000, 2.7500, 3.2500, 2.6250, 0.8750, 0.0000],\n              [2.2500, 2.4375, 2.8125, 2.2500, 0.7500, 0.0000],\n              [0.7500, 0.8125, 0.9375, 0.7500, 0.2500, 0.0000],\n              [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n\n    >>> m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n    >>> # Notice that values in top left corner are now changed\n    >>> m(input_3x3)\n    tensor([[[[1.0000, 1.4000, 1.8000, 1.6000, 0.8000, 0.0000],\n              [1.8000, 2.2000, 2.6000, 2.2400, 1.1200, 0.0000],\n              [2.6000, 3.0000, 3.4000, 2.8800, 1.4400, 0.0000],\n              [2.4000, 2.7200, 3.0400, 2.5600, 1.2800, 0.0000],\n              [1.2000, 1.3600, 1.5200, 1.2800, 0.6400, 0.0000],\n              [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])",
        "has_varargs": false
      },
      {
        "name": "UpsamplingBilinear2d",
        "api_path": "torch.nn.UpsamplingBilinear2d",
        "kind": "class",
        "params": [
          {
            "name": "size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "scale_factor",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          }
        ],
        "docstring": "Applies a 2D bilinear upsampling to an input signal composed of several input channels.\n\nTo specify the scale, it takes either the :attr:`size` or the :attr:`scale_factor`\nas it's constructor argument.\n\nWhen :attr:`size` is given, it is the output size of the image `(h, w)`.\n\nArgs:\n    size (int or Tuple[int, int], optional): output spatial sizes\n    scale_factor (float or Tuple[float, float], optional): multiplier for\n        spatial size.\n\n.. warning::\n    This class is deprecated in favor of :func:`~nn.functional.interpolate`. It is\n    equivalent to ``nn.functional.interpolate(..., mode='bilinear', align_corners=True)``.\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})`\n    - Output: :math:`(N, C, H_{out}, W_{out})` where\n\n.. math::\n    H_{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\n.. math::\n    W_{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\nExamples::\n\n    >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)\n    >>> input\n    tensor([[[[1., 2.],\n              [3., 4.]]]])\n\n    >>> # xdoctest: +IGNORE_WANT(\"do other tests modify the global state?\")\n    >>> m = nn.UpsamplingBilinear2d(scale_factor=2)\n    >>> m(input)\n    tensor([[[[1.0000, 1.3333, 1.6667, 2.0000],\n              [1.6667, 2.0000, 2.3333, 2.6667],\n              [2.3333, 2.6667, 3.0000, 3.3333],\n              [3.0000, 3.3333, 3.6667, 4.0000]]]])",
        "has_varargs": false
      },
      {
        "name": "UpsamplingNearest2d",
        "api_path": "torch.nn.UpsamplingNearest2d",
        "kind": "class",
        "params": [
          {
            "name": "size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          },
          {
            "name": "scale_factor",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Union"
          }
        ],
        "docstring": "Applies a 2D nearest neighbor upsampling to an input signal composed of several input channels.\n\nTo specify the scale, it takes either the :attr:`size` or the :attr:`scale_factor`\nas it's constructor argument.\n\nWhen :attr:`size` is given, it is the output size of the image `(h, w)`.\n\nArgs:\n    size (int or Tuple[int, int], optional): output spatial sizes\n    scale_factor (float or Tuple[float, float], optional): multiplier for\n        spatial size.\n\n.. warning::\n    This class is deprecated in favor of :func:`~nn.functional.interpolate`.\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})`\n    - Output: :math:`(N, C, H_{out}, W_{out})` where\n\n.. math::\n      H_{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\n.. math::\n      W_{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\nExamples::\n\n    >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)\n    >>> input\n    tensor([[[[1., 2.],\n              [3., 4.]]]])\n\n    >>> m = nn.UpsamplingNearest2d(scale_factor=2)\n    >>> m(input)\n    tensor([[[[1., 1., 2., 2.],\n              [1., 1., 2., 2.],\n              [3., 3., 4., 4.],\n              [3., 3., 4., 4.]]]])",
        "has_varargs": false
      },
      {
        "name": "ZeroPad1d",
        "api_path": "torch.nn.ZeroPad1d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor boundaries with zero.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in both boundaries. If a 2-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`)\n\nShape:\n    - Input: :math:`(C, W_{in})` or :math:`(N, C, W_{in})`.\n    - Output: :math:`(C, W_{out})` or :math:`(N, C, W_{out})`, where\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = nn.ZeroPad1d(2)\n    >>> input = torch.randn(1, 2, 4)\n    >>> input\n    tensor([[[-1.0491, -0.7152, -0.0749,  0.8530],\n             [-1.3287,  1.8966,  0.1466, -0.2771]]])\n    >>> m(input)\n    tensor([[[ 0.0000,  0.0000, -1.0491, -0.7152, -0.0749,  0.8530,  0.0000,\n               0.0000],\n             [ 0.0000,  0.0000, -1.3287,  1.8966,  0.1466, -0.2771,  0.0000,\n               0.0000]]])\n    >>> m = nn.ZeroPad1d(2)\n    >>> input = torch.randn(1, 2, 3)\n    >>> input\n    tensor([[[ 1.6616,  1.4523, -1.1255],\n             [-3.6372,  0.1182, -1.8652]]])\n    >>> m(input)\n    tensor([[[ 0.0000,  0.0000,  1.6616,  1.4523, -1.1255,  0.0000,  0.0000],\n             [ 0.0000,  0.0000, -3.6372,  0.1182, -1.8652,  0.0000,  0.0000]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.ZeroPad1d((3, 1))\n    >>> m(input)\n    tensor([[[ 0.0000,  0.0000,  0.0000,  1.6616,  1.4523, -1.1255,  0.0000],\n             [ 0.0000,  0.0000,  0.0000, -3.6372,  0.1182, -1.8652,  0.0000]]])",
        "has_varargs": false
      },
      {
        "name": "ZeroPad2d",
        "api_path": "torch.nn.ZeroPad2d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor boundaries with zero.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 4-`tuple`, uses (:math:`\\text{padding\\_left}`,\n        :math:`\\text{padding\\_right}`, :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`)\n\nShape:\n    - Input: :math:`(N, C, H_{in}, W_{in})` or :math:`(C, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, H_{out}, W_{out})` or :math:`(C, H_{out}, W_{out})`, where\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = nn.ZeroPad2d(2)\n    >>> input = torch.randn(1, 1, 3, 3)\n    >>> input\n    tensor([[[[-0.1678, -0.4418,  1.9466],\n              [ 0.9604, -0.4219, -0.5241],\n              [-0.9162, -0.5436, -0.6446]]]])\n    >>> m(input)\n    tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n              [ 0.0000,  0.0000, -0.1678, -0.4418,  1.9466,  0.0000,  0.0000],\n              [ 0.0000,  0.0000,  0.9604, -0.4219, -0.5241,  0.0000,  0.0000],\n              [ 0.0000,  0.0000, -0.9162, -0.5436, -0.6446,  0.0000,  0.0000],\n              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])\n    >>> # using different paddings for different sides\n    >>> m = nn.ZeroPad2d((1, 1, 2, 0))\n    >>> m(input)\n    tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n              [ 0.0000, -0.1678, -0.4418,  1.9466,  0.0000],\n              [ 0.0000,  0.9604, -0.4219, -0.5241,  0.0000],\n              [ 0.0000, -0.9162, -0.5436, -0.6446,  0.0000]]]])",
        "has_varargs": false
      },
      {
        "name": "ZeroPad3d",
        "api_path": "torch.nn.ZeroPad3d",
        "kind": "class",
        "params": [
          {
            "name": "padding",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Union"
          }
        ],
        "docstring": "Pads the input tensor boundaries with zero.\n\nFor `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.\n\nArgs:\n    padding (int, tuple): the size of the padding. If is `int`, uses the same\n        padding in all boundaries. If a 6-`tuple`, uses\n        (:math:`\\text{padding\\_left}`, :math:`\\text{padding\\_right}`,\n        :math:`\\text{padding\\_top}`, :math:`\\text{padding\\_bottom}`,\n        :math:`\\text{padding\\_front}`, :math:`\\text{padding\\_back}`)\n\nShape:\n    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})` or :math:`(C, D_{in}, H_{in}, W_{in})`.\n    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` or\n      :math:`(C, D_{out}, H_{out}, W_{out})`, where\n\n      :math:`D_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}`\n\n      :math:`H_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}`\n\n      :math:`W_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}`\n\nExamples::\n\n    >>> m = nn.ZeroPad3d(3)\n    >>> input = torch.randn(16, 3, 10, 20, 30)\n    >>> output = m(input)\n    >>> # using different paddings for different sides\n    >>> m = nn.ZeroPad3d((3, 3, 6, 6, 0, 1))\n    >>> output = m(input)",
        "has_varargs": false
      }
    ],
    "activation": [
      {
        "name": "CELU",
        "api_path": "torch.nn.CELU",
        "kind": "class",
        "params": [
          {
            "name": "alpha",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the CELU function element-wise.\n\n.. math::\n    \\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))\n\nMore details can be found in the paper `Continuously Differentiable Exponential Linear Units`_ .\n\nArgs:\n    alpha: the :math:`\\alpha` value for the CELU formulation. Default: 1.0\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/CELU.png\n\nExamples::\n\n    >>> m = nn.CELU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)\n\n.. _`Continuously Differentiable Exponential Linear Units`:\n    https://arxiv.org/abs/1704.07483",
        "has_varargs": false
      },
      {
        "name": "GELU",
        "api_path": "torch.nn.GELU",
        "kind": "class",
        "params": [
          {
            "name": "approximate",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "none",
            "annotation": "str"
          }
        ],
        "docstring": "Applies the Gaussian Error Linear Units function.\n\n.. math:: \\text{GELU}(x) = x * \\Phi(x)\n\nwhere :math:`\\Phi(x)` is the Cumulative Distribution Function for Gaussian Distribution.\n\nWhen the approximate argument is 'tanh', Gelu is estimated with:\n\n.. math:: \\text{GELU}(x) = 0.5 * x * (1 + \\text{Tanh}(\\sqrt{2 / \\pi} * (x + 0.044715 * x^3)))\n\nArgs:\n    approximate (str, optional): the gelu approximation algorithm to use:\n        ``'none'`` | ``'tanh'``. Default: ``'none'``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/GELU.png\n\nExamples::\n\n    >>> m = nn.GELU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "GLU",
        "api_path": "torch.nn.GLU",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-1",
            "annotation": "int"
          }
        ],
        "docstring": "Applies the gated linear unit function.\n\n:math:`{GLU}(a, b)= a \\otimes \\sigma(b)` where :math:`a` is the first half\nof the input matrices and :math:`b` is the second half.\n\nArgs:\n    dim (int): the dimension on which to split the input. Default: -1\n\nShape:\n    - Input: :math:`(\\ast_1, N, \\ast_2)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(\\ast_1, M, \\ast_2)` where :math:`M=N/2`\n\n.. image:: ../scripts/activation_images/GLU.png\n\nExamples::\n\n    >>> m = nn.GLU()\n    >>> input = torch.randn(4, 2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Hardsigmoid",
        "api_path": "torch.nn.Hardsigmoid",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Hardsigmoid function element-wise.\n\nHardsigmoid is defined as:\n\n.. math::\n    \\text{Hardsigmoid}(x) = \\begin{cases}\n        0 & \\text{if~} x \\le -3, \\\\\n        1 & \\text{if~} x \\ge +3, \\\\\n        x / 6 + 1 / 2 & \\text{otherwise}\n    \\end{cases}\n\nArgs:\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Hardsigmoid.png\n\nExamples::\n\n    >>> m = nn.Hardsigmoid()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Hardswish",
        "api_path": "torch.nn.Hardswish",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Hardswish function, element-wise.\n\nMethod described in the paper: `Searching for MobileNetV3 <https://arxiv.org/abs/1905.02244>`_.\n\nHardswish is defined as:\n\n.. math::\n    \\text{Hardswish}(x) = \\begin{cases}\n        0 & \\text{if~} x \\le -3, \\\\\n        x & \\text{if~} x \\ge +3, \\\\\n        x \\cdot (x + 3) /6 & \\text{otherwise}\n    \\end{cases}\n\nArgs:\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Hardswish.png\n\nExamples::\n\n    >>> m = nn.Hardswish()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Hardtanh",
        "api_path": "torch.nn.Hardtanh",
        "kind": "class",
        "params": [
          {
            "name": "min_val",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "-1.0",
            "annotation": "float"
          },
          {
            "name": "max_val",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          },
          {
            "name": "min_value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "max_value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies the HardTanh function element-wise.\n\nHardTanh is defined as:\n\n.. math::\n    \\text{HardTanh}(x) = \\begin{cases}\n        \\text{max\\_val} & \\text{ if } x > \\text{ max\\_val } \\\\\n        \\text{min\\_val} & \\text{ if } x < \\text{ min\\_val } \\\\\n        x & \\text{ otherwise } \\\\\n    \\end{cases}\n\nArgs:\n    min_val: minimum value of the linear region range. Default: -1\n    max_val: maximum value of the linear region range. Default: 1\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nKeyword arguments :attr:`min_value` and :attr:`max_value`\nhave been deprecated in favor of :attr:`min_val` and :attr:`max_val`.\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Hardtanh.png\n\nExamples::\n\n    >>> m = nn.Hardtanh(-2, 2)\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "LeakyReLU",
        "api_path": "torch.nn.LeakyReLU",
        "kind": "class",
        "params": [
          {
            "name": "negative_slope",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the LeakyReLU function element-wise.\n\n.. math::\n    \\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)\n\n\nor\n\n.. math::\n    \\text{LeakyReLU}(x) =\n    \\begin{cases}\n    x, & \\text{ if } x \\geq 0 \\\\\n    \\text{negative\\_slope} \\times x, & \\text{ otherwise }\n    \\end{cases}\n\nArgs:\n    negative_slope: Controls the angle of the negative slope (which is used for\n      negative input values). Default: 1e-2\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(*)`, same shape as the input\n\n.. image:: ../scripts/activation_images/LeakyReLU.png\n\nExamples::\n\n    >>> m = nn.LeakyReLU(0.1)\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "LogSoftmax",
        "api_path": "torch.nn.LogSoftmax",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies the :math:`\\log(\\text{Softmax}(x))` function to an n-dimensional input Tensor.\n\nThe LogSoftmax formulation can be simplified as:\n\n.. math::\n    \\text{LogSoftmax}(x_{i}) = \\log\\left(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} \\right)\n\nShape:\n    - Input: :math:`(*)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(*)`, same shape as the input\n\nArgs:\n    dim (int): A dimension along which LogSoftmax will be computed.\n\nReturns:\n    a Tensor of the same dimension and shape as the input with\n    values in the range [-inf, 0)\n\nExamples::\n\n    >>> m = nn.LogSoftmax(dim=1)\n    >>> input = torch.randn(2, 3)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Mish",
        "api_path": "torch.nn.Mish",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Mish function, element-wise.\n\nMish: A Self Regularized Non-Monotonic Neural Activation Function.\n\n.. math::\n    \\text{Mish}(x) = x * \\text{Tanh}(\\text{Softplus}(x))\n\n.. note::\n    See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Mish.png\n\nExamples::\n\n    >>> m = nn.Mish()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "PReLU",
        "api_path": "torch.nn.PReLU",
        "kind": "class",
        "params": [
          {
            "name": "num_parameters",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1",
            "annotation": "int"
          },
          {
            "name": "init",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.25",
            "annotation": "float"
          },
          {
            "name": "device",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": null
          }
        ],
        "docstring": "Applies the element-wise PReLU function.\n\n.. math::\n    \\text{PReLU}(x) = \\max(0,x) + a * \\min(0,x)\n\nor\n\n.. math::\n    \\text{PReLU}(x) =\n    \\begin{cases}\n    x, & \\text{ if } x \\ge 0 \\\\\n    ax, & \\text{ otherwise }\n    \\end{cases}\n\nHere :math:`a` is a learnable parameter. When called without arguments, `nn.PReLU()` uses a single\nparameter :math:`a` across all input channels. If called with `nn.PReLU(nChannels)`,\na separate :math:`a` is used for each input channel.\n\n\n.. note::\n    weight decay should not be used when learning :math:`a` for good performance.\n\n.. note::\n    Channel dim is the 2nd dim of input. When input has dims < 2, then there is\n    no channel dim and the number of channels = 1.\n\nArgs:\n    num_parameters (int): number of :math:`a` to learn.\n        Although it takes an int as input, there is only two values are legitimate:\n        1, or the number of channels at input. Default: 1\n    init (float): the initial value of :math:`a`. Default: 0.25\n\nShape:\n    - Input: :math:`( *)` where `*` means, any number of additional\n      dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\nAttributes:\n    weight (Tensor): the learnable weights of shape (:attr:`num_parameters`).\n\n.. image:: ../scripts/activation_images/PReLU.png\n\nExamples::\n\n    >>> m = nn.PReLU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "ReLU",
        "api_path": "torch.nn.ReLU",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the rectified linear unit function element-wise.\n\n:math:`\\text{ReLU}(x) = (x)^+ = \\max(0, x)`\n\nArgs:\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/ReLU.png\n\nExamples::\n\n    >>> m = nn.ReLU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)\n\n\n  An implementation of CReLU - https://arxiv.org/abs/1603.05201\n\n    >>> m = nn.ReLU()\n    >>> input = torch.randn(2).unsqueeze(0)\n    >>> output = torch.cat((m(input), m(-input)))",
        "has_varargs": false
      },
      {
        "name": "ReLU6",
        "api_path": "torch.nn.ReLU6",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the ReLU6 function element-wise.\n\n.. math::\n    \\text{ReLU6}(x) = \\min(\\max(0,x), 6)\n\nArgs:\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/ReLU6.png\n\nExamples::\n\n    >>> m = nn.ReLU6()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "SELU",
        "api_path": "torch.nn.SELU",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the SELU function element-wise.\n\n.. math::\n    \\text{SELU}(x) = \\text{scale} * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))\n\nwith :math:`\\alpha = 1.6732632423543772848170429916717` and\n:math:`\\text{scale} = 1.0507009873554804934193349852946`.\n\n.. warning::\n    When using ``kaiming_normal`` or ``kaiming_normal_`` for initialisation,\n    ``nonlinearity='linear'`` should be used instead of ``nonlinearity='selu'``\n    in order to get `Self-Normalizing Neural Networks`_.\n    See :func:`torch.nn.init.calculate_gain` for more information.\n\nMore details can be found in the paper `Self-Normalizing Neural Networks`_ .\n\nArgs:\n    inplace (bool, optional): can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/SELU.png\n\nExamples::\n\n    >>> m = nn.SELU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)\n\n.. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515",
        "has_varargs": false
      },
      {
        "name": "SiLU",
        "api_path": "torch.nn.SiLU",
        "kind": "class",
        "params": [
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Applies the Sigmoid Linear Unit (SiLU) function, element-wise.\n\nThe SiLU function is also known as the swish function.\n\n.. math::\n    \\text{silu}(x) = x * \\sigma(x), \\text{where } \\sigma(x) \\text{ is the logistic sigmoid.}\n\n.. note::\n    See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_\n    where the SiLU (Sigmoid Linear Unit) was originally coined, and see\n    `Sigmoid-Weighted Linear Units for Neural Network Function Approximation\n    in Reinforcement Learning <https://arxiv.org/abs/1702.03118>`_ and `Swish:\n    a Self-Gated Activation Function <https://arxiv.org/abs/1710.05941v1>`_\n    where the SiLU was experimented with later.\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/SiLU.png\n\nExamples::\n\n    >>> m = nn.SiLU()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Sigmoid",
        "api_path": "torch.nn.Sigmoid",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the Sigmoid function element-wise.\n\n.. math::\n    \\text{Sigmoid}(x) = \\sigma(x) = \\frac{1}{1 + \\exp(-x)}\n\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Sigmoid.png\n\nExamples::\n\n    >>> m = nn.Sigmoid()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "Softmax",
        "api_path": "torch.nn.Softmax",
        "kind": "class",
        "params": [
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Applies the Softmax function to an n-dimensional input Tensor.\n\nRescales them so that the elements of the n-dimensional output Tensor\nlie in the range [0,1] and sum to 1.\n\nSoftmax is defined as:\n\n.. math::\n    \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n\nWhen the input Tensor is a sparse tensor then the unspecified\nvalues are treated as ``-inf``.\n\nShape:\n    - Input: :math:`(*)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(*)`, same shape as the input\n\nReturns:\n    a Tensor of the same dimension and shape as the input with\n    values in the range [0, 1]\n\nArgs:\n    dim (int): A dimension along which Softmax will be computed (so every slice\n        along dim will sum to 1).\n\n.. note::\n    This module doesn't work directly with NLLLoss,\n    which expects the Log to be computed between the Softmax and itself.\n    Use `LogSoftmax` instead (it's faster and has better numerical properties).\n\nExamples::\n\n    >>> m = nn.Softmax(dim=1)\n    >>> input = torch.randn(2, 3)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Softplus",
        "api_path": "torch.nn.Softplus",
        "kind": "class",
        "params": [
          {
            "name": "beta",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "threshold",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "20.0",
            "annotation": "float"
          }
        ],
        "docstring": "Applies the Softplus function element-wise.\n\n.. math::\n    \\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))\n\nSoftPlus is a smooth approximation to the ReLU function and can be used\nto constrain the output of a machine to always be positive.\n\nFor numerical stability the implementation reverts to the linear function\nwhen :math:`input \\times \\beta > threshold`.\n\nArgs:\n    beta: the :math:`\\beta` value for the Softplus formulation. Default: 1\n    threshold: values above this revert to a linear function. Default: 20\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Softplus.png\n\nExamples::\n\n    >>> m = nn.Softplus()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Softshrink",
        "api_path": "torch.nn.Softshrink",
        "kind": "class",
        "params": [
          {
            "name": "lambd",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.5",
            "annotation": "float"
          }
        ],
        "docstring": "Applies the soft shrinkage function element-wise.\n\n.. math::\n    \\text{SoftShrinkage}(x) =\n    \\begin{cases}\n    x - \\lambda, & \\text{ if } x > \\lambda \\\\\n    x + \\lambda, & \\text{ if } x < -\\lambda \\\\\n    0, & \\text{ otherwise }\n    \\end{cases}\n\nArgs:\n    lambd: the :math:`\\lambda` (must be no less than zero) value for the Softshrink formulation. Default: 0.5\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Softshrink.png\n\nExamples::\n\n    >>> m = nn.Softshrink()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "Softsign",
        "api_path": "torch.nn.Softsign",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the element-wise Softsign function.\n\n.. math::\n    \\text{SoftSign}(x) = \\frac{x}{ 1 + |x|}\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Softsign.png\n\nExamples::\n\n    >>> m = nn.Softsign()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "Tanh",
        "api_path": "torch.nn.Tanh",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the Hyperbolic Tangent (Tanh) function element-wise.\n\nTanh is defined as:\n\n.. math::\n    \\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)} {\\exp(x) + \\exp(-x)}\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Tanh.png\n\nExamples::\n\n    >>> m = nn.Tanh()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "Tanhshrink",
        "api_path": "torch.nn.Tanhshrink",
        "kind": "class",
        "params": [
          {
            "name": "args",
            "kind": "VAR_POSITIONAL",
            "default": null,
            "annotation": null
          },
          {
            "name": "kwargs",
            "kind": "VAR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "Applies the element-wise Tanhshrink function.\n\n.. math::\n    \\text{Tanhshrink}(x) = x - \\tanh(x)\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Tanhshrink.png\n\nExamples::\n\n    >>> m = nn.Tanhshrink()\n    >>> input = torch.randn(2)\n    >>> output = m(input)",
        "has_varargs": true
      },
      {
        "name": "Threshold",
        "api_path": "torch.nn.Threshold",
        "kind": "class",
        "params": [
          {
            "name": "threshold",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          },
          {
            "name": "value",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Thresholds each element of the input Tensor.\n\nThreshold is defined as:\n\n.. math::\n    y =\n    \\begin{cases}\n    x, &\\text{ if } x > \\text{threshold} \\\\\n    \\text{value}, &\\text{ otherwise }\n    \\end{cases}\n\nArgs:\n    threshold: The value to threshold at\n    value: The value to replace with\n    inplace: can optionally do the operation in-place. Default: ``False``\n\nShape:\n    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n    - Output: :math:`(*)`, same shape as the input.\n\n.. image:: ../scripts/activation_images/Threshold.png\n\nExamples::\n\n    >>> m = nn.Threshold(0, 0.5)\n    >>> input = torch.arange(-3, 3)\n    >>> output = m(input)",
        "has_varargs": false
      },
      {
        "name": "elu",
        "api_path": "torch.nn.functional.elu",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Tensor"
          },
          {
            "name": "alpha",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "1.0",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Apply the Exponential Linear Unit (ELU) function element-wise.\n\nSee :class:`~torch.nn.ELU` for more details.",
        "has_varargs": false
      },
      {
        "name": "hardswish",
        "api_path": "torch.nn.functional.hardswish",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Tensor"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Apply hardswish function, element-wise.\n\nFollows implementation as described in the paper:\n`Searching for MobileNetV3`_.\n\n.. math::\n    \\text{Hardswish}(x) = \\begin{cases}\n        0 & \\text{if~} x \\le -3, \\\\\n        x & \\text{if~} x \\ge +3, \\\\\n        x \\cdot (x + 3) /6 & \\text{otherwise}\n    \\end{cases}\n\nSee :class:`~torch.nn.Hardswish` for more details.\n\n.. _`Searching for MobileNetV3`:\n    https://arxiv.org/abs/1905.02244",
        "has_varargs": false
      },
      {
        "name": "leaky_relu",
        "api_path": "torch.nn.functional.leaky_relu",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Tensor"
          },
          {
            "name": "negative_slope",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "0.01",
            "annotation": "float"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "leaky_relu(input, negative_slope=0.01, inplace=False) -> Tensor\n\nApplies element-wise,\n:math:`\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)`\n\nSee :class:`~torch.nn.LeakyReLU` for more details.",
        "has_varargs": false
      },
      {
        "name": "log_softmax",
        "api_path": "torch.nn.functional.log_softmax",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Tensor"
          },
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "_stacklevel",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "3",
            "annotation": "int"
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Apply a softmax followed by a logarithm.\n\nWhile mathematically equivalent to log(softmax(x)), doing these two\noperations separately is slower and numerically unstable. This function\nuses an alternative formulation to compute the output and gradient correctly.\n\nSee :class:`~torch.nn.LogSoftmax` for more details.\n\nArgs:\n    input (Tensor): input\n    dim (int): A dimension along which log_softmax will be computed.\n    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n      If specified, the input tensor is cast to :attr:`dtype` before the operation\n      is performed. This is useful for preventing data type overflows. Default: None.",
        "has_varargs": false
      },
      {
        "name": "mish",
        "api_path": "torch.nn.functional.mish",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Tensor"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Apply the Mish function, element-wise.\n\nMish: A Self Regularized Non-Monotonic Neural Activation Function.\n\n.. math::\n    \\text{Mish}(x) = x * \\text{Tanh}(\\text{Softplus}(x))\n\n.. note::\n    See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_\n\nSee :class:`~torch.nn.Mish` for more details.",
        "has_varargs": false
      },
      {
        "name": "relu",
        "api_path": "torch.nn.functional.relu",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Tensor"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "relu(input, inplace=False) -> Tensor\n\nApplies the rectified linear unit function element-wise. See\n:class:`~torch.nn.ReLU` for more details.",
        "has_varargs": false
      },
      {
        "name": "sigmoid",
        "api_path": "torch.nn.functional.sigmoid",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "sigmoid(input) -> Tensor\n\nApplies the element-wise function :math:`\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}`\n\nSee :class:`~torch.nn.Sigmoid` for more details.",
        "has_varargs": false
      },
      {
        "name": "silu",
        "api_path": "torch.nn.functional.silu",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Tensor"
          },
          {
            "name": "inplace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "False",
            "annotation": "bool"
          }
        ],
        "docstring": "Apply the Sigmoid Linear Unit (SiLU) function, element-wise.\n\nThe SiLU function is also known as the swish function.\n\n.. math::\n    \\text{silu}(x) = x * \\sigma(x), \\text{where } \\sigma(x) \\text{ is the logistic sigmoid.}\n\n.. note::\n    See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_\n    where the SiLU (Sigmoid Linear Unit) was originally coined, and see\n    `Sigmoid-Weighted Linear Units for Neural Network Function Approximation\n    in Reinforcement Learning <https://arxiv.org/abs/1702.03118>`_ and `Swish:\n    a Self-Gated Activation Function <https://arxiv.org/abs/1710.05941v1>`_\n    where the SiLU was experimented with later.\n\nSee :class:`~torch.nn.SiLU` for more details.",
        "has_varargs": false
      },
      {
        "name": "softmax",
        "api_path": "torch.nn.functional.softmax",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": "Tensor"
          },
          {
            "name": "dim",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          },
          {
            "name": "_stacklevel",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "3",
            "annotation": "int"
          },
          {
            "name": "dtype",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": "None",
            "annotation": "Optional"
          }
        ],
        "docstring": "Apply a softmax function.\n\nSoftmax is defined as:\n\n:math:`\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}`\n\nIt is applied to all slices along dim, and will re-scale them so that the elements\nlie in the range `[0, 1]` and sum to 1.\n\nSee :class:`~torch.nn.Softmax` for more details.\n\nArgs:\n    input (Tensor): input\n    dim (int): A dimension along which softmax will be computed.\n    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n      If specified, the input tensor is casted to :attr:`dtype` before the operation\n      is performed. This is useful for preventing data type overflows. Default: None.\n\n.. note::\n    This function doesn't work directly with NLLLoss,\n    which expects the Log to be computed between the Softmax and itself.\n    Use log_softmax instead (it's faster and has better numerical properties).",
        "has_varargs": false
      },
      {
        "name": "tanh",
        "api_path": "torch.nn.functional.tanh",
        "kind": "function",
        "params": [
          {
            "name": "input",
            "kind": "POSITIONAL_OR_KEYWORD",
            "default": null,
            "annotation": null
          }
        ],
        "docstring": "tanh(input) -> Tensor\n\nApplies element-wise,\n:math:`\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}`\n\nSee :class:`~torch.nn.Tanh` for more details.",
        "has_varargs": false
      }
    ]
  }
}