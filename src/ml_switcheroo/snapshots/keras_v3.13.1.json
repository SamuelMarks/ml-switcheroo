{
  "categories": {
    "activation": [
      {
        "api_path": "keras.activations.celu",
        "docstring": "Continuously Differentiable Exponential Linear Unit.\n\nThe CeLU activation function is defined as:\n\n`celu(x) = alpha * (exp(x / alpha) - 1) for x < 0`,`celu(x) = x for x >= 0`.\n\nwhere `alpha` is a scaling parameter that controls the activation's shape.\n\nArgs:\n    x: Input tensor.\n    alpha: The \u03b1 value for the CeLU formulation. Defaults to `1.0`.\n\nReference:\n\n- [Barron, J. T., 2017](https://arxiv.org/abs/1704.07483)",
        "has_varargs": false,
        "kind": "function",
        "name": "celu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha"
          }
        ]
      },
      {
        "api_path": "keras.activations.deserialize",
        "docstring": "Return a Keras activation function via its config.",
        "has_varargs": false,
        "kind": "function",
        "name": "deserialize",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "config"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "custom_objects"
          }
        ]
      },
      {
        "api_path": "keras.activations.elu",
        "docstring": "Exponential Linear Unit.\n\nThe exponential linear unit (ELU) with `alpha > 0` is defined as:\n\n- `x` if `x > 0`\n- alpha * `exp(x) - 1` if `x < 0`\n\nELUs have negative values which pushes the mean of the activations\ncloser to zero.\n\nMean activations that are closer to zero enable faster learning as they\nbring the gradient closer to the natural gradient.\nELUs saturate to a negative value when the argument gets smaller.\nSaturation means a small derivative which decreases the variation\nand the information that is propagated to the next layer.\n\nArgs:\n    x: Input tensor.\n    alpha: A scalar, slope of positive section. Defaults to `1.0`.\n\nReference:\n\n- [Clevert et al., 2016](https://arxiv.org/abs/1511.07289)",
        "has_varargs": false,
        "kind": "function",
        "name": "elu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha"
          }
        ]
      },
      {
        "api_path": "keras.activations.exponential",
        "docstring": "Exponential activation function.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "exponential",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.gelu",
        "docstring": "Gaussian error linear unit (GELU) activation function.\n\nThe Gaussian error linear unit (GELU) is defined as:\n\n`gelu(x) = x * P(X <= x)` where `P(X) ~ N(0, 1)`,\ni.e. `gelu(x) = 0.5 * x * (1 + erf(x / sqrt(2)))`.\n\nGELU weights inputs by their value, rather than gating\ninputs by their sign as in ReLU.\n\nArgs:\n    x: Input tensor.\n    approximate: A `bool`, whether to enable approximation.\n\nReference:\n\n- [Hendrycks et al., 2016](https://arxiv.org/abs/1606.08415)",
        "has_varargs": false,
        "kind": "function",
        "name": "gelu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "approximate"
          }
        ]
      },
      {
        "api_path": "keras.activations.get",
        "docstring": "Retrieve a Keras activation function via an identifier.",
        "has_varargs": false,
        "kind": "function",
        "name": "get",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "identifier"
          }
        ]
      },
      {
        "api_path": "keras.activations.glu",
        "docstring": "Gated Linear Unit (GLU) activation function.\n\nThe GLU activation function is defined as:\n\n`glu(x) = a * sigmoid(b)`,\n\nwhere `x` is split into two equal parts `a` and `b` along the given axis.\n\nArgs:\n    x: Input tensor.\n    axis: The axis along which to split the input tensor. Defaults to `-1`.\n\nReference:\n\n- [Dauphin et al., 2017](https://arxiv.org/abs/1612.08083)",
        "has_varargs": false,
        "kind": "function",
        "name": "glu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          }
        ]
      },
      {
        "api_path": "keras.activations.hard_shrink",
        "docstring": "Hard Shrink activation function.\n\nIt is defined as:\n\n`hard_shrink(x) = x` if `|x| > threshold`,\n`hard_shrink(x) = 0` otherwise.\n\nArgs:\n    x: Input tensor.\n    threshold: Threshold value. Defaults to 0.5.",
        "has_varargs": false,
        "kind": "function",
        "name": "hard_shrink",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "0.5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "threshold"
          }
        ]
      },
      {
        "api_path": "keras.activations.hard_sigmoid",
        "docstring": "Hard sigmoid activation function.\n\nThe hard sigmoid activation is defined as:\n\n- `0` if `if x <= -3`\n- `1` if `x >= 3`\n- `(x/6) + 0.5` if `-3 < x < 3`\n\nIt's a faster, piecewise linear approximation\nof the sigmoid activation.\n\nArgs:\n    x: Input tensor.\n\nReference:\n\n- [Wikipedia \"Hard sigmoid\"](https://en.wikipedia.org/wiki/Hard_sigmoid)",
        "has_varargs": false,
        "kind": "function",
        "name": "hard_sigmoid",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.hard_silu",
        "docstring": "Hard SiLU activation function, also known as Hard Swish.\n\nIt is defined as:\n\n- `0` if `if x < -3`\n- `x` if `x > 3`\n- `x * (x + 3) / 6` if `-3 <= x <= 3`\n\nIt's a faster, piecewise linear approximation of the silu activation.\n\nArgs:\n    x: Input tensor.\n\nReference:\n\n- [A Howard, 2019](https://arxiv.org/abs/1905.02244)",
        "has_varargs": false,
        "kind": "function",
        "name": "hard_silu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.hard_swish",
        "docstring": "Hard SiLU activation function, also known as Hard Swish.\n\nIt is defined as:\n\n- `0` if `if x < -3`\n- `x` if `x > 3`\n- `x * (x + 3) / 6` if `-3 <= x <= 3`\n\nIt's a faster, piecewise linear approximation of the silu activation.\n\nArgs:\n    x: Input tensor.\n\nReference:\n\n- [A Howard, 2019](https://arxiv.org/abs/1905.02244)",
        "has_varargs": false,
        "kind": "function",
        "name": "hard_silu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.hard_tanh",
        "docstring": "HardTanh activation function.\n\nIt is defined as:\n`hard_tanh(x) = -1 for x < -1`,\n`hard_tanh(x) = x for -1 <= x <= 1`,\n`hard_tanh(x) = 1 for x > 1`.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "hard_tanh",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.leaky_relu",
        "docstring": "Leaky relu activation function.\n\nArgs:\n    x: Input tensor.\n    negative_slope: A `float` that controls the slope\n        for values lower than the threshold.",
        "has_varargs": false,
        "kind": "function",
        "name": "leaky_relu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "0.2",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "negative_slope"
          }
        ]
      },
      {
        "api_path": "keras.activations.linear",
        "docstring": "Linear activation function (pass-through).\n\nA \"linear\" activation is an identity function:\nit returns the input, unmodified.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "linear",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.log_sigmoid",
        "docstring": "Logarithm of the sigmoid activation function.\n\nIt is defined as `f(x) = log(1 / (1 + exp(-x)))`.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "log_sigmoid",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.log_softmax",
        "docstring": "Log-Softmax activation function.\n\nEach input vector is handled independently.\nThe `axis` argument sets which axis of the input the function\nis applied along.\n\nArgs:\n    x: Input tensor.\n    axis: Integer, axis along which the softmax is applied.",
        "has_varargs": false,
        "kind": "function",
        "name": "log_softmax",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          }
        ]
      },
      {
        "api_path": "keras.activations.mish",
        "docstring": "Mish activation function.\n\nIt is defined as:\n\n`mish(x) = x * tanh(softplus(x))`\n\nwhere `softplus` is defined as:\n\n`softplus(x) = log(exp(x) + 1)`\n\nArgs:\n    x: Input tensor.\n\nReference:\n\n- [Misra, 2019](https://arxiv.org/abs/1908.08681)",
        "has_varargs": false,
        "kind": "function",
        "name": "mish",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.relu",
        "docstring": "Applies the rectified linear unit activation function.\n\nWith default values, this returns the standard ReLU activation:\n`max(x, 0)`, the element-wise maximum of 0 and the input tensor.\n\nModifying default parameters allows you to use non-zero thresholds,\nchange the max value of the activation,\nand to use a non-zero multiple of the input for values below the threshold.\n\nExamples:\n\n>>> x = [-10, -5, 0.0, 5, 10]\n>>> keras.activations.relu(x)\n[ 0.,  0.,  0.,  5., 10.]\n>>> keras.activations.relu(x, negative_slope=0.5)\n[-5. , -2.5,  0. ,  5. , 10. ]\n>>> keras.activations.relu(x, max_value=5.)\n[0., 0., 0., 5., 5.]\n>>> keras.activations.relu(x, threshold=5.)\n[-0., -0.,  0.,  0., 10.]\n\nArgs:\n    x: Input tensor.\n    negative_slope: A `float` that controls the slope\n        for values lower than the threshold.\n    max_value: A `float` that sets the saturation threshold (the largest\n        value the function will return).\n    threshold: A `float` giving the threshold value of the activation\n        function below which values will be damped or set to zero.\n\nReturns:\n    A tensor with the same shape and dtype as input `x`.",
        "has_varargs": false,
        "kind": "function",
        "name": "relu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "negative_slope"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "max_value"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "threshold"
          }
        ]
      },
      {
        "api_path": "keras.activations.relu6",
        "docstring": "Relu6 activation function.\n\nIt's the ReLU function, but truncated to a maximum value of 6.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "relu6",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.selu",
        "docstring": "Scaled Exponential Linear Unit (SELU).\n\nThe Scaled Exponential Linear Unit (SELU) activation function is defined as:\n\n- `scale * x` if `x > 0`\n- `scale * alpha * (exp(x) - 1)` if `x < 0`\n\nwhere `alpha` and `scale` are pre-defined constants\n(`alpha=1.67326324` and `scale=1.05070098`).\n\nBasically, the SELU activation function multiplies `scale` (> 1) with the\noutput of the `keras.activations.elu` function to ensure a slope larger\nthan one for positive inputs.\n\nThe values of `alpha` and `scale` are\nchosen so that the mean and variance of the inputs are preserved\nbetween two consecutive layers as long as the weights are initialized\ncorrectly (see `keras.initializers.LecunNormal` initializer)\nand the number of input units is \"large enough\"\n(see reference paper for more information).\n\nArgs:\n    x: Input tensor.\n\nNotes:\n\n- To be used together with the\n    `keras.initializers.LecunNormal` initializer.\n- To be used together with the dropout variant\n    `keras.layers.AlphaDropout` (rather than regular dropout).\n\nReference:\n\n- [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)",
        "has_varargs": false,
        "kind": "function",
        "name": "selu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.serialize",
        "docstring": null,
        "has_varargs": false,
        "kind": "function",
        "name": "serialize",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          }
        ]
      },
      {
        "api_path": "keras.activations.sigmoid",
        "docstring": "Sigmoid activation function.\n\nIt is defined as: `sigmoid(x) = 1 / (1 + exp(-x))`.\n\nFor small values (<-5),\n`sigmoid` returns a value close to zero, and for large values (>5)\nthe result of the function gets close to 1.\n\nSigmoid is equivalent to a 2-element softmax, where the second element is\nassumed to be zero. The sigmoid function always returns a value between\n0 and 1.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "sigmoid",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.silu",
        "docstring": "Swish (or Silu) activation function.\n\nIt is defined as: `swish(x) = x * sigmoid(x)`.\n\nThe Swish (or Silu) activation function is a smooth,\nnon-monotonic function that is unbounded above and\nbounded below.\n\nArgs:\n    x: Input tensor.\n\nReference:\n\n- [Ramachandran et al., 2017](https://arxiv.org/abs/1710.05941)",
        "has_varargs": false,
        "kind": "function",
        "name": "silu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.swish",
        "docstring": "Swish (or Silu) activation function.\n\nIt is defined as: `swish(x) = x * sigmoid(x)`.\n\nThe Swish (or Silu) activation function is a smooth,\nnon-monotonic function that is unbounded above and\nbounded below.\n\nArgs:\n    x: Input tensor.\n\nReference:\n\n- [Ramachandran et al., 2017](https://arxiv.org/abs/1710.05941)",
        "has_varargs": false,
        "kind": "function",
        "name": "silu",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.soft_shrink",
        "docstring": "Soft Shrink activation function.\n\nIt is defined as:\n\n`soft_shrink(x) = x - threshold` if `x > threshold`,\n`soft_shrink(x) = x + threshold` if `x < -threshold`,\n`soft_shrink(x) = 0` otherwise.\n\nArgs:\n    x: Input tensor.\n    threshold: Threshold value. Defaults to 0.5.",
        "has_varargs": false,
        "kind": "function",
        "name": "soft_shrink",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "0.5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "threshold"
          }
        ]
      },
      {
        "api_path": "keras.activations.softmax",
        "docstring": "Softmax converts a vector of values to a probability distribution.\n\nThe elements of the output vector are in range `[0, 1]` and sum to 1.\n\nEach input vector is handled independently.\nThe `axis` argument sets which axis of the input the function\nis applied along.\n\nSoftmax is often used as the activation for the last\nlayer of a classification network because the result could be interpreted as\na probability distribution.\n\nThe softmax of each vector x is computed as\n`exp(x) / sum(exp(x))`.\n\nThe input values in are the log-odds of the resulting probability.\n\nArgs:\n    x: Input tensor.\n    axis: Integer, axis along which the softmax is applied.",
        "has_varargs": false,
        "kind": "function",
        "name": "softmax",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          }
        ]
      },
      {
        "api_path": "keras.activations.softplus",
        "docstring": "Softplus activation function.\n\nIt is defined as: `softplus(x) = log(exp(x) + 1)`.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "softplus",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.softsign",
        "docstring": "Softsign activation function.\n\nSoftsign is defined as: `softsign(x) = x / (abs(x) + 1)`.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "softsign",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.sparse_plus",
        "docstring": "SparsePlus activation function.\n\nSparsePlus is defined as:\n\n`sparse_plus(x) = 0` for `x <= -1`.\n`sparse_plus(x) = (1/4) * (x + 1)^2` for `-1 < x < 1`.\n`sparse_plus(x) = x` for `x >= 1`.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "sparse_plus",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.sparse_sigmoid",
        "docstring": "Sparse sigmoid activation function.\n\nIt is defined as\n\n`f(x) = 0` for `x <= -1`,\n`f(x) = 0.5 * (x + 1)` for `-1 < x < 1`,\n`f(x) = 1` for `x >= 1`.\n\nArgs:\n    x: Input tensor.\n\nReference:\n\n- [M. Blondel, A. F. T. Martins, V. Niculae, 2019](https://arxiv.org/pdf/1901.02324)",
        "has_varargs": false,
        "kind": "function",
        "name": "sparse_sigmoid",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.sparsemax",
        "docstring": "Sparsemax activation function.\n\nFor each batch `i`, and class `j`,\nsparsemax activation function is defined as:\n\n`sparsemax(x)[i, j] = max(x[i, j] - \u03c4(x[i, :]), 0).`\n\nArgs:\n    x: Input tensor.\n    axis: `int`, axis along which the sparsemax operation is applied.\n\nReturns:\n    A tensor, output of sparsemax transformation. Has the same type and\n    shape as `x`.\n\nReference:\n\n- [Martins et.al., 2016](https://arxiv.org/abs/1602.02068)",
        "has_varargs": false,
        "kind": "function",
        "name": "sparsemax",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          }
        ]
      },
      {
        "api_path": "keras.activations.squareplus",
        "docstring": "Squareplus activation function.\n\nThe Squareplus activation function is defined as:\n\n`f(x) = (x + sqrt(x^2 + b)) / 2`\n\nWhere `b` is a smoothness parameter.\n\nArgs:\n    x: Input tensor.\n    b: Smoothness parameter. Defaults to 4.\n\nReference:\n\n- [Ramachandran et al., 2021](https://arxiv.org/abs/2112.11687)",
        "has_varargs": false,
        "kind": "function",
        "name": "squareplus",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": "4",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "b"
          }
        ]
      },
      {
        "api_path": "keras.activations.tanh",
        "docstring": "Hyperbolic tangent activation function.\n\nIt is defined as:\n`tanh(x) = sinh(x) / cosh(x)`, i.e.\n`tanh(x) = ((exp(x) - exp(-x)) / (exp(x) + exp(-x)))`.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "tanh",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.tanh_shrink",
        "docstring": "Tanh shrink activation function.\n\nIt is defined as:\n\n`f(x) = x - tanh(x)`.\n\nArgs:\n    x: Input tensor.",
        "has_varargs": false,
        "kind": "function",
        "name": "tanh_shrink",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          }
        ]
      },
      {
        "api_path": "keras.activations.threshold",
        "docstring": "Threshold activation function.\n\nIt is defined as:\n\n`threshold(x) = x` if `x > threshold`,\n`threshold(x) = default_value` otherwise.\n\nArgs:\n    x: Input tensor.\n    threshold: The value that decides when to retain or replace x.\n    default_value: Value to assign when `x <= threshold`.",
        "has_varargs": false,
        "kind": "function",
        "name": "threshold",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "threshold"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "default_value"
          }
        ]
      }
    ],
    "layer": [
      {
        "api_path": "keras.layers.Activation",
        "docstring": "Applies an activation function to an output.\n\nArgs:\n    activation: Activation function. It could be a callable, or the name of\n        an activation from the `keras.activations` namespace.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.\n\nExample:\n\n>>> layer = keras.layers.Activation('relu')\n>>> layer(np.array([-3.0, -1.0, 0.0, 2.0]))\n[0.0, 0.0, 0.0, 2.0]\n>>> layer = keras.layers.Activation(keras.activations.relu)\n>>> layer(np.array([-3.0, -1.0, 0.0, 2.0]))\n[0.0, 0.0, 0.0, 2.0]",
        "has_varargs": false,
        "kind": "class",
        "name": "Activation",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ActivityRegularization",
        "docstring": "Layer that applies an update to the cost function based input activity.\n\nArgs:\n    l1: L1 regularization factor (positive float).\n    l2: L2 regularization factor (positive float).\n\nInput shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\nOutput shape:\n    Same shape as input.",
        "has_varargs": false,
        "kind": "class",
        "name": "ActivityRegularization",
        "params": [
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "l1"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "l2"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AdaptiveAveragePooling1D",
        "docstring": "Adaptive average pooling operation for 1D temporal or spatial data.\n\nThis layer applies an adaptive average pooling operation, which pools the\ninput such that the output has a target length specified by `output_size`,\nregardless of the input length. The kernel size and stride are automatically\ncomputed to achieve the target output size.\n\nArgs:\n    output_size: Integer specifying the target output length.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, length, channels)`.\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, length)`.\n        Defaults to the value found in your Keras config file at\n        `~/.keras/keras.json`. If never set, `\"channels_last\"` is used.\n\nInput shape:\n    - If `data_format=\"channels_last\"`: 3D tensor\n        `(batch_size, length, channels)`\n    - If `data_format=\"channels_first\"`: 3D tensor\n        `(batch_size, channels, length)`\n\nOutput shape:\n    - If `data_format=\"channels_last\"`:\n        `(batch_size, output_length, channels)`\n    - If `data_format=\"channels_first\"`:\n        `(batch_size, channels, output_length)`\n\nExamples:\n    >>> import numpy as np\n    >>> input_seq = np.random.rand(1, 64, 3)\n    >>> layer = AdaptiveAveragePooling1D(output_size=32)\n    >>> output_seq = layer(input_seq)\n    >>> output_seq.shape\n    (1, 32, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "AdaptiveAveragePooling1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AdaptiveAveragePooling2D",
        "docstring": "Adaptive average pooling operation for 2D spatial data.\n\nThis layer applies an adaptive average pooling operation, which pools the\ninput such that the output has a target spatial size specified by\n`output_size`, regardless of the input spatial size. The kernel size\nand stride are automatically computed to achieve the target output size.\n\nArgs:\n    output_size: Integer or tuple of 2 integers specifying the\n        target output size.\n        If an integer, the same value is used for both height and width.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, height, width, channels)`.\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n        Defaults to the value found in your Keras config file at\n        `~/.keras/keras.json`. If never set, `\"channels_last\"` is used.\n\nInput shape:\n    - If `data_format=\"channels_last\"`: 4D tensor\n        `(batch_size, height, width, channels)`\n    - If `data_format=\"channels_first\"`: 4D tensor\n        `(batch_size, channels, height, width)`\n\nOutput shape:\n    - If `data_format=\"channels_last\"`:\n        `(batch_size, output_height, output_width, channels)`\n    - If `data_format=\"channels_first\"`:\n        `(batch_size, channels, output_height, output_width)`\n\nExamples:\n    >>> import numpy as np\n    >>> input_img = np.random.rand(1, 64, 64, 3)\n    >>> layer = AdaptiveAveragePooling2D(output_size=32)\n    >>> output_img = layer(input_img)\n    >>> output_img.shape\n    (1, 32, 32, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "AdaptiveAveragePooling2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AdaptiveAveragePooling3D",
        "docstring": "Adaptive average pooling operation for 3D volumetric data.\n\nThis layer applies an adaptive average pooling operation, which pools the\ninput such that the output has a target spatial size specified by\n`output_size`, regardless of the input spatial size. The kernel size\nand stride are automatically computed to achieve the target output size.\n\nArgs:\n    output_size: Integer or tuple of 3 integers specifying the\n        target output size.\n        If an integer, the same value is used for depth, height, and width.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, depth, height, width, channels)`.\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, depth, height, width)`.\n        Defaults to the value found in your Keras config file at\n        `~/.keras/keras.json`. If never set, `\"channels_last\"` is used.\n\nInput shape:\n    - If `data_format=\"channels_last\"`: 5D tensor\n        `(batch_size, depth, height, width, channels)`\n    - If `data_format=\"channels_first\"`: 5D tensor\n        `(batch_size, channels, depth, height, width)`\n\nOutput shape:\n    - If `data_format=\"channels_last\"`:\n        `(batch_size, output_depth, output_height, output_width, channels)`\n    - If `data_format=\"channels_first\"`:\n        `(batch_size, channels, output_depth, output_height, output_width)`\n\nExamples:\n    >>> import numpy as np\n    >>> input_vol = np.random.rand(1, 32, 32, 32, 3)\n    >>> layer = AdaptiveAveragePooling3D(output_size=16)\n    >>> output_vol = layer(input_vol)\n    >>> output_vol.shape\n    (1, 16, 16, 16, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "AdaptiveAveragePooling3D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AdaptiveMaxPooling1D",
        "docstring": "Adaptive max pooling operation for 1D temporal or spatial data.\n\nThis layer applies an adaptive max pooling operation, which pools the\ninput such that the output has a target length specified by `output_size`,\nregardless of the input length. The kernel size and stride are automatically\ncomputed to achieve the target output size.\n\nArgs:\n    output_size: Integer specifying the target output length.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, length, channels)`.\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, length)`.\n        Defaults to the value found in your Keras config file at\n        `~/.keras/keras.json`. If never set, `\"channels_last\"` is used.\n\nInput shape:\n    - If `data_format=\"channels_last\"`: 3D tensor\n        `(batch_size, length, channels)`\n    - If `data_format=\"channels_first\"`: 3D tensor\n        `(batch_size, channels, length)`\n\nOutput shape:\n    - If `data_format=\"channels_last\"`:\n        `(batch_size, output_length, channels)`\n    - If `data_format=\"channels_first\"`:\n        `(batch_size, channels, output_length)`\n\nExamples:\n    >>> import numpy as np\n    >>> input_seq = np.random.rand(1, 64, 3)\n    >>> layer = AdaptiveMaxPooling1D(output_size=32)\n    >>> output_seq = layer(input_seq)\n    >>> output_seq.shape\n    (1, 32, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "AdaptiveMaxPooling1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AdaptiveMaxPooling2D",
        "docstring": "Adaptive max pooling operation for 2D spatial data.\n\nThis layer applies an adaptive max pooling operation, which pools the\ninput such that the output has a target spatial size specified by\n`output_size`, regardless of the input spatial size. The kernel size\nand stride are automatically computed to achieve the target output size.\n\nArgs:\n    output_size: Integer or tuple of 2 integers specifying the\n        target output size.\n        If an integer, the same value is used for both height and width.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, height, width, channels)`.\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n        Defaults to the value found in your Keras config file at\n        `~/.keras/keras.json`. If never set, `\"channels_last\"` is used.\n\nInput shape:\n    - If `data_format=\"channels_last\"`: 4D tensor\n        `(batch_size, height, width, channels)`\n    - If `data_format=\"channels_first\"`: 4D tensor\n        `(batch_size, channels, height, width)`\n\nOutput shape:\n    - If `data_format=\"channels_last\"`:\n        `(batch_size, output_height, output_width, channels)`\n    - If `data_format=\"channels_first\"`:\n        `(batch_size, channels, output_height, output_width)`\n\nExamples:\n    >>> import numpy as np\n    >>> input_img = np.random.rand(1, 64, 64, 3)\n    >>> layer = AdaptiveMaxPooling2D(output_size=32)\n    >>> output_img = layer(input_img)\n    >>> output_img.shape\n    (1, 32, 32, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "AdaptiveMaxPooling2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AdaptiveMaxPooling3D",
        "docstring": "Adaptive max pooling operation for 3D volumetric data.\n\nThis layer applies an adaptive max pooling operation, which pools the\ninput such that the output has a target spatial size specified by\n`output_size`, regardless of the input spatial size. The kernel size\nand stride are automatically computed to achieve the target output size.\n\nArgs:\n    output_size: Integer or tuple of 3 integers specifying the\n        target output size.\n        If an integer, the same value is used for depth, height, and width.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, depth, height, width, channels)`.\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, depth, height, width)`.\n        Defaults to the value found in your Keras config file at\n        `~/.keras/keras.json`. If never set, `\"channels_last\"` is used.\n\nInput shape:\n    - If `data_format=\"channels_last\"`: 5D tensor\n        `(batch_size, depth, height, width, channels)`\n    - If `data_format=\"channels_first\"`: 5D tensor\n        `(batch_size, channels, depth, height, width)`\n\nOutput shape:\n    - If `data_format=\"channels_last\"`:\n        `(batch_size, output_depth, output_height, output_width, channels)`\n    - If `data_format=\"channels_first\"`:\n        `(batch_size, channels, output_depth, output_height, output_width)`\n\nExamples:\n    >>> import numpy as np\n    >>> input_vol = np.random.rand(1, 32, 32, 32, 3)\n    >>> layer = AdaptiveMaxPooling3D(output_size=16)\n    >>> output_vol = layer(input_vol)\n    >>> output_vol.shape\n    (1, 16, 16, 16, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "AdaptiveMaxPooling3D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Add",
        "docstring": "Performs elementwise addition operation.\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\n\nExamples:\n\n>>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Add()([x1, x2])\n\nUsage in a Keras model:\n\n>>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `added = keras.layers.add([x1, x2])`\n>>> added = keras.layers.Add()([x1, x2])\n>>> out = keras.layers.Dense(4)(added)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)",
        "has_varargs": false,
        "kind": "class",
        "name": "Add",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AdditiveAttention",
        "docstring": "Additive attention layer, a.k.a. Bahdanau-style attention.\n\nInputs are a list with 2 or 3 elements:\n1. A `query` tensor of shape `(batch_size, Tq, dim)`.\n2. A `value` tensor of shape `(batch_size, Tv, dim)`.\n3. A optional `key` tensor of shape `(batch_size, Tv, dim)`. If none\n    supplied, `value` will be used as `key`.\n\nThe calculation follows the steps:\n1. Calculate attention scores using `query` and `key` with shape\n    `(batch_size, Tq, Tv)` as a non-linear sum\n    `scores = reduce_sum(tanh(query + key), axis=-1)`.\n2. Use scores to calculate a softmax distribution with shape\n    `(batch_size, Tq, Tv)`.\n3. Use the softmax distribution to create a linear combination of `value`\n    with shape `(batch_size, Tq, dim)`.\n\nArgs:\n    use_scale: If `True`, will create a scalar variable to scale the\n        attention scores.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        attention scores. Defaults to `0.0`.\n\nCall arguments:\n    inputs: List of the following tensors:\n        - `query`: Query tensor of shape `(batch_size, Tq, dim)`.\n        - `value`: Value tensor of shape `(batch_size, Tv, dim)`.\n        - `key`: Optional key tensor of shape `(batch_size, Tv, dim)`. If\n            not given, will use `value` for both `key` and `value`, which is\n            the most common case.\n    mask: List of the following tensors:\n        - `query_mask`: A boolean mask tensor of shape `(batch_size, Tq)`.\n            If given, the output will be zero at the positions where\n            `mask==False`.\n        - `value_mask`: A boolean mask tensor of shape `(batch_size, Tv)`.\n            If given, will apply the mask such that values at positions\n             where `mask==False` do not contribute to the result.\n    return_attention_scores: bool, it `True`, returns the attention scores\n        (after masking and softmax) as an additional output argument.\n    training: Python boolean indicating whether the layer should behave in\n        training mode (adding dropout) or in inference mode (no dropout).\n    use_causal_mask: Boolean. Set to `True` for decoder self-attention. Adds\n        a mask such that position `i` cannot attend to positions `j > i`.\n        This prevents the flow of information from the future towards the\n        past. Defaults to `False`.\n\nOutput:\n    Attention outputs of shape `(batch_size, Tq, dim)`.\n    (Optional) Attention scores after masking and softmax with shape\n        `(batch_size, Tq, Tv)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "AdditiveAttention",
        "params": [
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_scale"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AlphaDropout",
        "docstring": "Applies Alpha Dropout to the input.\n\nAlpha Dropout is a `Dropout` that keeps mean and variance of inputs\nto their original values, in order to ensure the self-normalizing property\neven after this dropout.\nAlpha Dropout fits well to Scaled Exponential Linear Units (SELU) by\nrandomly setting activations to the negative saturation value.\n\nArgs:\n    rate: Float between 0 and 1. The multiplicative noise will have\n        standard deviation `sqrt(rate / (1 - rate))`.\n    noise_shape: 1D integer tensor representing the shape of the\n        binary alpha dropout mask that will be multiplied with the input.\n        For instance, if your inputs have shape\n        `(batch_size, timesteps, features)` and\n        you want the alpha dropout mask to be the same for all timesteps,\n        you can use `noise_shape=(batch_size, 1, features)`.\n    seed: A Python integer to use as random seed.\n\nCall arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n        training mode (adding alpha dropout) or in inference mode\n        (doing nothing).",
        "has_varargs": false,
        "kind": "class",
        "name": "AlphaDropout",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "noise_shape"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Attention",
        "docstring": "Dot-product attention layer, a.k.a. Luong-style attention.\n\nInputs are a list with 2 or 3 elements:\n1. A `query` tensor of shape `(batch_size, Tq, dim)`.\n2. A `value` tensor of shape `(batch_size, Tv, dim)`.\n3. A optional `key` tensor of shape `(batch_size, Tv, dim)`. If none\n    supplied, `value` will be used as a `key`.\n\nThe calculation follows the steps:\n1. Calculate attention scores using `query` and `key` with shape\n    `(batch_size, Tq, Tv)`.\n2. Use scores to calculate a softmax distribution with shape\n    `(batch_size, Tq, Tv)`.\n3. Use the softmax distribution to create a linear combination of `value`\n    with shape `(batch_size, Tq, dim)`.\n\nArgs:\n    use_scale: If `True`, will create a scalar variable to scale the\n        attention scores.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        attention scores. Defaults to `0.0`.\n    seed: A Python integer to use as random seed in case of `dropout`.\n    score_mode: Function to use to compute attention scores, one of\n        `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the\n        query and key vectors. `\"concat\"` refers to the hyperbolic tangent\n        of the concatenation of the `query` and `key` vectors.\n\nCall arguments:\n    inputs: List of the following tensors:\n        - `query`: Query tensor of shape `(batch_size, Tq, dim)`.\n        - `value`: Value tensor of shape `(batch_size, Tv, dim)`.\n        - `key`: Optional key tensor of shape `(batch_size, Tv, dim)`. If\n            not given, will use `value` for both `key` and `value`, which is\n            the most common case.\n    mask: List of the following tensors:\n        - `query_mask`: A boolean mask tensor of shape `(batch_size, Tq)`.\n            If given, the output will be zero at the positions where\n            `mask==False`.\n        - `value_mask`: A boolean mask tensor of shape `(batch_size, Tv)`.\n            If given, will apply the mask such that values at positions\n             where `mask==False` do not contribute to the result.\n    return_attention_scores: bool, it `True`, returns the attention scores\n        (after masking and softmax) as an additional output argument.\n    training: Python boolean indicating whether the layer should behave in\n        training mode (adding dropout) or in inference mode (no dropout).\n    use_causal_mask: Boolean. Set to `True` for decoder self-attention. Adds\n        a mask such that position `i` cannot attend to positions `j > i`.\n        This prevents the flow of information from the future towards the\n        past. Defaults to `False`.\n\nOutput:\n    Attention outputs of shape `(batch_size, Tq, dim)`.\n    (Optional) Attention scores after masking and softmax with shape\n        `(batch_size, Tq, Tv)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "Attention",
        "params": [
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_scale"
          },
          {
            "annotation": null,
            "default": "dot",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "score_mode"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AugMix",
        "docstring": "Performs the AugMix data augmentation technique.\n\nAugMix aims to produce images with variety while preserving the image\nsemantics and local statistics. During the augmentation process,\nthe same augmentation is applied across all images in the batch\nin num_chains different ways, with each chain consisting of\nchain_depth augmentations.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nReferences:\n    - [AugMix paper](https://arxiv.org/pdf/1912.02781)\n    - [Official Code](https://github.com/google-research/augmix)\n\nArgs:\n    value_range: the range of values the incoming images will have.\n        Represented as a two number tuple written (low, high).\n        This is typically either `(0, 1)` or `(0, 255)` depending\n        on how your preprocessing pipeline is set up.\n    num_chains: an integer representing the number of different chains to\n        be mixed, defaults to 3.\n    chain_depth: an integer representing the maximum number of\n        transformations to be applied in each chain. The actual number\n        of transformations in each chain will be sampled randomly\n        from the range `[0, `chain_depth`]`. Defaults to 3.\n    factor: The strength of the augmentation as a normalized value\n        between 0 and 1. Default is 0.3.\n    alpha: a float value used as the probability coefficients for the\n        Beta and Dirichlet distributions, defaults to 1.0.\n    all_ops: Use all operations (including random_brightness,\n        random_color_degeneration, random_contrast and random_sharpness).\n        Default is True.\n    interpolation: The interpolation method to use for resizing operations.\n        Options include `\"nearest\"`, `\"bilinear\"`. Default is `\"bilinear\"`.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "AugMix",
        "params": [
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "3",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_chains"
          },
          {
            "annotation": null,
            "default": "3",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "chain_depth"
          },
          {
            "annotation": null,
            "default": "0.3",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "all_ops"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AutoContrast",
        "docstring": "Performs the auto-contrast operation on an image.\n\nAuto contrast stretches the values of an image across the entire available\n`value_range`. This makes differences between pixels more obvious. An\nexample of this is if an image only has values `[0, 1]` out of the range\n`[0, 255]`, auto contrast will change the `1` values to be `255`.\n\nThis layer is active at both training and inference time.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    value_range: Range of values the incoming images will have.\n        Represented as a two number tuple written `(low, high)`.\n        This is typically either `(0, 1)` or `(0, 255)` depending\n        on how your preprocessing pipeline is set up.\n        Defaults to `(0, 255)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "AutoContrast",
        "params": [
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Average",
        "docstring": "Averages a list of inputs element-wise..\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\n\nExamples:\n\n>>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Average()([x1, x2])\n\nUsage in a Keras model:\n\n>>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `y = keras.layers.average([x1, x2])`\n>>> y = keras.layers.Average()([x1, x2])\n>>> out = keras.layers.Dense(4)(y)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)",
        "has_varargs": false,
        "kind": "class",
        "name": "Average",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AveragePooling1D",
        "docstring": "Average pooling for temporal data.\n\nDownsamples the input representation by taking the average value over the\nwindow defined by `pool_size`. The window is shifted by `strides`.  The\nresulting output when using \"valid\" padding option has a shape of:\n`output_shape = (input_shape - pool_size + 1) / strides)`\n\nThe resulting output shape when using the \"same\" padding option is:\n`output_shape = input_shape / strides`\n\nArgs:\n    pool_size: int, size of the max pooling window.\n    strides: int or None. Specifies how much the pooling window moves\n        for each pooling step. If None, it will default to `pool_size`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, steps)`.\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, downsampled_steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, downsampled_steps)`.\n\nExamples:\n\n`strides=1` and `padding=\"valid\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=1, padding=\"valid\")\n>>> avg_pool_1d(x)\n\n`strides=2` and `padding=\"valid\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=2, padding=\"valid\")\n>>> avg_pool_1d(x)\n\n`strides=1` and `padding=\"same\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=1, padding=\"same\")\n>>> avg_pool_1d(x)",
        "has_varargs": false,
        "kind": "class",
        "name": "AveragePooling1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AvgPool1D",
        "docstring": "Average pooling for temporal data.\n\nDownsamples the input representation by taking the average value over the\nwindow defined by `pool_size`. The window is shifted by `strides`.  The\nresulting output when using \"valid\" padding option has a shape of:\n`output_shape = (input_shape - pool_size + 1) / strides)`\n\nThe resulting output shape when using the \"same\" padding option is:\n`output_shape = input_shape / strides`\n\nArgs:\n    pool_size: int, size of the max pooling window.\n    strides: int or None. Specifies how much the pooling window moves\n        for each pooling step. If None, it will default to `pool_size`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, steps)`.\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, downsampled_steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, downsampled_steps)`.\n\nExamples:\n\n`strides=1` and `padding=\"valid\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=1, padding=\"valid\")\n>>> avg_pool_1d(x)\n\n`strides=2` and `padding=\"valid\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=2, padding=\"valid\")\n>>> avg_pool_1d(x)\n\n`strides=1` and `padding=\"same\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=1, padding=\"same\")\n>>> avg_pool_1d(x)",
        "has_varargs": false,
        "kind": "class",
        "name": "AveragePooling1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AveragePooling2D",
        "docstring": "Average pooling operation for 2D spatial data.\n\nDownsamples the input along its spatial dimensions (height and width)\nby taking the average value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.\n\nThe resulting output when using the `\"valid\"` padding option has a spatial\nshape (number of rows or columns) of:\n`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n(when `input_shape >= pool_size`)\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = input_shape`\n\nArgs:\n    pool_size: int or tuple of 2 integers, factors by which to downscale\n        (dim1, dim2). If only one integer is specified, the same\n        window length will be used for all dimensions.\n    strides: int or tuple of 2 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape `(batch_size, height, width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape `(batch_size, channels, height, width)`.\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape\n    `(batch_size, pooled_height, pooled_width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape\n    `(batch_size, channels, pooled_height, pooled_width)`.\n\nExamples:\n\n`strides=(1, 1)` and `padding=\"valid\"`:\n\n>>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"valid\")\n>>> avg_pool_2d(x)\n\n`strides=(2, 2)` and `padding=\"valid\"`:\n\n>>> x = np.array([[1., 2., 3., 4.],\n...              [5., 6., 7., 8.],\n...              [9., 10., 11., 12.]])\n>>> x = np.reshape(x, [1, 3, 4, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(2, 2), padding=\"valid\")\n>>> avg_pool_2d(x)\n\n`stride=(1, 1)` and `padding=\"same\"`:\n\n>>> x = np.array([[1., 2., 3.],\n...                  [4., 5., 6.],\n...                  [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"same\")\n>>> avg_pool_2d(x)",
        "has_varargs": false,
        "kind": "class",
        "name": "AveragePooling2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AvgPool2D",
        "docstring": "Average pooling operation for 2D spatial data.\n\nDownsamples the input along its spatial dimensions (height and width)\nby taking the average value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.\n\nThe resulting output when using the `\"valid\"` padding option has a spatial\nshape (number of rows or columns) of:\n`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n(when `input_shape >= pool_size`)\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = input_shape`\n\nArgs:\n    pool_size: int or tuple of 2 integers, factors by which to downscale\n        (dim1, dim2). If only one integer is specified, the same\n        window length will be used for all dimensions.\n    strides: int or tuple of 2 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape `(batch_size, height, width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape `(batch_size, channels, height, width)`.\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape\n    `(batch_size, pooled_height, pooled_width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape\n    `(batch_size, channels, pooled_height, pooled_width)`.\n\nExamples:\n\n`strides=(1, 1)` and `padding=\"valid\"`:\n\n>>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"valid\")\n>>> avg_pool_2d(x)\n\n`strides=(2, 2)` and `padding=\"valid\"`:\n\n>>> x = np.array([[1., 2., 3., 4.],\n...              [5., 6., 7., 8.],\n...              [9., 10., 11., 12.]])\n>>> x = np.reshape(x, [1, 3, 4, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(2, 2), padding=\"valid\")\n>>> avg_pool_2d(x)\n\n`stride=(1, 1)` and `padding=\"same\"`:\n\n>>> x = np.array([[1., 2., 3.],\n...                  [4., 5., 6.],\n...                  [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"same\")\n>>> avg_pool_2d(x)",
        "has_varargs": false,
        "kind": "class",
        "name": "AveragePooling2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AveragePooling3D",
        "docstring": "Average pooling operation for 3D data (spatial or spatio-temporal).\n\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the average value over an input window (of size defined by\n`pool_size`) for each channel of the input. The window is shifted by\n`strides` along each dimension.\n\nArgs:\n    pool_size: int or tuple of 3 integers, factors by which to downscale\n        (dim1, dim2, dim3). If only one integer is specified, the same\n        window length will be used for all dimensions.\n    strides: int or tuple of 3 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n\nExample:\n\n```python\ndepth = 30\nheight = 30\nwidth = 30\nchannels = 3\n\ninputs = keras.layers.Input(shape=(depth, height, width, channels))\nlayer = keras.layers.AveragePooling3D(pool_size=3)\noutputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "AveragePooling3D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.AvgPool3D",
        "docstring": "Average pooling operation for 3D data (spatial or spatio-temporal).\n\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the average value over an input window (of size defined by\n`pool_size`) for each channel of the input. The window is shifted by\n`strides` along each dimension.\n\nArgs:\n    pool_size: int or tuple of 3 integers, factors by which to downscale\n        (dim1, dim2, dim3). If only one integer is specified, the same\n        window length will be used for all dimensions.\n    strides: int or tuple of 3 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n\nExample:\n\n```python\ndepth = 30\nheight = 30\nwidth = 30\nchannels = 3\n\ninputs = keras.layers.Input(shape=(depth, height, width, channels))\nlayer = keras.layers.AveragePooling3D(pool_size=3)\noutputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "AveragePooling3D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.BatchNormalization",
        "docstring": "Layer that normalizes its inputs.\n\nBatch normalization applies a transformation that maintains the mean output\nclose to 0 and the output standard deviation close to 1.\n\nImportantly, batch normalization works differently during training and\nduring inference.\n\n**During training** (i.e. when using `fit()` or when calling the layer/model\nwith the argument `training=True`), the layer normalizes its output using\nthe mean and standard deviation of the current batch of inputs. That is to\nsay, for each channel being normalized, the layer returns\n`gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta`, where:\n\n- `epsilon` is small constant (configurable as part of the constructor\narguments)\n- `gamma` is a learned scaling factor (initialized as 1), which\ncan be disabled by passing `scale=False` to the constructor.\n- `beta` is a learned offset factor (initialized as 0), which\ncan be disabled by passing `center=False` to the constructor.\n\n**During inference** (i.e. when using `evaluate()` or `predict()` or when\ncalling the layer/model with the argument `training=False` (which is the\ndefault), the layer normalizes its output using a moving average of the\nmean and standard deviation of the batches it has seen during training. That\nis to say, it returns\n`gamma * (batch - self.moving_mean) / sqrt(self.moving_var+epsilon) + beta`.\n\n`self.moving_mean` and `self.moving_var` are non-trainable variables that\nare updated each time the layer in called in training mode, as such:\n\n- `moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)`\n- `moving_var = moving_var * momentum + var(batch) * (1 - momentum)`\n\nAs such, the layer will only normalize its inputs during inference\n*after having been trained on data that has similar statistics as the\ninference data*.\n\nArgs:\n    axis: Integer, the axis that should be normalized\n        (typically the features axis). For instance, after a `Conv2D` layer\n        with `data_format=\"channels_first\"`, use `axis=1`.\n    momentum: Momentum for the moving average.\n    epsilon: Small float added to variance to avoid dividing by zero.\n    center: If `True`, add offset of `beta` to normalized tensor.\n        If `False`, `beta` is ignored.\n    scale: If `True`, multiply by `gamma`. If `False`, `gamma` is not used.\n        When the next layer is linear this can be disabled\n        since the scaling will be done by the next layer.\n    beta_initializer: Initializer for the beta weight.\n    gamma_initializer: Initializer for the gamma weight.\n    moving_mean_initializer: Initializer for the moving mean.\n    moving_variance_initializer: Initializer for the moving variance.\n    beta_regularizer: Optional regularizer for the beta weight.\n    gamma_regularizer: Optional regularizer for the gamma weight.\n    beta_constraint: Optional constraint for the beta weight.\n    gamma_constraint: Optional constraint for the gamma weight.\n    synchronized: Only applicable with the TensorFlow backend.\n        If `True`, synchronizes the global batch statistics (mean and\n        variance) for the layer across all devices at each training step\n        in a distributed training strategy.\n        If `False`, each replica uses its own local batch statistics.\n    **kwargs: Base layer keyword arguments (e.g. `name` and `dtype`).\n\nCall arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode.\n        - `training=True`: The layer will normalize its inputs using\n        the mean and variance of the current batch of inputs.\n        - `training=False`: The layer will normalize its inputs using\n        the mean and variance of its moving statistics, learned during\n        training.\n    mask: Binary tensor of shape broadcastable to `inputs` tensor, with\n        `True` values indicating the positions for which mean and variance\n        should be computed. Masked elements of the current inputs are not\n        taken into account for mean and variance computation during\n        training. Any prior unmasked element values will be taken into\n        account until their momentum expires.\n\nReference:\n\n- [Ioffe and Szegedy, 2015](https://arxiv.org/abs/1502.03167).\n\n**About setting `layer.trainable = False` on a `BatchNormalization` layer:**\n\nThe meaning of setting `layer.trainable = False` is to freeze the layer,\ni.e. its internal state will not change during training:\nits trainable weights will not be updated\nduring `fit()` or `train_on_batch()`, and its state updates will not be run.\n\nUsually, this does not necessarily mean that the layer is run in inference\nmode (which is normally controlled by the `training` argument that can\nbe passed when calling a layer). \"Frozen state\" and \"inference mode\"\nare two separate concepts.\n\nHowever, in the case of the `BatchNormalization` layer, **setting\n`trainable = False` on the layer means that the layer will be\nsubsequently run in inference mode** (meaning that it will use\nthe moving mean and the moving variance to normalize the current batch,\nrather than using the mean and variance of the current batch).\n\nNote that:\n\n- Setting `trainable` on an model containing other layers will recursively\n    set the `trainable` value of all inner layers.\n- If the value of the `trainable` attribute is changed after calling\n    `compile()` on a model, the new value doesn't take effect for this model\n    until `compile()` is called again.",
        "has_varargs": false,
        "kind": "class",
        "name": "BatchNormalization",
        "params": [
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "momentum"
          },
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "center"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "scale"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_initializer"
          },
          {
            "annotation": null,
            "default": "ones",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "moving_mean_initializer"
          },
          {
            "annotation": null,
            "default": "ones",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "moving_variance_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_constraint"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "synchronized"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Bidirectional",
        "docstring": "Bidirectional wrapper for RNNs.\n\nArgs:\n    layer: `keras.layers.RNN` instance, such as\n        `keras.layers.LSTM` or `keras.layers.GRU`.\n        It could also be a `keras.layers.Layer` instance\n        that meets the following criteria:\n        1. Be a sequence-processing layer (accepts 3D+ inputs).\n        2. Have a `go_backwards`, `return_sequences` and `return_state`\n        attribute (with the same semantics as for the `RNN` class).\n        3. Have an `input_spec` attribute.\n        4. Implement serialization via `get_config()` and `from_config()`.\n        Note that the recommended way to create new RNN layers is to write a\n        custom RNN cell and use it with `keras.layers.RNN`, instead of\n        subclassing `keras.layers.Layer` directly.\n        When `return_sequences` is `True`, the output of the masked\n        timestep will be zero regardless of the layer's original\n        `zero_output_for_mask` value.\n    merge_mode: Mode by which outputs of the forward and backward RNNs\n        will be combined. One of `{\"sum\", \"mul\", \"concat\", \"ave\", None}`.\n        If `None`, the outputs will not be combined,\n        they will be returned as a list. Defaults to `\"concat\"`.\n    backward_layer: Optional `keras.layers.RNN`,\n        or `keras.layers.Layer` instance to be used to handle\n        backwards input processing.\n        If `backward_layer` is not provided, the layer instance passed\n        as the `layer` argument will be used to generate the backward layer\n        automatically.\n        Note that the provided `backward_layer` layer should have properties\n        matching those of the `layer` argument, in particular\n        it should have the same values for `stateful`, `return_states`,\n        `return_sequences`, etc. In addition, `backward_layer`\n        and `layer` should have different `go_backwards` argument values.\n        A `ValueError` will be raised if these requirements are not met.\n\nCall arguments:\n    The call arguments for this layer are the same as those of the\n    wrapped RNN layer. Beware that when passing the `initial_state`\n    argument during the call of this layer, the first half in the\n    list of elements in the `initial_state` list will be passed to\n    the forward RNN call and the last half in the list of elements\n    will be passed to the backward RNN call.\n\nNote: instantiating a `Bidirectional` layer from an existing RNN layer\ninstance will not reuse the weights state of the RNN layer instance -- the\n`Bidirectional` layer will have freshly initialized weights.\n\nExamples:\n\n```python\nmodel = Sequential([\n    Input(shape=(5, 10)),\n    Bidirectional(LSTM(10, return_sequences=True),\n    Bidirectional(LSTM(10)),\n    Dense(5, activation=\"softmax\"),\n])\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# With custom backward layer\nforward_layer = LSTM(10, return_sequences=True)\nbackward_layer = LSTM(10, activation='relu', return_sequences=True,\n                      go_backwards=True)\nmodel = Sequential([\n    Input(shape=(5, 10)),\n    Bidirectional(forward_layer, backward_layer=backward_layer),\n    Dense(5, activation=\"softmax\"),\n])\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "Bidirectional",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "layer"
          },
          {
            "annotation": null,
            "default": "concat",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "merge_mode"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weights"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "backward_layer"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.CategoryEncoding",
        "docstring": "A preprocessing layer which encodes integer features.\n\nThis layer provides options for condensing data into a categorical encoding\nwhen the total number of tokens are known in advance. It accepts integer\nvalues as inputs, and it outputs a dense or sparse representation of those\ninputs. For integer inputs where the total number of tokens is not known,\nuse `keras.layers.IntegerLookup` instead.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nExamples:\n\n**One-hot encoding data**\n\n>>> layer = keras.layers.CategoryEncoding(\n...           num_tokens=4, output_mode=\"one_hot\")\n>>> layer([3, 2, 0, 1])\narray([[0., 0., 0., 1.],\n        [0., 0., 1., 0.],\n        [1., 0., 0., 0.],\n        [0., 1., 0., 0.]]>\n\n**Multi-hot encoding data**\n\n>>> layer = keras.layers.CategoryEncoding(\n...           num_tokens=4, output_mode=\"multi_hot\")\n>>> layer([[0, 1], [0, 0], [1, 2], [3, 1]])\narray([[1., 1., 0., 0.],\n        [1., 0., 0., 0.],\n        [0., 1., 1., 0.],\n        [0., 1., 0., 1.]]>\n\n**Using weighted inputs in `\"count\"` mode**\n\n>>> layer = keras.layers.CategoryEncoding(\n...           num_tokens=4, output_mode=\"count\")\n>>> count_weights = np.array([[.1, .2], [.1, .1], [.2, .3], [.4, .2]])\n>>> layer([[0, 1], [0, 0], [1, 2], [3, 1]], count_weights=count_weights)\n  array([[0.1, 0.2, 0. , 0. ],\n         [0.2, 0. , 0. , 0. ],\n         [0. , 0.2, 0.3, 0. ],\n         [0. , 0.2, 0. , 0.4]]>\n\nArgs:\n    num_tokens: The total number of tokens the layer should support. All\n        inputs to the layer must integers in the range `0 <= value <\n        num_tokens`, or an error will be thrown.\n    output_mode: Specification for the output of the layer.\n        Values can be `\"one_hot\"`, `\"multi_hot\"` or `\"count\"`,\n        configuring the layer as follows:\n            - `\"one_hot\"`: Encodes each individual element in the input\n                into an array of `num_tokens` size, containing a 1 at the\n                element index. If the last dimension is size 1, will encode\n                on that dimension. If the last dimension is not size 1,\n                will append a new dimension for the encoded output.\n            - `\"multi_hot\"`: Encodes each sample in the input into a single\n                array of `num_tokens` size, containing a 1 for each\n                vocabulary term present in the sample. Treats the last\n                dimension as the sample dimension, if input shape is\n                `(..., sample_length)`, output shape will be\n                `(..., num_tokens)`.\n            - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a\n                count of the number of times the token at that index\n                appeared in the sample.\n        For all output modes, currently only output up to rank 2 is\n        supported.\n        Defaults to `\"multi_hot\"`.\n    sparse: Whether to return a sparse tensor; for backends that support\n        sparse tensors.\n\nCall arguments:\n    inputs: A 1D or 2D tensor of integer inputs.\n    count_weights: A tensor in the same shape as `inputs` indicating the\n        weight for each sample value when summing up in `count` mode.\n        Not used in `\"multi_hot\"` or `\"one_hot\"` modes.",
        "has_varargs": false,
        "kind": "class",
        "name": "CategoryEncoding",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_tokens"
          },
          {
            "annotation": null,
            "default": "multi_hot",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_mode"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sparse"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.CenterCrop",
        "docstring": "A preprocessing layer which crops images.\n\nThis layers crops the central portion of the images to a target size. If an\nimage is smaller than the target size, it will be resized and cropped\nso as to return the largest possible window in the image that matches\nthe target aspect ratio.\n\nInput pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`).\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format,\n    or `(..., channels, height, width)`, in `\"channels_first\"` format.\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., target_height, target_width, channels)`,\n    or `(..., channels, target_height, target_width)`,\n    in `\"channels_first\"` format.\n\nIf the input height/width is even and the target height/width is odd (or\ninversely), the input image is left-padded by 1 pixel.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    height: Integer, the height of the output shape.\n    width: Integer, the width of the output shape.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "has_varargs": false,
        "kind": "class",
        "name": "CenterCrop",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "height"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "width"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Concatenate",
        "docstring": "Concatenates a list of inputs.\n\nIt takes as input a list of tensors, all of the same shape except\nfor the concatenation axis, and returns a single tensor that is the\nconcatenation of all inputs.\n\nExamples:\n\n>>> x = np.arange(20).reshape(2, 2, 5)\n>>> y = np.arange(20, 30).reshape(2, 1, 5)\n>>> keras.layers.Concatenate(axis=1)([x, y])\n\nUsage in a Keras model:\n\n>>> x1 = keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n>>> x2 = keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n>>> y = keras.layers.Concatenate()([x1, x2])\n\nArgs:\n    axis: Axis along which to concatenate.\n    **kwargs: Standard layer keyword arguments.\n\nReturns:\n    A tensor, the concatenation of the inputs alongside axis `axis`.",
        "has_varargs": false,
        "kind": "class",
        "name": "Concatenate",
        "params": [
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Conv1D",
        "docstring": "1D convolution layer (e.g. temporal convolution).\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If `use_bias` is True, a bias vector is created and added to the\noutputs. Finally, if `activation` is not `None`, it is applied to the\noutputs as well.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, `\"valid\"`, `\"same\"` or `\"causal\"`(case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n        `\"causal\"` results in causal(dilated) convolutions, e.g. `output[t]`\n        does not depend on`input[t+1:]`. Useful when modeling temporal data\n        where the model should not violate the temporal order.\n        See [WaveNet: A Generative Model for Raw Audio, section2.1](\n        https://arxiv.org/abs/1609.03499).\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated convolution.\n    groups: A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n\nReturns:\n    A 3D tensor representing `activation(conv1d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nExample:\n\n>>> # The inputs are 128-length vectors with 10 timesteps, and the\n>>> # batch size is 4.\n>>> x = np.random.rand(4, 10, 128)\n>>> y = keras.layers.Conv1D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "groups"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Convolution1D",
        "docstring": "1D convolution layer (e.g. temporal convolution).\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If `use_bias` is True, a bias vector is created and added to the\noutputs. Finally, if `activation` is not `None`, it is applied to the\noutputs as well.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, `\"valid\"`, `\"same\"` or `\"causal\"`(case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n        `\"causal\"` results in causal(dilated) convolutions, e.g. `output[t]`\n        does not depend on`input[t+1:]`. Useful when modeling temporal data\n        where the model should not violate the temporal order.\n        See [WaveNet: A Generative Model for Raw Audio, section2.1](\n        https://arxiv.org/abs/1609.03499).\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated convolution.\n    groups: A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n\nReturns:\n    A 3D tensor representing `activation(conv1d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nExample:\n\n>>> # The inputs are 128-length vectors with 10 timesteps, and the\n>>> # batch size is 4.\n>>> x = np.random.rand(4, 10, 128)\n>>> y = keras.layers.Conv1D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "groups"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Conv1DTranspose",
        "docstring": "1D transposed convolution layer.\n\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the transpose convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        transposed convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the transposed convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    output_padding: An integer tuple/list of 1 integer specifying the\n        amount of padding along the time dimension of the output tensor.\n        The amount of output padding must be lower than the stride.\n        If set to `None` (default), the output shape is inferred.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: An integer tuple/list of 1 integer, specifying\n        the dilation rate to use for dilated convolution.\n        Currently, specifying a `dilation_rate` value != 1 is\n        incompatible with specifying a stride value != 1.\n        Also dilation rate larger than 1 is not currently supported.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n\nReturns:\n    A 3D tensor representing\n    `activation(conv1d_transpose(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nReferences:\n- [A guide to convolution arithmetic for deep learning](\n    https://arxiv.org/abs/1603.07285v1)\n- [Deconvolutional Networks](\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n\nExample:\n\n>>> x = np.random.rand(4, 10, 128)\n>>> y = keras.layers.Conv1DTranspose(32, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 21, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv1DTranspose",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Convolution1DTranspose",
        "docstring": "1D transposed convolution layer.\n\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the transpose convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        transposed convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the transposed convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    output_padding: An integer tuple/list of 1 integer specifying the\n        amount of padding along the time dimension of the output tensor.\n        The amount of output padding must be lower than the stride.\n        If set to `None` (default), the output shape is inferred.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: An integer tuple/list of 1 integer, specifying\n        the dilation rate to use for dilated convolution.\n        Currently, specifying a `dilation_rate` value != 1 is\n        incompatible with specifying a stride value != 1.\n        Also dilation rate larger than 1 is not currently supported.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n\nReturns:\n    A 3D tensor representing\n    `activation(conv1d_transpose(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nReferences:\n- [A guide to convolution arithmetic for deep learning](\n    https://arxiv.org/abs/1603.07285v1)\n- [Deconvolutional Networks](\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n\nExample:\n\n>>> x = np.random.rand(4, 10, 128)\n>>> y = keras.layers.Conv1DTranspose(32, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 21, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv1DTranspose",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Conv2D",
        "docstring": "2D convolution layer.\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a 2D spatial (or temporal) dimension (height and width) to\nproduce a tensor of outputs. If `use_bias` is True, a bias vector is created\nand added to the outputs. Finally, if `activation` is not `None`, it is\napplied to the outputs as well.\n\nNote on numerical precision: While in general Keras operation execution\nresults are identical across backends up to 1e-7 precision in float32,\n`Conv2D` operations may show larger variations. Due to the large\nnumber of element-wise multiplications and additions in convolution\noperations, especially with large inputs or kernel sizes, accumulated\nfloating-point differences can exceed this 1e-7 threshold. These variations\nare particularly noticeable when using different backends (e.g., TensorFlow\nvs JAX) or different hardware.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 2 integer, specifying the size of the\n        convolution window.\n    strides: int or tuple/list of 2 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution.\n    groups: A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n\nReturns:\n    A 4D tensor representing `activation(conv2d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 10, 128)\n>>> y = keras.layers.Conv2D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 8, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "groups"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Convolution2D",
        "docstring": "2D convolution layer.\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a 2D spatial (or temporal) dimension (height and width) to\nproduce a tensor of outputs. If `use_bias` is True, a bias vector is created\nand added to the outputs. Finally, if `activation` is not `None`, it is\napplied to the outputs as well.\n\nNote on numerical precision: While in general Keras operation execution\nresults are identical across backends up to 1e-7 precision in float32,\n`Conv2D` operations may show larger variations. Due to the large\nnumber of element-wise multiplications and additions in convolution\noperations, especially with large inputs or kernel sizes, accumulated\nfloating-point differences can exceed this 1e-7 threshold. These variations\nare particularly noticeable when using different backends (e.g., TensorFlow\nvs JAX) or different hardware.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 2 integer, specifying the size of the\n        convolution window.\n    strides: int or tuple/list of 2 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution.\n    groups: A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n\nReturns:\n    A 4D tensor representing `activation(conv2d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 10, 128)\n>>> y = keras.layers.Conv2D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 8, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "groups"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Conv2DTranspose",
        "docstring": "2D transposed convolution layer.\n\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the transposed convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        transposed convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the transposed convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    output_padding: An integer or tuple/list of 2 integers,\n        specifying the amount of padding along the height and width\n        of the output tensor.\n        Can be a single integer to specify the same value for all\n        spatial dimensions.\n        The amount of output padding along a given dimension must be\n        lower than the stride along that same dimension.\n        If set to `None` (default), the output shape is inferred.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n     dilation_rate: An integer or tuple/list of 2 integers,\n        specifying the dilation rate for\n        all spatial dimensions for dilated convolution.\n        Specifying different dilation rates\n        for different dimensions is not supported.\n        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible with specifying any stride value != 1.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n\nReturns:\n    A 4D tensor representing\n    `activation(conv2d_transpose(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nReferences:\n- [A guide to convolution arithmetic for deep learning](\n    https://arxiv.org/abs/1603.07285v1)\n- [Deconvolutional Networks](\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n\nExample:\n\n>>> x = np.random.rand(4, 10, 8, 128)\n>>> y = keras.layers.Conv2DTranspose(32, 2, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 20, 16, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv2DTranspose",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Convolution2DTranspose",
        "docstring": "2D transposed convolution layer.\n\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the transposed convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        transposed convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the transposed convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    output_padding: An integer or tuple/list of 2 integers,\n        specifying the amount of padding along the height and width\n        of the output tensor.\n        Can be a single integer to specify the same value for all\n        spatial dimensions.\n        The amount of output padding along a given dimension must be\n        lower than the stride along that same dimension.\n        If set to `None` (default), the output shape is inferred.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n     dilation_rate: An integer or tuple/list of 2 integers,\n        specifying the dilation rate for\n        all spatial dimensions for dilated convolution.\n        Specifying different dilation rates\n        for different dimensions is not supported.\n        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible with specifying any stride value != 1.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n\nReturns:\n    A 4D tensor representing\n    `activation(conv2d_transpose(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nReferences:\n- [A guide to convolution arithmetic for deep learning](\n    https://arxiv.org/abs/1603.07285v1)\n- [Deconvolutional Networks](\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n\nExample:\n\n>>> x = np.random.rand(4, 10, 8, 128)\n>>> y = keras.layers.Conv2DTranspose(32, 2, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 20, 16, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv2DTranspose",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Conv3D",
        "docstring": "3D convolution layer.\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a 3D spatial (or temporal) dimension (width,height and depth) to\nproduce a tensor of outputs. If `use_bias` is True, a bias vector is created\nand added to the outputs. Finally, if `activation` is not `None`, it is\napplied to the outputs as well.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 3 integer, specifying the size of the\n        convolution window.\n    strides: int or tuple/list of 3 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 3 integers, specifying the dilation\n        rate to use for dilated convolution.\n    groups: A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n    filters)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n    new_spatial_dim3)`\n\nReturns:\n    A 5D tensor representing `activation(conv3d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 10, 10, 128)\n>>> y = keras.layers.Conv3D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 8, 8, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv3D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "groups"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Convolution3D",
        "docstring": "3D convolution layer.\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a 3D spatial (or temporal) dimension (width,height and depth) to\nproduce a tensor of outputs. If `use_bias` is True, a bias vector is created\nand added to the outputs. Finally, if `activation` is not `None`, it is\napplied to the outputs as well.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 3 integer, specifying the size of the\n        convolution window.\n    strides: int or tuple/list of 3 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 3 integers, specifying the dilation\n        rate to use for dilated convolution.\n    groups: A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n    filters)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n    new_spatial_dim3)`\n\nReturns:\n    A 5D tensor representing `activation(conv3d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 10, 10, 128)\n>>> y = keras.layers.Conv3D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 8, 8, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv3D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "groups"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Conv3DTranspose",
        "docstring": "3D transposed convolution layer.\n\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the transposed convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        transposed convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the transposed convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n     output_padding: An integer or tuple/list of 3 integers,\n        specifying the amount of padding along the depth, height, and\n        width.\n        Can be a single integer to specify the same value for all\n        spatial dimensions.\n        The amount of output padding along a given dimension must be\n        lower than the stride along that same dimension.\n        If set to `None` (default), the output shape is inferred.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n    dilation_rate: an integer or tuple/list of 3 integers, specifying\n        the dilation rate to use for dilated convolution.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible with specifying any stride value != 1.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n    filters)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n    new_spatial_dim3)`\n\nReturns:\n    A 5D tensor representing `activation(conv3d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nReferences:\n- [A guide to convolution arithmetic for deep learning](\n    https://arxiv.org/abs/1603.07285v1)\n- [Deconvolutional Networks](\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n\nExample:\n\n>>> x = np.random.rand(4, 10, 8, 12, 128)\n>>> y = keras.layers.Conv3DTranspose(32, 2, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 20, 16, 24, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv3DTranspose",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_padding"
          },
          {
            "annotation": null,
            "default": "(1, 1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Convolution3DTranspose",
        "docstring": "3D transposed convolution layer.\n\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the transposed convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        transposed convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the transposed convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n     output_padding: An integer or tuple/list of 3 integers,\n        specifying the amount of padding along the depth, height, and\n        width.\n        Can be a single integer to specify the same value for all\n        spatial dimensions.\n        The amount of output padding along a given dimension must be\n        lower than the stride along that same dimension.\n        If set to `None` (default), the output shape is inferred.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n    dilation_rate: an integer or tuple/list of 3 integers, specifying\n        the dilation rate to use for dilated convolution.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible with specifying any stride value != 1.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    kernel_initializer: Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    kernel_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    kernel_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n    filters)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n    new_spatial_dim3)`\n\nReturns:\n    A 5D tensor representing `activation(conv3d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nReferences:\n- [A guide to convolution arithmetic for deep learning](\n    https://arxiv.org/abs/1603.07285v1)\n- [Deconvolutional Networks](\n    https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n\nExample:\n\n>>> x = np.random.rand(4, 10, 8, 12, 128)\n>>> y = keras.layers.Conv3DTranspose(32, 2, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 20, 16, 24, 32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Conv3DTranspose",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_padding"
          },
          {
            "annotation": null,
            "default": "(1, 1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ConvLSTM1D",
        "docstring": "1D Convolutional LSTM.\n\nSimilar to an LSTM layer, but the input transformations\nand recurrent transformations are both convolutional.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 1 integer, specifying the size of\n        the convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the\n        same height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated convolution.\n    activation: Activation function to use. By default hyperbolic tangent\n        activation function is applied (`tanh(x)`).\n    recurrent_activation: Activation function to use for the recurrent step.\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n        matrix, used for the linear transformation of the recurrent state.\n    bias_initializer: Initializer for the bias vector.\n    unit_forget_bias: Boolean. If `True`, add 1 to the bias of\n        the forget gate at initialization.\n        Use in combination with `bias_initializer=\"zeros\"`.\n        This is recommended in [Jozefowicz et al., 2015](\n        http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state.\n    seed: Random seed for dropout.\n    return_sequences: Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition\n        to the output. Default: `False`.\n    go_backwards: Boolean (default: `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.\n    stateful: Boolean (default False). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.\n    unroll: Boolean (default: `False`).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.\n\n\nCall arguments:\n    inputs: A 4D tensor.\n    initial_state: List of initial state tensors to be passed to the first\n        call of the cell.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether a\n        given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode.\n        This is only relevant if `dropout` or `recurrent_dropout` are set.\n\nInput shape:\n\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape: `(samples, time, channels, rows)`\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape: `(samples, time, rows, channels)`\n\nOutput shape:\n\n- If `return_state`: a list of tensors. The first tensor is the output.\n    The remaining tensors are the last states,\n    each 3D tensor with shape: `(samples, filters, new_rows)` if\n    `data_format='channels_first'`\n    or shape: `(samples, new_rows, filters)` if\n    `data_format='channels_last'`.\n    `rows` values might have changed due to padding.\n- If `return_sequences`: 4D tensor with shape: `(samples, timesteps,\n    filters, new_rows)` if data_format='channels_first'\n    or shape: `(samples, timesteps, new_rows, filters)` if\n    `data_format='channels_last'`.\n- Else, 3D tensor with shape: `(samples, filters, new_rows)` if\n    `data_format='channels_first'`\n    or shape: `(samples, new_rows, filters)` if\n    `data_format='channels_last'`.\n\nReferences:\n\n- [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)\n    (the current implementation does not include the feedback loop on the\n    cells output).",
        "has_varargs": false,
        "kind": "class",
        "name": "ConvLSTM1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "sigmoid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unit_forget_bias"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_sequences"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_state"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "go_backwards"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "stateful"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ConvLSTM2D",
        "docstring": "2D Convolutional LSTM.\n\nSimilar to an LSTM layer, but the input transformations\nand recurrent transformations are both convolutional.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 2 integers, specifying the size of the\n        convolution window.\n    strides: int or tuple/list of 2 integers, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution.\n    activation: Activation function to use. By default hyperbolic tangent\n        activation function is applied (`tanh(x)`).\n    recurrent_activation: Activation function to use for the recurrent step.\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n        matrix, used for the linear transformation of the recurrent state.\n    bias_initializer: Initializer for the bias vector.\n    unit_forget_bias: Boolean. If `True`, add 1 to the bias of the forget\n        gate at initialization.\n        Use in combination with `bias_initializer=\"zeros\"`.\n        This is recommended in [Jozefowicz et al., 2015](\n        http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state.\n    seed: Random seed for dropout.\n    return_sequences: Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition\n        to the output. Default: `False`.\n    go_backwards: Boolean (default: `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.\n    stateful: Boolean (default False). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.\n    unroll: Boolean (default: `False`).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.\n\n\nCall arguments:\n    inputs: A 5D tensor.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether a\n        given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode.\n        This is only relevant if `dropout` or `recurrent_dropout` are set.\n    initial_state: List of initial state tensors to be passed to the first\n        call of the cell.\n\nInput shape:\n\n- If `data_format='channels_first'`:\n    5D tensor with shape: `(samples, time, channels, rows, cols)`\n- If `data_format='channels_last'`:\n    5D tensor with shape: `(samples, time, rows, cols, channels)`\n\nOutput shape:\n\n- If `return_state`: a list of tensors. The first tensor is the output.\n    The remaining tensors are the last states,\n    each 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n    `data_format='channels_first'`\n    or shape: `(samples, new_rows, new_cols, filters)` if\n    `data_format='channels_last'`. `rows` and `cols` values might have\n    changed due to padding.\n- If `return_sequences`: 5D tensor with shape: `(samples, timesteps,\n    filters, new_rows, new_cols)` if data_format='channels_first'\n    or shape: `(samples, timesteps, new_rows, new_cols, filters)` if\n    `data_format='channels_last'`.\n- Else, 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n    `data_format='channels_first'`\n    or shape: `(samples, new_rows, new_cols, filters)` if\n    `data_format='channels_last'`.\n\nReferences:\n\n- [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)\n    (the current implementation does not include the feedback loop on the\n    cells output).",
        "has_varargs": false,
        "kind": "class",
        "name": "ConvLSTM2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "sigmoid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unit_forget_bias"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_sequences"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_state"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "go_backwards"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "stateful"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ConvLSTM3D",
        "docstring": "3D Convolutional LSTM.\n\nSimilar to an LSTM layer, but the input transformations\nand recurrent transformations are both convolutional.\n\nArgs:\n    filters: int, the dimension of the output space (the number of filters\n        in the convolution).\n    kernel_size: int or tuple/list of 3 integers, specifying the size of the\n        convolution window.\n    strides: int or tuple/list of 3 integers, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 3 integers, specifying the dilation\n        rate to use for dilated convolution.\n    activation: Activation function to use. By default hyperbolic tangent\n        activation function is applied (`tanh(x)`).\n    recurrent_activation: Activation function to use for the recurrent step.\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n        matrix, used for the linear transformation of the recurrent state.\n    bias_initializer: Initializer for the bias vector.\n    unit_forget_bias: Boolean. If `True`, add 1 to the bias of the forget\n        gate at initialization.\n        Use in combination with `bias_initializer=\"zeros\"`.\n        This is recommended in [Jozefowicz et al., 2015](\n        http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state.\n    seed: Random seed for dropout.\n    return_sequences: Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition\n        to the output. Default: `False`.\n    go_backwards: Boolean (default: `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.\n    stateful: Boolean (default False). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.\n    unroll: Boolean (default: `False`).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.\n\n\nCall arguments:\n    inputs: A 6D tensor.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether a\n        given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode.\n        This is only relevant if `dropout` or `recurrent_dropout` are set.\n    initial_state: List of initial state tensors to be passed to the first\n        call of the cell.\n\nInput shape:\n\n- If `data_format='channels_first'`:\n    5D tensor with shape: `(samples, time, channels, *spatial_dims)`\n- If `data_format='channels_last'`:\n    5D tensor with shape: `(samples, time, *spatial_dims, channels)`\n\nOutput shape:\n\n- If `return_state`: a list of tensors. The first tensor is the output.\n    The remaining tensors are the last states,\n    each 4D tensor with shape: `(samples, filters, *spatial_dims)` if\n    `data_format='channels_first'`\n    or shape: `(samples, *spatial_dims, filters)` if\n    `data_format='channels_last'`.\n- If `return_sequences`: 5D tensor with shape: `(samples, timesteps,\n    filters, *spatial_dims)` if data_format='channels_first'\n    or shape: `(samples, timesteps, *spatial_dims, filters)` if\n    `data_format='channels_last'`.\n- Else, 4D tensor with shape: `(samples, filters, *spatial_dims)` if\n    `data_format='channels_first'`\n    or shape: `(samples, *spatial_dims, filters)` if\n    `data_format='channels_last'`.\n\nReferences:\n\n- [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)\n    (the current implementation does not include the feedback loop on the\n    cells output).",
        "has_varargs": false,
        "kind": "class",
        "name": "ConvLSTM3D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "sigmoid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unit_forget_bias"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_sequences"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_state"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "go_backwards"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "stateful"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Cropping1D",
        "docstring": "Cropping layer for 1D input (e.g. temporal sequence).\n\nIt crops along the time dimension (axis 1).\n\nExample:\n\n>>> input_shape = (2, 3, 2)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> x\n[[[ 0  1]\n  [ 2  3]\n  [ 4  5]]\n [[ 6  7]\n  [ 8  9]\n  [10 11]]]\n>>> y = keras.layers.Cropping1D(cropping=1)(x)\n>>> y\n[[[2 3]]\n [[8 9]]]\n\nArgs:\n    cropping: Int, or tuple of int (length 2), or dictionary.\n        - If int: how many units should be trimmed off at the beginning and\n          end of the cropping dimension (axis 1).\n        - If tuple of 2 ints: how many units should be trimmed off at the\n          beginning and end of the cropping dimension\n          (`(left_crop, right_crop)`).\n\nInput shape:\n    3D tensor with shape `(batch_size, axis_to_crop, features)`\n\nOutput shape:\n    3D tensor with shape `(batch_size, cropped_axis, features)`",
        "has_varargs": false,
        "kind": "class",
        "name": "Cropping1D",
        "params": [
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "cropping"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Cropping2D",
        "docstring": "Cropping layer for 2D input (e.g. picture).\n\nIt crops along spatial dimensions, i.e. height and width.\n\nExample:\n\n>>> input_shape = (2, 28, 28, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = keras.layers.Cropping2D(cropping=((2, 2), (4, 4)))(x)\n>>> y.shape\n(2, 24, 20, 3)\n\nArgs:\n    cropping: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n        - If int: the same symmetric cropping is applied to height and\n          width.\n        - If tuple of 2 ints: interpreted as two different symmetric\n          cropping values for height and width:\n          `(symmetric_height_crop, symmetric_width_crop)`.\n        - If tuple of 2 tuples of 2 ints: interpreted as\n          `((top_crop, bottom_crop), (left_crop, right_crop))`.\n    data_format: A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.\n\nInput shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, height, width, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, height, width)`\n\nOutput shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, cropped_height, cropped_width, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, cropped_height, cropped_width)`",
        "has_varargs": false,
        "kind": "class",
        "name": "Cropping2D",
        "params": [
          {
            "annotation": null,
            "default": "((0, 0), (0, 0))",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "cropping"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Cropping3D",
        "docstring": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n\nExample:\n\n>>> input_shape = (2, 28, 28, 10, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = keras.layers.Cropping3D(cropping=(2, 4, 2))(x)\n>>> y.shape\n(2, 24, 20, 6, 3)\n\nArgs:\n    cropping: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n        - If int: the same symmetric cropping is applied to depth, height,\n          and width.\n        - If tuple of 3 ints: interpreted as three different symmetric\n          cropping values for depth, height, and width:\n          `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n        - If tuple of 3 tuples of 2 ints: interpreted as\n          `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\n          right_dim2_crop), (left_dim3_crop, right_dim3_crop))`.\n    data_format: A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.\n\nInput shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, first_axis_to_crop, second_axis_to_crop,\n      third_axis_to_crop, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, first_axis_to_crop, second_axis_to_crop,\n      third_axis_to_crop)`\n\nOutput shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, first_cropped_axis, second_cropped_axis,\n      third_cropped_axis, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, first_cropped_axis, second_cropped_axis,\n      third_cropped_axis)`",
        "has_varargs": false,
        "kind": "class",
        "name": "Cropping3D",
        "params": [
          {
            "annotation": null,
            "default": "((1, 1), (1, 1), (1, 1))",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "cropping"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.CutMix",
        "docstring": "CutMix data augmentation technique.\n\nCutMix is a data augmentation method where patches are cut and pasted\nbetween two images in the dataset, while the labels are also mixed\nproportionally to the area of the patches.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nReferences:\n   - [CutMix paper]( https://arxiv.org/abs/1905.04899).\n\nArgs:\n    factor: A single float or a tuple of two floats between 0 and 1.\n        If a tuple of numbers is passed, a `factor` is sampled\n        between the two values.\n        If a single float is passed, a value between 0 and the passed\n        float is sampled. These values define the range from which the\n        mixing weight is sampled. A higher factor increases the variability\n        in patch sizes, leading to more diverse and larger mixed patches.\n        Defaults to 1.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "CutMix",
        "params": [
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Dense",
        "docstring": "Just your regular densely-connected NN layer.\n\n`Dense` implements the operation:\n`output = activation(dot(input, kernel) + bias)`\nwhere `activation` is the element-wise activation function\npassed as the `activation` argument, `kernel` is a weights matrix\ncreated by the layer, and `bias` is a bias vector created by the layer\n(only applicable if `use_bias` is `True`). When this layer is\nfollowed by a `BatchNormalization` layer, it is recommended to set\n`use_bias=False` as `BatchNormalization` has its own bias term.\n\nNote: If the input to the layer has a rank greater than 2, `Dense`\ncomputes the dot product between the `inputs` and the `kernel` along the\nlast axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\nFor example, if input has dimensions `(batch_size, d0, d1)`, then we create\na `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2\nof the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are\n`batch_size * d0` such sub-tensors). The output in this case will have\nshape `(batch_size, d0, units)`.\n\nArgs:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n        If you don't specify anything, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix.\n    bias_initializer: Initializer for the bias vector.\n    kernel_regularizer: Regularizer function applied to\n        the `kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to\n        the output of the layer (its \"activation\").\n    kernel_constraint: Constraint function applied to\n        the `kernel` weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    lora_rank: Optional integer. If set, the layer's forward pass\n        will implement LoRA (Low-Rank Adaptation)\n        with the provided rank. LoRA sets the layer's kernel\n        to non-trainable and replaces it with a delta over the\n        original kernel, obtained via multiplying two lower-rank\n        trainable matrices. This can be useful to reduce the\n        computation cost of fine-tuning large dense layers.\n        You can also enable LoRA on an existing\n        `Dense` layer by calling `layer.enable_lora(rank)`.\n    lora_alpha: Optional integer. If set, this parameter scales the\n        low-rank adaptation delta (computed as the product of two lower-rank\n        trainable matrices) during the forward pass. The delta is scaled by\n        `lora_alpha / lora_rank`, allowing you to fine-tune the strength of\n        the LoRA adjustment independently of `lora_rank`.\n\nInput shape:\n    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n    The most common situation would be\n    a 2D input with shape `(batch_size, input_dim)`.\n\nOutput shape:\n    N-D tensor with shape: `(batch_size, ..., units)`.\n    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n    the output would have shape `(batch_size, units)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "Dense",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "units"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "lora_rank"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "lora_alpha"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "quantization_config"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.DepthwiseConv1D",
        "docstring": "1D depthwise convolution layer.\n\nDepthwise convolution is a type of convolution in which each input channel\nis convolved with a different kernel (called a depthwise kernel). You can\nunderstand depthwise convolution as the first step in a depthwise separable\nconvolution.\n\nIt is implemented via the following steps:\n\n- Split the input into individual channels.\n- Convolve each channel with an individual depthwise kernel with\n  `depth_multiplier` output channels.\n- Concatenate the convolved outputs along the channels axis.\n\nUnlike a regular 1D convolution, depthwise convolution does not mix\ninformation across different input channels.\n\nThe `depth_multiplier` argument determines how many filters are applied to\none input channel. As such, it controls the amount of output channels that\nare generated per input channel in the depthwise step.\n\nArgs:\n    kernel_size: int or tuple/list of 1 integer, specifying the size of the\n        depthwise convolution window.\n    strides: int or tuple/list of 1 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    depth_multiplier: The number of depthwise convolution output channels\n        for each input channel. The total number of depthwise convolution\n        output channels will be equal to `input_channel * depth_multiplier`.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated convolution.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    depthwise_initializer: Initializer for the convolution kernel.\n        If `None`, the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    depthwise_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    depthwise_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape:\n    `(batch_shape, new_steps, channels * depth_multiplier)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape:\n    `(batch_shape, channels * depth_multiplier, new_steps)`\n\nReturns:\n    A 3D tensor representing\n    `activation(depthwise_conv1d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 12)\n>>> y = keras.layers.DepthwiseConv1D(3, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 4, 36)",
        "has_varargs": false,
        "kind": "class",
        "name": "DepthwiseConv1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depth_multiplier"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.DepthwiseConv2D",
        "docstring": "2D depthwise convolution layer.\n\nDepthwise convolution is a type of convolution in which each input channel\nis convolved with a different kernel (called a depthwise kernel). You can\nunderstand depthwise convolution as the first step in a depthwise separable\nconvolution.\n\nIt is implemented via the following steps:\n\n- Split the input into individual channels.\n- Convolve each channel with an individual depthwise kernel with\n  `depth_multiplier` output channels.\n- Concatenate the convolved outputs along the channels axis.\n\nUnlike a regular 2D convolution, depthwise convolution does not mix\ninformation across different input channels.\n\nThe `depth_multiplier` argument determines how many filters are applied to\none input channel. As such, it controls the amount of output channels that\nare generated per input channel in the depthwise step.\n\nArgs:\n    kernel_size: int or tuple/list of 2 integer, specifying the size of the\n        depthwise convolution window.\n    strides: int or tuple/list of 2 integer, specifying the stride length\n        of the depthwise convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    depth_multiplier: The number of depthwise convolution output channels\n        for each input channel. The total number of depthwise convolution\n        output channels will be equal to `input_channel * depth_multiplier`.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file\n        at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    depthwise_initializer: Initializer for the convolution kernel.\n        If `None`, the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    bias_initializer: Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.\n    depthwise_regularizer: Optional regularizer for the convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    depthwise_constraint: Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape:\n    `(batch_size, new_height, new_width, channels * depth_multiplier)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape:\n    `(batch_size, channels * depth_multiplier, new_height, new_width)`\n\nReturns:\n    A 4D tensor representing\n    `activation(depthwise_conv2d(inputs, kernel) + bias)`.\n\nRaises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 10, 12)\n>>> y = keras.layers.DepthwiseConv2D(kernel_size=3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 8, 12)",
        "has_varargs": false,
        "kind": "class",
        "name": "DepthwiseConv2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depth_multiplier"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Discretization",
        "docstring": "A preprocessing layer which buckets continuous features by ranges.\n\nThis layer will place each element of its input data into one of several\ncontiguous ranges and output an integer index indicating which range each\nelement was placed in.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nInput shape:\n    Any array of dimension 2 or higher.\n\nOutput shape:\n    Same as input shape.\n\nArguments:\n    bin_boundaries: A list of bin boundaries.\n        The leftmost and rightmost bins\n        will always extend to `-inf` and `inf`,\n        so `bin_boundaries=[0., 1., 2.]`\n        generates bins `(-inf, 0.)`, `[0., 1.)`, `[1., 2.)`,\n        and `[2., +inf)`.\n        If this option is set, `adapt()` should not be called.\n    num_bins: The integer number of bins to compute.\n        If this option is set, `bin_boundaries` should not be set and\n        `adapt()` should be called to learn the bin boundaries.\n    epsilon: Error tolerance, typically a small fraction\n        close to zero (e.g. 0.01). Higher values of epsilon increase\n        the quantile approximation, and hence result in more\n        unequal buckets, but could improve performance\n        and resource consumption.\n    output_mode: Specification for the output of the layer.\n        Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or\n        `\"count\"` configuring the layer as follows:\n        - `\"int\"`: Return the discretized bin indices directly.\n        - `\"one_hot\"`: Encodes each individual element in the\n            input into an array the same size as `num_bins`,\n            containing a 1 at the input's bin\n            index. If the last dimension is size 1, will encode on that\n            dimension.  If the last dimension is not size 1,\n            will append a new dimension for the encoded output.\n        - `\"multi_hot\"`: Encodes each sample in the input into a\n            single array the same size as `num_bins`,\n            containing a 1 for each bin index\n            index present in the sample.\n            Treats the last dimension as the sample\n            dimension, if input shape is `(..., sample_length)`,\n            output shape will be `(..., num_tokens)`.\n        - `\"count\"`: As `\"multi_hot\"`, but the int array contains\n            a count of the number of times the bin index appeared\n            in the sample.\n        Defaults to `\"int\"`.\n    sparse: Boolean. Only applicable to `\"one_hot\"`, `\"multi_hot\"`,\n        and `\"count\"` output modes. Only supported with TensorFlow\n        backend. If `True`, returns a `SparseTensor` instead of\n        a dense `Tensor`. Defaults to `False`.\n\nExamples:\n\nDiscretize float values based on provided buckets.\n>>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n>>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n>>> layer(input)\narray([[0, 2, 3, 1],\n       [1, 3, 2, 1]])\n\nDiscretize float values based on a number of buckets to compute.\n>>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n>>> layer = Discretization(num_bins=4, epsilon=0.01)\n>>> layer.adapt(input)\n>>> layer(input)\narray([[0, 2, 3, 2],\n       [1, 3, 3, 1]])",
        "has_varargs": false,
        "kind": "class",
        "name": "Discretization",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bin_boundaries"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_bins"
          },
          {
            "annotation": null,
            "default": "0.01",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "int",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_mode"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sparse"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          }
        ]
      },
      {
        "api_path": "keras.layers.Dot",
        "docstring": "Computes element-wise dot product of two tensors.\n\nIt takes a list of inputs of size 2, and the axes\ncorresponding to each input along with the dot product\nis to be performed.\n\nLet's say `x` and `y` are the two input tensors with shapes\n`(2, 3, 5)` and `(2, 10, 3)`. The batch dimension should be\nof same size for both the inputs, and `axes` should correspond\nto the dimensions that have the same size in the corresponding\ninputs. e.g. with `axes=(1, 2)`, the dot product of `x`, and `y`\nwill result in a tensor with shape `(2, 5, 10)`\n\nExample:\n\n>>> x = np.arange(10).reshape(1, 5, 2)\n>>> y = np.arange(10, 20).reshape(1, 2, 5)\n>>> keras.layers.Dot(axes=(1, 2))([x, y])\n\nUsage in a Keras model:\n\n>>> x1 = keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n>>> x2 = keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n>>> y = keras.layers.Dot(axes=1)([x1, x2])\n\nArgs:\n    axes: Integer or tuple of integers, axis or axes along which to\n        take the dot product. If a tuple, should be two integers\n        corresponding to the desired axis from the first input and the\n        desired axis from the second input, respectively. Note that the\n        size of the two selected axes must match, and that\n        axis `0` (the batch axis) cannot be included.\n    normalize: Whether to L2-normalize samples along the dot product axis\n        before taking the dot product. If set to `True`, then\n        the output of the dot product is the cosine proximity\n        between the two samples.\n    **kwargs: Standard layer keyword arguments.\n\nReturns:\n    A tensor, the dot product of the samples from the inputs.",
        "has_varargs": false,
        "kind": "class",
        "name": "Dot",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axes"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "normalize"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Dropout",
        "docstring": "Applies dropout to the input.\n\nThe `Dropout` layer randomly sets input units to 0 with a frequency of\n`rate` at each step during training time, which helps prevent overfitting.\nInputs not set to 0 are scaled up by `1 / (1 - rate)` such that the sum over\nall inputs is unchanged.\n\nNote that the `Dropout` layer only applies when `training` is set to `True`\nin `call()`, such that no values are dropped during inference.\nWhen using `model.fit`, `training` will be appropriately set to `True`\nautomatically. In other contexts, you can set the argument explicitly\nto `True` when calling the layer.\n\n(This is in contrast to setting `trainable=False` for a `Dropout` layer.\n`trainable` does not affect the layer's behavior, as `Dropout` does\nnot have any variables/weights that can be frozen during training.)\n\nArgs:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    noise_shape: 1D integer tensor representing the shape of the\n        binary dropout mask that will be multiplied with the input.\n        For instance, if your inputs have shape\n        `(batch_size, timesteps, features)` and\n        you want the dropout mask to be the same for all timesteps,\n        you can use `noise_shape=(batch_size, 1, features)`.\n    seed: A Python integer to use as random seed.\n\nCall arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n        training mode (adding dropout) or in inference mode (doing nothing).",
        "has_varargs": false,
        "kind": "class",
        "name": "Dropout",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "noise_shape"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ELU",
        "docstring": "Applies an Exponential Linear Unit function to an output.\n\nFormula:\n\n```\nf(x) = alpha * (exp(x) - 1.) for x < 0\nf(x) = x for x >= 0\n```\n\nArgs:\n    alpha: float, slope of negative section. Defaults to `1.0`.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "ELU",
        "params": [
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.EinsumDense",
        "docstring": "A layer that uses `einsum` as the backing computation.\n\nThis layer can perform einsum calculations of arbitrary dimensionality.\n\nArgs:\n    equation: An equation describing the einsum to perform.\n        This equation must be a valid einsum string of the form\n        `ab,bc->ac`, `...ab,bc->...ac`, or\n        `ab...,bc->ac...` where 'ab', 'bc', and 'ac' can be any valid einsum\n        axis expression sequence.\n    output_shape: The expected shape of the output tensor\n        (excluding the batch dimension and any dimensions\n        represented by ellipses). You can specify `None` for any dimension\n        that is unknown or can be inferred from the input shape.\n    activation: Activation function to use. If you don't specify anything,\n        no activation is applied\n        (that is, a \"linear\" activation: `a(x) = x`).\n    bias_axes: A string containing the output dimension(s)\n        to apply a bias to. Each character in the `bias_axes` string\n        should correspond to a character in the output portion\n        of the `equation` string.\n    kernel_initializer: Initializer for the `kernel` weights matrix.\n    bias_initializer: Initializer for the bias vector.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    lora_rank: Optional integer. If set, the layer's forward pass\n        will implement LoRA (Low-Rank Adaptation)\n        with the provided rank. LoRA sets the layer's kernel\n        to non-trainable and replaces it with a delta over the\n        original kernel, obtained via multiplying two lower-rank\n        trainable matrices\n        (the factorization happens on the last dimension).\n        This can be useful to reduce the\n        computation cost of fine-tuning large dense layers.\n        You can also enable LoRA on an existing\n        `EinsumDense` layer by calling `layer.enable_lora(rank)`.\n     lora_alpha: Optional integer. If set, this parameter scales the\n        low-rank adaptation delta (computed as the product of two lower-rank\n        trainable matrices) during the forward pass. The delta is scaled by\n        `lora_alpha / lora_rank`, allowing you to fine-tune the strength of\n        the LoRA adjustment independently of `lora_rank`.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.\n\nExamples:\n\n**Biased dense layer with einsums**\n\nThis example shows how to instantiate a standard Keras dense layer using\neinsum operations. This example is equivalent to\n`keras.layers.Dense(64, use_bias=True)`.\n\n>>> layer = keras.layers.EinsumDense(\"ab,bc->ac\",\n...                                       output_shape=64,\n...                                       bias_axes=\"c\")\n>>> input_tensor = keras.Input(shape=[32])\n>>> output_tensor = layer(input_tensor)\n>>> output_tensor.shape\n(None, 64)\n\n**Applying a dense layer to a sequence**\n\nThis example shows how to instantiate a layer that applies the same dense\noperation to every element in a sequence. Here, the `output_shape` has two\nvalues (since there are two non-batch dimensions in the output); the first\ndimension in the `output_shape` is `None`, because the sequence dimension\n`b` has an unknown shape.\n\n>>> layer = keras.layers.EinsumDense(\"abc,cd->abd\",\n...                                       output_shape=(None, 64),\n...                                       bias_axes=\"d\")\n>>> input_tensor = keras.Input(shape=[32, 128])\n>>> output_tensor = layer(input_tensor)\n>>> output_tensor.shape\n(None, 32, 64)\n\n**Applying a dense layer to a sequence using ellipses**\n\nThis example shows how to instantiate a layer that applies the same dense\noperation to every element in a sequence, but uses the ellipsis notation\ninstead of specifying the batch and sequence dimensions.\n\nBecause we are using ellipsis notation and have specified only one axis, the\n`output_shape` arg is a single value. When instantiated in this way, the\nlayer can handle any number of sequence dimensions - including the case\nwhere no sequence dimension exists.\n\n>>> layer = keras.layers.EinsumDense(\"...x,xy->...y\",\n...                                       output_shape=64,\n...                                       bias_axes=\"y\")\n>>> input_tensor = keras.Input(shape=[32, 128])\n>>> output_tensor = layer(input_tensor)\n>>> output_tensor.shape\n(None, 32, 64)",
        "has_varargs": false,
        "kind": "class",
        "name": "EinsumDense",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "equation"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_shape"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_axes"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "lora_rank"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "lora_alpha"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gptq_unpacked_column_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "quantization_config"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Embedding",
        "docstring": "Turns nonnegative integers (indexes) into dense vectors of fixed size.\n\ne.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n\nThis layer can only be used on nonnegative integer inputs of a fixed range.\n\nExample:\n\n>>> model = keras.Sequential()\n>>> model.add(keras.layers.Embedding(1000, 64))\n>>> # The model will take as input an integer matrix of size (batch,\n>>> # input_length), and the largest integer (i.e. word index) in the input\n>>> # should be no larger than 999 (vocabulary size).\n>>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n>>> # dimension.\n>>> input_array = np.random.randint(1000, size=(32, 10))\n>>> model.compile('rmsprop', 'mse')\n>>> output_array = model.predict(input_array)\n>>> print(output_array.shape)\n(32, 10, 64)\n\nArgs:\n    input_dim: Integer. Size of the vocabulary,\n        i.e. maximum integer index + 1.\n    output_dim: Integer. Dimension of the dense embedding.\n    embeddings_initializer: Initializer for the `embeddings`\n        matrix (see `keras.initializers`).\n    embeddings_regularizer: Regularizer function applied to\n        the `embeddings` matrix (see `keras.regularizers`).\n    embeddings_constraint: Constraint function applied to\n        the `embeddings` matrix (see `keras.constraints`).\n    mask_zero: Boolean, whether or not the input value 0 is a special\n        \"padding\" value that should be masked out.\n        This is useful when using recurrent layers which\n        may take variable length input. If this is `True`,\n        then all subsequent layers in the model need\n        to support masking or an exception will be raised.\n        If `mask_zero` is set to `True`, as a consequence,\n        index 0 cannot be used in the vocabulary (`input_dim` should\n        equal size of vocabulary + 1).\n    weights: Optional floating-point matrix of size\n        `(input_dim, output_dim)`. The initial embeddings values\n        to use.\n    lora_rank: Optional integer. If set, the layer's forward pass\n        will implement LoRA (Low-Rank Adaptation)\n        with the provided rank. LoRA sets the layer's embeddings\n        matrix to non-trainable and replaces it with a delta over the\n        original matrix, obtained via multiplying two lower-rank\n        trainable matrices. This can be useful to reduce the\n        computation cost of fine-tuning large embedding layers.\n        You can also enable LoRA on an existing\n        `Embedding` layer by calling `layer.enable_lora(rank)`.\n    lora_alpha: Optional integer. If set, this parameter scales the\n        low-rank adaptation delta (computed as the product of two lower-rank\n        trainable matrices) during the forward pass. The delta is scaled by\n        `lora_alpha / lora_rank`, allowing you to fine-tune the strength of\n        the LoRA adjustment independently of `lora_rank`.\n\nInput shape:\n    2D tensor with shape: `(batch_size, input_length)`.\n\nOutput shape:\n    3D tensor with shape: `(batch_size, input_length, output_dim)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "Embedding",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "input_dim"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_dim"
          },
          {
            "annotation": null,
            "default": "uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "embeddings_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "embeddings_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "embeddings_constraint"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mask_zero"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weights"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "lora_rank"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "lora_alpha"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "quantization_config"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Equalization",
        "docstring": "Preprocessing layer for histogram equalization on image channels.\n\nHistogram equalization is a technique to adjust image intensities to\nenhance contrast by effectively spreading out the most frequent\nintensity values. This layer applies equalization on a channel-wise\nbasis, which can improve the visibility of details in images.\n\nThis layer works with both grayscale and color images, performing\nequalization independently on each color channel. At inference time,\nthe equalization is consistently applied.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    value_range: Optional list/tuple of 2 floats specifying the lower\n        and upper limits of the input data values. Defaults to `[0, 255]`.\n        If the input image has been scaled, use the appropriate range\n        (e.g., `[0.0, 1.0]`). The equalization will be scaled to this\n        range, and output values will be clipped accordingly.\n    bins: Integer specifying the number of histogram bins to use for\n        equalization. Defaults to 256, which is suitable for 8-bit images.\n        Larger values can provide more granular intensity redistribution.\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format,\n    or `(..., channels, height, width)`, in `\"channels_first\"` format.\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., target_height, target_width, channels)`,\n    or `(..., channels, target_height, target_width)`,\n    in `\"channels_first\"` format.\n\nExample:\n\n```python\n# Create an equalization layer for standard 8-bit images\nequalizer = keras.layers.Equalization()\n\n# An image with uneven intensity distribution\nimage = [...] # your input image\n\n# Apply histogram equalization\nequalized_image = equalizer(image)\n\n# For images with custom value range\ncustom_equalizer = keras.layers.Equalization(\n    value_range=[0.0, 1.0],  # for normalized images\n    bins=128  # fewer bins for more subtle equalization\n)\ncustom_equalized = custom_equalizer(normalized_image)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "Equalization",
        "params": [
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "256",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bins"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Flatten",
        "docstring": "Flattens the input. Does not affect the batch size.\n\nNote: If inputs are shaped `(batch,)` without a feature axis, then\nflattening adds an extra channel dimension and output shape is `(batch, 1)`.\n\nArgs:\n    data_format: A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, ..., channels)` while `\"channels_first\"` corresponds to\n        inputs with shape `(batch, channels, ...)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.\n\nExample:\n\n>>> x = keras.Input(shape=(10, 64))\n>>> y = keras.layers.Flatten()(x)\n>>> y.shape\n(None, 640)",
        "has_varargs": false,
        "kind": "class",
        "name": "Flatten",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.FlaxLayer",
        "docstring": "Keras Layer that wraps a [Flax](https://flax.readthedocs.io) module.\n\nThis layer enables the use of Flax components in the form of\n[`flax.linen.Module`](\n    https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html)\ninstances within Keras when using JAX as the backend for Keras.\n\nThe module method to use for the forward pass can be specified via the\n`method` argument and is `__call__` by default. This method must take the\nfollowing arguments with these exact names:\n\n- `self` if the method is bound to the module, which is the case for the\n    default of `__call__`, and `module` otherwise to pass the module.\n- `inputs`: the inputs to the model, a JAX array or a `PyTree` of arrays.\n- `training` *(optional)*: an argument specifying if we're in training mode\n    or inference mode, `True` is passed in training mode.\n\n`FlaxLayer` handles the non-trainable state of your model and required RNGs\nautomatically. Note that the `mutable` parameter of\n[`flax.linen.Module.apply()`](\n    https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html#flax.linen.apply)\nis set to `DenyList([\"params\"])`, therefore making the assumption that all\nthe variables outside of the \"params\" collection are non-trainable weights.\n\nThis example shows how to create a `FlaxLayer` from a Flax `Module` with\nthe default `__call__` method and no training argument:\n\n```python\nclass MyFlaxModule(flax.linen.Module):\n    @flax.linen.compact\n    def __call__(self, inputs):\n        x = inputs\n        x = flax.linen.Conv(features=32, kernel_size=(3, 3))(x)\n        x = flax.linen.relu(x)\n        x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n        x = x.reshape((x.shape[0], -1))  # flatten\n        x = flax.linen.Dense(features=200)(x)\n        x = flax.linen.relu(x)\n        x = flax.linen.Dense(features=10)(x)\n        x = flax.linen.softmax(x)\n        return x\n\nflax_module = MyFlaxModule()\nkeras_layer = FlaxLayer(flax_module)\n```\n\nThis example shows how to wrap the module method to conform to the required\nsignature. This allows having multiple input arguments and a training\nargument that has a different name and values. This additionally shows how\nto use a function that is not bound to the module.\n\n```python\nclass MyFlaxModule(flax.linen.Module):\n    @flax.linen.compact\n    def forward(self, input1, input2, deterministic):\n        ...\n        return outputs\n\ndef my_flax_module_wrapper(module, inputs, training):\n    input1, input2 = inputs\n    return module.forward(input1, input2, not training)\n\nflax_module = MyFlaxModule()\nkeras_layer = FlaxLayer(\n    module=flax_module,\n    method=my_flax_module_wrapper,\n)\n```\n\nArgs:\n    module: An instance of `flax.linen.Module` or subclass.\n    method: The method to call the model. This is generally a method in the\n        `Module`. If not provided, the `__call__` method is used. `method`\n        can also be a function not defined in the `Module`, in which case it\n        must take the `Module` as the first argument. It is used for both\n        `Module.init` and `Module.apply`. Details are documented in the\n        `method` argument of [`flax.linen.Module.apply()`](\n          https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html#flax.linen.apply).\n    variables: A `dict` containing all the variables of the module in the\n        same format as what is returned by [`flax.linen.Module.init()`](\n          https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html#flax.linen.init).\n        It should contain a \"params\" key and, if applicable, other keys for\n        collections of variables for non-trainable state. This allows\n        passing trained parameters and learned non-trainable state or\n        controlling the initialization. If `None` is passed, the module's\n        `init` function is called at build time to initialize the variables\n        of the model.",
        "has_varargs": false,
        "kind": "class",
        "name": "FlaxLayer",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "module"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "method"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "variables"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GRU",
        "docstring": "Gated Recurrent Unit - Cho et al. 2014.\n\nBased on available runtime hardware and constraints, this layer\nwill choose different implementations (cuDNN-based or backend-native)\nto maximize the performance. If a GPU is available and all\nthe arguments to the layer meet the requirement of the cuDNN kernel\n(see below for details), the layer will use a fast cuDNN implementation\nwhen using the TensorFlow backend.\n\nThe requirements to use the cuDNN implementation are:\n\n1. `activation` == `tanh`\n2. `recurrent_activation` == `sigmoid`\n3. `recurrent_dropout` == 0\n4. `unroll` is `False`\n5. `use_bias` is `True`\n6. `reset_after` is `True`\n7. Inputs, if use masking, are strictly right-padded.\n8. Eager execution is enabled in the outermost context.\n\nThere are two variants of the GRU implementation. The default one is based\non [v3](https://arxiv.org/abs/1406.1078v3) and has reset gate applied to\nhidden state before matrix multiplication. The other one is based on\n[original](https://arxiv.org/abs/1406.1078v1) and has the order reversed.\n\nThe second variant is compatible with CuDNNGRU (GPU-only) and allows\ninference on CPU. Thus it has separate biases for `kernel` and\n`recurrent_kernel`. To use this variant, set `reset_after=True` and\n`recurrent_activation='sigmoid'`.\n\nFor example:\n\n>>> inputs = np.random.random((32, 10, 8))\n>>> gru = keras.layers.GRU(4)\n>>> output = gru(inputs)\n>>> output.shape\n(32, 4)\n>>> gru = keras.layers.GRU(4, return_sequences=True, return_state=True)\n>>> whole_sequence_output, final_state = gru(inputs)\n>>> whole_sequence_output.shape\n(32, 10, 4)\n>>> final_state.shape\n(32, 4)\n\nArgs:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n        Default: hyperbolic tangent (`tanh`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use\n        for the recurrent step.\n        Default: sigmoid (`sigmoid`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer\n        should use a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation of the recurrent\n        state. Default: `\"orthogonal\"`.\n    bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector.\n        Default: `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n        layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector.\n        Default: `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.\n    seed: Random seed for dropout.\n    return_sequences: Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition\n        to the output. Default: `False`.\n    go_backwards: Boolean (default `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.\n    stateful: Boolean (default: `False`). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.\n    unroll: Boolean (default: `False`).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.\n    reset_after: GRU convention (whether to apply reset gate after or\n        before matrix multiplication). `False` is `\"before\"`,\n        `True` is `\"after\"` (default and cuDNN compatible).\n    use_cudnn: Whether to use a cuDNN-backed implementation. `\"auto\"` will\n        attempt to use cuDNN when feasible, and will fallback to the\n        default implementation if not.\n\nCall arguments:\n    inputs: A 3D tensor, with shape `(batch, timesteps, feature)`.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n        a given timestep should be masked  (optional).\n        An individual `True` entry indicates that the corresponding timestep\n        should be utilized, while a `False` entry indicates that the\n        corresponding timestep should be ignored. Defaults to `None`.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode. This argument is passed to the\n        cell when calling it. This is only relevant if `dropout` or\n        `recurrent_dropout` is used  (optional). Defaults to `None`.\n    initial_state: List of initial state tensors to be passed to the first\n        call of the cell (optional, `None` causes creation\n        of zero-filled initial state tensors). Defaults to `None`.",
        "has_varargs": false,
        "kind": "class",
        "name": "GRU",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "units"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "sigmoid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_sequences"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_state"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "go_backwards"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "stateful"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unroll"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reset_after"
          },
          {
            "annotation": null,
            "default": "auto",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_cudnn"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GRUCell",
        "docstring": "Cell class for the GRU layer.\n\nThis class processes one step within the whole time sequence input, whereas\n`keras.layer.GRU` processes the whole sequence.\n\nArgs:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use. Default: hyperbolic tangent\n        (`tanh`). If you pass None, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use for the recurrent step.\n        Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n        applied (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer\n        should use a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation\n        of the recurrent state. Default: `\"orthogonal\"`.\n    bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector.\n        Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector.\n        Default: `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.\n    reset_after: GRU convention (whether to apply reset gate after or\n        before matrix multiplication). False = \"before\",\n        True = \"after\" (default and cuDNN compatible).\n    seed: Random seed for dropout.\n\nCall arguments:\n    inputs: A 2D tensor, with shape `(batch, features)`.\n    states: A 2D tensor with shape `(batch, units)`, which is the state\n        from the previous time step.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode. Only relevant when `dropout` or\n        `recurrent_dropout` is used.\n\nExample:\n\n>>> inputs = np.random.random((32, 10, 8))\n>>> rnn = keras.layers.RNN(keras.layers.GRUCell(4))\n>>> output = rnn(inputs)\n>>> output.shape\n(32, 4)\n>>> rnn = keras.layers.RNN(\n...    keras.layers.GRUCell(4),\n...    return_sequences=True,\n...    return_state=True)\n>>> whole_sequence_output, final_state = rnn(inputs)\n>>> whole_sequence_output.shape\n(32, 10, 4)\n>>> final_state.shape\n(32, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "GRUCell",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "units"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "sigmoid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reset_after"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GaussianDropout",
        "docstring": "Apply multiplicative 1-centered Gaussian noise.\n\nAs it is a regularization layer, it is only active at training time.\n\nArgs:\n    rate: Float, drop probability (as with `Dropout`).\n        The multiplicative noise will have\n        standard deviation `sqrt(rate / (1 - rate))`.\n    seed: Integer, optional random seed to enable deterministic behavior.\n\nCall arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n        training mode (adding dropout) or in inference mode (doing nothing).",
        "has_varargs": false,
        "kind": "class",
        "name": "GaussianDropout",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GaussianNoise",
        "docstring": "Apply additive zero-centered Gaussian noise.\n\nThis is useful to mitigate overfitting\n(you could see it as a form of random data augmentation).\nGaussian Noise (GS) is a natural choice as corruption process\nfor real valued inputs.\n\nAs it is a regularization layer, it is only active at training time.\n\nArgs:\n    stddev: Float, standard deviation of the noise distribution.\n    seed: Integer, optional random seed to enable deterministic behavior.\n\nCall arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n        training mode (adding noise) or in inference mode (doing nothing).",
        "has_varargs": false,
        "kind": "class",
        "name": "GaussianNoise",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "stddev"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalAveragePooling1D",
        "docstring": "Global average pooling operation for temporal data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        temporal dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nCall arguments:\n    inputs: A 3D tensor.\n    mask: Binary tensor of shape `(batch_size, steps)` indicating whether\n        a given step should be masked (excluded from the average).\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    3D tensor with shape:\n    `(batch_size, steps, features)`\n- If `data_format='channels_first'`:\n    3D tensor with shape:\n    `(batch_size, features, steps)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, features)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        3D tensor with shape `(batch_size, 1, features)`\n    - If `data_format=\"channels_first\"`:\n        3D tensor with shape `(batch_size, features, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 3, 4)\n>>> y = keras.layers.GlobalAveragePooling1D()(x)\n>>> y.shape\n(2, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalAveragePooling1D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalAvgPool1D",
        "docstring": "Global average pooling operation for temporal data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        temporal dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nCall arguments:\n    inputs: A 3D tensor.\n    mask: Binary tensor of shape `(batch_size, steps)` indicating whether\n        a given step should be masked (excluded from the average).\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    3D tensor with shape:\n    `(batch_size, steps, features)`\n- If `data_format='channels_first'`:\n    3D tensor with shape:\n    `(batch_size, features, steps)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, features)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        3D tensor with shape `(batch_size, 1, features)`\n    - If `data_format=\"channels_first\"`:\n        3D tensor with shape `(batch_size, features, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 3, 4)\n>>> y = keras.layers.GlobalAveragePooling1D()(x)\n>>> y.shape\n(2, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalAveragePooling1D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalAveragePooling2D",
        "docstring": "Global average pooling operation for 2D data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, height, weight)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    4D tensor with shape:\n    `(batch_size, height, width, channels)`\n- If `data_format='channels_first'`:\n    4D tensor with shape:\n    `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        4D tensor with shape `(batch_size, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        4D tensor with shape `(batch_size, channels, 1, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 4, 5, 3)\n>>> y = keras.layers.GlobalAveragePooling2D()(x)\n>>> y.shape\n(2, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalAveragePooling2D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalAvgPool2D",
        "docstring": "Global average pooling operation for 2D data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, height, weight)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    4D tensor with shape:\n    `(batch_size, height, width, channels)`\n- If `data_format='channels_first'`:\n    4D tensor with shape:\n    `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        4D tensor with shape `(batch_size, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        4D tensor with shape `(batch_size, channels, 1, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 4, 5, 3)\n>>> y = keras.layers.GlobalAveragePooling2D()(x)\n>>> y.shape\n(2, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalAveragePooling2D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalAveragePooling3D",
        "docstring": "Global average pooling operation for 3D data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format='channels_first'`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        5D tensor with shape `(batch_size, 1, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        5D tensor with shape `(batch_size, channels, 1, 1, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 4, 5, 4, 3)\n>>> y = keras.layers.GlobalAveragePooling3D()(x)\n>>> y.shape\n(2, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalAveragePooling3D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalAvgPool3D",
        "docstring": "Global average pooling operation for 3D data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format='channels_first'`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        5D tensor with shape `(batch_size, 1, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        5D tensor with shape `(batch_size, channels, 1, 1, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 4, 5, 4, 3)\n>>> y = keras.layers.GlobalAveragePooling3D()(x)\n>>> y.shape\n(2, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalAveragePooling3D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalMaxPool1D",
        "docstring": "Global max pooling operation for temporal data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        temporal dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    3D tensor with shape:\n    `(batch_size, steps, features)`\n- If `data_format='channels_first'`:\n    3D tensor with shape:\n    `(batch_size, features, steps)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, features)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        3D tensor with shape `(batch_size, 1, features)`\n    - If `data_format=\"channels_first\"`:\n        3D tensor with shape `(batch_size, features, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 3, 4)\n>>> y = keras.layers.GlobalMaxPooling1D()(x)\n>>> y.shape\n(2, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalMaxPooling1D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalMaxPooling1D",
        "docstring": "Global max pooling operation for temporal data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        temporal dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    3D tensor with shape:\n    `(batch_size, steps, features)`\n- If `data_format='channels_first'`:\n    3D tensor with shape:\n    `(batch_size, features, steps)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, features)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        3D tensor with shape `(batch_size, 1, features)`\n    - If `data_format=\"channels_first\"`:\n        3D tensor with shape `(batch_size, features, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 3, 4)\n>>> y = keras.layers.GlobalMaxPooling1D()(x)\n>>> y.shape\n(2, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalMaxPooling1D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalMaxPool2D",
        "docstring": "Global max pooling operation for 2D data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, height, weight)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    4D tensor with shape:\n    `(batch_size, height, width, channels)`\n- If `data_format='channels_first'`:\n    4D tensor with shape:\n    `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        4D tensor with shape `(batch_size, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        4D tensor with shape `(batch_size, channels, 1, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 4, 5, 3)\n>>> y = keras.layers.GlobalMaxPooling2D()(x)\n>>> y.shape\n(2, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalMaxPooling2D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalMaxPooling2D",
        "docstring": "Global max pooling operation for 2D data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, height, weight)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    4D tensor with shape:\n    `(batch_size, height, width, channels)`\n- If `data_format='channels_first'`:\n    4D tensor with shape:\n    `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        4D tensor with shape `(batch_size, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        4D tensor with shape `(batch_size, channels, 1, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 4, 5, 3)\n>>> y = keras.layers.GlobalMaxPooling2D()(x)\n>>> y.shape\n(2, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalMaxPooling2D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalMaxPool3D",
        "docstring": "Global max pooling operation for 3D data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format='channels_first'`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        5D tensor with shape `(batch_size, 1, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        5D tensor with shape `(batch_size, channels, 1, 1, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 4, 5, 4, 3)\n>>> y = keras.layers.GlobalMaxPooling3D()(x)\n>>> y.shape\n(2, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalMaxPooling3D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GlobalMaxPooling3D",
        "docstring": "Global max pooling operation for 3D data.\n\nArgs:\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\nInput shape:\n\n- If `data_format='channels_last'`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format='channels_first'`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        5D tensor with shape `(batch_size, 1, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        5D tensor with shape `(batch_size, channels, 1, 1, 1)`\n\nExample:\n\n>>> x = np.random.rand(2, 4, 5, 4, 3)\n>>> y = keras.layers.GlobalMaxPooling3D()(x)\n>>> y.shape\n(2, 3)",
        "has_varargs": false,
        "kind": "class",
        "name": "GlobalMaxPooling3D",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "keepdims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GroupNormalization",
        "docstring": "Group normalization layer.\n\nGroup Normalization divides the channels into groups and computes\nwithin each group the mean and variance for normalization.\nEmpirically, its accuracy is more stable than batch norm in a wide\nrange of small batch sizes, if learning rate is adjusted linearly\nwith batch sizes.\n\nRelation to Layer Normalization:\nIf the number of groups is set to 1, then this operation becomes nearly\nidentical to Layer Normalization (see Layer Normalization docs for details).\n\nRelation to Instance Normalization:\nIf the number of groups is set to the input dimension (number of groups is\nequal to number of channels), then this operation becomes identical to\nInstance Normalization. You can achieve this via `groups=-1`.\n\nArgs:\n    groups: Integer, the number of groups for Group Normalization. Can be in\n        the range `[1, N]` where N is the input dimension. The input\n        dimension must be divisible by the number of groups.\n        Defaults to 32.\n    axis: Integer or List/Tuple. The axis or axes to normalize across.\n        Typically, this is the features axis/axes. The left-out axes are\n        typically the batch axis/axes. -1 is the last dimension in the\n        input. Defaults to `-1`.\n    epsilon: Small float added to variance to avoid dividing by zero.\n        Defaults to 1e-3.\n    center: If `True`, add offset of `beta` to normalized tensor.\n        If `False`, `beta` is ignored. Defaults to `True`.\n    scale: If `True`, multiply by `gamma`. If `False`, `gamma` is not used.\n        When the next layer is linear (also e.g. `relu`), this can be\n        disabled since the scaling will be done by the next layer.\n        Defaults to `True`.\n    beta_initializer: Initializer for the beta weight. Defaults to zeros.\n    gamma_initializer: Initializer for the gamma weight. Defaults to ones.\n    beta_regularizer: Optional regularizer for the beta weight. None by\n        default.\n    gamma_regularizer: Optional regularizer for the gamma weight. None by\n        default.\n    beta_constraint: Optional constraint for the beta weight.\n        None by default.\n    gamma_constraint: Optional constraint for the gamma weight. None by\n        default.  Input shape: Arbitrary. Use the keyword argument\n        `input_shape` (tuple of integers, does not include the samples\n        axis) when using this layer as the first layer in a model.\n        Output shape: Same shape as input.\n    **kwargs: Base layer keyword arguments (e.g. `name` and `dtype`).\n\nReference:\n\n- [Yuxin Wu & Kaiming He, 2018](https://arxiv.org/abs/1803.08494)",
        "has_varargs": false,
        "kind": "class",
        "name": "GroupNormalization",
        "params": [
          {
            "annotation": null,
            "default": "32",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "groups"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "center"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "scale"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_initializer"
          },
          {
            "annotation": null,
            "default": "ones",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.GroupQueryAttention",
        "docstring": "Grouped Query Attention layer.\n\nThis is an implementation of grouped-query attention introduced by\n[Ainslie et al., 2023](https://arxiv.org/abs/2305.13245). Here\n`num_key_value_heads` denotes number of groups, setting\n`num_key_value_heads` to 1 is equivalent to multi-query attention, and\nwhen `num_key_value_heads` is equal to `num_query_heads` it is equivalent\nto multi-head attention.\n\nThis layer first projects `query`, `key`, and `value` tensors. Then, `key`\nand `value` are repeated to match the number of heads of `query`.\n\nThen, the `query` is scaled and dot-producted with `key` tensors. These are\nsoftmaxed to obtain attention probabilities. The value tensors are then\ninterpolated by these probabilities and concatenated back to a single\ntensor.\n\nArgs:\n    head_dim: Size of each attention head.\n    num_query_heads: Number of query attention heads.\n    num_key_value_heads: Number of key and value attention heads.\n    dropout: Dropout probability.\n    use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n    flash_attention: If `None`, the layer attempts to use flash\n        attention for faster and more memory-efficient attention\n        computations when possible. This behavior can be configured using\n        `keras.config.enable_flash_attention()` or\n        `keras.config.disable_flash_attention()`.\n    kernel_initializer: Initializer for dense layer kernels.\n    bias_initializer: Initializer for dense layer biases.\n    kernel_regularizer: Regularizer for dense layer kernels.\n    bias_regularizer: Regularizer for dense layer biases.\n    activity_regularizer: Regularizer for dense layer activity.\n    kernel_constraint: Constraint for dense layer kernels.\n    bias_constraint: Constraint for dense layer kernels.\n    seed: Optional integer to seed the dropout layer.\n\nCall arguments:\n    query: Query tensor of shape `(batch_dim, target_seq_len, feature_dim)`,\n        where `batch_dim` is batch size, `target_seq_len` is the length of\n        target sequence, and `feature_dim` is dimension of feature.\n    value: Value tensor of shape `(batch_dim, source_seq_len, feature_dim)`,\n        where `batch_dim` is batch size, `source_seq_len` is the length of\n        source sequence, and `feature_dim` is dimension of feature.\n    key: Optional key tensor of shape\n        `(batch_dim, source_seq_len, feature_dim)`. If not given, will use\n        `value` for both `key` and `value`, which is most common case.\n    attention_mask: A boolean mask of shape\n        `(batch_dim, target_seq_len, source_seq_len)`, that prevents\n        attention to certain positions. The boolean mask specifies which\n        query elements can attend to which key elements, where 1 indicates\n        attention and 0 indicates no attention. Broadcasting can happen for\n        the missing batch dimensions and the head dimension.\n    return_attention_scores: A boolean to indicate whether the output\n        should be `(attention_output, attention_scores)` if `True`, or\n        `attention_output` if `False`. Defaults to `False`.\n    training: Python boolean indicating whether the layer should behave in\n        training mode (adding dropout) or in inference mode (no dropout).\n        Will go with either using the training mode of the parent\n        layer/model or `False` (inference) if there is no parent layer.\n    use_causal_mask: A boolean to indicate whether to apply a causal mask to\n        prevent tokens from attending to future tokens (e.g., used in a\n        decoder Transformer).\n\nReturns:\n    attention_output: Result of the computation, of shape\n        `(batch_dim, target_seq_len, feature_dim)`, where `target_seq_len`\n        is for target sequence length and `feature_dim` is the query input\n        last dim.\n    attention_scores: (Optional) attention coefficients of shape\n        `(batch_dim, num_query_heads, target_seq_len, source_seq_len)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "GroupedQueryAttention",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "head_dim"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_query_heads"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_key_value_heads"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "flash_attention"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.HashedCrossing",
        "docstring": "A preprocessing layer which crosses features using the \"hashing trick\".\n\nThis layer performs crosses of categorical features using the \"hashing\ntrick\". Conceptually, the transformation can be thought of as:\n`hash(concatenate(features)) % num_bins`.\n\nThis layer currently only performs crosses of scalar inputs and batches of\nscalar inputs. Valid input shapes are `(batch_size, 1)`, `(batch_size,)` and\n`()`.\n\n**Note:** This layer wraps `tf.keras.layers.HashedCrossing`. It cannot\nbe used as part of the compiled computation graph of a model with\nany backend other than TensorFlow.\nIt can however be used with any backend when running eagerly.\nIt can also always be used as part of an input preprocessing pipeline\nwith any backend (outside the model itself), which is how we recommend\nto use this layer.\n\n**Note:** This layer is safe to use inside a `tf.data` pipeline\n(independently of which backend you're using).\n\nArgs:\n    num_bins: Number of hash bins.\n    output_mode: Specification for the output of the layer. Values can be\n        `\"int\"`, or `\"one_hot\"` configuring the layer as follows:\n        - `\"int\"`: Return the integer bin indices directly.\n        - `\"one_hot\"`: Encodes each individual element in the input into an\n            array the same size as `num_bins`, containing a 1 at the input's\n            bin index. Defaults to `\"int\"`.\n    sparse: Boolean. Only applicable to `\"one_hot\"` mode and only valid\n        when using the TensorFlow backend. If `True`, returns\n        a `SparseTensor` instead of a dense `Tensor`. Defaults to `False`.\n    **kwargs: Keyword arguments to construct a layer.\n\nExamples:\n\n**Crossing two scalar features.**\n\n>>> layer = keras.layers.HashedCrossing(\n...     num_bins=5)\n>>> feat1 = np.array(['A', 'B', 'A', 'B', 'A'])\n>>> feat2 = np.array([101, 101, 101, 102, 102])\n>>> layer((feat1, feat2))\narray([1, 4, 1, 1, 3])\n\n**Crossing and one-hotting two scalar features.**\n\n>>> layer = keras.layers.HashedCrossing(\n...     num_bins=5, output_mode='one_hot')\n>>> feat1 = np.array(['A', 'B', 'A', 'B', 'A'])\n>>> feat2 = np.array([101, 101, 101, 102, 102])\n>>> layer((feat1, feat2))\narray([[0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 1., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 0., 1., 0.]], dtype=float32)",
        "has_varargs": false,
        "kind": "class",
        "name": "HashedCrossing",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_bins"
          },
          {
            "annotation": null,
            "default": "int",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_mode"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sparse"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Hashing",
        "docstring": "A preprocessing layer which hashes and bins categorical features.\n\nThis layer transforms categorical inputs to hashed output. It element-wise\nconverts a ints or strings to ints in a fixed range. The stable hash\nfunction uses `tensorflow::ops::Fingerprint` to produce the same output\nconsistently across all platforms.\n\nThis layer uses [FarmHash64](https://github.com/google/farmhash) by default,\nwhich provides a consistent hashed output across different platforms and is\nstable across invocations, regardless of device and context, by mixing the\ninput bits thoroughly.\n\nIf you want to obfuscate the hashed output, you can also pass a random\n`salt` argument in the constructor. In that case, the layer will use the\n[SipHash64](https://github.com/google/highwayhash) hash function, with\nthe `salt` value serving as additional input to the hash function.\n\n**Note:** This layer internally uses TensorFlow. It cannot\nbe used as part of the compiled computation graph of a model with\nany backend other than TensorFlow.\nIt can however be used with any backend when running eagerly.\nIt can also always be used as part of an input preprocessing pipeline\nwith any backend (outside the model itself), which is how we recommend\nto use this layer.\n\n**Note:** This layer is safe to use inside a `tf.data` pipeline\n(independently of which backend you're using).\n\n**Example (FarmHash64)**\n\n>>> layer = keras.layers.Hashing(num_bins=3)\n>>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]\n>>> layer(inp)\narray([[1],\n        [0],\n        [1],\n        [1],\n        [2]])>\n\n**Example (FarmHash64) with a mask value**\n\n>>> layer = keras.layers.Hashing(num_bins=3, mask_value='')\n>>> inp = [['A'], ['B'], [''], ['C'], ['D']]\n>>> layer(inp)\narray([[1],\n        [1],\n        [0],\n        [2],\n        [2]])\n\n**Example (SipHash64)**\n\n>>> layer = keras.layers.Hashing(num_bins=3, salt=[133, 137])\n>>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]\n>>> layer(inp)\narray([[1],\n        [2],\n        [1],\n        [0],\n        [2]])\n\n**Example (Siphash64 with a single integer, same as `salt=[133, 133]`)**\n\n>>> layer = keras.layers.Hashing(num_bins=3, salt=133)\n>>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]\n>>> layer(inp)\narray([[0],\n        [0],\n        [2],\n        [1],\n        [0]])\n\nArgs:\n    num_bins: Number of hash bins. Note that this includes the `mask_value`\n        bin, so the effective number of bins is `(num_bins - 1)`\n        if `mask_value` is set.\n    mask_value: A value that represents masked inputs, which are mapped to\n        index 0. `None` means no mask term will be added and the\n        hashing will start at index 0. Defaults to `None`.\n    salt: A single unsigned integer or None.\n        If passed, the hash function used will be SipHash64,\n        with these values used as an additional input\n        (known as a \"salt\" in cryptography).\n        These should be non-zero. If `None`, uses the FarmHash64 hash\n        function. It also supports tuple/list of 2 unsigned\n        integer numbers, see reference paper for details.\n        Defaults to `None`.\n    output_mode: Specification for the output of the layer. Values can be\n        `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or\n        `\"count\"` configuring the layer as follows:\n        - `\"int\"`: Return the integer bin indices directly.\n        - `\"one_hot\"`: Encodes each individual element in the input into an\n            array the same size as `num_bins`, containing a 1\n            at the input's bin index. If the last dimension is size 1,\n            will encode on that dimension.\n            If the last dimension is not size 1, will append a new\n            dimension for the encoded output.\n        - `\"multi_hot\"`: Encodes each sample in the input into a\n            single array the same size as `num_bins`,\n            containing a 1 for each bin index\n            index present in the sample. Treats the last dimension\n            as the sample dimension, if input shape is\n            `(..., sample_length)`, output shape will be\n            `(..., num_tokens)`.\n        - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of\n            the number of times the bin index appeared in the sample.\n        Defaults to `\"int\"`.\n    sparse: Boolean. Only applicable to `\"one_hot\"`, `\"multi_hot\"`,\n        and `\"count\"` output modes. Only supported with TensorFlow\n        backend. If `True`, returns a `SparseTensor` instead of\n        a dense `Tensor`. Defaults to `False`.\n    **kwargs: Keyword arguments to construct a layer.\n\nInput shape:\n    A single string, a list of strings, or an `int32` or `int64` tensor\n    of shape `(batch_size, ...,)`.\n\nOutput shape:\n    An `int32` tensor of shape `(batch_size, ...)`.\n\nReference:\n\n- [SipHash with salt](https://www.131002.net/siphash/siphash.pdf)",
        "has_varargs": false,
        "kind": "class",
        "name": "Hashing",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_bins"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mask_value"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "salt"
          },
          {
            "annotation": null,
            "default": "int",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_mode"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sparse"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Identity",
        "docstring": "Identity layer.\n\nThis layer should be used as a placeholder when no operation is to be\nperformed. The layer just returns its `inputs` argument as output.",
        "has_varargs": false,
        "kind": "class",
        "name": "Identity",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.InputLayer",
        "docstring": "This is the class from which all layers inherit.\n\nA layer is a callable object that takes as input one or more tensors and\nthat outputs one or more tensors. It involves *computation*, defined\nin the `call()` method, and a *state* (weight variables). State can be\ncreated:\n\n* in `__init__()`, for instance via `self.add_weight()`;\n* in the optional `build()` method, which is invoked by the first\n  `__call__()` to the layer, and supplies the shape(s) of the input(s),\n  which may not have been known at initialization time.\n\nLayers are recursively composable: If you assign a Layer instance as an\nattribute of another Layer, the outer layer will start tracking the weights\ncreated by the inner layer. Nested layers should be instantiated in the\n`__init__()` method or `build()` method.\n\nUsers will just instantiate a layer and then treat it as a callable.\n\nArgs:\n    trainable: Boolean, whether the layer's variables should be trainable.\n    name: String name of the layer.\n    dtype: The dtype of the layer's computations and weights. Can also be a\n        `keras.DTypePolicy`, which allows the computation and weight dtype\n        to differ. Defaults to `None`. `None` means to use\n        `keras.config.dtype_policy()`, which is a `float32` policy unless\n        set to different value (via `keras.config.set_dtype_policy()`).\n\nAttributes:\n    name: The name of the layer (string).\n    dtype: Dtype of the layer's weights. Alias of `layer.variable_dtype`.\n    variable_dtype: Dtype of the layer's weights.\n    compute_dtype: The dtype of the layer's computations.\n        Layers automatically cast inputs to this dtype, which causes\n        the computations and output to also be in this dtype.\n        When mixed precision is used with a\n        `keras.DTypePolicy`, this will be different\n        than `variable_dtype`.\n    trainable_weights: List of variables to be included in backprop.\n    non_trainable_weights: List of variables that should not be\n        included in backprop.\n    weights: The concatenation of the lists trainable_weights and\n        non_trainable_weights (in this order).\n    trainable: Whether the layer should be trained (boolean), i.e.\n        whether its potentially-trainable weights should be returned\n        as part of `layer.trainable_weights`.\n    input_spec: Optional (list of) `InputSpec` object(s) specifying the\n        constraints on inputs that can be accepted by the layer.\n\nWe recommend that descendants of `Layer` implement the following methods:\n\n* `__init__()`: Defines custom layer attributes, and creates layer weights\n    that do not depend on input shapes, using `add_weight()`,\n    or other state.\n* `build(self, input_shape)`: This method can be used to create weights that\n    depend on the shape(s) of the input(s), using `add_weight()`, or other\n    state. `__call__()` will automatically build the layer\n    (if it has not been built yet) by calling `build()`.\n* `call(self, *args, **kwargs)`: Called in `__call__` after making\n    sure `build()` has been called. `call()` performs the logic of applying\n    the layer to the input arguments.\n    Two reserved keyword arguments you can optionally use in `call()` are:\n        1. `training` (boolean, whether the call is in inference mode or\n            training mode).\n        2. `mask` (boolean tensor encoding masked timesteps in the input,\n            used e.g. in RNN layers).\n    A typical signature for this method is `call(self, inputs)`, and user\n    could optionally add `training` and `mask` if the layer need them.\n* `get_config(self)`: Returns a dictionary containing the configuration\n    used to initialize this layer. If the keys differ from the arguments\n    in `__init__()`, then override `from_config(self)` as well.\n    This method is used when saving\n    the layer or a model that contains this layer.\n\nExamples:\n\nHere's a basic example: a layer with two variables, `w` and `b`,\nthat returns `y = w . x + b`.\nIt shows how to implement `build()` and `call()`.\nVariables set as attributes of a layer are tracked as weights\nof the layers (in `layer.weights`).\n\n```python\nclass SimpleDense(Layer):\n    def __init__(self, units=32):\n        super().__init__()\n        self.units = units\n\n    # Create the state of the layer (weights)\n    def build(self, input_shape):\n        self.kernel = self.add_weight(\n            shape=(input_shape[-1], self.units),\n            initializer=\"glorot_uniform\",\n            trainable=True,\n            name=\"kernel\",\n        )\n        self.bias = self.add_weight(\n            shape=(self.units,),\n            initializer=\"zeros\",\n            trainable=True,\n            name=\"bias\",\n        )\n\n    # Defines the computation\n    def call(self, inputs):\n        return ops.matmul(inputs, self.kernel) + self.bias\n\n# Instantiates the layer.\nlinear_layer = SimpleDense(4)\n\n# This will also call `build(input_shape)` and create the weights.\ny = linear_layer(ops.ones((2, 2)))\nassert len(linear_layer.weights) == 2\n\n# These weights are trainable, so they're listed in `trainable_weights`:\nassert len(linear_layer.trainable_weights) == 2\n```\n\nBesides trainable weights, updated via backpropagation during training,\nlayers can also have non-trainable weights. These weights are meant to\nbe updated manually during `call()`. Here's a example layer that computes\nthe running sum of its inputs:\n\n```python\nclass ComputeSum(Layer):\n\n  def __init__(self, input_dim):\n      super(ComputeSum, self).__init__()\n      # Create a non-trainable weight.\n      self.total = self.add_weight(\n        shape=(),\n        initializer=\"zeros\",\n        trainable=False,\n        name=\"total\",\n      )\n\n  def call(self, inputs):\n      self.total.assign(self.total + ops.sum(inputs))\n      return self.total\n\nmy_sum = ComputeSum(2)\nx = ops.ones((2, 2))\ny = my_sum(x)\n\nassert my_sum.weights == [my_sum.total]\nassert my_sum.non_trainable_weights == [my_sum.total]\nassert my_sum.trainable_weights == []\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "InputLayer",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "shape"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "batch_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sparse"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ragged"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "batch_shape"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "input_tensor"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "optional"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.InputSpec",
        "docstring": "Specifies the rank, dtype and shape of every input to a layer.\n\nLayers can expose (if appropriate) an `input_spec` attribute:\nan instance of `InputSpec`, or a nested structure of `InputSpec` instances\n(one per input tensor). These objects enable the layer to run input\ncompatibility checks for input structure, input rank, input shape, and\ninput dtype for the first argument of `Layer.__call__`.\n\nA `None` entry in a shape is compatible with any dimension.\n\nArgs:\n    dtype: Expected dtype of the input.\n    shape: Shape tuple, expected shape of the input\n        (may include `None` for dynamic axes).\n        Includes the batch size.\n    ndim: Integer, expected rank of the input.\n    max_ndim: Integer, maximum rank of the input.\n    min_ndim: Integer, minimum rank of the input.\n    axes: Dictionary mapping integer axes to\n        a specific dimension value.\n    allow_last_axis_squeeze: If `True`, allow inputs of rank N+1 as long\n        as the last axis of the input is 1, as well as inputs of rank N-1\n        as long as the last axis of the spec is 1.\n    name: Expected key corresponding to this input when passing data as\n        a dictionary.\n    optional: Boolean, whether the input is optional or not.\n        An optional input can accept `None` values.\n\nExample:\n\n```python\nclass MyLayer(Layer):\n    def __init__(self):\n        super().__init__()\n        # The layer will accept inputs with\n        # shape (*, 28, 28) & (*, 28, 28, 1)\n        # and raise an appropriate error message otherwise.\n        self.input_spec = InputSpec(\n            shape=(None, 28, 28, 1),\n            allow_last_axis_squeeze=True)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "InputSpec",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "shape"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ndim"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "max_ndim"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "min_ndim"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axes"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "allow_last_axis_squeeze"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "optional"
          }
        ]
      },
      {
        "api_path": "keras.layers.IntegerLookup",
        "docstring": "A preprocessing layer that maps integers to (possibly encoded) indices.\n\nThis layer maps a set of arbitrary integer input tokens into indexed integer\noutput via a table-based vocabulary lookup. The layer's output indices will\nbe contiguously arranged up to the maximum vocab size, even if the input\ntokens are non-continguous or unbounded. The layer supports multiple options\nfor encoding the output via `output_mode`, and has optional support for\nout-of-vocabulary (OOV) tokens and masking.\n\nThe vocabulary for the layer must be either supplied on construction or\nlearned via `adapt()`. During `adapt()`, the layer will analyze a data set,\ndetermine the frequency of individual integer tokens, and create a\nvocabulary from them. If the vocabulary is capped in size, the most frequent\ntokens will be used to create the vocabulary and all others will be treated\nas OOV.\n\nThere are two possible output modes for the layer.  When `output_mode` is\n`\"int\"`, input integers are converted to their index in the vocabulary (an\ninteger).  When `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`,\ninput integers are encoded into an array where each dimension corresponds to\nan element in the vocabulary.\n\nThe vocabulary can optionally contain a mask token as well as an OOV token\n(which can optionally occupy multiple indices in the vocabulary, as set\nby `num_oov_indices`).\nThe position of these tokens in the vocabulary is fixed. When `output_mode`\nis `\"int\"`, the vocabulary will begin with the mask token at index 0,\nfollowed by OOV indices, followed by the rest of the vocabulary. When\n`output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` the vocabulary will\nbegin with OOV indices and instances of the mask token will be dropped.\n\n**Note:** This layer uses TensorFlow internally. It cannot\nbe used as part of the compiled computation graph of a model with\nany backend other than TensorFlow.\nIt can however be used with any backend when running eagerly.\nIt can also always be used as part of an input preprocessing pipeline\nwith any backend (outside the model itself), which is how we recommend\nto use this layer.\n\n**Note:** This layer is safe to use inside a `tf.data` pipeline\n(independently of which backend you're using).\n\nArgs:\n    max_tokens: Maximum size of the vocabulary for this layer. This should\n        only be specified when adapting the vocabulary or when setting\n        `pad_to_max_tokens=True`. If None, there is no cap on the size of\n        the vocabulary. Note that this size includes the OOV\n        and mask tokens. Defaults to `None`.\n    num_oov_indices: The number of out-of-vocabulary tokens to use.\n        If this value is more than 1, OOV inputs are modulated to\n        determine their OOV value.\n        If this value is 0, OOV inputs will cause an error when calling\n        the layer. Defaults to `1`.\n    mask_token: An integer token that represents masked inputs. When\n        `output_mode` is `\"int\"`, the token is included in vocabulary\n        and mapped to index 0. In other output modes,\n        the token will not appear in the vocabulary and instances\n        of the mask token in the input will be dropped.\n        If set to None, no mask term will be added. Defaults to `None`.\n    oov_token: Only used when `invert` is `True`. The token to return\n        for OOV indices. Defaults to `-1`.\n    vocabulary: Optional. Either an array of integers or a string path to a\n        text file. If passing an array, can pass a tuple, list,\n        1D NumPy array, or 1D tensor containing the integer vocbulary terms.\n        If passing a file path, the file should contain one line per term\n        in the vocabulary. If this argument is set,\n        there is no need to `adapt()` the layer.\n    vocabulary_dtype: The dtype of the vocabulary terms.\n        Only `vocabulary_dtype='int64'` is supported at this time.\n        Defaults to `\"int64\"`.\n    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`.\n        A tuple, list, 1D NumPy array, or 1D tensor or the same length\n        as the vocabulary, containing the floating point inverse document\n        frequency weights, which will be multiplied by per sample term\n        counts for the final TF-IDF weight.\n        If the `vocabulary` argument is set, and `output_mode` is\n        `\"tf_idf\"`, this argument must be supplied.\n    invert: Only valid when `output_mode` is `\"int\"`.\n        If `True`, this layer will map indices to vocabulary items\n        instead of mapping vocabulary items to indices.\n        Defaults to `False`.\n    output_mode: Specification for the output of the layer. Values can be\n        `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`\n        configuring the layer as follows:\n        - `\"int\"`: Return the vocabulary indices of the input tokens.\n        - `\"one_hot\"`: Encodes each individual element in the input into an\n            array the same size as the vocabulary,\n            containing a 1 at the element index. If the last dimension\n            is size 1, will encode on that dimension.\n            If the last dimension is not size 1, will append a new\n            dimension for the encoded output.\n        - `\"multi_hot\"`: Encodes each sample in the input into a single\n            array the same size as the vocabulary,\n            containing a 1 for each vocabulary term present in the sample.\n            Treats the last dimension as the sample dimension,\n            if input shape is `(..., sample_length)`,\n            output shape will be `(..., num_tokens)`.\n        - `\"count\"`: As `\"multi_hot\"`, but the int array contains\n            a count of the number of times the token at that index\n            appeared in the sample.\n        - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is\n            applied to find the value in each token slot.\n        For `\"int\"` output, the output shape matches the input shape.\n        For `\"one_hot\"` output, the output shape is\n        `input_shape + (vocabulary_size,)`, where `input_shape` may\n        have arbitrary rank. For other output modes (`\"multi_hot\"`,\n        `\"count\"`, `\"tf_idf\"`), the output shape is `(batch_size,\n        vocabulary_size)`. Defaults to `\"int\"`.\n    pad_to_max_tokens: Only applicable when `output_mode` is `\"multi_hot\"`,\n        `\"count\"`, or `\"tf_idf\"`. If `True`, the output will have\n        its feature axis padded to `max_tokens` even if the number\n        of unique tokens in the vocabulary is less than `max_tokens`,\n        resulting in a tensor of shape `(batch_size, max_tokens)`\n        regardless of vocabulary size. Defaults to `False`.\n    sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n        `\"tf_idf\"` output modes. Only supported with TensorFlow\n        backend. If `True`, returns a `SparseTensor`\n        instead of a dense `Tensor`. Defaults to `False`.\n\nExamples:\n\n**Creating a lookup layer with a known vocabulary**\n\nThis example creates a lookup layer with a pre-existing vocabulary.\n\n>>> vocab = [12, 36, 1138, 42]\n>>> data = np.array([[12, 1138, 42], [42, 1000, 36]])  # Note OOV tokens\n>>> layer = IntegerLookup(vocabulary=vocab)\n>>> layer(data)\narray([[1, 3, 4],\n       [4, 0, 2]])\n\n**Creating a lookup layer with an adapted vocabulary**\n\nThis example creates a lookup layer and generates the vocabulary by\nanalyzing the dataset.\n\n>>> data = np.array([[12, 1138, 42], [42, 1000, 36]])\n>>> layer = IntegerLookup()\n>>> layer.adapt(data)\n>>> layer.get_vocabulary()\n[-1, 42, 1138, 1000, 36, 12]\n\nNote that the OOV token -1 have been added to the vocabulary. The remaining\ntokens are sorted by frequency (42, which has 2 occurrences, is first) then\nby inverse sort order.\n\n>>> data = np.array([[12, 1138, 42], [42, 1000, 36]])\n>>> layer = IntegerLookup()\n>>> layer.adapt(data)\n>>> layer(data)\narray([[5, 2, 1],\n       [1, 3, 4]])\n\n**Lookups with multiple OOV indices**\n\nThis example demonstrates how to use a lookup layer with multiple OOV\nindices.  When a layer is created with more than one OOV index, any OOV\ntokens are hashed into the number of OOV buckets, distributing OOV tokens in\na deterministic fashion across the set.\n\n>>> vocab = [12, 36, 1138, 42]\n>>> data = np.array([[12, 1138, 42], [37, 1000, 36]])\n>>> layer = IntegerLookup(vocabulary=vocab, num_oov_indices=2)\n>>> layer(data)\narray([[2, 4, 5],\n       [1, 0, 3]])\n\nNote that the output for OOV token 37 is 1, while the output for OOV token\n1000 is 0. The in-vocab terms have their output index increased by 1 from\nearlier examples (12 maps to 2, etc) in order to make space for the extra\nOOV token.\n\n**One-hot output**\n\nConfigure the layer with `output_mode='one_hot'`. Note that the first\n`num_oov_indices` dimensions in the ont_hot encoding represent OOV values.\n\n>>> vocab = [12, 36, 1138, 42]\n>>> data = np.array([12, 36, 1138, 42, 7])  # Note OOV tokens\n>>> layer = IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n>>> layer(data)\narray([[0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1.],\n        [1., 0., 0., 0., 0.]], dtype=float32)\n\n**Multi-hot output**\n\nConfigure the layer with `output_mode='multi_hot'`. Note that the first\n`num_oov_indices` dimensions in the multi_hot encoding represent OOV tokens\n\n>>> vocab = [12, 36, 1138, 42]\n>>> data = np.array([[12, 1138, 42, 42],\n...                  [42,    7, 36,  7]])  # Note OOV tokens\n>>> layer = IntegerLookup(vocabulary=vocab, output_mode='multi_hot')\n>>> layer(data)\narray([[0., 1., 0., 1., 1.],\n       [1., 0., 1., 0., 1.]], dtype=float32)\n\n**Token count output**\n\nConfigure the layer with `output_mode='count'`. As with multi_hot output,\nthe first `num_oov_indices` dimensions in the output represent OOV tokens.\n\n>>> vocab = [12, 36, 1138, 42]\n>>> data = np.array([[12, 1138, 42, 42],\n...                  [42,    7, 36,  7]])  # Note OOV tokens\n>>> layer = IntegerLookup(vocabulary=vocab, output_mode='count')\n>>> layer(data)\narray([[0., 1., 0., 1., 2.],\n       [2., 0., 1., 0., 1.]], dtype=float32)\n\n**TF-IDF output**\n\nConfigure the layer with `output_mode='tf_idf'`. As with multi_hot output,\nthe first `num_oov_indices` dimensions in the output represent OOV tokens.\n\nEach token bin will output `token_count * idf_weight`, where the idf weights\nare the inverse document frequency weights per token. These should be\nprovided along with the vocabulary. Note that the `idf_weight` for OOV\ntokens will default to the average of all idf weights passed in.\n\n>>> vocab = [12, 36, 1138, 42]\n>>> idf_weights = [0.25, 0.75, 0.6, 0.4]\n>>> data = np.array([[12, 1138, 42, 42],\n...                  [42,    7, 36,  7]])  # Note OOV tokens\n>>> layer = IntegerLookup(\n...     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)\n>>> layer(data)\narray([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n        [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)\n\nTo specify the idf weights for oov tokens, you will need to pass the entire\nvocabulary including the leading oov token.\n\n>>> vocab = [-1, 12, 36, 1138, 42]\n>>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]\n>>> data = np.array([[12, 1138, 42, 42],\n...                  [42,    7, 36,  7]])  # Note OOV tokens\n>>> layer = IntegerLookup(\n...     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)\n>>> layer(data)\narray([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n        [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)\n\nWhen adapting the layer in `\"tf_idf\"` mode, each input sample will\nbe considered a document, and IDF weight per token will be\ncalculated as:\n`log(1 + num_documents / (1 + token_document_count))`.\n\n**Inverse lookup**\n\nThis example demonstrates how to map indices to tokens using this layer.\n(You can also use `adapt()` with `inverse=True`, but for simplicity we'll\npass the vocab in this example.)\n\n>>> vocab = [12, 36, 1138, 42]\n>>> data = np.array([[1, 3, 4], [4, 0, 2]])\n>>> layer = IntegerLookup(vocabulary=vocab, invert=True)\n>>> layer(data)\narray([[  12, 1138,   42],\n       [  42,   -1,   36]])\n\nNote that the first index correspond to the oov token by default.\n\n**Forward and inverse lookup pairs**\n\nThis example demonstrates how to use the vocabulary of a standard lookup\nlayer to create an inverse lookup layer.\n\n>>> vocab = [12, 36, 1138, 42]\n>>> data = np.array([[12, 1138, 42], [42, 1000, 36]])\n>>> layer = IntegerLookup(vocabulary=vocab)\n>>> i_layer = IntegerLookup(\n...     vocabulary=layer.get_vocabulary(), invert=True)\n>>> int_data = layer(data)\n>>> i_layer(int_data)\narray([[  12, 1138,   42],\n       [  42,   -1,   36]])\n\nIn this example, the input token 1000 resulted in an output of -1, since\n1000 was not in the vocabulary - it got represented as an OOV, and all OOV\ntokens are returned as -1 in the inverse layer. Also, note that for the\ninverse to work, you must have already set the forward layer vocabulary\neither directly or via `adapt()` before calling `get_vocabulary()`.",
        "has_varargs": false,
        "kind": "class",
        "name": "IntegerLookup",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "max_tokens"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_oov_indices"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mask_token"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "oov_token"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "vocabulary"
          },
          {
            "annotation": null,
            "default": "int64",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "vocabulary_dtype"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "idf_weights"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "invert"
          },
          {
            "annotation": null,
            "default": "int",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_mode"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sparse"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pad_to_max_tokens"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.JaxLayer",
        "docstring": "Keras Layer that wraps a JAX model.\n\nThis layer enables the use of JAX components within Keras when using JAX as\nthe backend for Keras.\n\n## Model function\n\nThis layer accepts JAX models in the form of a function, `call_fn`, which\nmust take the following arguments with these exact names:\n\n- `params`: trainable parameters of the model.\n- `state` (*optional*): non-trainable state of the model. Can be omitted if\n    the model has no non-trainable state.\n- `rng` (*optional*): a `jax.random.PRNGKey` instance. Can be omitted if the\n    model does not need RNGs, neither during training nor during inference.\n- `inputs`: inputs to the model, a JAX array or a `PyTree` of arrays.\n- `training` (*optional*): an argument specifying if we're in training mode\n    or inference mode, `True` is passed in training mode. Can be omitted if\n    the model behaves the same in training mode and inference mode.\n\nThe `inputs` argument is mandatory. Inputs to the model must be provided via\na single argument. If the JAX model takes multiple inputs as separate\narguments, they must be combined into a single structure, for instance in a\n`tuple` or a `dict`.\n\n## Model weights initialization\n\nThe initialization of the `params` and `state` of the model can be handled\nby this layer, in which case the `init_fn` argument must be provided. This\nallows the model to be initialized dynamically with the right shape.\nAlternatively, and if the shape is known, the `params` argument and\noptionally the `state` argument can be used to create an already initialized\nmodel.\n\nThe `init_fn` function, if provided, must take the following arguments with\nthese exact names:\n\n- `rng`: a `jax.random.PRNGKey` instance.\n- `inputs`: a JAX array or a `PyTree` of arrays with placeholder values to\n    provide the shape of the inputs.\n- `training` (*optional*): an argument specifying if we're in training mode\n    or inference mode. `True` is always passed to `init_fn`. Can be omitted\n    regardless of whether `call_fn` has a `training` argument.\n\n## Models with non-trainable state\n\nFor JAX models that have non-trainable state:\n\n- `call_fn` must have a `state` argument\n- `call_fn` must return a `tuple` containing the outputs of the model and\n    the new non-trainable state of the model\n- `init_fn` must return a `tuple` containing the initial trainable params of\n    the model and the initial non-trainable state of the model.\n\nThis code shows a possible combination of `call_fn` and `init_fn` signatures\nfor a model with non-trainable state. In this example, the model has a\n`training` argument and an `rng` argument in `call_fn`.\n\n```python\ndef stateful_call(params, state, rng, inputs, training):\n    outputs = ...\n    new_state = ...\n    return outputs, new_state\n\ndef stateful_init(rng, inputs):\n    initial_params = ...\n    initial_state = ...\n    return initial_params, initial_state\n```\n\n## Models without non-trainable state\n\nFor JAX models with no non-trainable state:\n\n- `call_fn` must not have a `state` argument\n- `call_fn` must return only the outputs of the model\n- `init_fn` must return only the initial trainable params of the model.\n\nThis code shows a possible combination of `call_fn` and `init_fn` signatures\nfor a model without non-trainable state. In this example, the model does not\nhave a `training` argument and does not have an `rng` argument in `call_fn`.\n\n```python\ndef stateless_call(params, inputs):\n    outputs = ...\n    return outputs\n\ndef stateless_init(rng, inputs):\n    initial_params = ...\n    return initial_params\n```\n\n## Conforming to the required signature\n\nIf a model has a different signature than the one required by `JaxLayer`,\none can easily write a wrapper method to adapt the arguments. This example\nshows a model that has multiple inputs as separate arguments, expects\nmultiple RNGs in a `dict`, and has a `deterministic` argument with the\nopposite meaning of `training`. To conform, the inputs are combined in a\nsingle structure using a `tuple`, the RNG is split and used the populate the\nexpected `dict`, and the Boolean flag is negated:\n\n```python\ndef my_model_fn(params, rngs, input1, input2, deterministic):\n    ...\n    if not deterministic:\n        dropout_rng = rngs[\"dropout\"]\n        keep = jax.random.bernoulli(dropout_rng, dropout_rate, x.shape)\n        x = jax.numpy.where(keep, x / dropout_rate, 0)\n        ...\n    ...\n    return outputs\n\ndef my_model_wrapper_fn(params, rng, inputs, training):\n    input1, input2 = inputs\n    rng1, rng2 = jax.random.split(rng)\n    rngs = {\"dropout\": rng1, \"preprocessing\": rng2}\n    deterministic = not training\n    return my_model_fn(params, rngs, input1, input2, deterministic)\n\nkeras_layer = JaxLayer(my_model_wrapper_fn, params=initial_params)\n```\n\n## Usage with Haiku modules\n\n`JaxLayer` enables the use of [Haiku](https://dm-haiku.readthedocs.io)\ncomponents in the form of\n[`haiku.Module`](https://dm-haiku.readthedocs.io/en/latest/api.html#module).\nThis is achieved by transforming the module per the Haiku pattern and then\npassing `module.apply` in the `call_fn` parameter and `module.init` in the\n`init_fn` parameter if needed.\n\nIf the model has non-trainable state, it should be transformed with\n[`haiku.transform_with_state`](\n  https://dm-haiku.readthedocs.io/en/latest/api.html#haiku.transform_with_state).\nIf the model has no non-trainable state, it should be transformed with\n[`haiku.transform`](\n  https://dm-haiku.readthedocs.io/en/latest/api.html#haiku.transform).\nAdditionally, and optionally, if the module does not use RNGs in \"apply\", it\ncan be transformed with\n[`haiku.without_apply_rng`](\n  https://dm-haiku.readthedocs.io/en/latest/api.html#without-apply-rng).\n\nThe following example shows how to create a `JaxLayer` from a Haiku module\nthat uses random number generators via `hk.next_rng_key()` and takes a\ntraining positional argument:\n\n```python\nclass MyHaikuModule(hk.Module):\n    def __call__(self, x, training):\n        x = hk.Conv2D(32, (3, 3))(x)\n        x = jax.nn.relu(x)\n        x = hk.AvgPool((1, 2, 2, 1), (1, 2, 2, 1), \"VALID\")(x)\n        x = hk.Flatten()(x)\n        x = hk.Linear(200)(x)\n        if training:\n            x = hk.dropout(rng=hk.next_rng_key(), rate=0.3, x=x)\n        x = jax.nn.relu(x)\n        x = hk.Linear(10)(x)\n        x = jax.nn.softmax(x)\n        return x\n\ndef my_haiku_module_fn(inputs, training):\n    module = MyHaikuModule()\n    return module(inputs, training)\n\ntransformed_module = hk.transform(my_haiku_module_fn)\n\nkeras_layer = JaxLayer(\n    call_fn=transformed_module.apply,\n    init_fn=transformed_module.init,\n)\n```\n\nArgs:\n    call_fn: The function to call the model. See description above for the\n        list of arguments it takes and the outputs it returns.\n    init_fn: the function to call to initialize the model. See description\n        above for the list of arguments it takes and the outputs it returns.\n        If `None`, then `params` and/or `state` must be provided.\n  params: A `PyTree` containing all the model trainable parameters. This\n        allows passing trained parameters or controlling the initialization.\n        If both `params` and `state` are `None`, `init_fn` is called at\n        build time to initialize the trainable parameters of the model.\n  state: A `PyTree` containing all the model non-trainable state. This\n        allows passing learned state or controlling the initialization. If\n        both `params` and `state` are `None`, and `call_fn` takes a `state`\n        argument, then `init_fn` is called at build time to initialize the\n        non-trainable state of the model.\n  seed: Seed for random number generator. Optional.\n  dtype: The dtype of the layer's computations and weights. Can also be a\n        `keras.DTypePolicy`. Optional. Defaults to the default policy.",
        "has_varargs": false,
        "kind": "class",
        "name": "JaxLayer",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "call_fn"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "init_fn"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "params"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "state"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.LSTM",
        "docstring": "Long Short-Term Memory layer - Hochreiter 1997.\n\nBased on available runtime hardware and constraints, this layer\nwill choose different implementations (cuDNN-based or backend-native)\nto maximize the performance. If a GPU is available and all\nthe arguments to the layer meet the requirement of the cuDNN kernel\n(see below for details), the layer will use a fast cuDNN implementation\nwhen using the TensorFlow backend.\nThe requirements to use the cuDNN implementation are:\n\n1. `activation` == `tanh`\n2. `recurrent_activation` == `sigmoid`\n3. `recurrent_dropout` == 0\n4. `unroll` is `False`\n5. `use_bias` is `True`\n6. Inputs, if use masking, are strictly right-padded.\n7. Eager execution is enabled in the outermost context.\n\nFor example:\n\n>>> inputs = np.random.random((32, 10, 8))\n>>> lstm = keras.layers.LSTM(4)\n>>> output = lstm(inputs)\n>>> output.shape\n(32, 4)\n>>> lstm = keras.layers.LSTM(\n...     4, return_sequences=True, return_state=True)\n>>> whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n>>> whole_seq_output.shape\n(32, 10, 4)\n>>> final_memory_state.shape\n(32, 4)\n>>> final_carry_state.shape\n(32, 4)\n\nArgs:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n        Default: hyperbolic tangent (`tanh`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use\n        for the recurrent step.\n        Default: sigmoid (`sigmoid`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer\n        should use a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation of the recurrent\n        state. Default: `\"orthogonal\"`.\n    bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n    unit_forget_bias: Boolean (default `True`). If `True`,\n        add 1 to the bias of the forget gate at initialization.\n        Setting it to `True` will also force `bias_initializer=\"zeros\"`.\n        This is recommended in [Jozefowicz et al.](\n        https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector.\n        Default: `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n        layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector.\n        Default: `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.\n    seed: Random seed for dropout.\n    return_sequences: Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition\n        to the output. Default: `False`.\n    go_backwards: Boolean (default: `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.\n    stateful: Boolean (default: `False`). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.\n    unroll: Boolean (default False).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.\n    use_cudnn: Whether to use a cuDNN-backed implementation. `\"auto\"` will\n        attempt to use cuDNN when feasible, and will fallback to the\n        default implementation if not.\n\nCall arguments:\n    inputs: A 3D tensor, with shape `(batch, timesteps, feature)`.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n        a given timestep should be masked  (optional).\n        An individual `True` entry indicates that the corresponding timestep\n        should be utilized, while a `False` entry indicates that the\n        corresponding timestep should be ignored. Defaults to `None`.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode. This argument is passed to the\n        cell when calling it. This is only relevant if `dropout` or\n        `recurrent_dropout` is used  (optional). Defaults to `None`.\n    initial_state: List of initial state tensors to be passed to the first\n        call of the cell (optional, `None` causes creation\n        of zero-filled initial state tensors). Defaults to `None`.",
        "has_varargs": false,
        "kind": "class",
        "name": "LSTM",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "units"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "sigmoid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unit_forget_bias"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_sequences"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_state"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "go_backwards"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "stateful"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unroll"
          },
          {
            "annotation": null,
            "default": "auto",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_cudnn"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.LSTMCell",
        "docstring": "Cell class for the LSTM layer.\n\nThis class processes one step within the whole time sequence input, whereas\n`keras.layer.LSTM` processes the whole sequence.\n\nArgs:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use. Default: hyperbolic tangent\n        (`tanh`). If you pass None, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use for the recurrent step.\n        Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n        applied (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer\n        should use a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation\n        of the recurrent state. Default: `\"orthogonal\"`.\n    bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n    unit_forget_bias: Boolean (default `True`). If `True`,\n        add 1 to the bias of the forget gate at initialization.\n        Setting it to `True` will also force `bias_initializer=\"zeros\"`.\n        This is recommended in [Jozefowicz et al.](\n        https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector.\n        Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector.\n        Default: `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.\n    seed: Random seed for dropout.\n\nCall arguments:\n    inputs: A 2D tensor, with shape `(batch, features)`.\n    states: A 2D tensor with shape `(batch, units)`, which is the state\n        from the previous time step.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode. Only relevant when `dropout` or\n        `recurrent_dropout` is used.\n\nExample:\n\n>>> inputs = np.random.random((32, 10, 8))\n>>> rnn = keras.layers.RNN(keras.layers.LSTMCell(4))\n>>> output = rnn(inputs)\n>>> output.shape\n(32, 4)\n>>> rnn = keras.layers.RNN(\n...    keras.layers.LSTMCell(4),\n...    return_sequences=True,\n...    return_state=True)\n>>> whole_sequence_output, final_state = rnn(inputs)\n>>> whole_sequence_output.shape\n(32, 10, 4)\n>>> final_state.shape\n(32, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "LSTMCell",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "units"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "sigmoid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unit_forget_bias"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Lambda",
        "docstring": "Wraps arbitrary expressions as a `Layer` object.\n\nThe `Lambda` layer exists so that arbitrary expressions can be used\nas a `Layer` when constructing Sequential\nand Functional API models. `Lambda` layers are best suited for simple\noperations or quick experimentation. For more advanced use cases,\nprefer writing new subclasses of `Layer`.\n\nWARNING: `Lambda` layers have (de)serialization limitations!\n\nThe main reason to subclass `Layer` instead of using a\n`Lambda` layer is saving and inspecting a model. `Lambda` layers\nare saved by serializing the Python bytecode, which is fundamentally\nnon-portable and potentially unsafe.\nThey should only be loaded in the same environment where\nthey were saved. Subclassed layers can be saved in a more portable way\nby overriding their `get_config()` method. Models that rely on\nsubclassed Layers are also often easier to visualize and reason about.\n\nExample:\n\n```python\n# add a x -> x^2 layer\nmodel.add(Lambda(lambda x: x ** 2))\n```\n\nArgs:\n    function: The function to be evaluated. Takes input tensor as first\n        argument.\n    output_shape: Expected output shape from function. This argument\n        can usually be inferred if not explicitly provided.\n        Can be a tuple or function. If a tuple, it only specifies\n        the first dimension onward; sample dimension is assumed\n        either the same as the input:\n        `output_shape = (input_shape[0], ) + output_shape` or,\n        the input is `None` and the sample dimension is also `None`:\n        `output_shape = (None, ) + output_shape`.\n        If a function, it specifies the\n        entire shape as a function of the input shape:\n        `output_shape = f(input_shape)`.\n    mask: Either None (indicating no masking) or a callable with the same\n        signature as the `compute_mask` layer method, or a tensor\n        that will be returned as output mask regardless\n        of what the input is.\n    arguments: Optional dictionary of keyword arguments to be passed to the\n        function.",
        "has_varargs": false,
        "kind": "class",
        "name": "Lambda",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "function"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_shape"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mask"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "arguments"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.LayerNormalization",
        "docstring": "Layer normalization layer (Ba et al., 2016).\n\nNormalize the activations of the previous layer for each given example in a\nbatch independently, rather than across a batch like Batch Normalization.\ni.e. applies a transformation that maintains the mean activation within each\nexample close to 0 and the activation standard deviation close to 1.\n\nIf `scale` or `center` are enabled, the layer will scale the normalized\noutputs by broadcasting them with a trainable variable `gamma`, and center\nthe outputs by broadcasting with a trainable variable `beta`. `gamma` will\ndefault to a ones tensor and `beta` will default to a zeros tensor, so that\ncentering and scaling are no-ops before training has begun.\n\nSo, with scaling and centering enabled the normalization equations\nare as follows:\n\nLet the intermediate activations for a mini-batch to be the `inputs`.\n\nFor each sample `x_i` in `inputs` with `k` features, we compute the mean and\nvariance of the sample:\n\n```python\nmean_i = sum(x_i[j] for j in range(k)) / k\nvar_i = sum((x_i[j] - mean_i) ** 2 for j in range(k)) / k\n```\n\nand then compute a normalized `x_i_normalized`, including a small factor\n`epsilon` for numerical stability.\n\n```python\nx_i_normalized = (x_i - mean_i) / sqrt(var_i + epsilon)\n```\n\nAnd finally `x_i_normalized ` is linearly transformed by `gamma` and `beta`,\nwhich are learned parameters:\n\n```python\noutput_i = x_i_normalized * gamma + beta\n```\n\n`gamma` and `beta` will span the axes of `inputs` specified in `axis`, and\nthis part of the inputs' shape must be fully defined.\n\nFor example:\n\n>>> layer = keras.layers.LayerNormalization(axis=[1, 2, 3])\n>>> layer.build([5, 20, 30, 40])\n>>> print(layer.beta.shape)\n(20, 30, 40)\n>>> print(layer.gamma.shape)\n(20, 30, 40)\n\nNote that other implementations of layer normalization may choose to define\n`gamma` and `beta` over a separate set of axes from the axes being\nnormalized across. For example, Group Normalization\n([Wu et al. 2018](https://arxiv.org/abs/1803.08494)) with group size of 1\ncorresponds to a Layer Normalization that normalizes across height, width,\nand channel and has `gamma` and `beta` span only the channel dimension.\nSo, this Layer Normalization implementation will not match a Group\nNormalization layer with group size set to 1.\n\nArgs:\n    axis: Integer or List/Tuple. The axis or axes to normalize across.\n        Typically, this is the features axis/axes. The left-out axes are\n        typically the batch axis/axes. `-1` is the last dimension in the\n        input. Defaults to `-1`.\n    epsilon: Small float added to variance to avoid dividing by zero.\n        Defaults to 1e-3.\n    center: If True, add offset of `beta` to normalized tensor. If False,\n        `beta` is ignored. Defaults to `True`.\n    scale: If True, multiply by `gamma`. If False, `gamma` is not used.\n        When the next layer is linear (also e.g. `nn.relu`), this can be\n        disabled since the scaling will be done by the next layer.\n        Defaults to `True`.\n    beta_initializer: Initializer for the beta weight. Defaults to zeros.\n    gamma_initializer: Initializer for the gamma weight. Defaults to ones.\n    beta_regularizer: Optional regularizer for the beta weight.\n        None by default.\n    gamma_regularizer: Optional regularizer for the gamma weight.\n        None by default.\n    beta_constraint: Optional constraint for the beta weight.\n        None by default.\n    gamma_constraint: Optional constraint for the gamma weight.\n        None by default.\n    **kwargs: Base layer keyword arguments (e.g. `name` and `dtype`).\n\n\nReference:\n\n- [Lei Ba et al., 2016](https://arxiv.org/abs/1607.06450).",
        "has_varargs": false,
        "kind": "class",
        "name": "LayerNormalization",
        "params": [
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "center"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "scale"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_initializer"
          },
          {
            "annotation": null,
            "default": "ones",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.LeakyReLU",
        "docstring": "Leaky version of a Rectified Linear Unit activation layer.\n\nThis layer allows a small gradient when the unit is not active.\n\nFormula:\n\n``` python\nf(x) = alpha * x if x < 0\nf(x) = x if x >= 0\n```\n\nExample:\n\n``` python\nleaky_relu_layer = LeakyReLU(negative_slope=0.5)\ninput = np.array([-10, -5, 0.0, 5, 10])\nresult = leaky_relu_layer(input)\n# result = [-5. , -2.5,  0. ,  5. , 10.]\n```\n\nArgs:\n    negative_slope: Float >= 0.0. Negative slope coefficient.\n      Defaults to `0.3`.\n    **kwargs: Base layer keyword arguments, such as\n        `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "LeakyReLU",
        "params": [
          {
            "annotation": null,
            "default": "0.3",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "negative_slope"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Masking",
        "docstring": "Masks a sequence by using a mask value to skip timesteps.\n\nFor each timestep in the input tensor (dimension #1 in the tensor),\nif all values in the input tensor at that timestep\nare equal to `mask_value`, then the timestep will be masked (skipped)\nin all downstream layers (as long as they support masking).\n\nIf any downstream layer does not support masking yet receives such\nan input mask, an exception will be raised.\n\nExample:\n\nConsider a NumPy data array `x` of shape `(samples, timesteps, features)`,\nto be fed to an LSTM layer. You want to mask timestep #3 and #5 because you\nlack data for these timesteps. You can:\n\n- Set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`\n- Insert a `Masking` layer with `mask_value=0.` before the LSTM layer:\n\n```python\nsamples, timesteps, features = 32, 10, 8\ninputs = np.random.random([samples, timesteps, features]).astype(np.float32)\ninputs[:, 3, :] = 0.\ninputs[:, 5, :] = 0.\n\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Masking(mask_value=0.0))\nmodel.add(keras.layers.LSTM(32))\noutput = model(inputs)\n# The time step 3 and 5 will be skipped from LSTM calculation.\n```\n\nNote: in the Keras masking convention, a masked timestep is denoted by\na mask value of `False`, while a non-masked (i.e. usable) timestep\nis denoted by a mask value of `True`.",
        "has_varargs": false,
        "kind": "class",
        "name": "Masking",
        "params": [
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mask_value"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MaxNumBoundingBoxes",
        "docstring": "Ensure the maximum number of bounding boxes.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    max_number: Desired output number of bounding boxes.\n    padding_value: The padding value of the `boxes` and `labels` in\n        `bounding_boxes`. Defaults to `-1`.",
        "has_varargs": false,
        "kind": "class",
        "name": "MaxNumBoundingBoxes",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "max_number"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MaxPool1D",
        "docstring": "Max pooling operation for 1D temporal data.\n\nDownsamples the input representation by taking the maximum value over a\nspatial window of size `pool_size`. The window is shifted by `strides`.\n\nThe resulting output when using the `\"valid\"` padding option has a shape of:\n`output_shape = (input_shape - pool_size + 1) / strides)`.\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = input_shape / strides`\n\nArgs:\n    pool_size: int, size of the max pooling window.\n    strides: int or None. Specifies how much the pooling window moves\n        for each pooling step. If None, it will default to `pool_size`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, steps)`.\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, downsampled_steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, downsampled_steps)`.\n\nExamples:\n\n`strides=1` and `padding=\"valid\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=1, padding=\"valid\")\n>>> max_pool_1d(x)\n\n`strides=2` and `padding=\"valid\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=2, padding=\"valid\")\n>>> max_pool_1d(x)\n\n`strides=1` and `padding=\"same\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=1, padding=\"same\")\n>>> max_pool_1d(x)",
        "has_varargs": false,
        "kind": "class",
        "name": "MaxPooling1D",
        "params": [
          {
            "annotation": null,
            "default": "2",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MaxPooling1D",
        "docstring": "Max pooling operation for 1D temporal data.\n\nDownsamples the input representation by taking the maximum value over a\nspatial window of size `pool_size`. The window is shifted by `strides`.\n\nThe resulting output when using the `\"valid\"` padding option has a shape of:\n`output_shape = (input_shape - pool_size + 1) / strides)`.\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = input_shape / strides`\n\nArgs:\n    pool_size: int, size of the max pooling window.\n    strides: int or None. Specifies how much the pooling window moves\n        for each pooling step. If None, it will default to `pool_size`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, steps)`.\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, downsampled_steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, downsampled_steps)`.\n\nExamples:\n\n`strides=1` and `padding=\"valid\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=1, padding=\"valid\")\n>>> max_pool_1d(x)\n\n`strides=2` and `padding=\"valid\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=2, padding=\"valid\")\n>>> max_pool_1d(x)\n\n`strides=1` and `padding=\"same\"`:\n\n>>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=1, padding=\"same\")\n>>> max_pool_1d(x)",
        "has_varargs": false,
        "kind": "class",
        "name": "MaxPooling1D",
        "params": [
          {
            "annotation": null,
            "default": "2",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MaxPool2D",
        "docstring": "Max pooling operation for 2D spatial data.\n\nDownsamples the input along its spatial dimensions (height and width)\nby taking the maximum value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.\n\nThe resulting output when using the `\"valid\"` padding option has a spatial\nshape (number of rows or columns) of:\n`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n(when `input_shape >= pool_size`)\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = math.floor((input_shape - 1) / strides) + 1`\n\nArgs:\n    pool_size: int or tuple of 2 integers, factors by which to downscale\n        (dim1, dim2). If only one integer is specified, the same\n        window length will be used for all dimensions.\n    strides: int or tuple of 2 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape `(batch_size, height, width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape `(batch_size, channels, height, width)`.\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape\n    `(batch_size, pooled_height, pooled_width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape\n    `(batch_size, channels, pooled_height, pooled_width)`.\n\nExamples:\n\n`strides=(1, 1)` and `padding=\"valid\"`:\n\n>>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"valid\")\n>>> max_pool_2d(x)\n\n`strides=(2, 2)` and `padding=\"valid\"`:\n\n>>> x = np.array([[1., 2., 3., 4.],\n...               [5., 6., 7., 8.],\n...               [9., 10., 11., 12.]])\n>>> x = np.reshape(x, [1, 3, 4, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(2, 2), padding=\"valid\")\n>>> max_pool_2d(x)\n\n`stride=(1, 1)` and `padding=\"same\"`:\n\n>>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"same\")\n>>> max_pool_2d(x)",
        "has_varargs": false,
        "kind": "class",
        "name": "MaxPooling2D",
        "params": [
          {
            "annotation": null,
            "default": "(2, 2)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MaxPooling2D",
        "docstring": "Max pooling operation for 2D spatial data.\n\nDownsamples the input along its spatial dimensions (height and width)\nby taking the maximum value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.\n\nThe resulting output when using the `\"valid\"` padding option has a spatial\nshape (number of rows or columns) of:\n`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n(when `input_shape >= pool_size`)\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = math.floor((input_shape - 1) / strides) + 1`\n\nArgs:\n    pool_size: int or tuple of 2 integers, factors by which to downscale\n        (dim1, dim2). If only one integer is specified, the same\n        window length will be used for all dimensions.\n    strides: int or tuple of 2 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape `(batch_size, height, width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape `(batch_size, channels, height, width)`.\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    4D tensor with shape\n    `(batch_size, pooled_height, pooled_width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape\n    `(batch_size, channels, pooled_height, pooled_width)`.\n\nExamples:\n\n`strides=(1, 1)` and `padding=\"valid\"`:\n\n>>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"valid\")\n>>> max_pool_2d(x)\n\n`strides=(2, 2)` and `padding=\"valid\"`:\n\n>>> x = np.array([[1., 2., 3., 4.],\n...               [5., 6., 7., 8.],\n...               [9., 10., 11., 12.]])\n>>> x = np.reshape(x, [1, 3, 4, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(2, 2), padding=\"valid\")\n>>> max_pool_2d(x)\n\n`stride=(1, 1)` and `padding=\"same\"`:\n\n>>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"same\")\n>>> max_pool_2d(x)",
        "has_varargs": false,
        "kind": "class",
        "name": "MaxPooling2D",
        "params": [
          {
            "annotation": null,
            "default": "(2, 2)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MaxPool3D",
        "docstring": "Max pooling operation for 3D data (spatial or spatio-temporal).\n\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the maximum value over an input window (of size defined by\n`pool_size`) for each channel of the input. The window is shifted by\n`strides` along each dimension.\n\nArgs:\n    pool_size: int or tuple of 3 integers, factors by which to downscale\n        (dim1, dim2, dim3). If only one integer is specified, the same\n        window length will be used for all dimensions.\n    strides: int or tuple of 3 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n\nExample:\n\n```python\ndepth = 30\nheight = 30\nwidth = 30\nchannels = 3\n\ninputs = keras.layers.Input(shape=(depth, height, width, channels))\nlayer = keras.layers.MaxPooling3D(pool_size=3)\noutputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "MaxPooling3D",
        "params": [
          {
            "annotation": null,
            "default": "(2, 2, 2)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MaxPooling3D",
        "docstring": "Max pooling operation for 3D data (spatial or spatio-temporal).\n\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the maximum value over an input window (of size defined by\n`pool_size`) for each channel of the input. The window is shifted by\n`strides` along each dimension.\n\nArgs:\n    pool_size: int or tuple of 3 integers, factors by which to downscale\n        (dim1, dim2, dim3). If only one integer is specified, the same\n        window length will be used for all dimensions.\n    strides: int or tuple of 3 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n\nExample:\n\n```python\ndepth = 30\nheight = 30\nwidth = 30\nchannels = 3\n\ninputs = keras.layers.Input(shape=(depth, height, width, channels))\nlayer = keras.layers.MaxPooling3D(pool_size=3)\noutputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "MaxPooling3D",
        "params": [
          {
            "annotation": null,
            "default": "(2, 2, 2)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pool_size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Maximum",
        "docstring": "Computes element-wise maximum on a list of inputs.\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\n\nExamples:\n\n>>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Maximum()([x1, x2])\n\nUsage in a Keras model:\n\n>>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `y = keras.layers.maximum([x1, x2])`\n>>> y = keras.layers.Maximum()([x1, x2])\n>>> out = keras.layers.Dense(4)(y)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)",
        "has_varargs": false,
        "kind": "class",
        "name": "Maximum",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MelSpectrogram",
        "docstring": "A preprocessing layer to convert raw audio signals to Mel spectrograms.\n\nThis layer takes `float32`/`float64` single or batched audio signal as\ninputs and computes the Mel spectrogram using Short-Time Fourier Transform\nand Mel scaling. The input should be a 1D (unbatched) or 2D (batched) tensor\nrepresenting audio signals. The output will be a 2D or 3D tensor\nrepresenting Mel spectrograms.\n\nA spectrogram is an image-like representation that shows the frequency\nspectrum of a signal over time. It uses x-axis to represent time, y-axis to\nrepresent frequency, and each pixel to represent intensity.\nMel spectrograms are a special type of spectrogram that use the mel scale,\nwhich approximates how humans perceive sound. They are commonly used in\nspeech and music processing tasks like speech recognition, speaker\nidentification, and music genre classification.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nReferences:\n- [Spectrogram](https://en.wikipedia.org/wiki/Spectrogram),\n- [Mel scale](https://en.wikipedia.org/wiki/Mel_scale).\n\nArgs:\n    fft_length: Integer, size of the FFT window.\n    sequence_stride: Integer, number of samples between successive STFT\n        columns.\n    sequence_length: Integer, size of the window used for applying\n        `window` to each audio frame. If `None`, defaults to `fft_length`.\n    window: String, name of the window function to use. Available values\n        are `\"hann\"` and `\"hamming\"`. If `window` is a tensor, it will be\n        used directly as the window and its length must be\n        `sequence_length`. If `window` is `None`, no windowing is\n        used. Defaults to `\"hann\"`.\n    sampling_rate: Integer, sample rate of the input signal.\n    num_mel_bins: Integer, number of mel bins to generate.\n    min_freq: Float, minimum frequency of the mel bins.\n    max_freq: Float, maximum frequency of the mel bins.\n        If `None`, defaults to `sampling_rate / 2`.\n    power_to_db: If True, convert the power spectrogram to decibels.\n    top_db: Float, minimum negative cut-off `max(10 * log10(S)) - top_db`.\n    mag_exp: Float, exponent for the magnitude spectrogram.\n        1 for magnitude, 2 for power, etc. Default is 2.\n    ref_power: Float, the power is scaled relative to it\n        `10 * log10(S / ref_power)`.\n    min_power: Float, minimum value for power and `ref_power`.\n\nExamples:\n\n**Unbatched audio signal**\n\n>>> layer = keras.layers.MelSpectrogram(num_mel_bins=64,\n...                                     sampling_rate=8000,\n...                                     sequence_stride=256,\n...                                     fft_length=2048)\n>>> layer(keras.random.uniform(shape=(16000,))).shape\n(64, 63)\n\n**Batched audio signal**\n\n>>> layer = keras.layers.MelSpectrogram(num_mel_bins=80,\n...                                     sampling_rate=8000,\n...                                     sequence_stride=128,\n...                                     fft_length=2048)\n>>> layer(keras.random.uniform(shape=(2, 16000))).shape\n(2, 80, 125)\n\nInput shape:\n    1D (unbatched) or 2D (batched) tensor with shape:`(..., samples)`.\n\nOutput shape:\n    2D (unbatched) or 3D (batched) tensor with\n    shape:`(..., num_mel_bins, time)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "MelSpectrogram",
        "params": [
          {
            "annotation": null,
            "default": "2048",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fft_length"
          },
          {
            "annotation": null,
            "default": "512",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sequence_stride"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sequence_length"
          },
          {
            "annotation": null,
            "default": "hann",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "window"
          },
          {
            "annotation": null,
            "default": "16000",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sampling_rate"
          },
          {
            "annotation": null,
            "default": "128",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_mel_bins"
          },
          {
            "annotation": null,
            "default": "20.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "min_freq"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "max_freq"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "power_to_db"
          },
          {
            "annotation": null,
            "default": "80.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "top_db"
          },
          {
            "annotation": null,
            "default": "2.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mag_exp"
          },
          {
            "annotation": null,
            "default": "1e-10",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "min_power"
          },
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ref_power"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Minimum",
        "docstring": "Computes elementwise minimum on a list of inputs.\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\n\nExamples:\n\n>>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Minimum()([x1, x2])\n\nUsage in a Keras model:\n\n>>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `y = keras.layers.minimum([x1, x2])`\n>>> y = keras.layers.Minimum()([x1, x2])\n>>> out = keras.layers.Dense(4)(y)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)",
        "has_varargs": false,
        "kind": "class",
        "name": "Minimum",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MixUp",
        "docstring": "MixUp implements the MixUp data augmentation technique.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nReferences:\n    - [MixUp paper](https://arxiv.org/abs/1710.09412).\n    - [MixUp for Object Detection paper](https://arxiv.org/pdf/1902.04103).\n\nArgs:\n    alpha: Float between 0 and 1. Controls the blending strength.\n           Smaller values mean less mixing, while larger values allow\n           for more  blending between images. Defaults to 0.2,\n           recommended for ImageNet1k classification.\n    seed: Integer. Used to create a random seed.\n\nExample:\n```python\n(images, labels), _ = keras.datasets.cifar10.load_data()\nimages, labels = images[:8], labels[:8]\nlabels = keras.ops.cast(keras.ops.one_hot(labels.flatten(), 10), \"float32\")\nmix_up = keras.layers.MixUp(alpha=0.2)\noutput = mix_up({\"images\": images, \"labels\": labels})\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "MixUp",
        "params": [
          {
            "annotation": null,
            "default": "0.2",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.MultiHeadAttention",
        "docstring": "MultiHeadAttention layer.\n\nThis is an implementation of multi-headed attention as described in the\npaper \"Attention is all you Need\"\n[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762).\nIf `query`, `key,` `value` are the same, then\nthis is self-attention. Each timestep in `query` attends to the\ncorresponding sequence in `key`, and returns a fixed-width vector.\n\nThis layer first projects `query`, `key` and `value`. These are\n(effectively) a list of tensors of length `num_attention_heads`, where the\ncorresponding shapes are `(batch_size, <query dimensions>, key_dim)`,\n`(batch_size, <key/value dimensions>, key_dim)`,\n`(batch_size, <key/value dimensions>, value_dim)`.\n\nThen, the query and key tensors are dot-producted and scaled. These are\nsoftmaxed to obtain attention probabilities. The value tensors are then\ninterpolated by these probabilities, then concatenated back to a single\ntensor.\n\nFinally, the result tensor with the last dimension as `value_dim` can take\na linear projection and return.\n\nArgs:\n    num_heads: Number of attention heads.\n    key_dim: Size of each attention head for query and key.\n    value_dim: Size of each attention head for value.\n    dropout: Dropout probability.\n    use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n    output_shape: The expected shape of an output tensor, besides the batch\n        and sequence dims. If not specified, projects back to the query\n        feature dim (the query input's last dimension).\n    attention_axes: axes over which the attention is applied. `None` means\n        attention over all axes, but batch, heads, and features.\n    flash_attention: If `None`, the layer attempts to use flash\n        attention for faster and more memory-efficient attention\n        computations when possible. This behavior can be configured using\n        `keras.config.enable_flash_attention()` or\n        `keras.config.disable_flash_attention()`.\n    kernel_initializer: Initializer for dense layer kernels.\n    bias_initializer: Initializer for dense layer biases.\n    kernel_regularizer: Regularizer for dense layer kernels.\n    bias_regularizer: Regularizer for dense layer biases.\n    activity_regularizer: Regularizer for dense layer activity.\n    kernel_constraint: Constraint for dense layer kernels.\n    bias_constraint: Constraint for dense layer kernels.\n    seed: Optional integer to seed the dropout layer.\n\nCall arguments:\n    query: Query tensor of shape `(B, T, dim)`, where `B` is the batch size,\n        `T` is the target sequence length, and dim is the feature dimension.\n    value: Value tensor of shape `(B, S, dim)`, where `B` is the batch size,\n        `S` is the source sequence length, and dim is the feature dimension.\n    key: Optional key tensor of shape `(B, S, dim)`. If not given, will\n        use `value` for both `key` and `value`, which is the most common\n        case.\n    attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n        attention to certain positions. The boolean mask specifies which\n        query elements can attend to which key elements, 1 indicates\n        attention and 0 indicates no attention. Broadcasting can happen for\n        the missing batch dimensions and the head dimension.\n    return_attention_scores: A boolean to indicate whether the output should\n        be `(attention_output, attention_scores)` if `True`, or\n        `attention_output` if `False`. Defaults to `False`.\n    training: Python boolean indicating whether the layer should behave in\n        training mode (adding dropout) or in inference mode (no dropout).\n        Will go with either using the training mode of the parent\n        layer/model, or `False` (inference) if there is no parent layer.\n    use_causal_mask: A boolean to indicate whether to apply a causal mask to\n        prevent tokens from attending to future tokens (e.g., used in a\n        decoder Transformer).\n\nReturns:\n    attention_output: The result of the computation, of shape `(B, T, E)`,\n        where `T` is for target sequence shapes and `E` is the query input\n        last dimension if `output_shape` is `None`. Otherwise, the\n        multi-head outputs are projected to the shape specified by\n        `output_shape`.\n    attention_scores: (Optional) multi-head attention coefficients over\n        attention axes.",
        "has_varargs": false,
        "kind": "class",
        "name": "MultiHeadAttention",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_heads"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "key_dim"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_dim"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_shape"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "attention_axes"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "flash_attention"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Multiply",
        "docstring": "Performs elementwise multiplication.\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\n\nExamples:\n\n>>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Multiply()([x1, x2])\n\nUsage in a Keras model:\n\n>>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `y = keras.layers.multiply([x1, x2])`\n>>> y = keras.layers.Multiply()([x1, x2])\n>>> out = keras.layers.Dense(4)(y)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)",
        "has_varargs": false,
        "kind": "class",
        "name": "Multiply",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Normalization",
        "docstring": "A preprocessing layer that normalizes continuous features.\n\nThis layer will shift and scale inputs into a distribution centered around\n0 with standard deviation 1. It accomplishes this by precomputing the mean\nand variance of the data, and calling `(input - mean) / sqrt(var)` at\nruntime.\n\nThe mean and variance values for the layer must be either supplied on\nconstruction or learned via `adapt()`. `adapt()` will compute the mean and\nvariance of the data and store them as the layer's weights. `adapt()` should\nbe called before `fit()`, `evaluate()`, or `predict()`.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    axis: Integer, tuple of integers, or None. The axis or axes that should\n        have a separate mean and variance for each index in the shape.\n        For example, if shape is `(None, 5)` and `axis=1`, the layer will\n        track 5 separate mean and variance values for the last axis.\n        If `axis` is set to `None`, the layer will normalize\n        all elements in the input by a scalar mean and variance.\n        When `-1`, the last axis of the input is assumed to be a\n        feature dimension and is normalized per index.\n        Note that in the specific case of batched scalar inputs where\n        the only axis is the batch axis, the default will normalize\n        each index in the batch separately.\n        In this case, consider passing `axis=None`. Defaults to `-1`.\n    mean: The mean value(s) to use during normalization. The passed value(s)\n        will be broadcast to the shape of the kept axes above;\n        if the value(s) cannot be broadcast, an error will be raised when\n        this layer's `build()` method is called.\n        `mean` and `variance` must be specified together.\n    variance: The variance value(s) to use during normalization. The passed\n        value(s) will be broadcast to the shape of the kept axes above;\n        if the value(s) cannot be broadcast, an error will be raised when\n        this layer's `build()` method is called.\n        `mean` and `variance` must be specified together.\n    invert: If `True`, this layer will apply the inverse transformation\n        to its inputs: it would turn a normalized input back into its\n        original form.\n\nExamples:\n\nCalculate a global mean and variance by analyzing the dataset in `adapt()`.\n\n>>> adapt_data = np.array([1., 2., 3., 4., 5.], dtype='float32')\n>>> input_data = np.array([1., 2., 3.], dtype='float32')\n>>> layer = keras.layers.Normalization(axis=None)\n>>> layer.adapt(adapt_data)\n>>> layer(input_data)\narray([-1.4142135, -0.70710677, 0.], dtype=float32)\n\nCalculate a mean and variance for each index on the last axis.\n\n>>> adapt_data = np.array([[0., 7., 4.],\n...                        [2., 9., 6.],\n...                        [0., 7., 4.],\n...                        [2., 9., 6.]], dtype='float32')\n>>> input_data = np.array([[0., 7., 4.]], dtype='float32')\n>>> layer = keras.layers.Normalization(axis=-1)\n>>> layer.adapt(adapt_data)\n>>> layer(input_data)\narray([-1., -1., -1.], dtype=float32)\n\nPass the mean and variance directly.\n\n>>> input_data = np.array([[1.], [2.], [3.]], dtype='float32')\n>>> layer = keras.layers.Normalization(mean=3., variance=2.)\n>>> layer(input_data)\narray([[-1.4142135 ],\n       [-0.70710677],\n       [ 0.        ]], dtype=float32)\n\nUse the layer to de-normalize inputs (after adapting the layer).\n\n>>> adapt_data = np.array([[0., 7., 4.],\n...                        [2., 9., 6.],\n...                        [0., 7., 4.],\n...                        [2., 9., 6.]], dtype='float32')\n>>> input_data = np.array([[1., 2., 3.]], dtype='float32')\n>>> layer = keras.layers.Normalization(axis=-1, invert=True)\n>>> layer.adapt(adapt_data)\n>>> layer(input_data)\narray([2., 10., 8.], dtype=float32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Normalization",
        "params": [
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mean"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "variance"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "invert"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.PReLU",
        "docstring": "Parametric Rectified Linear Unit activation layer.\n\nFormula:\n``` python\nf(x) = alpha * x for x < 0\nf(x) = x for x >= 0\n```\nwhere `alpha` is a learned array with the same shape as x.\n\nArgs:\n    alpha_initializer: Initializer function for the weights.\n    alpha_regularizer: Regularizer for the weights.\n    alpha_constraint: Constraint for the weights.\n    shared_axes: The axes along which to share learnable parameters for the\n        activation function. For example, if the incoming feature maps are\n        from a 2D convolution with output shape\n        `(batch, height, width, channels)`, and you wish to share parameters\n        across space so that each filter only has one set of parameters,\n        set `shared_axes=[1, 2]`.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "PReLU",
        "params": [
          {
            "annotation": null,
            "default": "Zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "shared_axes"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Permute",
        "docstring": "Permutes the dimensions of the input according to a given pattern.\n\nUseful e.g. connecting RNNs and convnets.\n\nArgs:\n    dims: Tuple of integers. Permutation pattern does not include the\n        batch dimension. Indexing starts at 1.\n        For instance, `(1, 3, 2)` permutes the second and third dimensions\n        of the input.\n\nInput shape:\n    Arbitrary.\n\nOutput shape:\n    Same as the input shape, but with the dimensions re-ordered according\n    to the specified pattern.\n\nExample:\n\n>>> x = keras.Input(shape=(10, 64))\n>>> y = keras.layers.Permute((2, 1))(x)\n>>> y.shape\n(None, 64, 10)",
        "has_varargs": false,
        "kind": "class",
        "name": "Permute",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dims"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Pipeline",
        "docstring": "Applies a series of layers to an input.\n\nThis class is useful to build a preprocessing pipeline,\nin particular an image data augmentation pipeline.\nCompared to a `Sequential` model, `Pipeline` features\na few important differences:\n\n- It's not a `Model`, just a plain layer.\n- When the layers in the pipeline are compatible\n    with `tf.data`, the pipeline will also\n    remain `tf.data` compatible. That is to say,\n    the pipeline will not attempt to convert\n    its inputs to backend-native tensors\n    when in a tf.data context (unlike a `Sequential`\n    model).\n\nExample:\n\n```python\nfrom keras import layers\npreprocessing_pipeline = layers.Pipeline([\n    layers.AutoContrast(),\n    layers.RandomZoom(0.2),\n    layers.RandomRotation(0.2),\n])\n\n# `ds` is a tf.data.Dataset\npreprocessed_ds = ds.map(\n    preprocessing_pipeline,\n    num_parallel_calls=4,\n)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "Pipeline",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "layers"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          }
        ]
      },
      {
        "api_path": "keras.layers.RMSNormalization",
        "docstring": "Root Mean Square (RMS) Normalization layer.\n\nThis layer normalizes the input tensor based on its RMS value.\n\nThe Keras layer performs the operation as described in\n[Root Mean Square Layer Normalization](https://arxiv.org/pdf/1910.07467)\nby Biao Zhang et al.\n\n\nIf `scale` is enabled, the layer will scale the normalized outputs via\na learnable scaling factor.\n\nSo, with scaling enabled, the normalization equations\nare as follows:\n\nLet the intermediate activations for a mini-batch to be the `inputs`.\n\n```python\nrms_normalization(x) = x * rsqrt(mean(square(x))) * scale\n```\n\nFor example:\n\n>>> layer = keras.layers.RMSNormalization()\n>>> layer.build([5, 20, 30, 10])\n>>> print(layer.scale.shape)\n(10,)\n>>> layer(np.random.rand(1, 10)).numpy()\narray([[0.35098287, 1.0495652 , 1.4645109 , 1.2944688 , 0.31124955,\n        1.2768592 , 1.184331  , 0.17474432, 0.49955517, 1.2428929 ]],\n    dtype=float32)\n\nArgs:\n    axis: int. The axis on which to perform the normalization.\n    epsilon: float. A small number to add to avoid division by zero.",
        "has_varargs": false,
        "kind": "class",
        "name": "RMSNormalization",
        "params": [
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "1e-06",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RNN",
        "docstring": "Base class for recurrent layers.\n\nArgs:\n    cell: A RNN cell instance or a list of RNN cell instances.\n        A RNN cell is a class that has:\n        - A `call(input_at_t, states_at_t)` method, returning\n        `(output_at_t, states_at_t_plus_1)`. The call method of the\n        cell can also take the optional argument `constants`, see\n        section \"Note on passing external constants\" below.\n        - A `state_size` attribute. This can be a single integer\n        (single state) in which case it is the size of the recurrent\n        state. This can also be a list/tuple of integers\n        (one size per state).\n        - A `output_size` attribute, a single integer.\n        - A `get_initial_state(batch_size=None)`\n        method that creates a tensor meant to be fed to `call()` as the\n        initial state, if the user didn't specify any initial state\n        via other means. The returned initial state should have\n        shape `(batch_size, cell.state_size)`.\n        The cell might choose to create a tensor full of zeros,\n        or other values based on the cell's implementation.\n        `inputs` is the input tensor to the RNN layer, with shape\n        `(batch_size, timesteps, features)`.\n        If this method is not implemented\n        by the cell, the RNN layer will create a zero filled tensor\n        with shape `(batch_size, cell.state_size)`.\n        In the case that `cell` is a list of RNN cell instances, the cells\n        will be stacked on top of each other in the RNN, resulting in an\n        efficient stacked RNN.\n    return_sequences: Boolean (default `False`). Whether to return the last\n        output in the output sequence, or the full sequence.\n    return_state: Boolean (default `False`).\n        Whether to return the last state in addition to the output.\n    go_backwards: Boolean (default `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.\n    stateful: Boolean (default `False`). If True, the last state\n        for each sample at index `i` in a batch will be used as initial\n        state for the sample of index `i` in the following batch.\n    unroll: Boolean (default `False`).\n        If True, the network will be unrolled, else a symbolic loop will be\n        used. Unrolling can speed-up a RNN, although it tends to be more\n        memory-intensive. Unrolling is only suitable for short sequences.\n    zero_output_for_mask: Boolean (default `False`).\n        Whether the output should use zeros for the masked timesteps.\n        Note that this field is only used when `return_sequences`\n        is `True` and `mask` is provided.\n        It can useful if you want to reuse the raw output sequence of\n        the RNN without interference from the masked timesteps, e.g.,\n        merging bidirectional RNNs.\n\nCall arguments:\n    sequences: A 3-D tensor with shape `(batch_size, timesteps, features)`.\n    initial_state: List of initial state tensors to be passed to the first\n        call of the cell.\n    mask: Binary tensor of shape `[batch_size, timesteps]`\n        indicating whether a given timestep should be masked.\n        An individual `True` entry indicates that the corresponding\n        timestep should be utilized, while a `False` entry indicates\n        that the corresponding timestep should be ignored.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode. This argument is passed\n        to the cell when calling it.\n        This is for use with cells that use dropout.\n\nOutput shape:\n\n- If `return_state`: a list of tensors. The first tensor is\nthe output. The remaining tensors are the last states,\neach with shape `(batch_size, state_size)`, where `state_size` could\nbe a high dimension tensor shape.\n- If `return_sequences`: 3D tensor with shape\n`(batch_size, timesteps, output_size)`.\n\nMasking:\n\nThis layer supports masking for input data with a variable number\nof timesteps. To introduce masks to your data,\nuse a `keras.layers.Embedding` layer with the `mask_zero` parameter\nset to `True`.\n\nNote on using statefulness in RNNs:\n\nYou can set RNN layers to be 'stateful', which means that the states\ncomputed for the samples in one batch will be reused as initial states\nfor the samples in the next batch. This assumes a one-to-one mapping\nbetween samples in different successive batches.\n\nTo enable statefulness:\n\n- Specify `stateful=True` in the layer constructor.\n- Specify a fixed batch size for your model, by passing\n    `batch_size=...` to the `Input` layer(s) of your model.\n    Remember to also specify the same `batch_size=...` when\n    calling `fit()`, or otherwise use a generator-like\n    data source like a `keras.utils.PyDataset` or a\n    `tf.data.Dataset`.\n- Specify `shuffle=False` when calling `fit()`, since your\n    batches are expected to be temporally ordered.\n\nTo reset the states of your model, call `.reset_state()` on either\na specific layer, or on your entire model.\n\nNote on specifying the initial state of RNNs:\n\nYou can specify the initial state of RNN layers symbolically by\ncalling them with the keyword argument `initial_state`. The value of\n`initial_state` should be a tensor or list of tensors representing\nthe initial state of the RNN layer.\n\nYou can specify the initial state of RNN layers numerically by\ncalling `reset_state()` with the keyword argument `states`. The value of\n`states` should be a numpy array or list of numpy arrays representing\nthe initial state of the RNN layer.\n\nExamples:\n\n```python\nfrom keras.layers import RNN\nfrom keras import ops\n\n# First, let's define a RNN Cell, as a layer subclass.\nclass MinimalRNNCell(keras.Layer):\n\n    def __init__(self, units, **kwargs):\n        super().__init__(**kwargs)\n        self.units = units\n        self.state_size = units\n\n    def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      initializer='uniform',\n                                      name='kernel')\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            initializer='uniform',\n            name='recurrent_kernel')\n\n    def call(self, inputs, states):\n        prev_output = states[0]\n        h = ops.matmul(inputs, self.kernel)\n        output = h + ops.matmul(prev_output, self.recurrent_kernel)\n        return output, [output]\n\n# Let's use this cell in a RNN layer:\n\ncell = MinimalRNNCell(32)\nx = keras.Input((None, 5))\nlayer = RNN(cell)\ny = layer(x)\n\n# Here's how to use the cell to build a stacked RNN:\n\ncells = [MinimalRNNCell(32), MinimalRNNCell(64)]\nx = keras.Input((None, 5))\nlayer = RNN(cells)\ny = layer(x)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "RNN",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "cell"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_sequences"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_state"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "go_backwards"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "stateful"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unroll"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "zero_output_for_mask"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandAugment",
        "docstring": "RandAugment performs the Rand Augment operation on input images.\n\nThis layer can be thought of as an all-in-one image augmentation layer. The\npolicy implemented by this layer has been benchmarked extensively and is\neffective on a wide variety of datasets.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nReferences:\n    - [RandAugment](https://arxiv.org/abs/1909.13719)\n\nArgs:\n    value_range: The range of values the input image can take.\n        Default is `(0, 255)`. Typically, this would be `(0, 1)`\n        for normalized images or `(0, 255)` for raw images.\n    num_ops: The number of augmentation operations to apply sequentially\n        to each image. Default is 2.\n    factor: The strength of the augmentation as a normalized value\n        between 0 and 1. Default is 0.5.\n    interpolation: The interpolation method to use for resizing operations.\n        Options include `nearest`, `bilinear`. Default is `bilinear`.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandAugment",
        "params": [
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "2",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_ops"
          },
          {
            "annotation": null,
            "default": "0.5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomBrightness",
        "docstring": "A preprocessing layer which randomly adjusts brightness during training.\n\nThis layer will randomly increase/reduce the brightness for the input RGB\nimages. At inference time, the output will be identical to the input.\nCall the layer with `training=True` to adjust the brightness of the input.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: Float or a list/tuple of 2 floats between -1.0 and 1.0. The\n        factor is used to determine the lower bound and upper bound of the\n        brightness adjustment. A float value will be chosen randomly between\n        the limits. When -1.0 is chosen, the output image will be black, and\n        when 1.0 is chosen, the image will be fully white.\n        When only one float is provided, eg, 0.2,\n        then -0.2 will be used for lower bound and 0.2\n        will be used for upper bound.\n    value_range: Optional list/tuple of 2 floats\n        for the lower and upper limit\n        of the values of the input data.\n        To make no change, use `[0.0, 1.0]`, e.g., if the image input\n        has been scaled before this layer. Defaults to `[0.0, 255.0]`.\n        The brightness adjustment will be scaled to this range, and the\n        output values will be clipped to this range.\n    seed: optional integer, for fixed RNG behavior.\n\nInputs: 3D (HWC) or 4D (NHWC) tensor, with float or int dtype. Input pixel\n    values can be of any range (e.g. `[0., 1.)` or `[0, 255]`)\n\nOutput: 3D (HWC) or 4D (NHWC) tensor with brightness adjusted based on the\n    `factor`. By default, the layer will output floats.\n    The output value will be clipped to the range `[0, 255]`,\n    the valid range of RGB colors, and\n    rescaled based on the `value_range` if needed.\n\nExample:\n\n```python\nrandom_bright = keras.layers.RandomBrightness(factor=0.2)\n\n# An image with shape [2, 2, 3]\nimage = [[[1, 2, 3], [4 ,5 ,6]], [[7, 8, 9], [10, 11, 12]]]\n\n# Assume we randomly select the factor to be 0.1, then it will apply\n# 0.1 * 255 to all the channel\noutput = random_bright(image, training=True)\n\n# output will be int64 with 25.5 added to each channel and round down.\n>>> array([[[26.5, 27.5, 28.5]\n            [29.5, 30.5, 31.5]]\n           [[32.5, 33.5, 34.5]\n            [35.5, 36.5, 37.5]]],\n          shape=(2, 2, 3), dtype=int64)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomBrightness",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomColorDegeneration",
        "docstring": "Randomly performs the color degeneration operation on given images.\n\nThe sharpness operation first converts an image to gray scale, then back to\ncolor. It then takes a weighted average between original image and the\ndegenerated image. This makes colors appear more dull.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: A tuple of two floats or a single float.\n        `factor` controls the extent to which the\n        image sharpness is impacted. `factor=0.0` makes this layer perform a\n        no-op operation, while a value of 1.0 uses the degenerated result\n        entirely. Values between 0 and 1 result in linear interpolation\n        between the original image and the sharpened image.\n        Values should be between `0.0` and `1.0`. If a tuple is used, a\n        `factor` is sampled between the two values for every image\n        augmented. If a single float is used, a value between `0.0` and the\n        passed float is sampled. In order to ensure the value is always the\n        same, please pass a tuple with two identical floats: `(0.5, 0.5)`.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomColorDegeneration",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomColorJitter",
        "docstring": "RandomColorJitter class randomly apply brightness, contrast, saturation\nand hue image processing operation sequentially and randomly on the\ninput.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    value_range: the range of values the incoming images will have.\n        Represented as a two number tuple written [low, high].\n        This is typically either `[0, 1]` or `[0, 255]` depending\n        on how your preprocessing pipeline is set up.\n    brightness_factor: Float or a list/tuple of 2 floats between -1.0\n        and 1.0. The factor is used to determine the lower bound and\n        upper bound of the brightness adjustment. A float value will\n        be chosen randomly between the limits. When -1.0 is chosen,\n        the output image will be black, and when 1.0 is chosen, the\n        image will be fully white. When only one float is provided,\n        eg, 0.2, then -0.2 will be used for lower bound and 0.2 will\n        be used for upper bound.\n    contrast_factor: a positive float represented as fraction of value,\n        or a tuple of size 2 representing lower and upper bound. When\n        represented as a single float, lower = upper. The contrast\n        factor will be randomly picked between `[1.0 - lower, 1.0 +\n        upper]`. For any pixel x in the channel, the output will be\n        `(x - mean) * factor + mean` where `mean` is the mean value\n        of the channel.\n    saturation_factor: A tuple of two floats or a single float. `factor`\n        controls the extent to which the image saturation is impacted.\n        `factor=0.5` makes this layer perform a no-op operation.\n        `factor=0.0` makes the image fully grayscale. `factor=1.0`\n        makes the image fully saturated. Values should be between\n        `0.0` and `1.0`. If a tuple is used, a `factor` is sampled\n        between the two values for every image augmented. If a single\n        float is used, a value between `0.0` and the passed float is\n        sampled. To ensure the value is always the same, pass a tuple\n        with two identical floats: `(0.5, 0.5)`.\n    hue_factor: A single float or a tuple of two floats. `factor`\n        controls the extent to which the image hue is impacted.\n        `factor=0.0` makes this layer perform a no-op operation,\n        while a value of `1.0` performs the most aggressive contrast\n        adjustment available. If a tuple is used, a `factor` is\n        sampled between the two values for every image augmented.\n        If a single float is used, a value between `0.0` and the\n        passed float is sampled. In order to ensure the value is\n        always the same, please pass a tuple with two identical\n        floats: `(0.5, 0.5)`.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomColorJitter",
        "params": [
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "brightness_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "contrast_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "saturation_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "hue_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomContrast",
        "docstring": "A preprocessing layer which randomly adjusts contrast during training.\n\nThis layer will randomly adjust the contrast of an image or images\nby a random factor. Contrast is adjusted independently\nfor each channel of each image during training.\n\nFor each channel, this layer computes the mean of the image pixels in the\nchannel and then adjusts each component `x` of each pixel to\n`(x - mean) * contrast_factor + mean`.\n\nInput pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\nin integer or floating point dtype.\nBy default, the layer will output floats.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\nArgs:\n    factor: a positive float represented as fraction of value, or a tuple of\n        size 2 representing lower and upper bound.\n        When represented as a single float, lower = upper.\n        The contrast factor will be randomly picked between\n        `[1.0 - lower, 1.0 + upper]`. For any pixel x in the channel,\n        the output will be `(x - mean) * factor + mean`\n        where `mean` is the mean value of the channel.\n    value_range: the range of values the incoming images will have.\n        Represented as a two-number tuple written `[low, high]`. This is\n        typically either `[0, 1]` or `[0, 255]` depending on how your\n        preprocessing pipeline is set up.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomContrast",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomCrop",
        "docstring": "A preprocessing layer which randomly crops images during training.\n\nDuring training, this layer will randomly choose a location to crop images\ndown to a target size. The layer will crop all the images in the same batch\nto the same cropping location.\n\nAt inference time, and during training if an input image is smaller than the\ntarget size, the input will be resized and cropped so as to return the\nlargest possible window in the image that matches the target aspect ratio.\nIf you need to apply random cropping at inference time, set `training` to\nTrue when calling the layer.\n\nInput pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\nof integer or floating point dtype. By default, the layer will output\nfloats.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., target_height, target_width, channels)`.\n\nArgs:\n    height: Integer, the height of the output shape.\n    width: Integer, the width of the output shape.\n    seed: Integer. Used to create a random seed.\n    **kwargs: Base layer keyword arguments, such as\n        `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomCrop",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "height"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "width"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomElasticTransform",
        "docstring": "A preprocessing layer that applies random elastic transformations.\n\nThis layer distorts input images by applying elastic deformations,\nsimulating a physically realistic transformation. The magnitude of the\ndistortion is controlled by the `scale` parameter, while the `factor`\ndetermines the probability of applying the transformation.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: A single float or a tuple of two floats.\n        `factor` controls the probability of applying the transformation.\n        - `factor=0.0` ensures no erasing is applied.\n        - `factor=1.0` means erasing is always applied.\n        - If a tuple `(min, max)` is provided, a probability value\n          is sampled between `min` and `max` for each image.\n        - If a single float is provided, a probability is sampled\n          between `0.0` and the given float.\n        Default is 1.0.\n    scale: A float or a tuple of two floats defining the magnitude of\n        the distortion applied.\n        - If a tuple `(min, max)` is provided, a random scale value is\n          sampled within this range.\n        - If a single float is provided, a random scale value is sampled\n          between `0.0` and the given float.\n        Default is 1.0.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n        `\"bilinear\"`.\n    fill_mode: Points outside the boundaries of the input are filled\n        according to the given mode. Available methods are `\"constant\"`,\n        `\"nearest\"`, `\"wrap\"` and `\"reflect\"`. Defaults to `\"constant\"`.\n        - `\"reflect\"`: `(d c b a | a b c d | d c b a)`\n            The input is extended by reflecting about the edge of the last\n            pixel.\n        - `\"constant\"`: `(k k k k | a b c d | k k k k)`\n            The input is extended by filling all values beyond\n            the edge with the same constant value k specified by\n            `fill_value`.\n        - `\"wrap\"`: `(a b c d | a b c d | a b c d)`\n            The input is extended by wrapping around to the opposite edge.\n        - `\"nearest\"`: `(a a a a | a b c d | d d d d)`\n            The input is extended by the nearest pixel.\n        Note that when using torch backend, `\"reflect\"` is redirected to\n        `\"mirror\"` `(c d c b | a b c d | c b a b)` because torch does not\n        support `\"reflect\"`.\n        Note that torch backend does not support `\"wrap\"`.\n    fill_value: a float represents the value to be filled outside the\n        boundaries when `fill_mode=\"constant\"`.\n    value_range: the range of values the incoming images will have.\n        Represented as a two-number tuple written `[low, high]`. This is\n        typically either `[0, 1]` or `[0, 255]` depending on how your\n        preprocessing pipeline is set up.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomElasticTransform",
        "params": [
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "scale"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "reflect",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_mode"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomErasing",
        "docstring": "Random Erasing data augmentation technique.\n\nRandom Erasing is a data augmentation method where random patches of\nan image are erased (replaced by a constant value or noise)\nduring training to improve generalization.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nReferences:\n   - [Random Erasing paper](https://arxiv.org/abs/1708.04896).\n\nArgs:\n    factor: A single float or a tuple of two floats.\n        `factor` controls the probability of applying the transformation.\n        - `factor=0.0` ensures no erasing is applied.\n        - `factor=1.0` means erasing is always applied.\n        - If a tuple `(min, max)` is provided, a probability value\n          is sampled between `min` and `max` for each image.\n        - If a single float is provided, a probability is sampled\n          between `0.0` and the given float.\n        Default is 1.0.\n    scale: A tuple of two floats representing the aspect ratio range of\n        the erased patch. This defines the width-to-height ratio of\n        the patch to be erased. It can help control the rw shape of\n        the erased region. Default is (0.02, 0.33).\n    fill_value: A value to fill the erased region with. This can be set to\n        a constant value or `None` to sample a random value\n        from a normal distribution. Default is `None`.\n    value_range: the range of values the incoming images will have.\n        Represented as a two-number tuple written `[low, high]`. This is\n        typically either `[0, 1]` or `[0, 255]` depending on how your\n        preprocessing pipeline is set up.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomErasing",
        "params": [
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0.02, 0.33)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "scale"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomFlip",
        "docstring": "A preprocessing layer which randomly flips images during training.\n\nThis layer will flip the images horizontally and or vertically based on the\n`mode` attribute. During inference time, the output will be identical to\ninput. Call the layer with `training=True` to flip the input.\nInput pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\nof integer or floating point dtype.\nBy default, the layer will output floats.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\nArgs:\n    mode: String indicating which flip mode to use. Can be `\"horizontal\"`,\n        `\"vertical\"`, or `\"horizontal_and_vertical\"`. `\"horizontal\"` is a\n        left-right flip and `\"vertical\"` is a top-bottom flip. Defaults to\n        `\"horizontal_and_vertical\"`\n    seed: Integer. Used to create a random seed.\n    **kwargs: Base layer keyword arguments, such as\n        `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomFlip",
        "params": [
          {
            "annotation": null,
            "default": "horizontal_and_vertical",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mode"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomGaussianBlur",
        "docstring": "Applies random Gaussian blur to images for data augmentation.\n\nThis layer performs a Gaussian blur operation on input images with a\nrandomly selected degree of blurring, controlled by the `factor` and\n`sigma` arguments.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: A single float or a tuple of two floats.\n        `factor` controls the extent to which the image hue is impacted.\n        `factor=0.0` makes this layer perform a no-op operation,\n        while a value of `1.0` performs the most aggressive\n        blurring available. If a tuple is used, a `factor` is\n        sampled between the two values for every image augmented. If a\n        single float is used, a value between `0.0` and the passed float is\n        sampled. Default is 1.0.\n    kernel_size: Integer. Size of the Gaussian kernel used for blurring.\n        Must be an odd integer. Default is 3.\n    sigma: Float or tuple of two floats. Standard deviation of the Gaussian\n        kernel. Controls the intensity of the blur. If a tuple is provided,\n        a value is sampled between the two for each image. Default is 1.0.\n    value_range: the range of values the incoming images will have.\n        Represented as a two-number tuple written `[low, high]`. This is\n        typically either `[0, 1]` or `[0, 255]` depending on how your\n        preprocessing pipeline is set up.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomGaussianBlur",
        "params": [
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "3",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sigma"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomGrayscale",
        "docstring": "Preprocessing layer for random conversion of RGB images to grayscale.\n\nThis layer randomly converts input images to grayscale with a specified\nfactor. When applied, it maintains the original number of channels\nbut sets all channels to the same grayscale value. This can be useful\nfor data augmentation and training models to be robust to color\nvariations.\n\nThe conversion preserves the perceived luminance of the original color\nimage using standard RGB to grayscale conversion coefficients. Images\nthat are not selected for conversion remain unchanged.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: Float between 0 and 1, specifying the factor of\n        converting each image to grayscale. Defaults to 0.5. A value of\n        1.0 means all images will be converted, while 0.0 means no images\n        will be converted.\n    data_format: String, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format,\n    or `(..., channels, height, width)`, in `\"channels_first\"` format.\n\nOutput shape:\n    Same as input shape. The output maintains the same number of channels\n    as the input, even for grayscale-converted images where all channels\n    will have the same value.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomGrayscale",
        "params": [
          {
            "annotation": null,
            "default": "0.5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomHue",
        "docstring": "Randomly adjusts the hue on given images.\n\nThis layer will randomly increase/reduce the hue for the input RGB\nimages.\n\nThe image hue is adjusted by converting the image(s) to HSV and rotating the\nhue channel (H) by delta. The image is then converted back to RGB.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: A single float or a tuple of two floats.\n        `factor` controls the extent to which the\n        image hue is impacted. `factor=0.0` makes this layer perform a\n        no-op operation, while a value of `1.0` performs the most aggressive\n        contrast adjustment available. If a tuple is used, a `factor` is\n        sampled between the two values for every image augmented. If a\n        single float is used, a value between `0.0` and the passed float is\n        sampled. In order to ensure the value is always the same, please\n        pass a tuple with two identical floats: `(0.5, 0.5)`.\n    value_range: the range of values the incoming images will have.\n        Represented as a two-number tuple written `[low, high]`. This is\n        typically either `[0, 1]` or `[0, 255]` depending on how your\n        preprocessing pipeline is set up.\n    seed: Integer. Used to create a random seed.\n\nExample:\n\n```python\n(images, labels), _ = keras.datasets.cifar10.load_data()\nrandom_hue = keras.layers.RandomHue(factor=0.5, value_range=[0, 1])\nimages = keras.ops.cast(images, \"float32\")\naugmented_images_batch = random_hue(images[:8])\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomHue",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomInvert",
        "docstring": "Preprocessing layer for random inversion of image colors.\n\nThis layer randomly inverts the colors of input images with a specified\nprobability range. When applied, each image has a chance of having its\ncolors inverted, where the pixel values are transformed to their\ncomplementary values. Images that are not selected for inversion\nremain unchanged.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: A single float or a tuple of two floats.\n        `factor` controls the probability of inverting the image colors.\n        If a tuple is provided, the value is sampled between the two values\n        for each image, where `factor[0]` is the minimum and `factor[1]` is\n        the maximum probability. If a single float is provided, a value\n        between `0.0` and the provided float is sampled.\n        Defaults to `(0, 1)`.\n    value_range: a tuple or a list of two elements. The first value\n        represents the lower bound for values in passed images, the second\n        represents the upper bound. Images passed to the layer should have\n        values within `value_range`. Defaults to `(0, 255)`.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomInvert",
        "params": [
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomPerspective",
        "docstring": "A preprocessing layer that applies random perspective transformations.\n\nThis layer distorts the perspective of input images by shifting their\ncorner points, simulating a 3D-like transformation. The amount of distortion\nis controlled by the `factor` and `scale` parameters.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: A float or a tuple of two floats.\n        Represents the probability of applying the perspective\n        transformation to each image in the batch.\n        - `factor=0.0` ensures no transformation is applied.\n        - `factor=1.0` means the transformation is always applied.\n        - If a tuple `(min, max)` is provided, a probability is randomly\n          sampled between `min` and `max` for each image.\n        - If a single float is given, the probability is sampled between\n          `0.0` and the provided float.\n        Default is 1.0.\n    scale: A float defining the relative amount of perspective shift.\n        Determines how much the image corners are displaced, affecting\n        the intensity of the perspective effect.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n        `\"bilinear\"`.\n    fill_value: a float represents the value to be filled outside the\n        boundaries when `fill_mode=\"constant\"`.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomPerspective",
        "params": [
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "scale"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomPosterization",
        "docstring": "Reduces the number of bits for each color channel.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nReferences:\n- [AutoAugment: Learning Augmentation Policies from Data](https://arxiv.org/abs/1805.09501)\n- [RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/abs/1909.13719)\n\nArgs:\n    value_range: a tuple or a list of two elements. The first value\n        represents the lower bound for values in passed images, the second\n        represents the upper bound. Images passed to the layer should have\n        values within `value_range`. Defaults to `(0, 255)`.\n    factor: integer, the number of bits to keep for each channel. Must be a\n        value between 1-8.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomPosterization",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomRotation",
        "docstring": "A preprocessing layer which randomly rotates images during training.\n\nThis layer will apply random rotations to each image, filling empty space\naccording to `fill_mode`.\n\nBy default, random rotations are only applied during training.\nAt inference time, the layer does nothing. If you need to apply random\nrotations at inference time, pass `training=True` when calling the layer.\n\nInput pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\nof integer or floating point dtype.\nBy default, the layer will output floats.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format\n\nArgs:\n    factor: a float represented as fraction of 2 Pi, or a tuple of size 2\n        representing lower and upper bound for rotating clockwise and\n        counter-clockwise. A positive values means rotating\n        counter clock-wise,\n        while a negative value means clock-wise.\n        When represented as a single\n        float, this value is used for both the upper and lower bound.\n        For instance, `factor=(-0.2, 0.3)`\n        results in an output rotation by a random\n        amount in the range `[-20% * 360, 30% * 360]`.\n        `factor=0.2` results in an\n        output rotating by a random amount\n        in the range `[-20% * 360, 20% * 360]`.\n    fill_mode: Points outside the boundaries of the input are filled\n        according to the given mode\n        (one of `{\"constant\", \"reflect\", \"wrap\", \"nearest\"}`).\n        - *reflect*: `(d c b a | a b c d | d c b a)`\n            The input is extended by reflecting about\n            the edge of the last pixel.\n        - *constant*: `(k k k k | a b c d | k k k k)`\n            The input is extended by\n            filling all values beyond the edge with\n            the same constant value k = 0.\n        - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by\n            wrapping around to the opposite edge.\n        - *nearest*: `(a a a a | a b c d | d d d d)`\n            The input is extended by the nearest pixel.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n        `\"bilinear\"`.\n    seed: Integer. Used to create a random seed.\n    fill_value: a float represents the value to be filled outside\n        the boundaries when `fill_mode=\"constant\"`.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomRotation",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "reflect",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_mode"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomSaturation",
        "docstring": "Randomly adjusts the saturation on given images.\n\nThis layer will randomly increase/reduce the saturation for the input RGB\nimages.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: A tuple of two floats or a single float.\n        `factor` controls the extent to which the image saturation\n        is impacted. `factor=0.5` makes this layer perform a no-op\n        operation. `factor=0.0` makes the image fully grayscale.\n        `factor=1.0` makes the image fully saturated. Values should\n        be between `0.0` and `1.0`. If a tuple is used, a `factor`\n        is sampled between the two values for every image augmented.\n        If a single float is used, a value between `0.0` and the passed\n        float is sampled. To ensure the value is always the same,\n        pass a tuple with two identical floats: `(0.5, 0.5)`.\n    value_range: the range of values the incoming images will have.\n        Represented as a two-number tuple written `[low, high]`. This is\n        typically either `[0, 1]` or `[0, 255]` depending on how your\n        preprocessing pipeline is set up.\n    seed: Integer. Used to create a random seed.\n\nExample:\n```python\n(images, labels), _ = keras.datasets.cifar10.load_data()\nimages = images.astype(\"float32\")\nrandom_saturation = keras.layers.RandomSaturation(factor=0.2)\naugmented_images = random_saturation(images)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomSaturation",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomSharpness",
        "docstring": "Randomly performs the sharpness operation on given images.\n\nThe sharpness operation first performs a blur, then blends between the\noriginal image and the processed image. This operation adjusts the clarity\nof the edges in an image, ranging from blurred to enhanced sharpness.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    factor: A tuple of two floats or a single float.\n        `factor` controls the extent to which the image sharpness\n        is impacted. `factor=0.0` results in a fully blurred image,\n        `factor=0.5` applies no operation (preserving the original image),\n        and `factor=1.0` enhances the sharpness beyond the original. Values\n        should be between `0.0` and `1.0`. If a tuple is used, a `factor`\n        is sampled between the two values for every image augmented.\n        If a single float is used, a value between `0.0` and the passed\n        float is sampled. To ensure the value is always the same,\n        pass a tuple with two identical floats: `(0.5, 0.5)`.\n    value_range: the range of values the incoming images will have.\n        Represented as a two-number tuple written `[low, high]`. This is\n        typically either `[0, 1]` or `[0, 255]` depending on how your\n        preprocessing pipeline is set up.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomSharpness",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomShear",
        "docstring": "A preprocessing layer that randomly applies shear transformations to\nimages.\n\nThis layer shears the input images along the x-axis and/or y-axis by a\nrandomly selected factor within the specified range. The shear\ntransformation is applied to each image independently in a batch. Empty\nregions created during the transformation are filled according to the\n`fill_mode` and `fill_value` parameters.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    x_factor: A tuple of two floats. For each augmented image, a value\n        is sampled from the provided range. If a float is passed, the\n        range is interpreted as `(0, x_factor)`. Values represent a\n        percentage of the image to shear over. For example, 0.3 shears\n        pixels up to 30% of the way across the image. All provided values\n        should be positive.\n    y_factor: A tuple of two floats. For each augmented image, a value\n        is sampled from the provided range. If a float is passed, the\n        range is interpreted as `(0, y_factor)`. Values represent a\n        percentage of the image to shear over. For example, 0.3 shears\n        pixels up to 30% of the way across the image. All provided values\n        should be positive.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n        `\"bilinear\"`.\n    fill_mode: Points outside the boundaries of the input are filled\n        according to the given mode. Available methods are `\"constant\"`,\n        `\"nearest\"`, `\"wrap\"` and `\"reflect\"`. Defaults to `\"constant\"`.\n        - `\"reflect\"`: `(d c b a | a b c d | d c b a)`\n            The input is extended by reflecting about the edge of the\n            last pixel.\n        - `\"constant\"`: `(k k k k | a b c d | k k k k)`\n            The input is extended by filling all values beyond the edge\n            with the same constant value `k` specified by `fill_value`.\n        - `\"wrap\"`: `(a b c d | a b c d | a b c d)`\n            The input is extended by wrapping around to the opposite edge.\n        - `\"nearest\"`: `(a a a a | a b c d | d d d d)`\n            The input is extended by the nearest pixel.\n        Note that when using torch backend, `\"reflect\"` is redirected to\n        `\"mirror\"` `(c d c b | a b c d | c b a b)` because torch does\n        not support `\"reflect\"`.\n        Note that torch backend does not support `\"wrap\"`.\n    fill_value: A float representing the value to be filled outside the\n        boundaries when `fill_mode=\"constant\"`.\n    seed: Integer. Used to create a random seed.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomShear",
        "params": [
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "x_factor"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "y_factor"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "reflect",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_mode"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomTranslation",
        "docstring": "A preprocessing layer which randomly translates images during training.\n\nThis layer will apply random translations to each image during training,\nfilling empty space according to `fill_mode`.\n\nInput pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\nof integer or floating point dtype. By default, the layer will output\nfloats.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format,\n    or `(..., channels, height, width)`, in `\"channels_first\"` format.\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., target_height, target_width, channels)`,\n    or `(..., channels, target_height, target_width)`,\n    in `\"channels_first\"` format.\n\nArgs:\n    height_factor: a float represented as fraction of value, or a tuple of\n        size 2 representing lower and upper bound for shifting vertically. A\n        negative value means shifting image up, while a positive value means\n        shifting image down. When represented as a single positive float,\n        this value is used for both the upper and lower bound. For instance,\n        `height_factor=(-0.2, 0.3)` results in an output shifted by a random\n        amount in the range `[-20%, +30%]`. `height_factor=0.2` results in\n        an output height shifted by a random amount in the range\n        `[-20%, +20%]`.\n    width_factor: a float represented as fraction of value, or a tuple of\n        size 2 representing lower and upper bound for shifting horizontally.\n        A negative value means shifting image left, while a positive value\n        means shifting image right. When represented as a single positive\n        float, this value is used for both the upper and lower bound. For\n        instance, `width_factor=(-0.2, 0.3)` results in an output shifted\n        left by 20%, and shifted right by 30%. `width_factor=0.2` results\n        in an output height shifted left or right by 20%.\n    fill_mode: Points outside the boundaries of the input are filled\n        according to the given mode. Available methods are `\"constant\"`,\n        `\"nearest\"`, `\"wrap\"` and `\"reflect\"`. Defaults to `\"constant\"`.\n        - `\"reflect\"`: `(d c b a | a b c d | d c b a)`\n            The input is extended by reflecting about the edge of the last\n            pixel.\n        - `\"constant\"`: `(k k k k | a b c d | k k k k)`\n            The input is extended by filling all values beyond\n            the edge with the same constant value k specified by\n            `fill_value`.\n        - `\"wrap\"`: `(a b c d | a b c d | a b c d)`\n            The input is extended by wrapping around to the opposite edge.\n        - `\"nearest\"`: `(a a a a | a b c d | d d d d)`\n            The input is extended by the nearest pixel.\n        Note that when using torch backend, `\"reflect\"` is redirected to\n        `\"mirror\"` `(c d c b | a b c d | c b a b)` because torch does not\n        support `\"reflect\"`.\n        Note that torch backend does not support `\"wrap\"`.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n        `\"bilinear\"`.\n    seed: Integer. Used to create a random seed.\n    fill_value: a float represents the value to be filled outside the\n        boundaries when `fill_mode=\"constant\"`.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomTranslation",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "height_factor"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "width_factor"
          },
          {
            "annotation": null,
            "default": "reflect",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_mode"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RandomZoom",
        "docstring": "A preprocessing layer which randomly zooms images during training.\n\nThis layer will randomly zoom in or out on each axis of an image\nindependently, filling empty space according to `fill_mode`.\n\nInput pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\nof integer or floating point dtype.\nBy default, the layer will output floats.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format,\n    or `(..., channels, height, width)`, in `\"channels_first\"` format.\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., target_height, target_width, channels)`,\n    or `(..., channels, target_height, target_width)`,\n    in `\"channels_first\"` format.\n\nArgs:\n    height_factor: a float represented as fraction of value, or a tuple of\n        size 2 representing lower and upper bound for zooming vertically.\n        When represented as a single float, this value is used for both the\n        upper and lower bound. A positive value means zooming out, while a\n        negative value means zooming in. For instance,\n        `height_factor=(0.2, 0.3)` result in an output zoomed out by a\n        random amount in the range `[+20%, +30%]`.\n        `height_factor=(-0.3, -0.2)` result in an output zoomed in by a\n        random amount in the range `[+20%, +30%]`.\n    width_factor: a float represented as fraction of value, or a tuple of\n        size 2 representing lower and upper bound for zooming horizontally.\n        When represented as a single float, this value is used for both the\n        upper and lower bound. For instance, `width_factor=(0.2, 0.3)`\n        result in an output zooming out between 20% to 30%.\n        `width_factor=(-0.3, -0.2)` result in an output zooming in between\n        20% to 30%. `None` means i.e., zooming vertical and horizontal\n        directions by preserving the aspect ratio. Defaults to `None`.\n    fill_mode: Points outside the boundaries of the input are filled\n        according to the given mode. Available methods are `\"constant\"`,\n        `\"nearest\"`, `\"wrap\"` and `\"reflect\"`. Defaults to `\"reflect\"`.\n        - `\"reflect\"`: `(d c b a | a b c d | d c b a)`\n            The input is extended by reflecting about the edge of the last\n            pixel.\n        - `\"constant\"`: `(k k k k | a b c d | k k k k)`\n            The input is extended by filling all values beyond\n            the edge with the same constant value k specified by\n            `fill_value`.\n        - `\"wrap\"`: `(a b c d | a b c d | a b c d)`\n            The input is extended by wrapping around to the opposite edge.\n        - `\"nearest\"`: `(a a a a | a b c d | d d d d)`\n            The input is extended by the nearest pixel.\n        Note that when using torch backend, `\"reflect\"` is redirected to\n        `\"mirror\"` `(c d c b | a b c d | c b a b)` because torch does not\n        support `\"reflect\"`.\n        Note that torch backend does not support `\"wrap\"`.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n        `\"bilinear\"`.\n    seed: Integer. Used to create a random seed.\n    fill_value: a float that represents the value to be filled outside\n        the boundaries when `fill_mode=\"constant\"`.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.\n\nExample:\n\n>>> input_img = np.random.random((32, 224, 224, 3))\n>>> layer = keras.layers.RandomZoom(.5, .2)\n>>> out_img = layer(input_img)",
        "has_varargs": false,
        "kind": "class",
        "name": "RandomZoom",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "height_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "width_factor"
          },
          {
            "annotation": null,
            "default": "reflect",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_mode"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ReLU",
        "docstring": "Rectified Linear Unit activation function layer.\n\nFormula:\n``` python\nf(x) = max(x,0)\nf(x) = max_value if x >= max_value\nf(x) = x if threshold <= x < max_value\nf(x) = negative_slope * (x - threshold) otherwise\n```\n\nExample:\n``` python\nrelu_layer = keras.layers.ReLU(\n    max_value=10,\n    negative_slope=0.5,\n    threshold=0,\n)\ninput = np.array([-10, -5, 0.0, 5, 10])\nresult = relu_layer(input)\n# result = [-5. , -2.5,  0. ,  5. , 10.]\n```\n\nArgs:\n    max_value: Float >= 0. Maximum activation value. None means unlimited.\n        Defaults to `None`.\n    negative_slope: Float >= 0. Negative slope coefficient.\n        Defaults to `0.0`.\n    threshold: Float >= 0. Threshold value for thresholded activation.\n        Defaults to `0.0`.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "ReLU",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "max_value"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "negative_slope"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "threshold"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.RepeatVector",
        "docstring": "Repeats the input n times.\n\nExample:\n\n>>> x = keras.Input(shape=(32,))\n>>> y = keras.layers.RepeatVector(3)(x)\n>>> y.shape\n(None, 3, 32)\n\nArgs:\n    n: Integer, repetition factor.\n\nInput shape:\n    2D tensor with shape `(batch_size, features)`.\n\nOutput shape:\n    3D tensor with shape `(batch_size, n, features)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "RepeatVector",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "n"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Rescaling",
        "docstring": "A preprocessing layer which rescales input values to a new range.\n\nThis layer rescales every value of an input (often an image) by multiplying\nby `scale` and adding `offset`.\n\nFor instance:\n\n1. To rescale an input in the `[0, 255]` range\nto be in the `[0, 1]` range, you would pass `scale=1./255`.\n\n2. To rescale an input in the `[0, 255]` range to be in the `[-1, 1]` range,\nyou would pass `scale=1./127.5, offset=-1`.\n\nThe rescaling is applied both during training and inference. Inputs can be\nof integer or floating point dtype, and by default the layer will output\nfloats.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    scale: Float, the scale to apply to the inputs.\n    offset: Float, the offset to apply to the inputs.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "Rescaling",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "scale"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "offset"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Reshape",
        "docstring": "Layer that reshapes inputs into the given shape.\n\nArgs:\n    target_shape: Target shape. Tuple of integers, does not include the\n        samples dimension (batch size). One element of the `target_shape`\n        can be -1 in which case the missing value is inferred from the\n        size of the array and remaining dimensions.\n\nInput shape:\n    Arbitrary, but required to be compatible with `target_shape`.\n\nOutput shape:\n    `(batch_size, *target_shape)`\n\nExample:\n\n>>> x = keras.Input(shape=(12,))\n>>> y = keras.layers.Reshape((3, 4))(x)\n>>> y.shape\n(None, 3, 4)\n\n>>> # another example with shape inference using `-1` as dimension\n>>> y = keras.layers.Reshape((-1, 2, 2))(x)\n>>> y.shape\n(None, 3, 2, 2)",
        "has_varargs": false,
        "kind": "class",
        "name": "Reshape",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "target_shape"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Resizing",
        "docstring": "A preprocessing layer which resizes images.\n\nThis layer resizes an image input to a target height and width. The input\nshould be a 4D (batched) or 3D (unbatched) tensor in `\"channels_last\"`\nformat. Input pixel values can be of any range\n(e.g. `[0., 1.)` or `[0, 255]`).\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nInput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format,\n    or `(..., channels, height, width)`, in `\"channels_first\"` format.\n\nOutput shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., target_height, target_width, channels)`,\n    or `(..., channels, target_height, target_width)`,\n    in `\"channels_first\"` format.\n\nArgs:\n    height: Integer, the height of the output shape.\n    width: Integer, the width of the output shape.\n    interpolation: String, the interpolation method.\n        Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`,\n        `\"lanczos3\"`, `\"lanczos5\"`. Defaults to `\"bilinear\"`.\n    crop_to_aspect_ratio: If `True`, resize the images without aspect\n        ratio distortion. When the original aspect ratio differs\n        from the target aspect ratio, the output image will be\n        cropped so as to return the\n        largest possible window in the image (of size `(height, width)`)\n        that matches the target aspect ratio. By default\n        (`crop_to_aspect_ratio=False`), aspect ratio may not be preserved.\n    pad_to_aspect_ratio: If `True`, pad the images without aspect\n        ratio distortion. When the original aspect ratio differs\n        from the target aspect ratio, the output image will be\n        evenly padded on the short side.\n    fill_mode: When using `pad_to_aspect_ratio=True`, padded areas\n        are filled according to the given mode. Only `\"constant\"` is\n        supported at this time\n        (fill with constant value, equal to `fill_value`).\n    fill_value: Float. Padding value to use when `pad_to_aspect_ratio=True`.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.",
        "has_varargs": false,
        "kind": "class",
        "name": "Resizing",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "height"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "width"
          },
          {
            "annotation": null,
            "default": "bilinear",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "crop_to_aspect_ratio"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pad_to_aspect_ratio"
          },
          {
            "annotation": null,
            "default": "constant",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_mode"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fill_value"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "antialias"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ReversibleEmbedding",
        "docstring": "An embedding layer which can project backwards to the input dim.\n\nThis layer is an extension of `keras.layers.Embedding` for language models.\nThis layer can be called \"in reverse\" with `reverse=True`, in which case the\nlayer will linearly project from `output_dim` back to `input_dim`.\n\nBy default, the reverse projection will use the transpose of the\n`embeddings` weights to project to `input_dim` (weights are \"tied\"). If\n`tie_weights=False`, the model will use a separate, trainable variable for\nreverse projection.\n\nThis layer has no bias terms.\n\nArgs:\n    input_dim: Integer. Size of the vocabulary,\n        i.e. maximum integer index + 1.\n    output_dim: Integer. Dimension of the dense embedding.\n    tie_weights: Boolean, whether or not the matrix for embedding and\n        the matrix for the `reverse` projection should share the same\n        weights.\n    embeddings_initializer: Initializer for the `embeddings`\n        matrix (see `keras.initializers`).\n    embeddings_regularizer: Regularizer function applied to\n        the `embeddings` matrix (see `keras.regularizers`).\n    embeddings_constraint: Constraint function applied to\n        the `embeddings` matrix (see `keras.constraints`).\n    mask_zero: Boolean, whether or not the input value 0 is a special\n        \"padding\" value that should be masked out.\n    reverse_dtype: The dtype for the reverse projection computation.\n        Defaults to the `compute_dtype` of the layer.\n    logit_soft_cap: If `logit_soft_cap` is set and `reverse=True`, the\n        output logits will be scaled by\n        `tanh(logits / logit_soft_cap) * logit_soft_cap`. This narrows the\n        range of output logits and can improve training.\n    **kwargs: other keyword arguments passed to `keras.layers.Embedding`,\n        including `name`, `trainable`, `dtype` etc.\n\nCall arguments:\n    inputs: The tensor inputs to the layer.\n    reverse: Boolean. If `True` the layer will perform a linear projection\n        from `output_dim` to `input_dim`, instead of a normal embedding\n        call. Default to `False`.\n\nExample:\n```python\nbatch_size = 16\nvocab_size = 100\nhidden_dim = 32\nseq_length = 50\n\n# Generate random inputs.\ntoken_ids = np.random.randint(vocab_size, size=(batch_size, seq_length))\n\nembedding = keras.layers.ReversibleEmbedding(vocab_size, hidden_dim)\n# Embed tokens to shape `(batch_size, seq_length, hidden_dim)`.\nhidden_states = embedding(token_ids)\n# Project hidden states to shape `(batch_size, seq_length, vocab_size)`.\nlogits = embedding(hidden_states, reverse=True)\n```\n\nReferences:\n- [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)\n- [Press and Wolf, 2016](https://arxiv.org/abs/1608.05859)",
        "has_varargs": false,
        "kind": "class",
        "name": "ReversibleEmbedding",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "input_dim"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_dim"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "tie_weights"
          },
          {
            "annotation": null,
            "default": "uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "embeddings_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "embeddings_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "embeddings_constraint"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mask_zero"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reverse_dtype"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "logit_soft_cap"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.STFTSpectrogram",
        "docstring": "Layer to compute the Short-Time Fourier Transform (STFT) on a 1D signal.\n\nA layer that computes Spectrograms of the input signal to produce\na spectrogram. This layers utilizes Short-Time Fourier Transform (STFT) by\nThe layer computes Spectrograms based on STFT by utilizing convolution\nkernels, which allows parallelization on GPUs and trainable kernels for\nfine-tuning support. This layer allows different modes of output\n(e.g., log-scaled magnitude, phase, power spectral density, etc.) and\nprovides flexibility in windowing, padding, and scaling options for the\nSTFT calculation.\n\nExamples:\n\nApply it as a non-trainable preprocessing layer on 3 audio tracks of\n1 channel, 10 seconds and sampled at 16 kHz.\n\n>>> layer = keras.layers.STFTSpectrogram(\n...     mode='log',\n...     frame_length=256,\n...     frame_step=128,   # 50% overlap\n...     fft_length=512,\n...     window=\"hann\",\n...     padding=\"valid\",\n...     trainable=False,  # non-trainable, preprocessing only\n... )\n>>> layer(keras.random.uniform(shape=(3, 160000, 1))).shape\n(3, 1249, 257)\n\nApply it as a trainable processing layer on 3 stereo audio tracks of\n2 channels, 10 seconds and sampled at 16 kHz. This is initialized as the\nnon-trainable layer, but then can be trained jointly within a model.\n\n>>> layer = keras.layers.STFTSpectrogram(\n...     mode='log',\n...     frame_length=256,\n...     frame_step=128,    # 50% overlap\n...     fft_length=512,\n...     window=\"hamming\",  # hamming windowing function\n...     padding=\"same\",    # padding to preserve the time dimension\n...     trainable=True,    # trainable, this is the default in keras\n... )\n>>> layer(keras.random.uniform(shape=(3, 160000, 2))).shape\n(3, 1250, 514)\n\nSimilar to the last example, but add an extra dimension so the output is\nan image to be used with image models. We apply this here on a signal of\n3 input channels to output an image tensor, hence is directly applicable\nwith an image model.\n\n>>> layer = keras.layers.STFTSpectrogram(\n...     mode='log',\n...     frame_length=256,\n...     frame_step=128,\n...     fft_length=512,\n...     padding=\"same\",\n...     expand_dims=True,  # this adds the extra dimension\n... )\n>>> layer(keras.random.uniform(shape=(3, 160000, 3))).shape\n(3, 1250, 257, 3)\n\nArgs:\n    mode: String, the output type of the spectrogram. Can be one of\n        `\"log\"`, `\"magnitude`\", `\"psd\"`, `\"real`\", `\"imag`\", `\"angle`\",\n        `\"stft`\". Defaults to `\"log`\".\n    frame_length: Integer, The length of each frame (window) for STFT in\n        samples. Defaults to 256.\n    frame_step: Integer, the step size (hop length) between\n        consecutive frames. If not provided, defaults to half the\n        frame_length. Defaults to `frame_length // 2`.\n    fft_length: Integer, the size of frequency bins used in the Fast-Fourier\n        Transform (FFT) to apply to each frame. Should be greater than or\n        equal to `frame_length`.  Recommended to be a power of two. Defaults\n        to the smallest power of two that is greater than or equal\n        to `frame_length`.\n    window: (String or array_like), the windowing function to apply to each\n        frame. Can be `\"hann`\" (default), `\"hamming`\", or a custom window\n        provided as an array_like.\n    periodic: Boolean, if True, the window function will be treated as\n        periodic. Defaults to `False`.\n    scaling: String, type of scaling applied to the window. Can be\n        `\"density`\", `\"spectrum`\", or None. Default is `\"density`\".\n    padding: String, padding strategy. Can be `\"valid`\" or `\"same`\".\n        Defaults to `\"valid\"`.\n    expand_dims: Boolean, if True, will expand the output into spectrograms\n        into two dimensions to be compatible with image models.\n        Defaults to `False`.\n    data_format: String, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, weight)`. Defaults to `\"channels_last\"`.\n\nRaises:\n    ValueError: If an invalid value is provided for `\"mode`\", `\"scaling`\",\n        `\"padding`\", or other input arguments.\n    TypeError: If the input data type is not one of `\"float16`\",\n        `\"float32`\", or `\"float64`\".\n\nInput shape:\n    A 3D tensor of shape `(batch_size, time_length, input_channels)`, if\n    `data_format==\"channels_last\"`, and of shape\n    `(batch_size, input_channels, time_length)` if\n    `data_format==\"channels_first\"`, where `time_length` is the length of\n    the input signal, and `input_channels` is the number of input channels.\n    The same kernels are applied to each channel independently.\n\nOutput shape:\n    If `data_format==\"channels_first\" and not expand_dims`, a 3D tensor:\n        `(batch_size, input_channels * freq_channels, new_time_length)`\n    If `data_format==\"channels_last\" and not expand_dims`, a 3D tensor:\n        `(batch_size, new_time_length, input_channels * freq_channels)`\n    If `data_format==\"channels_first\" and expand_dims`, a 4D tensor:\n        `(batch_size, input_channels, new_time_length, freq_channels)`\n    If `data_format==\"channels_last\" and expand_dims`, a 4D tensor:\n        `(batch_size, new_time_length, freq_channels, input_channels)`\n\n    where `new_time_length` depends on the padding, and `freq_channels` is\n    the number of FFT bins `(fft_length // 2 + 1)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "STFTSpectrogram",
        "params": [
          {
            "annotation": null,
            "default": "log",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mode"
          },
          {
            "annotation": null,
            "default": "256",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "frame_length"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "frame_step"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "fft_length"
          },
          {
            "annotation": null,
            "default": "hann",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "window"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "periodic"
          },
          {
            "annotation": null,
            "default": "density",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "scaling"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "expand_dims"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.SeparableConv1D",
        "docstring": "1D separable convolution layer.\n\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf `use_bias` is True and a bias initializer is provided,\nit adds a bias vector to the output. It then optionally applies an\nactivation function to produce the final output.\n\nArgs:\n    filters: int, the dimensionality of the output space (i.e. the number\n        of filters in the pointwise convolution).\n    kernel_size: int or tuple/list of 1 integers, specifying the size of the\n        depthwise convolution window.\n    strides: int or tuple/list of 1 integers, specifying the stride length\n        of the depthwise convolution. If only one int is specified, the same\n        stride size will be used for all dimensions. `strides > 1` is\n        incompatible with `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated convolution. If only one int is specified,\n        the same dilation rate will be used for all dimensions.\n    depth_multiplier: The number of depthwise convolution output channels\n        for each input channel. The total number of depthwise convolution\n        output channels will be equal to `input_channel * depth_multiplier`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    depthwise_initializer: An initializer for the depthwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    pointwise_initializer: An initializer for the pointwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    bias_initializer: An initializer for the bias vector. If None, the\n        default initializer ('\"zeros\"') will be used.\n    depthwise_regularizer: Optional regularizer for the depthwise\n        convolution kernel.\n    pointwise_regularizer: Optional regularizer for the pointwise\n        convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    depthwise_constraint: Optional projection function to be applied to the\n        depthwise kernel after being updated by an `Optimizer` (e.g. used\n        for norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape).\n    pointwise_constraint: Optional projection function to be applied to the\n        pointwise kernel after being updated by an `Optimizer`.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n\nReturns:\n    A 3D tensor representing\n    `activation(separable_conv1d(inputs, kernel) + bias)`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 12)\n>>> y = keras.layers.SeparableConv1D(3, 4, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 4, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "SeparableConv1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depth_multiplier"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_initializer"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.SeparableConvolution1D",
        "docstring": "1D separable convolution layer.\n\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf `use_bias` is True and a bias initializer is provided,\nit adds a bias vector to the output. It then optionally applies an\nactivation function to produce the final output.\n\nArgs:\n    filters: int, the dimensionality of the output space (i.e. the number\n        of filters in the pointwise convolution).\n    kernel_size: int or tuple/list of 1 integers, specifying the size of the\n        depthwise convolution window.\n    strides: int or tuple/list of 1 integers, specifying the stride length\n        of the depthwise convolution. If only one int is specified, the same\n        stride size will be used for all dimensions. `strides > 1` is\n        incompatible with `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated convolution. If only one int is specified,\n        the same dilation rate will be used for all dimensions.\n    depth_multiplier: The number of depthwise convolution output channels\n        for each input channel. The total number of depthwise convolution\n        output channels will be equal to `input_channel * depth_multiplier`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    depthwise_initializer: An initializer for the depthwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    pointwise_initializer: An initializer for the pointwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    bias_initializer: An initializer for the bias vector. If None, the\n        default initializer ('\"zeros\"') will be used.\n    depthwise_regularizer: Optional regularizer for the depthwise\n        convolution kernel.\n    pointwise_regularizer: Optional regularizer for the pointwise\n        convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    depthwise_constraint: Optional projection function to be applied to the\n        depthwise kernel after being updated by an `Optimizer` (e.g. used\n        for norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape).\n    pointwise_constraint: Optional projection function to be applied to the\n        pointwise kernel after being updated by an `Optimizer`.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n\nReturns:\n    A 3D tensor representing\n    `activation(separable_conv1d(inputs, kernel) + bias)`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 12)\n>>> y = keras.layers.SeparableConv1D(3, 4, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 4, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "SeparableConv1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depth_multiplier"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_initializer"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.SeparableConv2D",
        "docstring": "2D separable convolution layer.\n\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf `use_bias` is True and a bias initializer is provided,\nit adds a bias vector to the output. It then optionally applies an\nactivation function to produce the final output.\n\nArgs:\n    filters: int, the dimensionality of the output space (i.e. the number\n        of filters in the pointwise convolution).\n    kernel_size: int or tuple/list of 2 integers, specifying the size of the\n        depthwise convolution window.\n    strides: int or tuple/list of 2 integers, specifying the stride length\n        of the depthwise convolution. If only one int is specified, the same\n        stride size will be used for all dimensions. `strides > 1` is\n        incompatible with `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file\n        at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution. If only one int is specified,\n        the same dilation rate will be used for all dimensions.\n    depth_multiplier: The number of depthwise convolution output channels\n        for each input channel. The total number of depthwise convolution\n        output channels will be equal to `input_channel * depth_multiplier`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    depthwise_initializer: An initializer for the depthwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    pointwise_initializer: An initializer for the pointwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    bias_initializer: An initializer for the bias vector. If None, the\n        default initializer ('\"zeros\"') will be used.\n    depthwise_regularizer: Optional regularizer for the depthwise\n        convolution kernel.\n    pointwise_regularizer: Optional regularizer for the pointwise\n        convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    depthwise_constraint: Optional projection function to be applied to the\n        depthwise kernel after being updated by an `Optimizer` (e.g. used\n        for norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape).\n    pointwise_constraint: Optional projection function to be applied to the\n        pointwise kernel after being updated by an `Optimizer`.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n\nReturns:\n    A 4D tensor representing\n    `activation(separable_conv2d(inputs, kernel) + bias)`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 10, 12)\n>>> y = keras.layers.SeparableConv2D(3, 4, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 4, 4, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "SeparableConv2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depth_multiplier"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_initializer"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.SeparableConvolution2D",
        "docstring": "2D separable convolution layer.\n\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf `use_bias` is True and a bias initializer is provided,\nit adds a bias vector to the output. It then optionally applies an\nactivation function to produce the final output.\n\nArgs:\n    filters: int, the dimensionality of the output space (i.e. the number\n        of filters in the pointwise convolution).\n    kernel_size: int or tuple/list of 2 integers, specifying the size of the\n        depthwise convolution window.\n    strides: int or tuple/list of 2 integers, specifying the stride length\n        of the depthwise convolution. If only one int is specified, the same\n        stride size will be used for all dimensions. `strides > 1` is\n        incompatible with `dilation_rate > 1`.\n    padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input. When `padding=\"same\"` and\n        `strides=1`, the output has the same size as the input.\n    data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file\n        at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution. If only one int is specified,\n        the same dilation rate will be used for all dimensions.\n    depth_multiplier: The number of depthwise convolution output channels\n        for each input channel. The total number of depthwise convolution\n        output channels will be equal to `input_channel * depth_multiplier`.\n    activation: Activation function. If `None`, no activation is applied.\n    use_bias: bool, if `True`, bias will be added to the output.\n    depthwise_initializer: An initializer for the depthwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    pointwise_initializer: An initializer for the pointwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.\n    bias_initializer: An initializer for the bias vector. If None, the\n        default initializer ('\"zeros\"') will be used.\n    depthwise_regularizer: Optional regularizer for the depthwise\n        convolution kernel.\n    pointwise_regularizer: Optional regularizer for the pointwise\n        convolution kernel.\n    bias_regularizer: Optional regularizer for the bias vector.\n    activity_regularizer: Optional regularizer function for the output.\n    depthwise_constraint: Optional projection function to be applied to the\n        depthwise kernel after being updated by an `Optimizer` (e.g. used\n        for norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape).\n    pointwise_constraint: Optional projection function to be applied to the\n        pointwise kernel after being updated by an `Optimizer`.\n    bias_constraint: Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.\n\nInput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`\n\nOutput shape:\n\n- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n\nReturns:\n    A 4D tensor representing\n    `activation(separable_conv2d(inputs, kernel) + bias)`.\n\nExample:\n\n>>> x = np.random.rand(4, 10, 10, 12)\n>>> y = keras.layers.SeparableConv2D(3, 4, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 4, 4, 4)",
        "has_varargs": false,
        "kind": "class",
        "name": "SeparableConv2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filters"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_size"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "strides"
          },
          {
            "annotation": null,
            "default": "valid",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dilation_rate"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depth_multiplier"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_initializer"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "depthwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pointwise_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.SimpleRNN",
        "docstring": "Fully-connected RNN where the output is to be fed back as the new input.\n\nArgs:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n        Default: hyperbolic tangent (`tanh`).\n        If you pass None, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses\n        a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation of the recurrent\n        state.  Default: `\"orthogonal\"`.\n    bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector.\n        Default: `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n        layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix.  Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector.\n        Default: `None`.\n    dropout: Float between 0 and 1.\n        Fraction of the units to drop for the linear transformation\n        of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1.\n        Fraction of the units to drop for the linear transformation of the\n        recurrent state. Default: 0.\n    return_sequences: Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state\n        in addition to the output. Default: `False`.\n    go_backwards: Boolean (default: `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.\n    stateful: Boolean (default: `False`). If `True`, the last state\n        for each sample at index i in a batch will be used as the\n        initial state for the sample of index i in the following batch.\n    unroll: Boolean (default: `False`).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up an RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.\n\nCall arguments:\n    sequence: A 3D tensor, with shape `[batch, timesteps, feature]`.\n    mask: Binary tensor of shape `[batch, timesteps]` indicating whether\n        a given timestep should be masked. An individual `True` entry\n        indicates that the corresponding timestep should be utilized,\n        while a `False` entry indicates that the corresponding timestep\n        should be ignored.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode.\n        This argument is passed to the cell when calling it.\n        This is only relevant if `dropout` or `recurrent_dropout` is used.\n    initial_state: List of initial state tensors to be passed to the first\n        call of the cell.\n\nExample:\n\n```python\ninputs = np.random.random((32, 10, 8))\nsimple_rnn = keras.layers.SimpleRNN(4)\noutput = simple_rnn(inputs)  # The output has shape `(32, 4)`.\nsimple_rnn = keras.layers.SimpleRNN(\n    4, return_sequences=True, return_state=True\n)\n# whole_sequence_output has shape `(32, 10, 4)`.\n# final_state has shape `(32, 4)`.\nwhole_sequence_output, final_state = simple_rnn(inputs)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "SimpleRNN",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "units"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activity_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_sequences"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "return_state"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "go_backwards"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "stateful"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "unroll"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.SimpleRNNCell",
        "docstring": "Cell class for SimpleRNN.\n\nThis class processes one step within the whole time sequence input, whereas\n`keras.layer.SimpleRNN` processes the whole sequence.\n\nArgs:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n        Default: hyperbolic tangent (`tanh`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer\n        should use a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation\n        of the recurrent state. Default: `\"orthogonal\"`.\n    bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector.\n        Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector.\n        Default: `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.\n    seed: Random seed for dropout.\n\nCall arguments:\n    sequence: A 2D tensor, with shape `(batch, features)`.\n    states: A 2D tensor with shape `(batch, units)`, which is the state\n        from the previous time step.\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode. Only relevant when `dropout` or\n        `recurrent_dropout` is used.\n\nExample:\n\n```python\ninputs = np.random.random([32, 10, 8]).astype(np.float32)\nrnn = keras.layers.RNN(keras.layers.SimpleRNNCell(4))\noutput = rnn(inputs)  # The output has shape `(32, 4)`.\nrnn = keras.layers.RNN(\n    keras.layers.SimpleRNNCell(4),\n    return_sequences=True,\n    return_state=True\n)\n# whole_sequence_output has shape `(32, 10, 4)`.\n# final_state has shape `(32, 4)`.\nwhole_sequence_output, final_state = rnn(inputs)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "SimpleRNNCell",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "units"
          },
          {
            "annotation": null,
            "default": "tanh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "activation"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_bias"
          },
          {
            "annotation": null,
            "default": "glorot_uniform",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_initializer"
          },
          {
            "annotation": null,
            "default": "orthogonal",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_initializer"
          },
          {
            "annotation": null,
            "default": "zeros",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_initializer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_regularizer"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "kernel_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_constraint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "bias_constraint"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dropout"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "recurrent_dropout"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Softmax",
        "docstring": "Softmax activation layer.\n\nFormula:\n``` python\nexp_x = exp(x - max(x))\nf(x) = exp_x / sum(exp_x)\n```\n\nExample:\n>>> softmax_layer = keras.layers.Softmax()\n>>> input = np.array([1.0, 2.0, 1.0])\n>>> result = softmax_layer(input)\n>>> result\n[0.21194157, 0.5761169, 0.21194157]\n\n\nArgs:\n    axis: Integer, or list of Integers, axis along which the softmax\n        normalization is applied.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.\n\nCall arguments:\n    inputs: The inputs (logits) to the softmax layer.\n    mask: A boolean mask of the same shape as `inputs`. The mask\n        specifies 1 to keep and 0 to mask. Defaults to `None`.\n\nReturns:\n    Softmaxed output with the same shape as `inputs`.",
        "has_varargs": false,
        "kind": "class",
        "name": "Softmax",
        "params": [
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Solarization",
        "docstring": "Applies `(max_value - pixel + min_value)` for each pixel in the image.\n\nWhen created without `threshold` parameter, the layer performs solarization\nto all values. When created with specified `threshold` the layer only\naugments pixels that are above the `threshold` value.\n\n**Note:** This layer is safe to use inside a `tf.data` or `grain` pipeline\n(independently of which backend you're using).\n\nArgs:\n    addition_factor: (Optional)  A tuple of two floats or a single float,\n        between 0 and 1.\n        For each augmented image a value is\n        sampled from the provided range. If a float is passed, the range is\n        interpreted as `(0, addition_factor)`. If specified, this value\n        (times the value range of input images, e.g. 255), is\n        added to each pixel before solarization and thresholding.\n        Defaults to 0.0.\n    threshold_factor: (Optional)  A tuple of two floats or a single float.\n        For each augmented image a value is\n        sampled from the provided range. If a float is passed, the range is\n        interpreted as `(0, threshold_factor)`. If specified, only pixel\n        values above this threshold will be solarized.\n    value_range: a tuple or a list of two elements. The first value\n        represents the lower bound for values in input images, the second\n        represents the upper bound. Images passed to the layer should have\n        values within `value_range`. Typical values to pass\n        are `(0, 255)` (RGB image) or `(0., 1.)` (scaled image).\n    seed: Integer. Used to create a random seed.\n    **kwargs: Base layer keyword arguments, such as `name` and `dtype`.\n\nExample:\n\n```python\n(images, labels), _ = keras.datasets.cifar10.load_data()\nprint(images[0, 0, 0])\n# [59 62 63]\n# Note that images are Tensor with values in the range [0, 255]\nsolarization = Solarization(value_range=(0, 255))\nimages = solarization(images)\nprint(images[0, 0, 0])\n# [196, 193, 192]\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "Solarization",
        "params": [
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "addition_factor"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "threshold_factor"
          },
          {
            "annotation": null,
            "default": "(0, 255)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "value_range"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.SpatialDropout1D",
        "docstring": "Spatial 1D version of Dropout.\n\nThis layer performs the same function as Dropout, however, it drops\nentire 1D feature maps instead of individual elements. If adjacent frames\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, `SpatialDropout1D` will help promote independence\nbetween feature maps and should be used instead.\n\nArgs:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n\nCall arguments:\n    inputs: A 3D tensor.\n    training: Python boolean indicating whether the layer\n        should behave in training mode (applying dropout)\n        or in inference mode (pass-through).\n\nInput shape:\n    3D tensor with shape: `(samples, timesteps, channels)`\n\nOutput shape: Same as input.\n\nReference:\n\n- [Tompson et al., 2014](https://arxiv.org/abs/1411.4280)",
        "has_varargs": false,
        "kind": "class",
        "name": "SpatialDropout1D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.layers.SpatialDropout2D",
        "docstring": "Spatial 2D version of Dropout.\n\nThis version performs the same function as Dropout, however, it drops\nentire 2D feature maps instead of individual elements. If adjacent pixels\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, `SpatialDropout2D` will help promote independence\nbetween feature maps and should be used instead.\n\nArgs:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    data_format: `\"channels_first\"` or `\"channels_last\"`.\n        In `\"channels_first\"` mode, the channels dimension (the depth)\n        is at index 1, in `\"channels_last\"` mode is it at index 3.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n\nCall arguments:\n    inputs: A 4D tensor.\n    training: Python boolean indicating whether the layer\n        should behave in training mode (applying dropout)\n        or in inference mode (pass-through).\n\nInput shape:\n    4D tensor with shape: `(samples, channels, rows, cols)` if\n        data_format='channels_first'\n    or 4D tensor with shape: `(samples, rows, cols, channels)` if\n        data_format='channels_last'.\n\nOutput shape: Same as input.\n\nReference:\n\n- [Tompson et al., 2014](https://arxiv.org/abs/1411.4280)",
        "has_varargs": false,
        "kind": "class",
        "name": "SpatialDropout2D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.layers.SpatialDropout3D",
        "docstring": "Spatial 3D version of Dropout.\n\nThis version performs the same function as Dropout, however, it drops\nentire 3D feature maps instead of individual elements. If adjacent voxels\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, SpatialDropout3D will help promote independence\nbetween feature maps and should be used instead.\n\nArgs:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    data_format: `\"channels_first\"` or `\"channels_last\"`.\n        In `\"channels_first\"` mode, the channels dimension (the depth)\n        is at index 1, in `\"channels_last\"` mode is it at index 4.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.\n\nCall arguments:\n    inputs: A 5D tensor.\n    training: Python boolean indicating whether the layer\n            should behave in training mode (applying dropout)\n            or in inference mode (pass-through).\n\nInput shape:\n    5D tensor with shape: `(samples, channels, dim1, dim2, dim3)` if\n        data_format='channels_first'\n    or 5D tensor with shape: `(samples, dim1, dim2, dim3, channels)` if\n        data_format='channels_last'.\n\nOutput shape: Same as input.\n\nReference:\n\n- [Tompson et al., 2014](https://arxiv.org/abs/1411.4280)",
        "has_varargs": false,
        "kind": "class",
        "name": "SpatialDropout3D",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rate"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "seed"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.layers.SpectralNormalization",
        "docstring": "Performs spectral normalization on the weights of a target layer.\n\nThis wrapper controls the Lipschitz constant of the weights of a layer by\nconstraining their spectral norm, which can stabilize the training of GANs.\n\nArgs:\n    layer: A `keras.layers.Layer` instance that\n        has either a `kernel` (e.g. `Conv2D`, `Dense`...)\n        or an `embeddings` attribute (`Embedding` layer).\n    power_iterations: int, the number of iterations during normalization.\n    **kwargs: Base wrapper keyword arguments.\n\nExamples:\n\nWrap `keras.layers.Conv2D`:\n>>> x = np.random.rand(1, 10, 10, 1)\n>>> conv2d = SpectralNormalization(keras.layers.Conv2D(2, 2))\n>>> y = conv2d(x)\n>>> y.shape\n(1, 9, 9, 2)\n\nWrap `keras.layers.Dense`:\n>>> x = np.random.rand(1, 10, 10, 1)\n>>> dense = SpectralNormalization(keras.layers.Dense(10))\n>>> y = dense(x)\n>>> y.shape\n(1, 10, 10, 10)\n\nReference:\n\n- [Spectral Normalization for GAN](https://arxiv.org/abs/1802.05957).",
        "has_varargs": false,
        "kind": "class",
        "name": "SpectralNormalization",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "layer"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "power_iterations"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.StackedRNNCells",
        "docstring": "Wrapper allowing a stack of RNN cells to behave as a single cell.\n\nUsed to implement efficient stacked RNNs.\n\nArgs:\n  cells: List of RNN cell instances.\n\nExample:\n\n```python\nbatch_size = 3\nsentence_length = 5\nnum_features = 2\nnew_shape = (batch_size, sentence_length, num_features)\nx = np.reshape(np.arange(30), new_shape)\n\nrnn_cells = [keras.layers.LSTMCell(128) for _ in range(2)]\nstacked_lstm = keras.layers.StackedRNNCells(rnn_cells)\nlstm_layer = keras.layers.RNN(stacked_lstm)\n\nresult = lstm_layer(x)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "StackedRNNCells",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "cells"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.StringLookup",
        "docstring": "A preprocessing layer that maps strings to (possibly encoded) indices.\n\nThis layer translates a set of arbitrary strings into integer output via a\ntable-based vocabulary lookup. This layer will perform no splitting or\ntransformation of input strings. For a layer that can split and tokenize\nnatural language, see the `keras.layers.TextVectorization` layer.\n\nThe vocabulary for the layer must be either supplied on construction or\nlearned via `adapt()`. During `adapt()`, the layer will analyze a data set,\ndetermine the frequency of individual strings tokens, and create a\nvocabulary from them. If the vocabulary is capped in size, the most frequent\ntokens will be used to create the vocabulary and all others will be treated\nas out-of-vocabulary (OOV).\n\nThere are two possible output modes for the layer. When `output_mode` is\n`\"int\"`, input strings are converted to their index in the vocabulary (an\ninteger).\nWhen `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`, input strings\nare encoded into an array where each dimension corresponds to an element in\nthe vocabulary.\n\nThe vocabulary can optionally contain a mask token as well as an OOV token\n(which can optionally occupy multiple indices in the vocabulary, as set\nby `num_oov_indices`).\nThe position of these tokens in the vocabulary is fixed. When `output_mode`\nis `\"int\"`, the vocabulary will begin with the mask token (if set), followed\nby OOV indices, followed by the rest of the vocabulary. When `output_mode`\nis `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` the vocabulary will begin with\nOOV indices and instances of the mask token will be dropped.\n\n**Note:** This layer uses TensorFlow internally. It cannot\nbe used as part of the compiled computation graph of a model with\nany backend other than TensorFlow.\nIt can however be used with any backend when running eagerly.\nIt can also always be used as part of an input preprocessing pipeline\nwith any backend (outside the model itself), which is how we recommend\nusing this layer.\n\n**Note:** This layer is safe to use inside a `tf.data` pipeline\n(independently of which backend you're using).\n\nArgs:\n    max_tokens: Maximum size of the vocabulary for this layer. This should\n        only be specified when adapting the vocabulary or when setting\n        `pad_to_max_tokens=True`. If None, there is no cap on the size of\n        the vocabulary. Note that this size includes the OOV\n        and mask tokens. Defaults to `None`.\n    num_oov_indices: The number of out-of-vocabulary tokens to use.\n        If this value is more than 1, OOV inputs are modulated to\n        determine their OOV value.\n        If this value is 0, OOV inputs will cause an error when calling\n        the layer. Defaults to `1`.\n    mask_token: A token that represents masked inputs. When `output_mode` is\n        `\"int\"`, the token is included in the vocabulary and mapped to index\n        0.\n        In other output modes, the token will not appear in the vocabulary\n        and instances of the mask token in the input will be dropped.\n        If set to `None`, no mask term will be added. Defaults to `None`.\n    oov_token: Only used when `invert` is True. The token to return for OOV\n        indices. Defaults to `\"[UNK]\"`.\n    vocabulary: Optional. Either an array of strings or a string path to a\n        text file. If passing an array, you can pass a tuple, list, 1D NumPy\n        array, or 1D tensor containing the string vocabulary terms.\n        If passing a file path, the file should contain one line per term in\n        the vocabulary. If this argument is set, there is no need to\n        `adapt()` the layer.\n    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`.\n        A tuple, list, 1D NumPy array, or 1D tensor or the same length\n        as the vocabulary, containing the floating point inverse document\n        frequency weights, which will be multiplied by per sample term\n        counts for the final TF-IDF weight.\n        If the `vocabulary` argument is set and `output_mode` is `\"tf_idf\"`,\n        this argument must be supplied.\n    invert: Only valid when `output_mode` is `\"int\"`.\n        If `True`, this layer will map indices to vocabulary items\n        instead of mapping vocabulary items to indices.\n        Defaults to `False`.\n    output_mode: Specification for the output of the layer. Values can be\n        `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`\n        configuring the layer as follows:\n        - `\"int\"`: Return the vocabulary indices of the input tokens.\n        - `\"one_hot\"`: Encodes each individual element in the input into an\n            array the same size as the vocabulary,\n            containing a 1 at the element index. If the last dimension\n            is size 1, will encode on that dimension.\n            If the last dimension is not size 1, will append a new\n            dimension for the encoded output.\n        - `\"multi_hot\"`: Encodes each sample in the input into a single\n            array the same size as the vocabulary containing a 1 for each\n            vocabulary term present in the sample.\n            Treats the last dimension as the sample dimension, if the input\n            shape is `(..., sample_length)`, the output shape will be\n            `(..., num_tokens)`.\n        - `\"count\"`: As `\"multi_hot\"`, but the int array contains\n            a count of the number of times the token at that index\n            appeared in the sample.\n        - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is\n            applied to find the value in each token slot.\n        For `\"int\"` output, any shape of input and output is supported.\n        For all other output modes, currently only output up to rank 2\n        is supported. Defaults to `\"int\"`.\n    pad_to_max_tokens: Only applicable when `output_mode` is `\"multi_hot\"`,\n        `\"count\"`, or `\"tf_idf\"`. If `True`, the output will have\n        its feature axis padded to `max_tokens` even if the number\n        of unique tokens in the vocabulary is less than `max_tokens`,\n        resulting in a tensor of shape `(batch_size, max_tokens)`\n        regardless of vocabulary size. Defaults to `False`.\n    sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n        `\"tf_idf\"` output modes. Only supported with TensorFlow\n        backend. If `True`, returns a `SparseTensor`\n        instead of a dense `Tensor`. Defaults to `False`.\n    encoding: Optional. The text encoding to use to interpret the input\n        strings. Defaults to `\"utf-8\"`.\n\nExamples:\n\n**Creating a lookup layer with a known vocabulary**\n\nThis example creates a lookup layer with a pre-existing vocabulary.\n\n>>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n>>> data = [[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]]\n>>> layer = StringLookup(vocabulary=vocab)\n>>> layer(data)\narray([[1, 3, 4],\n       [4, 0, 2]])\n\n**Creating a lookup layer with an adapted vocabulary**\n\nThis example creates a lookup layer and generates the vocabulary by\nanalyzing the dataset.\n\n>>> data = [[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]]\n>>> layer = StringLookup()\n>>> layer.adapt(data)\n>>> layer.get_vocabulary()\n['[UNK]', 'd', 'z', 'c', 'b', 'a']\n\nNote that the OOV token `\"[UNK]\"` has been added to the vocabulary.\nThe remaining tokens are sorted by frequency\n(`\"d\"`, which has 2 occurrences, is first) then by inverse sort order.\n\n>>> data = [[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]]\n>>> layer = StringLookup()\n>>> layer.adapt(data)\n>>> layer(data)\narray([[5, 3, 1],\n       [1, 2, 4]])\n\n**Lookups with multiple OOV indices**\n\nThis example demonstrates how to use a lookup layer with multiple OOV\nindices.  When a layer is created with more than one OOV index, any OOV\nvalues are hashed into the number of OOV buckets, distributing OOV values in\na deterministic fashion across the set.\n\n>>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n>>> data = [[\"a\", \"c\", \"d\"], [\"m\", \"z\", \"b\"]]\n>>> layer = StringLookup(vocabulary=vocab, num_oov_indices=2)\n>>> layer(data)\narray([[2, 4, 5],\n       [0, 1, 3]])\n\nNote that the output for OOV value 'm' is 0, while the output for OOV value\n`\"z\"` is 1. The in-vocab terms have their output index increased by 1 from\nearlier examples (a maps to 2, etc) in order to make space for the extra OOV\nvalue.\n\n**One-hot output**\n\nConfigure the layer with `output_mode='one_hot'`. Note that the first\n`num_oov_indices` dimensions in the ont_hot encoding represent OOV values.\n\n>>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n>>> data = [\"a\", \"b\", \"c\", \"d\", \"z\"]\n>>> layer = StringLookup(vocabulary=vocab, output_mode='one_hot')\n>>> layer(data)\narray([[0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.],\n       [1., 0., 0., 0., 0.]], dtype=int64)\n\n**Multi-hot output**\n\nConfigure the layer with `output_mode='multi_hot'`. Note that the first\n`num_oov_indices` dimensions in the multi_hot encoding represent OOV values.\n\n>>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n>>> data = [[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]]\n>>> layer = StringLookup(vocabulary=vocab, output_mode='multi_hot')\n>>> layer(data)\narray([[0., 1., 0., 1., 1.],\n       [1., 0., 1., 0., 1.]], dtype=int64)\n\n**Token count output**\n\nConfigure the layer with `output_mode='count'`. As with multi_hot output,\nthe first `num_oov_indices` dimensions in the output represent OOV values.\n\n>>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n>>> data = [[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]]\n>>> layer = StringLookup(vocabulary=vocab, output_mode='count')\n>>> layer(data)\narray([[0., 1., 0., 1., 2.],\n       [2., 0., 1., 0., 1.]], dtype=int64)\n\n**TF-IDF output**\n\nConfigure the layer with `output_mode=\"tf_idf\"`. As with multi_hot output,\nthe first `num_oov_indices` dimensions in the output represent OOV values.\n\nEach token bin will output `token_count * idf_weight`, where the idf weights\nare the inverse document frequency weights per token. These should be\nprovided along with the vocabulary. Note that the `idf_weight` for OOV\nvalues will default to the average of all idf weights passed in.\n\n>>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n>>> idf_weights = [0.25, 0.75, 0.6, 0.4]\n>>> data = [[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]]\n>>> layer = StringLookup(output_mode=\"tf_idf\")\n>>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n>>> layer(data)\narray([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n       [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)\n\nTo specify the idf weights for OOV values, you will need to pass the entire\nvocabulary including the leading OOV token.\n\n>>> vocab = [\"[UNK]\", \"a\", \"b\", \"c\", \"d\"]\n>>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]\n>>> data = [[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]]\n>>> layer = StringLookup(output_mode=\"tf_idf\")\n>>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n>>> layer(data)\narray([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n       [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)\n\nWhen adapting the layer in `\"tf_idf\"` mode, each input sample will be\nconsidered a document, and IDF weight per token will be calculated as\n`log(1 + num_documents / (1 + token_document_count))`.\n\n**Inverse lookup**\n\nThis example demonstrates how to map indices to strings using this layer.\n(You can also use `adapt()` with `inverse=True`, but for simplicity we'll\npass the vocab in this example.)\n\n>>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n>>> data = [[1, 3, 4], [4, 0, 2]]\n>>> layer = StringLookup(vocabulary=vocab, invert=True)\n>>> layer(data)\narray([[b'a', b'c', b'd'],\n       [b'd', b'[UNK]', b'b']], dtype=object)\n\nNote that the first index corresponds to the OOV token by default.\n\n\n**Forward and inverse lookup pairs**\n\nThis example demonstrates how to use the vocabulary of a standard lookup\nlayer to create an inverse lookup layer.\n\n>>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n>>> data = [[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]]\n>>> layer = StringLookup(vocabulary=vocab)\n>>> i_layer = StringLookup(vocabulary=vocab, invert=True)\n>>> int_data = layer(data)\n>>> i_layer(int_data)\narray([[b'a', b'c', b'd'],\n       [b'd', b'[UNK]', b'b']], dtype=object)\n\nIn this example, the input value `\"z\"` resulted in an output of `\"[UNK]\"`,\nsince 1000 was not in the vocabulary - it got represented as an OOV, and all\nOOV values are returned as `\"[UNK]\"` in the inverse layer. Also, note that\nfor the inverse to work, you must have already set the forward layer\nvocabulary either directly or via `adapt()` before calling\n`get_vocabulary()`.",
        "has_varargs": false,
        "kind": "class",
        "name": "StringLookup",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "max_tokens"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "num_oov_indices"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "mask_token"
          },
          {
            "annotation": null,
            "default": "[UNK]",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "oov_token"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "vocabulary"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "idf_weights"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "invert"
          },
          {
            "annotation": null,
            "default": "int",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_mode"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pad_to_max_tokens"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sparse"
          },
          {
            "annotation": null,
            "default": "utf-8",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "encoding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Subtract",
        "docstring": "Performs elementwise subtraction.\n\nIt takes as input a list of tensors of size 2 both of the\nsame shape, and returns a single tensor (inputs[0] - inputs[1])\nof same shape.\n\nExamples:\n\n>>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Subtract()([x1, x2])\n\nUsage in a Keras model:\n\n>>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `subtracted = keras.layers.subtract([x1, x2])`\n>>> subtracted = keras.layers.Subtract()([x1, x2])\n>>> out = keras.layers.Dense(4)(subtracted)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)",
        "has_varargs": false,
        "kind": "class",
        "name": "Subtract",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.TFSMLayer",
        "docstring": "Reload a Keras model/layer that was saved via SavedModel / ExportArchive.\n\nArguments:\n    filepath: `str` or `pathlib.Path` object. The path to the SavedModel.\n    call_endpoint: Name of the endpoint to use as the `call()` method\n        of the reloaded layer. If the SavedModel was created\n        via `model.export()`,\n        then the default endpoint name is `'serve'`. In other cases\n        it may be named `'serving_default'`.\n\nExample:\n\n```python\nmodel.export(\"path/to/artifact\")\nreloaded_layer = TFSMLayer(\"path/to/artifact\")\noutputs = reloaded_layer(inputs)\n```\n\nThe reloaded object can be used like a regular Keras layer, and supports\ntraining/fine-tuning of its trainable weights. Note that the reloaded\nobject retains none of the internal structure or custom methods of the\noriginal object -- it's a brand new layer created around the saved\nfunction.\n\n**Limitations:**\n\n* Only call endpoints with a single `inputs` tensor argument\n(which may optionally be a dict/tuple/list of tensors) are supported.\nFor endpoints with multiple separate input tensor arguments, consider\nsubclassing `TFSMLayer` and implementing a `call()` method with a\ncustom signature.\n* If you need training-time behavior to differ from inference-time behavior\n(i.e. if you need the reloaded object to support a `training=True` argument\nin `__call__()`), make sure that the training-time call function is\nsaved as a standalone endpoint in the artifact, and provide its name\nto the `TFSMLayer` via the `call_training_endpoint` argument.",
        "has_varargs": false,
        "kind": "class",
        "name": "TFSMLayer",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "filepath"
          },
          {
            "annotation": null,
            "default": "serve",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "call_endpoint"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "call_training_endpoint"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "trainable"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.layers.TextVectorization",
        "docstring": "A preprocessing layer which maps text features to integer sequences.\n\nThis layer has basic options for managing text in a Keras model. It\ntransforms a batch of strings (one example = one string) into either a list\nof token indices (one example = 1D tensor of integer token indices) or a\ndense representation (one example = 1D tensor of float values representing\ndata about the example's tokens). This layer is meant to handle natural\nlanguage inputs. To handle simple string inputs (categorical strings or\npre-tokenized strings) see `kers_core.layers.StringLookup`.\n\nThe vocabulary for the layer must be either supplied on construction or\nlearned via `adapt()`. When this layer is adapted, it will analyze the\ndataset, determine the frequency of individual string values, and create a\nvocabulary from them. This vocabulary can have unlimited size or be capped,\ndepending on the configuration options for this layer; if there are more\nunique values in the input than the maximum vocabulary size, the most\nfrequent terms will be used to create the vocabulary.\n\nThe processing of each example contains the following steps:\n\n1. Standardize each example (usually lowercasing + punctuation stripping)\n2. Split each example into substrings (usually words)\n3. Recombine substrings into tokens (usually ngrams)\n4. Index tokens (associate a unique int value with each token)\n5. Transform each example using this index, either into a vector of ints or\n   a dense float vector.\n\nSome notes on passing callables to customize splitting and normalization for\nthis layer:\n\n1. Any callable can be passed to this Layer, but if you want to serialize\n   this object you should only pass functions that are registered Keras\n   serializables (see `keras.saving.register_keras_serializable`\n   for more details).\n2. When using a custom callable for `standardize`, the data received\n   by the callable will be exactly as passed to this layer. The callable\n   should return a tensor of the same shape as the input.\n3. When using a custom callable for `split`, the data received by the\n   callable will have the 1st dimension squeezed out - instead of\n   `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n   see `[\"string to split\", \"another string to split\"]`.\n   The callable should return a `tf.Tensor` of dtype `string`\n   with the first dimension containing the split tokens -\n   in this example, we should see something like `[[\"string\", \"to\",\n   \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`.\n\n**Note:** This layer uses TensorFlow internally. It cannot\nbe used as part of the compiled computation graph of a model with\nany backend other than TensorFlow.\nIt can however be used with any backend when running eagerly.\nIt can also always be used as part of an input preprocessing pipeline\nwith any backend (outside the model itself), which is how we recommend\nto use this layer.\n\n**Note:** This layer is safe to use inside a `tf.data` pipeline\n(independently of which backend you're using).\n\nArgs:\n    max_tokens: Maximum size of the vocabulary for this layer. This should\n        only be specified when adapting a vocabulary or when setting\n        `pad_to_max_tokens=True`. Note that this vocabulary\n        contains 1 OOV token, so the effective number of tokens is\n        `(max_tokens - 1 - (1 if output_mode == \"int\" else 0))`.\n    standardize: Optional specification for standardization to apply to the\n        input text. Values can be:\n        - `None`: No standardization.\n        - `\"lower_and_strip_punctuation\"`: Text will be lowercased and all\n            punctuation removed.\n        - `\"lower\"`: Text will be lowercased.\n        - `\"strip_punctuation\"`: All punctuation will be removed.\n        - Callable: Inputs will passed to the callable function,\n            which should be standardized and returned.\n    split: Optional specification for splitting the input text.\n        Values can be:\n        - `None`: No splitting.\n        - `\"whitespace\"`: Split on whitespace.\n        - `\"character\"`: Split on each unicode character.\n        - Callable: Standardized inputs will passed to the callable\n            function, which should be split and returned.\n    ngrams: Optional specification for ngrams to create from the\n        possibly-split input text. Values can be `None`, an integer\n        or tuple of integers; passing an integer will create ngrams\n        up to that integer, and passing a tuple of integers will\n        create ngrams for the specified values in the tuple.\n        Passing `None` means that no ngrams will be created.\n    output_mode: Optional specification for the output of the layer.\n        Values can be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`,\n        configuring the layer as follows:\n        - `\"int\"`: Outputs integer indices, one integer index per split\n            string token. When `output_mode == \"int\"`,\n            0 is reserved for masked locations;\n            this reduces the vocab size to `max_tokens - 2`\n            instead of `max_tokens - 1`.\n        - `\"multi_hot\"`: Outputs a single int array per batch, of either\n            vocab_size or max_tokens size, containing 1s in all elements\n            where the token mapped to that index exists at least\n            once in the batch item.\n        - `\"count\"`: Like `\"multi_hot\"`, but the int array contains\n            a count of the number of times the token at that index\n            appeared in the batch item.\n        - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm\n            is applied to find the value in each token slot.\n        For `\"int\"` output, any shape of input and output is supported.\n        For all other output modes, currently only rank 1 inputs\n        (and rank 2 outputs after splitting) are supported.\n    output_sequence_length: Only valid in INT mode. If set, the output will\n        have its time dimension padded or truncated to exactly\n        `output_sequence_length` values, resulting in a tensor of shape\n        `(batch_size, output_sequence_length)` regardless of how many tokens\n        resulted from the splitting step. Defaults to `None`. If `ragged`\n        is `True` then `output_sequence_length` may still truncate the\n        output.\n    pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`,\n        and `\"tf_idf\"` modes. If `True`, the output will have\n        its feature axis padded to `max_tokens` even if the number\n        of unique tokens in the vocabulary is less than `max_tokens`,\n        resulting in a tensor of shape `(batch_size, max_tokens)`\n        regardless of vocabulary size. Defaults to `False`.\n    vocabulary: Optional. Either an array of strings or a string path to a\n        text file. If passing an array, can pass a tuple, list,\n        1D NumPy array, or 1D tensor containing the string vocabulary terms.\n        If passing a file path, the file should contain one line per term\n        in the vocabulary. If this argument is set,\n        there is no need to `adapt()` the layer.\n    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list,\n        1D NumPy array, or 1D tensor of the same length as the vocabulary,\n        containing the floating point inverse document frequency weights,\n        which will be multiplied by per sample term counts for\n        the final `tf_idf` weight. If the `vocabulary` argument is set,\n        and `output_mode` is `\"tf_idf\"`, this argument must be supplied.\n    ragged: Boolean. Only applicable to `\"int\"` output mode.\n        Only supported with TensorFlow backend.\n        If `True`, returns a `RaggedTensor` instead of a dense `Tensor`,\n        where each sequence may have a different length\n        after string splitting. Defaults to `False`.\n    sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n        `\"tf_idf\"` output modes. Only supported with TensorFlow\n        backend. If `True`, returns a `SparseTensor`\n        instead of a dense `Tensor`. Defaults to `False`.\n    encoding: Optional. The text encoding to use to interpret the input\n        strings. Defaults to `\"utf-8\"`.\n\nExamples:\n\nThis example instantiates a `TextVectorization` layer that lowercases text,\nsplits on whitespace, strips punctuation, and outputs integer vocab indices.\n\n>>> max_tokens = 5000  # Maximum vocab size.\n>>> max_len = 4  # Sequence length to pad the outputs to.\n>>> # Create the layer.\n>>> vectorize_layer = TextVectorization(\n...     max_tokens=max_tokens,\n...     output_mode='int',\n...     output_sequence_length=max_len)\n\n>>> # Now that the vocab layer has been created, call `adapt` on the\n>>> # list of strings to create the vocabulary.\n>>> vectorize_layer.adapt([\"foo bar\", \"bar baz\", \"baz bada boom\"])\n\n>>> # Now, the layer can map strings to integers -- you can use an\n>>> # embedding layer to map these integers to learned embeddings.\n>>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n>>> vectorize_layer(input_data)\narray([[4, 1, 3, 0],\n       [1, 2, 0, 0]])\n\nThis example instantiates a `TextVectorization` layer by passing a list\nof vocabulary terms to the layer's `__init__()` method.\n\n>>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n>>> max_len = 4  # Sequence length to pad the outputs to.\n>>> # Create the layer, passing the vocab directly. You can also pass the\n>>> # vocabulary arg a path to a file containing one vocabulary word per\n>>> # line.\n>>> vectorize_layer = keras.layers.TextVectorization(\n...     max_tokens=max_tokens,\n...     output_mode='int',\n...     output_sequence_length=max_len,\n...     vocabulary=vocab_data)\n\n>>> # Because we've passed the vocabulary directly, we don't need to adapt\n>>> # the layer - the vocabulary is already set. The vocabulary contains the\n>>> # padding token ('') and OOV token ('[UNK]')\n>>> # as well as the passed tokens.\n>>> vectorize_layer.get_vocabulary()\n['', '[UNK]', 'earth', 'wind', 'and', 'fire']",
        "has_varargs": false,
        "kind": "class",
        "name": "TextVectorization",
        "params": [
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "max_tokens"
          },
          {
            "annotation": null,
            "default": "lower_and_strip_punctuation",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "standardize"
          },
          {
            "annotation": null,
            "default": "whitespace",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "split"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ngrams"
          },
          {
            "annotation": null,
            "default": "int",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_mode"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_sequence_length"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "pad_to_max_tokens"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "vocabulary"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "idf_weights"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "sparse"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ragged"
          },
          {
            "annotation": null,
            "default": "utf-8",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "encoding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.TimeDistributed",
        "docstring": "This wrapper allows to apply a layer to every temporal slice of an input.\n\nEvery input should be at least 3D, and the dimension of index one of the\nfirst input will be considered to be the temporal dimension.\n\nConsider a batch of 32 video samples, where each sample is a 128x128 RGB\nimage with `channels_last` data format, across 10 timesteps.\nThe batch input shape is `(32, 10, 128, 128, 3)`.\n\nYou can then use `TimeDistributed` to apply the same `Conv2D` layer to each\nof the 10 timesteps, independently:\n\n>>> inputs = layers.Input(shape=(10, 128, 128, 3), batch_size=32)\n>>> conv_2d_layer = layers.Conv2D(64, (3, 3))\n>>> outputs = layers.TimeDistributed(conv_2d_layer)(inputs)\n>>> outputs.shape\n(32, 10, 126, 126, 64)\n\nBecause `TimeDistributed` applies the same instance of `Conv2D` to each of\nthe timestamps, the same set of weights are used at each timestamp.\n\nArgs:\n    layer: a `keras.layers.Layer` instance.\n\nCall arguments:\n    inputs: Input tensor of shape (batch, time, ...) or nested tensors,\n        and each of which has shape (batch, time, ...).\n    training: Python boolean indicating whether the layer should behave in\n        training mode or in inference mode. This argument is passed to the\n        wrapped layer (only if the layer supports this argument).\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n        a given timestep should be masked. This argument is passed to the\n        wrapped layer (only if the layer supports this argument).",
        "has_varargs": false,
        "kind": "class",
        "name": "TimeDistributed",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "layer"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.TorchModuleWrapper",
        "docstring": "Torch module wrapper layer.\n\n`TorchModuleWrapper` is a wrapper class that can turn any\n`torch.nn.Module` into a Keras layer, in particular by making its\nparameters trackable by Keras.\n\n`TorchModuleWrapper` is only compatible with the PyTorch backend and\ncannot be used with the TensorFlow or JAX backends.\n\nArgs:\n    module: `torch.nn.Module` instance. If it's a `LazyModule`\n        instance, then its parameters must be initialized before\n        passing the instance to `TorchModuleWrapper` (e.g. by calling\n        it once).\n    output_shape :The shape of the output of this layer. It helps Keras\n        perform automatic shape inference.\n    name: The name of the layer (string).\n\nExample:\n\nHere's an example of how the `TorchModuleWrapper` can be used with vanilla\nPyTorch modules.\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport keras\nfrom keras.layers import TorchModuleWrapper\n\nclass Classifier(keras.Model):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # Wrap `torch.nn.Module`s with `TorchModuleWrapper`\n        # if they contain parameters\n        self.conv1 = TorchModuleWrapper(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3))\n        )\n        self.conv2 = TorchModuleWrapper(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3))\n        )\n        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n        self.flatten = nn.Flatten()\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc = TorchModuleWrapper(nn.Linear(1600, 10))\n\n    def call(self, inputs):\n        x = F.relu(self.conv1(inputs))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = self.flatten(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return F.softmax(x, dim=1)\n\n\nmodel = Classifier()\nmodel.build((1, 28, 28))\nprint(\"Output shape:\", model(torch.ones(1, 1, 28, 28).to(\"cuda\")).shape)\n\nmodel.compile(\n    loss=\"sparse_categorical_crossentropy\",\n    optimizer=\"adam\",\n    metrics=[\"accuracy\"]\n)\nmodel.fit(train_loader, epochs=5)\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "TorchModuleWrapper",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "module"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "output_shape"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.UnitNormalization",
        "docstring": "Unit normalization layer.\n\nNormalize a batch of inputs so that each input in the batch has a L2 norm\nequal to 1 (across the axes specified in `axis`).\n\nExample:\n\n>>> data = np.arange(6).reshape(2, 3)\n>>> normalized_data = keras.layers.UnitNormalization()(data)\n>>> np.sum(normalized_data[0, :] ** 2)\n1.0\n\nArgs:\n    axis: Integer or list/tuple. The axis or axes to normalize across.\n        Typically, this is the features axis or axes. The left-out axes are\n        typically the batch axis or axes. `-1` is the last dimension\n        in the input. Defaults to `-1`.",
        "has_varargs": false,
        "kind": "class",
        "name": "UnitNormalization",
        "params": [
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.UpSampling1D",
        "docstring": "Upsampling layer for 1D inputs.\n\nRepeats each temporal step `size` times along the time axis.\n\nExample:\n\n>>> input_shape = (2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> x\n[[[ 0  1  2]\n  [ 3  4  5]]\n [[ 6  7  8]\n  [ 9 10 11]]]\n>>> y = keras.layers.UpSampling1D(size=2)(x)\n>>> y\n[[[ 0.  1.  2.]\n  [ 0.  1.  2.]\n  [ 3.  4.  5.]\n  [ 3.  4.  5.]]\n [[ 6.  7.  8.]\n  [ 6.  7.  8.]\n  [ 9. 10. 11.]\n  [ 9. 10. 11.]]]\n\nArgs:\n    size: Integer. Upsampling factor.\n\nInput shape:\n    3D tensor with shape: `(batch_size, steps, features)`.\n\nOutput shape:\n    3D tensor with shape: `(batch_size, upsampled_steps, features)`.",
        "has_varargs": false,
        "kind": "class",
        "name": "UpSampling1D",
        "params": [
          {
            "annotation": null,
            "default": "2",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "size"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.UpSampling2D",
        "docstring": "Upsampling layer for 2D inputs.\n\nThe implementation uses interpolative resizing, given the resize method\n(specified by the `interpolation` argument). Use `interpolation=nearest`\nto repeat the rows and columns of the data.\n\nExample:\n\n>>> input_shape = (2, 2, 1, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> print(x)\n[[[[ 0  1  2]]\n  [[ 3  4  5]]]\n [[[ 6  7  8]]\n  [[ 9 10 11]]]]\n>>> y = keras.layers.UpSampling2D(size=(1, 2))(x)\n>>> print(y)\n[[[[ 0  1  2]\n   [ 0  1  2]]\n  [[ 3  4  5]\n   [ 3  4  5]]]\n [[[ 6  7  8]\n   [ 6  7  8]]\n  [[ 9 10 11]\n   [ 9 10 11]]]]\n\nArgs:\n    size: Int, or tuple of 2 integers.\n        The upsampling factors for rows and columns.\n    data_format: A string,\n        one of `\"channels_last\"` (default) or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`.\n        When unspecified, uses\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json` (if exists) else `\"channels_last\"`.\n        Defaults to `\"channels_last\"`.\n    interpolation: A string, one of `\"bicubic\"`, `\"bilinear\"`, `\"lanczos3\"`,\n        `\"lanczos5\"`, `\"nearest\"`.\n\nInput shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, rows, cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, rows, cols)`\n\nOutput shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, upsampled_rows, upsampled_cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, upsampled_rows, upsampled_cols)`",
        "has_varargs": false,
        "kind": "class",
        "name": "UpSampling2D",
        "params": [
          {
            "annotation": null,
            "default": "(2, 2)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": "nearest",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "interpolation"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.UpSampling3D",
        "docstring": "Upsampling layer for 3D inputs.\n\nRepeats the 1st, 2nd and 3rd dimensions\nof the data by `size[0]`, `size[1]` and `size[2]` respectively.\n\nExample:\n\n>>> input_shape = (2, 1, 2, 1, 3)\n>>> x = np.ones(input_shape)\n>>> y = keras.layers.UpSampling3D(size=(2, 2, 2))(x)\n>>> y.shape\n(2, 2, 4, 2, 3)\n\nArgs:\n    size: Int, or tuple of 3 integers.\n        The upsampling factors for dim1, dim2 and dim3.\n    data_format: A string,\n        one of `\"channels_last\"` (default) or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        When unspecified, uses\n        `image_data_format` value found in your Keras config file at\n         `~/.keras/keras.json` (if exists) else `\"channels_last\"`.\n        Defaults to `\"channels_last\"`.\n\nInput shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, dim1, dim2, dim3, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, dim1, dim2, dim3)`\n\nOutput shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3,\n        channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, upsampled_dim1, upsampled_dim2,\n        upsampled_dim3)`",
        "has_varargs": false,
        "kind": "class",
        "name": "UpSampling3D",
        "params": [
          {
            "annotation": null,
            "default": "(2, 2, 2)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "size"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.Wrapper",
        "docstring": "Abstract wrapper base class.\n\nWrappers take another layer and augment it in various ways.\nDo not use this class as a layer, it is only an abstract base class.\nTwo usable wrappers are the `TimeDistributed` and `Bidirectional` layers.\n\nArgs:\n    layer: The layer to be wrapped.",
        "has_varargs": false,
        "kind": "class",
        "name": "Wrapper",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "layer"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ZeroPadding1D",
        "docstring": "Zero-padding layer for 1D input (e.g. temporal sequence).\n\nExample:\n\n>>> input_shape = (2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> x\n[[[ 0  1  2]\n  [ 3  4  5]]\n [[ 6  7  8]\n  [ 9 10 11]]]\n>>> y = keras.layers.ZeroPadding1D(padding=2)(x)\n>>> y\n[[[ 0  0  0]\n  [ 0  0  0]\n  [ 0  1  2]\n  [ 3  4  5]\n  [ 0  0  0]\n  [ 0  0  0]]\n [[ 0  0  0]\n  [ 0  0  0]\n  [ 6  7  8]\n  [ 9 10 11]\n  [ 0  0  0]\n  [ 0  0  0]]]\n\nArgs:\n    padding: Int, or tuple of int (length 2), or dictionary.\n        - If int: how many zeros to add at the beginning and end of\n          the padding dimension (axis 1).\n        - If tuple of 2 ints: how many zeros to add at the beginning and the\n          end of the padding dimension (`(left_pad, right_pad)`).\n    data_format: A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, axis_to_pad, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, axis_to_pad)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.\n\nInput shape:\n    3D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, axis_to_pad, features)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, features, axis_to_pad)`\n\nOutput shape:\n    3D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, padded_axis, features)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, features, padded_axis)`",
        "has_varargs": false,
        "kind": "class",
        "name": "ZeroPadding1D",
        "params": [
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ZeroPadding2D",
        "docstring": "Zero-padding layer for 2D input (e.g. picture).\n\nThis layer can add rows and columns of zeros at the top, bottom, left and\nright side of an image tensor.\n\nExample:\n\n>>> input_shape = (1, 1, 2, 2)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> x\n[[[[0 1]\n   [2 3]]]]\n>>> y = keras.layers.ZeroPadding2D(padding=1)(x)\n>>> y\n[[[[0 0]\n   [0 0]\n   [0 0]\n   [0 0]]\n  [[0 0]\n   [0 1]\n   [2 3]\n   [0 0]]\n  [[0 0]\n   [0 0]\n   [0 0]\n   [0 0]]]]\n\nArgs:\n    padding: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n        - If int: the same symmetric padding is applied to height and width.\n        - If tuple of 2 ints: interpreted as two different symmetric padding\n          values for height and width:\n          `(symmetric_height_pad, symmetric_width_pad)`.\n        - If tuple of 2 tuples of 2 ints: interpreted as\n         `((top_pad, bottom_pad), (left_pad, right_pad))`.\n    data_format: A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.\n\nInput shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, height, width, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, height, width)`\n\nOutput shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, padded_height, padded_width, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, padded_height, padded_width)`",
        "has_varargs": false,
        "kind": "class",
        "name": "ZeroPadding2D",
        "params": [
          {
            "annotation": null,
            "default": "(1, 1)",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.layers.ZeroPadding3D",
        "docstring": "Zero-padding layer for 3D data (spatial or spatio-temporal).\n\nExample:\n\n>>> input_shape = (1, 1, 2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = keras.layers.ZeroPadding3D(padding=2)(x)\n>>> y.shape\n(1, 5, 6, 6, 3)\n\nArgs:\n    padding: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n        - If int: the same symmetric padding is applied to depth, height,\n          and width.\n        - If tuple of 3 ints: interpreted as three different symmetric\n          padding values for depth, height, and width:\n          `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n        - If tuple of 3 tuples of 2 ints: interpreted as\n          `((left_dim1_pad, right_dim1_pad), (left_dim2_pad,\n          right_dim2_pad), (left_dim3_pad, right_dim3_pad))`.\n    data_format: A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.\n\nInput shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, first_axis_to_pad, second_axis_to_pad,\n      third_axis_to_pad, depth)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, depth, first_axis_to_pad, second_axis_to_pad,\n      third_axis_to_pad)`\n\nOutput shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, first_padded_axis, second_padded_axis,\n      third_axis_to_pad, depth)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, depth, first_padded_axis, second_padded_axis,\n      third_axis_to_pad)`",
        "has_varargs": false,
        "kind": "class",
        "name": "ZeroPadding3D",
        "params": [
          {
            "annotation": null,
            "default": "((1, 1), (1, 1), (1, 1))",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "padding"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "data_format"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      }
    ],
    "loss": [
      {
        "api_path": "keras.losses.BinaryCrossentropy",
        "docstring": "Computes the cross-entropy loss between true labels and predicted labels.\n\nUse this cross-entropy loss for binary (0 or 1) classification applications.\nThe loss function requires the following inputs:\n\n- `y_true` (true label): This is either 0 or 1.\n- `y_pred` (predicted value): This is the model's prediction, i.e, a single\n    floating-point value which either represents a\n    [logit](https://en.wikipedia.org/wiki/Logit), (i.e, value in [-inf, inf]\n    when `from_logits=True`) or a probability (i.e, value in [0., 1.] when\n    `from_logits=False`).\n\nArgs:\n    from_logits: Whether to interpret `y_pred` as a tensor of\n        [logit](https://en.wikipedia.org/wiki/Logit) values. By default, we\n        assume that `y_pred` is probabilities (i.e., values in [0, 1]).\n    label_smoothing: Float in range [0, 1]. When 0, no smoothing occurs.\n        When > 0, we compute the loss between the predicted labels\n        and a smoothed version of the true labels, where the smoothing\n        squeezes the labels towards 0.5. Larger values of\n        `label_smoothing` correspond to heavier smoothing.\n    axis: The axis along which to compute crossentropy (the features axis).\n        Defaults to `-1`.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nExamples:\n\n**Recommended Usage:** (set `from_logits=True`)\n\nWith `compile()` API:\n\n```python\nmodel.compile(\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    ...\n)\n```\n\nAs a standalone function:\n\n>>> # Example 1: (batch_size = 1, number of samples = 4)\n>>> y_true = np.array([0, 1, 0, 0])\n>>> y_pred = np.array([-18.6, 0.51, 2.94, -12.8])\n>>> bce = keras.losses.BinaryCrossentropy(from_logits=True)\n>>> bce(y_true, y_pred)\n0.8654\n\n>>> # Example 2: (batch_size = 2, number of samples = 4)\n>>> y_true = np.array([[0, 1], [0, 0]])\n>>> y_pred = np.array([[-18.6, 0.51], [2.94, -12.8]])\n>>> # Using default 'auto'/'sum_over_batch_size' reduction type.\n>>> bce = keras.losses.BinaryCrossentropy(from_logits=True)\n>>> bce(y_true, y_pred)\n0.8654\n>>> # Using 'sample_weight' attribute\n>>> bce(y_true, y_pred, sample_weight=[0.8, 0.2])\n0.243\n>>> # Using 'sum' reduction` type.\n>>> bce = keras.losses.BinaryCrossentropy(from_logits=True,\n...     reduction=\"sum\")\n>>> bce(y_true, y_pred)\n1.730\n>>> # Using 'none' reduction type.\n>>> bce = keras.losses.BinaryCrossentropy(from_logits=True,\n...     reduction=None)\n>>> bce(y_true, y_pred)\narray([0.235, 1.496], dtype=float32)\n\n**Default Usage:** (set `from_logits=False`)\n\n>>> # Make the following updates to the above \"Recommended Usage\" section\n>>> # 1. Set `from_logits=False`\n>>> keras.losses.BinaryCrossentropy() # OR ...('from_logits=False')\n>>> # 2. Update `y_pred` to use probabilities instead of logits\n>>> y_pred = [0.6, 0.3, 0.2, 0.8] # OR [[0.6, 0.3], [0.2, 0.8]]",
        "has_varargs": false,
        "kind": "class",
        "name": "BinaryCrossentropy",
        "params": [
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "from_logits"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "label_smoothing"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "binary_crossentropy",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.BinaryFocalCrossentropy",
        "docstring": "Computes focal cross-entropy loss between true labels and predictions.\n\nBinary cross-entropy loss is often used for binary (0 or 1) classification\ntasks. The loss function requires the following inputs:\n\n- `y_true` (true label): This is either 0 or 1.\n- `y_pred` (predicted value): This is the model's prediction, i.e, a single\n    floating-point value which either represents a\n    [logit](https://en.wikipedia.org/wiki/Logit), (i.e, value in [-inf, inf]\n    when `from_logits=True`) or a probability (i.e, value in `[0., 1.]` when\n    `from_logits=False`).\n\nAccording to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it\nhelps to apply a \"focal factor\" to down-weight easy examples and focus more\non hard examples. By default, the focal tensor is computed as follows:\n\n`focal_factor = (1 - output) ** gamma` for class 1\n`focal_factor = output ** gamma` for class 0\nwhere `gamma` is a focusing parameter. When `gamma=0`, this function is\nequivalent to the binary crossentropy loss.\n\nArgs:\n    apply_class_balancing: A bool, whether to apply weight balancing on the\n        binary classes 0 and 1.\n    alpha: A weight balancing factor for class 1, default is `0.25` as\n        mentioned in reference [Lin et al., 2018](\n        https://arxiv.org/pdf/1708.02002.pdf).  The weight for class 0 is\n        `1.0 - alpha`.\n    gamma: A focusing parameter used to compute the focal factor, default is\n        `2.0` as mentioned in the reference\n        [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf).\n    from_logits: Whether to interpret `y_pred` as a tensor of\n        [logit](https://en.wikipedia.org/wiki/Logit) values. By default, we\n        assume that `y_pred` are probabilities (i.e., values in `[0, 1]`).\n    label_smoothing: Float in `[0, 1]`. When `0`, no smoothing occurs.\n        When > `0`, we compute the loss between the predicted labels\n        and a smoothed version of the true labels, where the smoothing\n        squeezes the labels towards `0.5`.\n        Larger values of `label_smoothing` correspond to heavier smoothing.\n    axis: The axis along which to compute crossentropy (the features axis).\n        Defaults to `-1`.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nExamples:\n\nWith the `compile()` API:\n\n```python\nmodel.compile(\n    loss=keras.losses.BinaryFocalCrossentropy(\n        gamma=2.0, from_logits=True),\n    ...\n)\n```\n\nAs a standalone function:\n\n>>> # Example 1: (batch_size = 1, number of samples = 4)\n>>> y_true = np.array([0, 1, 0, 0])\n>>> y_pred = np.array([-18.6, 0.51, 2.94, -12.8])\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...    gamma=2, from_logits=True)\n>>> loss(y_true, y_pred)\n0.691\n\n>>> # Apply class weight\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...     apply_class_balancing=True, gamma=2, from_logits=True)\n>>> loss(y_true, y_pred)\n0.51\n\n>>> # Example 2: (batch_size = 2, number of samples = 4)\n>>> y_true = np.array([[0, 1], [0, 0]])\n>>> y_pred = np.array([[-18.6, 0.51], [2.94, -12.8]])\n>>> # Using default 'auto'/'sum_over_batch_size' reduction type.\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...     gamma=3, from_logits=True)\n>>> loss(y_true, y_pred)\n0.647\n\n>>> # Apply class weight\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...      apply_class_balancing=True, gamma=3, from_logits=True)\n>>> loss(y_true, y_pred)\n0.482\n\n>>> # Using 'sample_weight' attribute with focal effect\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...     gamma=3, from_logits=True)\n>>> loss(y_true, y_pred, sample_weight=[0.8, 0.2])\n0.133\n\n>>> # Apply class weight\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...      apply_class_balancing=True, gamma=3, from_logits=True)\n>>> loss(y_true, y_pred, sample_weight=[0.8, 0.2])\n0.097\n\n>>> # Using 'sum' reduction` type.\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...     gamma=4, from_logits=True,\n...     reduction=\"sum\")\n>>> loss(y_true, y_pred)\n1.222\n\n>>> # Apply class weight\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...     apply_class_balancing=True, gamma=4, from_logits=True,\n...     reduction=\"sum\")\n>>> loss(y_true, y_pred)\n0.914\n\n>>> # Using 'none' reduction type.\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...     gamma=5, from_logits=True,\n...     reduction=None)\n>>> loss(y_true, y_pred)\narray([0.0017 1.1561], dtype=float32)\n\n>>> # Apply class weight\n>>> loss = keras.losses.BinaryFocalCrossentropy(\n...     apply_class_balancing=True, gamma=5, from_logits=True,\n...     reduction=None)\n>>> loss(y_true, y_pred)\narray([0.0004 0.8670], dtype=float32)",
        "has_varargs": false,
        "kind": "class",
        "name": "BinaryFocalCrossentropy",
        "params": [
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "apply_class_balancing"
          },
          {
            "annotation": null,
            "default": "0.25",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha"
          },
          {
            "annotation": null,
            "default": "2.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "from_logits"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "label_smoothing"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "binary_focal_crossentropy",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.CTC",
        "docstring": "CTC (Connectionist Temporal Classification) loss.\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "CTC",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "ctc",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.CategoricalCrossentropy",
        "docstring": "Computes the crossentropy loss between the labels and predictions.\n\nUse this crossentropy loss function when there are two or more label\nclasses. We expect labels to be provided in a `one_hot` representation. If\nyou want to provide labels as integers, please use\n`SparseCategoricalCrossentropy` loss. There should be `num_classes` floating\npoint values per feature, i.e., the shape of both `y_pred` and `y_true` are\n`[batch_size, num_classes]`.\n\nArgs:\n    from_logits: Whether `y_pred` is expected to be a logits tensor. By\n        default, we assume that `y_pred` encodes a probability distribution.\n    label_smoothing: Float in [0, 1]. When > 0, label values are smoothed,\n        meaning the confidence on label values are relaxed. For example, if\n        `0.1`, use `0.1 / num_classes` for non-target labels and\n        `0.9 + 0.1 / num_classes` for target labels.\n    axis: The axis along which to compute crossentropy (the features\n        axis). Defaults to `-1`.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nExamples:\n\nStandalone usage:\n\n>>> y_true = np.array([[0, 1, 0], [0, 0, 1]])\n>>> y_pred = np.array([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n>>> # Using 'auto'/'sum_over_batch_size' reduction type.\n>>> cce = keras.losses.CategoricalCrossentropy()\n>>> cce(y_true, y_pred)\n1.177\n\n>>> # Calling with 'sample_weight'.\n>>> cce(y_true, y_pred, sample_weight=np.array([0.3, 0.7]))\n0.814\n\n>>> # Using 'sum' reduction type.\n>>> cce = keras.losses.CategoricalCrossentropy(\n...     reduction=\"sum\")\n>>> cce(y_true, y_pred)\n2.354\n\n>>> # Using 'none' reduction type.\n>>> cce = keras.losses.CategoricalCrossentropy(\n...     reduction=None)\n>>> cce(y_true, y_pred)\narray([0.0513, 2.303], dtype=float32)\n\nUsage with the `compile()` API:\n\n```python\nmodel.compile(optimizer='sgd',\n              loss=keras.losses.CategoricalCrossentropy())\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "CategoricalCrossentropy",
        "params": [
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "from_logits"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "label_smoothing"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "categorical_crossentropy",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.CategoricalFocalCrossentropy",
        "docstring": "Computes the alpha balanced focal crossentropy loss.\n\nUse this crossentropy loss function when there are two or more label\nclasses and if you want to handle class imbalance without using\n`class_weights`. We expect labels to be provided in a `one_hot`\nrepresentation.\n\nAccording to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it\nhelps to apply a focal factor to down-weight easy examples and focus more on\nhard examples. The general formula for the focal loss (FL)\nis as follows:\n\n`FL(p_t) = (1 - p_t) ** gamma * log(p_t)`\n\nwhere `p_t` is defined as follows:\n`p_t = output if y_true == 1, else 1 - output`\n\n`(1 - p_t) ** gamma` is the `modulating_factor`, where `gamma` is a focusing\nparameter. When `gamma` = 0, there is no focal effect on the cross entropy.\n`gamma` reduces the importance given to simple examples in a smooth manner.\n\nThe authors use alpha-balanced variant of focal loss (FL) in the paper:\n`FL(p_t) = -alpha * (1 - p_t) ** gamma * log(p_t)`\n\nwhere `alpha` is the weight factor for the classes. If `alpha` = 1, the\nloss won't be able to handle class imbalance properly as all\nclasses will have the same weight. This can be a constant or a list of\nconstants. If alpha is a list, it must have the same length as the number\nof classes.\n\nThe formula above can be generalized to:\n`FL(p_t) = alpha * (1 - p_t) ** gamma * CrossEntropy(y_true, y_pred)`\n\nwhere minus comes from `CrossEntropy(y_true, y_pred)` (CE).\n\nExtending this to multi-class case is straightforward:\n`FL(p_t) = alpha * (1 - p_t) ** gamma * CategoricalCE(y_true, y_pred)`\n\nIn the snippet below, there is `num_classes` floating pointing values per\nexample. The shape of both `y_pred` and `y_true` are\n`(batch_size, num_classes)`.\n\nArgs:\n    alpha: A weight balancing factor for all classes, default is `0.25` as\n        mentioned in the reference. It can be a list of floats or a scalar.\n        In the multi-class case, alpha may be set by inverse class\n        frequency by using `compute_class_weight` from `sklearn.utils`.\n    gamma: A focusing parameter, default is `2.0` as mentioned in the\n        reference. It helps to gradually reduce the importance given to\n        simple (easy) examples in a smooth manner.\n    from_logits: Whether `output` is expected to be a logits tensor. By\n        default, we consider that `output` encodes a probability\n        distribution.\n    label_smoothing: Float in [0, 1]. When > 0, label values are smoothed,\n        meaning the confidence on label values are relaxed. For example, if\n        `0.1`, use `0.1 / num_classes` for non-target labels and\n        `0.9 + 0.1 / num_classes` for target labels.\n    axis: The axis along which to compute crossentropy (the features\n        axis). Defaults to `-1`.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nExamples:\n\nStandalone usage:\n\n>>> y_true = [[0., 1., 0.], [0., 0., 1.]]\n>>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n>>> # Using 'auto'/'sum_over_batch_size' reduction type.\n>>> cce = keras.losses.CategoricalFocalCrossentropy()\n>>> cce(y_true, y_pred)\n0.23315276\n\n>>> # Calling with 'sample_weight'.\n>>> cce(y_true, y_pred, sample_weight=np.array([0.3, 0.7]))\n0.1632\n\n>>> # Using 'sum' reduction type.\n>>> cce = keras.losses.CategoricalFocalCrossentropy(\n...     reduction=\"sum\")\n>>> cce(y_true, y_pred)\n0.46631\n\n>>> # Using 'none' reduction type.\n>>> cce = keras.losses.CategoricalFocalCrossentropy(\n...     reduction=None)\n>>> cce(y_true, y_pred)\narray([3.2058331e-05, 4.6627346e-01], dtype=float32)\n\nUsage with the `compile()` API:\n\n```python\nmodel.compile(optimizer='adam',\n              loss=keras.losses.CategoricalFocalCrossentropy())\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "CategoricalFocalCrossentropy",
        "params": [
          {
            "annotation": null,
            "default": "0.25",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha"
          },
          {
            "annotation": null,
            "default": "2.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "from_logits"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "label_smoothing"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "categorical_focal_crossentropy",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.CategoricalGeneralizedCrossEntropy",
        "docstring": "Computes the Generalized Cross Entropy loss between `y_true` & `y_pred`.\n\nGeneralized Cross Entropy (GCE) is a noise-robust loss function\nthat provides better robustness against noisy labels than\nstandard cross entropy.\nIt generalizes both cross entropy and mean absolute error through\nthe parameter q, where values closer to 1 make the loss more robust\nto noisy labels.\n\nFormula:\n```python\nloss = (1 - p**q) / q\n```\nwhere `p` is the predicted probability for the true class and `q`\nis the noise parameter.\n\nArgs:\n    q: Float in range `(0, 1)`. It is the noise parameter.\n       Controls the behavior of the loss:\n        - As `q` approaches 0: Behaves more like cross entropy\n        - As `q` approaches 1: Behaves more like mean absolute error\n       Defaults to `0.5`\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nExample:\n```python\ny_true = np.array([0, 1, 0, 1])\ny_pred = np.array([[0.7, 0.3], [0.2, 0.8], [0.6, 0.4], [0.4, 0.6]])\nkeras.losses.CategoricalGeneralizedCrossEntropy()(y_true, y_pred)\n```\n\nReferences:\n    - [Zhang, Sabuncu, 2018](https://arxiv.org/abs/1805.07836)\n      (\"Generalized Cross Entropy Loss for Training\n        Deep Neural Networks with Noisy Labels\")",
        "has_varargs": false,
        "kind": "class",
        "name": "CategoricalGeneralizedCrossEntropy",
        "params": [
          {
            "annotation": null,
            "default": "0.5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "q"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "categorical_generalized_cross_entropy",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.CategoricalHinge",
        "docstring": "Computes the categorical hinge loss between `y_true` & `y_pred`.\n\nFormula:\n\n```python\nloss = maximum(neg - pos + 1, 0)\n```\n\nwhere `neg=maximum((1-y_true)*y_pred)` and `pos=sum(y_true*y_pred)`\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "CategoricalHinge",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "categorical_hinge",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.Circle",
        "docstring": "Computes Circle Loss between integer labels and L2-normalized embeddings.\n\nThis is a metric learning loss designed to minimize within-class distance\nand maximize between-class distance in a flexible manner by dynamically\nadjusting the penalty strength based on optimization status of each\nsimilarity score.\n\nTo use Circle Loss effectively, the model should output embeddings without\nan activation function (such as a `Dense` layer with `activation=None`)\nfollowed by UnitNormalization layer to ensure unit-norm embeddings.\n\nArgs:\n    gamma: Scaling factor that determines the largest scale of each\n        similarity score. Defaults to `80`.\n    margin: The relaxation factor, below this distance, negatives are\n    up weighted and positives are down weighted. Similarly, above this\n    distance negatives are down weighted and positive are up weighted.\n        Defaults to `0.4`.\n    remove_diagonal: Boolean, whether to remove self-similarities from the\n        positive mask. Defaults to `True`.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nExamples:\n\nUsage with the `compile()` API:\n\n```python\nmodel = models.Sequential([\n    keras.layers.Input(shape=(224, 224, 3)),\n    keras.layers.Conv2D(16, (3, 3), activation='relu'),\n    keras.layers.Flatten(),\n    keras.layers.Dense(64, activation=None),  # No activation\n    keras.layers.UnitNormalization()  # L2 normalization\n])\n\nmodel.compile(optimizer=\"adam\", loss=keras.losses.Circle())\n```\n\nReference:\n- [Yifan Sun et al., 2020](https://arxiv.org/abs/2002.10857)",
        "has_varargs": false,
        "kind": "class",
        "name": "Circle",
        "params": [
          {
            "annotation": null,
            "default": "80.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gamma"
          },
          {
            "annotation": null,
            "default": "0.4",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "margin"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "remove_diagonal"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "circle",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.CosineSimilarity",
        "docstring": "Computes the cosine similarity between `y_true` & `y_pred`.\n\nNote that it is a number between -1 and 1. When it is a negative number\nbetween -1 and 0, 0 indicates orthogonality and values closer to -1\nindicate greater similarity. This makes it usable as a loss function in a\nsetting where you try to maximize the proximity between predictions and\ntargets. If either `y_true` or `y_pred` is a zero vector, cosine similarity\nwill be 0 regardless of the proximity between predictions and targets.\n\nFormula:\n\n```python\nloss = -sum(l2_norm(y_true) * l2_norm(y_pred))\n```\n\nArgs:\n    axis: The axis along which the cosine similarity is computed\n        (the features axis). Defaults to `-1`.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "CosineSimilarity",
        "params": [
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "cosine_similarity",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.Dice",
        "docstring": "Computes the Dice loss value between `y_true` and `y_pred`.\n\nFormula:\n```python\nloss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))\n```\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    axis: Tuple for which dimensions the loss is calculated. Defaults to\n        `None`.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nReturns:\n    Dice loss value.\n\nExample:\n\n>>> y_true = [[[[1.0], [1.0]], [[0.0], [0.0]]],\n...           [[[1.0], [1.0]], [[0.0], [0.0]]]]\n>>> y_pred = [[[[0.0], [1.0]], [[0.0], [1.0]]],\n...           [[[0.4], [0.0]], [[0.0], [0.9]]]]\n>>> axis = (1, 2, 3)\n>>> loss = keras.losses.Dice(axis=axis, reduction=None)(y_true, y_pred)\n>>> assert loss.shape == (2,)\n>>> loss\narray([0.5, 0.75757575], shape=(2,), dtype=float32)\n\n>>> loss = keras.losses.Dice()(y_true, y_pred)\n>>> assert loss.shape == ()\n>>> loss\narray(0.6164384, shape=(), dtype=float32)\n\n>>> y_true = np.array(y_true)\n>>> y_pred = np.array(y_pred)\n>>> loss = keras.losses.Dice(axis=axis, reduction=None)(y_true, y_pred)\n>>> assert loss.shape == (2,)\n>>> loss\narray([0.5, 0.75757575], shape=(2,), dtype=float32)",
        "has_varargs": false,
        "kind": "class",
        "name": "Dice",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "dice",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.Hinge",
        "docstring": "Computes the hinge loss between `y_true` & `y_pred`.\n\nFormula:\n\n```python\nloss = maximum(1 - y_true * y_pred, 0)\n```\n\n`y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\nprovided we will convert them to -1 or 1.\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "Hinge",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "hinge",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.Huber",
        "docstring": "Computes the Huber loss between `y_true` & `y_pred`.\n\nFormula:\n\n```python\nfor x in error:\n    if abs(x) <= delta:\n        loss.append(0.5 * x^2)\n    elif abs(x) > delta:\n        loss.append(delta * abs(x) - 0.5 * delta^2)\n\nloss = mean(loss, axis=-1)\n```\nSee: [Huber loss](https://en.wikipedia.org/wiki/Huber_loss).\n\nArgs:\n    delta: A float, the point where the Huber loss function changes from a\n        quadratic to linear.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "Huber",
        "params": [
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "delta"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "huber_loss",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.KLDivergence",
        "docstring": "Computes Kullback-Leibler divergence loss between `y_true` & `y_pred`.\n\nFormula:\n\n```python\nloss = y_true * log(y_true / y_pred)\n```\n\n`y_true` and `y_pred` are expected to be probability\ndistributions, with values between 0 and 1. They will get\nclipped to the `[0, 1]` range.\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "KLDivergence",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "kl_divergence",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.LogCosh",
        "docstring": "Computes the logarithm of the hyperbolic cosine of the prediction error.\n\nFormula:\n\n```python\nerror = y_pred - y_true\nlogcosh = mean(log((exp(error) + exp(-error))/2), axis=-1)`\n```\nwhere x is the error `y_pred - y_true`.\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "LogCosh",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "log_cosh",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.MeanAbsoluteError",
        "docstring": "Computes the mean of absolute difference between labels and predictions.\n\nFormula:\n\n```python\nloss = mean(abs(y_true - y_pred))\n```\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "MeanAbsoluteError",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "mean_absolute_error",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.MeanAbsolutePercentageError",
        "docstring": "Computes the mean absolute percentage error between `y_true` & `y_pred`.\n\nFormula:\n\n```python\nloss = 100 * mean(abs((y_true - y_pred) / y_true))\n```\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "MeanAbsolutePercentageError",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "mean_absolute_percentage_error",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.MeanSquaredError",
        "docstring": "Computes the mean of squares of errors between labels and predictions.\n\nFormula:\n\n```python\nloss = mean(square(y_true - y_pred))\n```\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "MeanSquaredError",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "mean_squared_error",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.MeanSquaredLogarithmicError",
        "docstring": "Computes the mean squared logarithmic error between `y_true` & `y_pred`.\n\nFormula:\n\n```python\nloss = mean(square(log(y_true + 1) - log(y_pred + 1)))\n```\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "MeanSquaredLogarithmicError",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "mean_squared_logarithmic_error",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.Poisson",
        "docstring": "Computes the Poisson loss between `y_true` & `y_pred`.\n\nFormula:\n\n```python\nloss = y_pred - y_true * log(y_pred)\n```\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "Poisson",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "poisson",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.SparseCategoricalCrossentropy",
        "docstring": "Computes the crossentropy loss between the labels and predictions.\n\nUse this crossentropy loss function when there are two or more label\nclasses.  We expect labels to be provided as integers. If you want to\nprovide labels using `one-hot` representation, please use\n`CategoricalCrossentropy` loss.  There should be `# classes` floating point\nvalues per feature for `y_pred` and a single floating point value per\nfeature for `y_true`.\n\nIn the snippet below, there is a single floating point value per example for\n`y_true` and `num_classes` floating pointing values per example for\n`y_pred`. The shape of `y_true` is `[batch_size]` and the shape of `y_pred`\nis `[batch_size, num_classes]`.\n\nArgs:\n    from_logits: Whether `y_pred` is expected to be a logits tensor. By\n        default, we assume that `y_pred` encodes a probability distribution.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    axis: The axis along which to compute crossentropy (the features\n        axis). Defaults to `-1`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nExamples:\n\n>>> y_true = np.array([1, 2])\n>>> y_pred = np.array([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n>>> # Using 'auto'/'sum_over_batch_size' reduction type.\n>>> scce = keras.losses.SparseCategoricalCrossentropy()\n>>> scce(y_true, y_pred)\n1.177\n\n>>> # Calling with 'sample_weight'.\n>>> scce(y_true, y_pred, sample_weight=np.array([0.3, 0.7]))\n0.814\n\n>>> # Using 'sum' reduction type.\n>>> scce = keras.losses.SparseCategoricalCrossentropy(\n...     reduction=\"sum\")\n>>> scce(y_true, y_pred)\n2.354\n\n>>> # Using 'none' reduction type.\n>>> scce = keras.losses.SparseCategoricalCrossentropy(\n...     reduction=None)\n>>> scce(y_true, y_pred)\narray([0.0513, 2.303], dtype=float32)\n\nUsage with the `compile()` API:\n\n```python\nmodel.compile(optimizer='sgd',\n              loss=keras.losses.SparseCategoricalCrossentropy())\n```",
        "has_varargs": false,
        "kind": "class",
        "name": "SparseCategoricalCrossentropy",
        "params": [
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "from_logits"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ignore_class"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "-1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "sparse_categorical_crossentropy",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.SquaredHinge",
        "docstring": "Computes the squared hinge loss between `y_true` & `y_pred`.\n\nFormula:\n\n```python\nloss = square(maximum(1 - y_true * y_pred, 0))\n```\n\n`y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\nprovided we will convert them to -1 or 1.\n\nArgs:\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.",
        "has_varargs": false,
        "kind": "class",
        "name": "SquaredHinge",
        "params": [
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "squared_hinge",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      },
      {
        "api_path": "keras.losses.Tversky",
        "docstring": "Computes the Tversky loss value between `y_true` and `y_pred`.\n\nThis loss function is weighted by the alpha and beta coefficients\nthat penalize false positives and false negatives.\n\nWith `alpha=0.5` and `beta=0.5`, the loss value becomes equivalent to\nDice Loss.\n\nArgs:\n    alpha: The coefficient controlling incidence of false positives.\n        Defaults to `0.5`.\n    beta: The coefficient controlling incidence of false negatives.\n        Defaults to `0.5`.\n    reduction: Type of reduction to apply to the loss. In almost all cases\n        this should be `\"sum_over_batch_size\"`. Supported options are\n        `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n        `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n        `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n        sample size, and `\"mean_with_sample_weight\"` sums the loss and\n        divides by the sum of the sample weights. `\"none\"` and `None`\n        perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n    name: Optional name for the loss instance.\n    dtype: The dtype of the loss's computations. Defaults to `None`, which\n        means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n        `\"float32\"` unless set to different value\n        (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n        provided, then the `compute_dtype` will be utilized.\n\nReturns:\n    Tversky loss value.\n\nReference:\n\n- [Salehi et al., 2017](https://arxiv.org/abs/1706.05721)",
        "has_varargs": false,
        "kind": "class",
        "name": "Tversky",
        "params": [
          {
            "annotation": null,
            "default": "0.5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "alpha"
          },
          {
            "annotation": null,
            "default": "0.5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta"
          },
          {
            "annotation": null,
            "default": "sum_over_batch_size",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "reduction"
          },
          {
            "annotation": null,
            "default": "tversky",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "axis"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dtype"
          }
        ]
      }
    ],
    "optimizer": [
      {
        "api_path": "keras.optimizers.Adadelta",
        "docstring": "Optimizer that implements the Adadelta algorithm.\n\nAdadelta optimization is a stochastic gradient descent method that is based\non adaptive learning rate per dimension to address two drawbacks:\n\n- The continual decay of learning rates throughout training.\n- The need for a manually selected global learning rate.\n\nAdadelta is a more robust extension of Adagrad that adapts learning rates\nbased on a moving window of gradient updates, instead of accumulating all\npast gradients. This way, Adadelta continues learning even when many updates\nhave been done. Compared to Adagrad, in the original version of Adadelta you\ndon't have to set an initial learning rate. In this version, the initial\nlearning rate can be set, as in most other Keras optimizers.\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`. Note that `Adadelta`\n        tends to benefit from higher initial learning rate values compared\n        to other optimizers. To match the exact form in the original paper,\n        use 1.0.\n    rho: A floating point value. The decay rate. Defaults to `0.95`.\n    epsilon: Small floating point value for maintaining numerical stability.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nReference:\n\n- [Zeiler, 2012](http://arxiv.org/abs/1212.5701)",
        "has_varargs": false,
        "kind": "class",
        "name": "Adadelta",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.95",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rho"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "adadelta",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Adafactor",
        "docstring": "Optimizer that implements the Adafactor algorithm.\n\nAdafactor is commonly used in NLP tasks, and has the advantage\nof taking less memory because it only saves partial information of previous\ngradients.\n\nThe default argument setup is based on the original paper (see reference).\nWhen gradients are of dimension > 2, Adafactor optimizer will delete the\nlast 2 dimensions separately in its accumulator variables.\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    beta_2_decay: float, defaults to -0.8. The decay rate of `beta_2`.\n    epsilon_1: float, defaults to 1e-30. A small offset to keep denominator\n        away from 0.\n    epsilon_2: float, defaults to 1e-3. A small offset to avoid learning\n        rate becoming too small by time.\n    clip_threshold: float, defaults to 1.0. Clipping threshold. This is a\n        part of Adafactor algorithm, independent from `clipnorm`,\n        `clipvalue`, and `global_clipnorm`.\n    relative_step: bool, defaults to `True`. If `learning_rate` is a\n        constant and `relative_step=True`, learning rate will be adjusted\n        based on current iterations. This is a default learning rate decay\n        in Adafactor.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nReference:\n\n- [Shazeer, Noam et al., 2018](https://arxiv.org/abs/1804.04235).",
        "has_varargs": false,
        "kind": "class",
        "name": "Adafactor",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "-0.8",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_2_decay"
          },
          {
            "annotation": null,
            "default": "1e-30",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon_1"
          },
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon_2"
          },
          {
            "annotation": null,
            "default": "1.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clip_threshold"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "relative_step"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "adafactor",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Adagrad",
        "docstring": "Optimizer that implements the Adagrad algorithm.\n\nAdagrad is an optimizer with parameter-specific learning rates,\nwhich are adapted relative to how frequently a parameter gets\nupdated during training. The more updates a parameter receives,\nthe smaller the updates.\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`. Note that `Adagrad`\n        tends to benefit from higher initial learning rate values compared\n        to other optimizers. To match the exact form in the original paper,\n        use `1.0`.\n    initial_accumulator_value: Floating point value. Starting value for the\n        accumulators (per-parameter momentum values). Must be non-negative.\n    epsilon: Small floating point value for maintaining numerical stability.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nReference:\n\n- [Duchi et al., 2011](\n    http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf).",
        "has_varargs": false,
        "kind": "class",
        "name": "Adagrad",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "initial_accumulator_value"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "adagrad",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Adam",
        "docstring": "Optimizer that implements the Adam algorithm.\n\nAdam optimization is a stochastic gradient descent method that is based on\nadaptive estimation of first-order and second-order moments.\n\nAccording to\n[Kingma et al., 2014](http://arxiv.org/abs/1412.6980),\nthe method is \"*computationally\nefficient, has little memory requirement, invariant to diagonal rescaling of\ngradients, and is well suited for problems that are large in terms of\ndata/parameters*\".\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    beta_1: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 1st moment estimates. Defaults to\n        `0.9`.\n    beta_2: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 2nd moment estimates. Defaults to\n        `0.999`.\n    epsilon: A small constant for numerical stability. This epsilon is\n        \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n        Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults\n        to `1e-7`.\n    amsgrad: Boolean. Whether to apply AMSGrad variant of this algorithm\n        from the paper \"On the Convergence of Adam and beyond\". Defaults\n        to `False`.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).",
        "has_varargs": false,
        "kind": "class",
        "name": "Adam",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.9",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_1"
          },
          {
            "annotation": null,
            "default": "0.999",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_2"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "amsgrad"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "adam",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.AdamW",
        "docstring": "Optimizer that implements the AdamW algorithm.\n\nAdamW optimization is a stochastic gradient descent method that is based on\nadaptive estimation of first-order and second-order moments with an added\nmethod to decay weights per the techniques discussed in the paper,\n'Decoupled Weight Decay Regularization' by\n[Loshchilov, Hutter et al., 2019](https://arxiv.org/abs/1711.05101).\n\nAccording to\n[Kingma et al., 2014](http://arxiv.org/abs/1412.6980),\nthe underlying Adam method is \"*computationally\nefficient, has little memory requirement, invariant to diagonal rescaling of\ngradients, and is well suited for problems that are large in terms of\ndata/parameters*\".\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    beta_1: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 1st moment estimates.\n        Defaults to `0.9`.\n    beta_2: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 2nd moment estimates.\n        Defaults to `0.999`.\n    epsilon: A small constant for numerical stability. This epsilon is\n        \"epsilon hat\" in the Kingma and Ba paper (in the formula just\n        before Section 2.1), not the epsilon in Algorithm 1 of the paper.\n        Defaults to 1e-7.\n    amsgrad: Boolean. Whether to apply AMSGrad variant of this algorithm\n        from the paper \"On the Convergence of Adam and beyond\".\n        Defaults to `False`.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nReferences:\n\n- [Loshchilov et al., 2019](https://arxiv.org/abs/1711.05101)\n- [Kingma et al., 2014](http://arxiv.org/abs/1412.6980) for `adam`\n- [Reddi et al., 2018](\n    https://openreview.net/pdf?id=ryQu7f-RZ) for `amsgrad`.",
        "has_varargs": false,
        "kind": "class",
        "name": "AdamW",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.004",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "0.9",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_1"
          },
          {
            "annotation": null,
            "default": "0.999",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_2"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "amsgrad"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "adamw",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Adamax",
        "docstring": "Optimizer that implements the Adamax algorithm.\n\nAdamax, a variant of Adam based on the infinity norm, is a first-order\ngradient-based optimization method. Due to its capability of adjusting the\nlearning rate based on data characteristics, it is suited to learn\ntime-variant process, e.g., speech data with dynamically changed noise\nconditions. Default parameters follow those provided in the paper (see\nreferences below).\n\nInitialization:\n\n```python\nm = 0  # Initialize initial 1st moment vector\nu = 0  # Initialize the exponentially weighted infinity norm\nt = 0  # Initialize timestep\n```\n\nThe update rule for parameter `w` with gradient `g` is described at the end\nof section 7.1 of the paper (see the reference section):\n\n```python\nt += 1\nm = beta1 * m + (1 - beta) * g\nu = max(beta2 * u, abs(g))\ncurrent_lr = learning_rate / (1 - beta1 ** t)\nw = w - current_lr * m / (u + epsilon)\n```\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    beta_1: A float value or a constant float tensor. The exponential decay\n        rate for the 1st moment estimates.\n    beta_2: A float value or a constant float tensor. The exponential decay\n        rate for the exponentially weighted infinity norm.\n    epsilon: A small constant for numerical stability.\n        name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nReference:\n\n- [Kingma et al., 2014](http://arxiv.org/abs/1412.6980)",
        "has_varargs": false,
        "kind": "class",
        "name": "Adamax",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.9",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_1"
          },
          {
            "annotation": null,
            "default": "0.999",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_2"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "adamax",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Ftrl",
        "docstring": "Optimizer that implements the FTRL algorithm.\n\n\"Follow The Regularized Leader\" (FTRL) is an optimization algorithm\ndeveloped at Google for click-through rate prediction in the early 2010s. It\nis most suitable for shallow models with large and sparse feature spaces.\nThe algorithm is described by\n[McMahan et al., 2013](https://research.google.com/pubs/archive/41159.pdf).\nThe Keras version has support for both online L2 regularization\n(the L2 regularization described in the paper\nabove) and shrinkage-type L2 regularization\n(which is the addition of an L2 penalty to the loss function).\n\nInitialization:\n\n```python\nn = 0\nsigma = 0\nz = 0\n```\n\nUpdate rule for one variable `w`:\n\n```python\nprev_n = n\nn = n + g ** 2\nsigma = (n ** -lr_power - prev_n ** -lr_power) / lr\nz = z + g - sigma * w\nif abs(z) < lambda_1:\n  w = 0\nelse:\n  w = (sgn(z) * lambda_1 - z) / ((beta + sqrt(n)) / alpha + lambda_2)\n```\n\nNotation:\n\n- `lr` is the learning rate\n- `g` is the gradient for the variable\n- `lambda_1` is the L1 regularization strength\n- `lambda_2` is the L2 regularization strength\n- `lr_power` is the power to scale n.\n\nCheck the documentation for the `l2_shrinkage_regularization_strength`\nparameter for more details when shrinkage is enabled, in which case gradient\nis replaced with a gradient with shrinkage.\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    learning_rate_power: A float value, must be less or equal to zero.\n        Controls how the learning rate decreases during training. Use zero\n        for a fixed learning rate.\n    initial_accumulator_value: The starting value for accumulators. Only\n        zero or positive values are allowed.\n    l1_regularization_strength: A float value, must be greater than or equal\n        to zero. Defaults to `0.0`.\n    l2_regularization_strength: A float value, must be greater than or equal\n        to zero. Defaults to `0.0`.\n    l2_shrinkage_regularization_strength: A float value, must be greater\n        than or equal to zero. This differs from L2 above in that the L2\n        above is a stabilization penalty, whereas this L2 shrinkage is a\n        magnitude penalty. When input is sparse shrinkage will only happen\n        on the active weights.\n    beta: A float value, representing the beta value from the paper.\n        Defaults to `0.0`.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).",
        "has_varargs": false,
        "kind": "class",
        "name": "Ftrl",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "-0.5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate_power"
          },
          {
            "annotation": null,
            "default": "0.1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "initial_accumulator_value"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "l1_regularization_strength"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "l2_regularization_strength"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "l2_shrinkage_regularization_strength"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "ftrl",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Lamb",
        "docstring": "Optimizer that implements the Lamb algorithm.\n\nLamb is a stochastic gradient descent method that\nuses layer-wise adaptive moments to adjusts the\nlearning rate for each parameter based on the ratio of the\nnorm of the weight to the norm of the gradient\nThis helps to stabilize the training process and improves convergence\nespecially for large batch sizes.\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    beta_1: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 1st moment estimates. Defaults to\n        `0.9`.\n    beta_2: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 2nd moment estimates. Defaults to\n        `0.999`.\n    epsilon: A small constant for numerical stability.\n        Defaults to `1e-7`.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nReferences:\n    - [Yang et al.](https://arxiv.org/pdf/1904.00962)",
        "has_varargs": false,
        "kind": "class",
        "name": "Lamb",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.9",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_1"
          },
          {
            "annotation": null,
            "default": "0.999",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_2"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "lamb",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Lion",
        "docstring": "Optimizer that implements the Lion algorithm.\n\nThe Lion optimizer is a stochastic-gradient-descent method that uses the\nsign operator to control the magnitude of the update, unlike other adaptive\noptimizers such as Adam that rely on second-order moments. This makes\nLion more memory-efficient as it only keeps track of the momentum. According\nto the authors (see reference), its performance gain over Adam grows with\nthe batch size. Because the update of Lion is produced through the sign\noperation, resulting in a larger norm, a suitable learning rate for Lion is\ntypically 3-10x smaller than that for AdamW. The weight decay for Lion\nshould in turn be 3-10x larger than that for AdamW to maintain a\nsimilar strength (lr * wd).\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    beta_1: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        rate to combine the current gradient and the 1st moment estimate.\n        Defaults to `0.9`.\n    beta_2: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 1st moment estimate. Defaults to\n        `0.99`.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nReferences:\n\n- [Chen et al., 2023](http://arxiv.org/abs/2302.06675)\n- [Authors' implementation](\n    http://github.com/google/automl/tree/master/lion)",
        "has_varargs": false,
        "kind": "class",
        "name": "Lion",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.9",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_1"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_2"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "lion",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.LossScaleOptimizer",
        "docstring": "An optimizer that dynamically scales the loss to prevent underflow.\n\nLoss scaling is a technique to prevent numeric underflow in intermediate\ngradients when float16 is used. To prevent underflow, the loss is multiplied\n(or \"scaled\") by a certain factor called the \"loss scale\", which causes\nintermediate gradients to be scaled by the loss scale as well. The final\ngradients are divided (or \"unscaled\") by the loss scale to bring them back\nto their original value.\n\n`LossScaleOptimizer` wraps another optimizer and applies dynamic loss\nscaling to it. This loss scale is dynamically updated over time as follows:\n- On any train step, if a nonfinite gradient is encountered, the loss scale\n  is halved, and the train step is skipped.\n- If `dynamic_growth_steps` have occurred since the last time the loss scale\n  was updated, and no nonfinite gradients have occurred, the loss scale\n  is doubled.\n\nArgs:\n    inner_optimizer: The `keras.optimizers.Optimizer` instance to wrap.\n    initial_scale: Float. The initial loss scale. This scale will be updated\n        during training. It is recommended for this to be a very high\n        number, because a loss scale that is too high gets lowered far more\n        quickly than a loss scale that is too low gets raised.\n    dynamic_growth_steps: Int. How often to update the scale upwards. After\n        every `dynamic_growth_steps` steps with finite gradients, the\n        loss scale is doubled.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).",
        "has_varargs": false,
        "kind": "class",
        "name": "LossScaleOptimizer",
        "params": [
          {
            "annotation": null,
            "default": null,
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "inner_optimizer"
          },
          {
            "annotation": null,
            "default": "32768.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "initial_scale"
          },
          {
            "annotation": null,
            "default": "2000",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "dynamic_growth_steps"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Muon",
        "docstring": "Optimizer that implements the Muon algorithm.\n\nNote that this optimizer should not be used in the following layers:\n\n1. Embedding layer\n2. Final output fully connected layer\n3. Any {0,1}-D variables\n\nThese should all be optimized using AdamW.\n\nThe Muon optimizer can use both the Muon update step or the\nAdamW update step based on the following:\n\n- For any variable that isn't 2D, the AdamW step\n    will be used. This is not configurable.\n- If the argument `exclude_embeddings` (defaults to `True`) is set\nto `True`, the AdamW step will be used.\n- For any variablewith a name that matches an expression\n    listed in the argument `exclude_layers` (a list), the\n    AdamW step will be used.\n- Any other variable uses the Muon step.\n\nTypically, you only need to pass the name of your densely-connected\noutput layer to `exclude_layers`, e.g.\n`exclude_layers=[\"output_dense\"]`.\n\nReferences:\n    - [Original implementation](https://github.com/KellerJordan/Muon)\n    - [Liu et al, 2025](https://arxiv.org/abs/2502.16982)\n\nArgs:\n    learning_rate: A float,\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    adam_beta_1: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use.\n        The exponential decay rate for the 1st moment estimates. Defaults to\n        `0.9`.\n    adam_beta_2: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use.\n        The exponential decay rate for the 2nd moment estimates. Defaults to\n        `0.999`.\n    adam_weight_decay: Float. If set, weight decay is applied when using\n        the Adam optimizer.\n    epsilon: A small constant for numerical stability. This is\n        \"epsilon hat\" in the Kingma and Ba paper\n        (in the formula just before Section 2.1),\n        not the epsilon in Algorithm 1 of the paper.\n        It be used at Adamw.Defaults to `1e-7`.\n    exclude_layers: List of strings, keywords of layer names to exclude.\n        All layers with keywords in their path will use adamw.\n    exclude_embeddings: Boolean value\n        If True, embedding layers will use adamw.\n    muon_a: Float, parameter a of the muon algorithm.\n        It is recommended to use the default value\n    muon_b: Float, parameter b of the muon algorithm.\n        It is recommended to use the default value\n    muon_c: Float, parameter c of the muon algorithm.\n        It is recommended to use the default value\n    adam_lr_ratio: Float, the ratio of the learning rate when\n            using Adam to the main learning rate.\n            It is recommended to set it to 1\n    momentum: Float, momentum used by internal SGD.\n    ns_steps: Integer, number of Newton-Schulz iterations to run.\n    nesterov: Boolean, whether to use Nesterov-style momentum\n    {{base_optimizer_keyword_args}}\n    rms_rate: Float. A parameter from https://arxiv.org/abs/2502.16982\n        that can enhance the stability of Muon, allowing it to use the\n        same learning rate and weight decay as Adam. Defaults to `0.2`.\n        Set to `None` to disable this feature.",
        "has_varargs": false,
        "kind": "class",
        "name": "Muon",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.9",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "adam_beta_1"
          },
          {
            "annotation": null,
            "default": "0.999",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "adam_beta_2"
          },
          {
            "annotation": null,
            "default": "0.004",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "adam_weight_decay"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "0.004",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "muon",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "exclude_layers"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "exclude_embeddings"
          },
          {
            "annotation": null,
            "default": "3.4445",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "muon_a"
          },
          {
            "annotation": null,
            "default": "-4.775",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "muon_b"
          },
          {
            "annotation": null,
            "default": "2.0315",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "muon_c"
          },
          {
            "annotation": null,
            "default": "1",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "adam_lr_ratio"
          },
          {
            "annotation": null,
            "default": "0.95",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "momentum"
          },
          {
            "annotation": null,
            "default": "5",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ns_steps"
          },
          {
            "annotation": null,
            "default": "True",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "nesterov"
          },
          {
            "annotation": null,
            "default": "0.2",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rms_rate"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.Nadam",
        "docstring": "Optimizer that implements the Nadam algorithm.\n\nMuch like Adam is essentially RMSprop with momentum, Nadam is Adam with\nNesterov momentum.\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    beta_1: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 1st moment estimates.\n        Defaults to `0.9`.\n    beta_2: A float value or a constant float tensor, or a callable\n        that takes no arguments and returns the actual value to use. The\n        exponential decay rate for the 2nd moment estimates. Defaults to\n        `0.999`.\n    epsilon: A small constant for numerical stability. This epsilon is\n        \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n        Section 2.1), not the epsilon in Algorithm 1 of the paper.\n        Defaults to `1e-7`.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nReference:\n\n- [Dozat, 2015](http://cs229.stanford.edu/proj2015/054_report.pdf).",
        "has_varargs": false,
        "kind": "class",
        "name": "Nadam",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.9",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_1"
          },
          {
            "annotation": null,
            "default": "0.999",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "beta_2"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "nadam",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.RMSprop",
        "docstring": "Optimizer that implements the RMSprop algorithm.\n\nThe gist of RMSprop is to:\n\n- Maintain a moving (discounted) average of the square of gradients\n- Divide the gradient by the root of this average\n\nThis implementation of RMSprop uses plain momentum, not Nesterov momentum.\n\nThe centered version additionally maintains a moving average of the\ngradients, and uses that average to estimate the variance.\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.001`.\n    rho: float, defaults to 0.9. Discounting factor for the old gradients.\n    momentum: float, defaults to 0.0. If not 0.0., the optimizer tracks the\n        momentum value, with a decay rate equals to `1 - momentum`.\n    epsilon: A small constant for numerical stability. This epsilon is\n        \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n        Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults\n        to 1e-7.\n    centered: Boolean. If `True`, gradients are normalized by the estimated\n        variance of the gradient; if False, by the uncentered second moment.\n        Setting this to `True` may help with training, but is slightly more\n        expensive in terms of computation and memory. Defaults to `False`.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).\n\n\nExample:\n\n>>> opt = keras.optimizers.RMSprop(learning_rate=0.1)\n>>> var1 = keras.backend.Variable(10.0)\n>>> loss = lambda: (var1 ** 2) / 2.0  # d(loss) / d(var1) = var1\n>>> opt.minimize(loss, [var1])\n>>> var1\n9.683772\n\nReference:\n\n- [Hinton, 2012](\n    http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)",
        "has_varargs": false,
        "kind": "class",
        "name": "RMSprop",
        "params": [
          {
            "annotation": null,
            "default": "0.001",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.9",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "rho"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "momentum"
          },
          {
            "annotation": null,
            "default": "1e-07",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "epsilon"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "centered"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "rmsprop",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      },
      {
        "api_path": "keras.optimizers.SGD",
        "docstring": "Gradient descent (with momentum) optimizer.\n\nUpdate rule for parameter `w` with gradient `g` when `momentum` is 0:\n\n```python\nw = w - learning_rate * g\n```\n\nUpdate rule when `momentum` is larger than 0:\n\n```python\nvelocity = momentum * velocity - learning_rate * g\nw = w + velocity\n```\n\nWhen `nesterov=True`, this rule becomes:\n\n```python\nvelocity = momentum * velocity - learning_rate * g\nw = w + momentum * velocity - learning_rate * g\n```\n\nArgs:\n    learning_rate: A float, a\n        `keras.optimizers.schedules.LearningRateSchedule` instance, or\n        a callable that takes no arguments and returns the actual value to\n        use. The learning rate. Defaults to `0.01`.\n    momentum: float hyperparameter >= 0 that accelerates gradient descent in\n        the relevant direction and dampens oscillations. 0 is vanilla\n        gradient descent. Defaults to `0.0`.\n    nesterov: boolean. Whether to apply Nesterov momentum.\n        Defaults to `False`.\n    name: String. The name to use\n        for momentum accumulator weights created by\n        the optimizer.\n    weight_decay: Float. If set, weight decay is applied.\n    clipnorm: Float. If set, the gradient of each weight is individually\n        clipped so that its norm is no higher than this value.\n    clipvalue: Float. If set, the gradient of each weight is clipped to be\n        no higher than this value.\n    global_clipnorm: Float. If set, the gradient of all weights is clipped\n        so that their global norm is no higher than this value.\n    use_ema: Boolean, defaults to `False`.\n        If `True`, exponential moving average\n        (EMA) is applied. EMA consists of computing an exponential moving\n        average of the weights of the model (as the weight values change\n        after each training batch), and periodically overwriting the\n        weights with their moving average.\n    ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n        This is the momentum to use when computing\n        the EMA of the model's weights:\n        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n        current_variable_value`.\n    ema_overwrite_frequency: Int or None, defaults to None. Only used if\n        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n        we overwrite the model variable by its moving average.\n        If None, the optimizer\n        does not overwrite model variables in the middle of training,\n        and you need to explicitly overwrite the variables\n        at the end of training by calling\n        `optimizer.finalize_variable_values()` (which updates the model\n        variables in-place). When using the built-in `fit()` training loop,\n        this happens automatically after the last epoch,\n        and you don't need to do anything.\n    loss_scale_factor: Float or `None`. If a float, the scale factor will\n        be multiplied the loss before computing gradients, and the inverse\n        of the scale factor will be multiplied by the gradients before\n        updating variables. Useful for preventing underflow during\n        mixed precision training. Alternately,\n        `keras.optimizers.LossScaleOptimizer` will\n        automatically set a loss scale factor.\n    gradient_accumulation_steps: Int or `None`. If an int, model & optimizer\n        variables will not be updated at every step; instead they will be\n        updated every `gradient_accumulation_steps` steps, using the average\n        value of the gradients since the last update. This is known as\n        \"gradient accumulation\". This can be useful\n        when your batch size is very small, in order to reduce gradient\n        noise at each update step. EMA frequency will look at \"accumulated\"\n        iterations value (optimizer steps // gradient_accumulation_steps).\n        Learning rate schedules will look at \"real\" iterations value\n        (optimizer steps).",
        "has_varargs": false,
        "kind": "class",
        "name": "SGD",
        "params": [
          {
            "annotation": null,
            "default": "0.01",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "learning_rate"
          },
          {
            "annotation": null,
            "default": "0.0",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "momentum"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "nesterov"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "weight_decay"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipnorm"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "clipvalue"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "global_clipnorm"
          },
          {
            "annotation": null,
            "default": "False",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "use_ema"
          },
          {
            "annotation": null,
            "default": "0.99",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_momentum"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "ema_overwrite_frequency"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "loss_scale_factor"
          },
          {
            "annotation": null,
            "default": "None",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "gradient_accumulation_steps"
          },
          {
            "annotation": null,
            "default": "SGD",
            "kind": "POSITIONAL_OR_KEYWORD",
            "name": "name"
          },
          {
            "annotation": null,
            "default": null,
            "kind": "VAR_KEYWORD",
            "name": "kwargs"
          }
        ]
      }
    ]
  },
  "version": "3.13.1"
}